{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AwRHw5SJtsWa",
    "outputId": "80853dec-8486-4061-828c-74d77bd5607f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "import os\n",
    "\n",
    "BASE_PATH = \"/content/gdrive/MyDrive/CLAUSEAI\"\n",
    "RAW_TXT_FOLDER = f\"{BASE_PATH}/Data/Raw/full_contract_txt\"\n",
    "OUTPUT_CLEAN_FOLDER = f\"{BASE_PATH}/Data/Transformed\"\n",
    "\n",
    "os.makedirs(OUTPUT_CLEAN_FOLDER, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4fK0kt_unqA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2KwOEcHupVH",
    "outputId": "04d0db9c-2db1-498d-e78f-21cbb221ca10"
   },
   "outputs": [],
   "source": [
    "all_texts = []\n",
    "\n",
    "for file in os.listdir(RAW_TXT_FOLDER):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(os.path.join(RAW_TXT_FOLDER, file), \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            text = f.read()\n",
    "        all_texts.append({\"filename\": file, \"text\": text})\n",
    "\n",
    "df = pd.DataFrame(all_texts)\n",
    "print(\"Loaded TXT Files:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3TGuIuIJVS1i",
    "outputId": "d9542e18-f754-4931-895e-14016a2060c4"
   },
   "outputs": [],
   "source": [
    "with open(f\"{BASE_PATH}/Data/Raw/CUAD_v1.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "master_clauses_df = pd.read_csv(f\"{BASE_PATH}/Data/Raw/master_clauses.csv\")\n",
    "\n",
    "print(\"CUAD Loaded:\", len(labels))\n",
    "print(\"Master Clauses:\", master_clauses_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7gkWZtAjVUz2"
   },
   "outputs": [],
   "source": [
    "df[\"char_count\"] = df[\"text\"].apply(len)\n",
    "df[\"token_count\"] = df[\"text\"].apply(lambda x: len(re.findall(r\"\\b\\w+\\b\", x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AC8qP3RzVZdx",
    "outputId": "e9dcdc33-e99b-4f7f-95fe-e453c0e05c8c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df[\"char_count\"], bins=30)\n",
    "plt.title(\"Character Count Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(df[\"token_count\"], bins=30)\n",
    "plt.title(\"Token Count Distribution\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(df[\"char_count\"], df[\"token_count\"])\n",
    "plt.xlabel(\"Characters\")\n",
    "plt.ylabel(\"Tokens\")\n",
    "plt.title(\"Characters vs Tokens\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.boxplot(df[\"token_count\"])\n",
    "plt.ylabel(\"Tokens\")\n",
    "plt.title(\"Token Count Boxplot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ZprtUBOAVeeE",
    "outputId": "59e933cd-46ca-47dc-f4d1-245286d452ae"
   },
   "outputs": [],
   "source": [
    "all_words = \" \".join(df[\"text\"].tolist())\n",
    "tokens = re.findall(r\"\\b[a-zA-Z]{4,}\\b\", all_words.lower())\n",
    "common_terms = Counter(tokens).most_common(20)\n",
    "\n",
    "for word, freq in common_terms:\n",
    "    print(word, \":\", freq)\n",
    "\n",
    "words = [w for w, _ in common_terms]\n",
    "freqs = [f for _, f in common_terms]\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(words, freqs)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Top 20 Frequent Words\")\n",
    "plt.show()\n",
    "\n",
    "wc = WordCloud(width=1200, height=800).generate(\" \".join(tokens))\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "de8VZnHuVmBR"
   },
   "outputs": [],
   "source": [
    "def clean_contract(text):\n",
    "\n",
    "    text = re.sub(r\"Page\\s*\\d+\", \"\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\"\\b\\d+\\s*/\\s*\\d+\\b\", \"\", text)\n",
    "    text = re.sub(r\"(\\w+)-\\s*\\n\\s*(\\w+)\", r\"\\1\\2\", text)\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
    "    text = re.sub(r\"[•●▪►■□\\t]\", \" \", text)\n",
    "    text = re.sub(r\"[ ]{2,}\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "\n",
    "    cleaned_lines = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        stripped = line.strip()\n",
    "        if stripped.isupper() and len(stripped.split()) <= 6:\n",
    "            cleaned_lines.append(stripped)\n",
    "        else:\n",
    "            cleaned_lines.append(stripped.lower())\n",
    "\n",
    "    return \"\\n\".join(cleaned_lines).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BVuyaaCdVpnN",
    "outputId": "303b5f10-efbf-4264-bd97-897c601aeabf"
   },
   "outputs": [],
   "source": [
    "cleaned_files = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    cleaned_text = clean_contract(row[\"text\"])\n",
    "    filename = f\"contract_{idx+1}_cleaned.txt\"\n",
    "\n",
    "    with open(os.path.join(OUTPUT_CLEAN_FOLDER, filename), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned_text)\n",
    "\n",
    "    cleaned_files.append({\"contract_id\": idx+1, \"filename\": filename})\n",
    "\n",
    "print(\"Cleaning completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "x_xOoq2jVtx8",
    "outputId": "f84f5270-154f-414b-b6d0-1cd8ddb84101"
   },
   "outputs": [],
   "source": [
    "clean_df = pd.DataFrame(cleaned_files)\n",
    "print(\"Final Cleaned DF:\", clean_df.shape)\n",
    "clean_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4eiLyxvhVxV8",
    "outputId": "84821332-ee5d-4c7b-dc1b-27f1185e3d5e"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain langchain-community langchain-core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DB9WmXHhW-ap"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "CHUNKS_FOLDER = f\"{BASE_PATH}/Data/chunks\"\n",
    "os.makedirs(CHUNKS_FOLDER, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mj8dlDaXXh8O"
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
    "    )\n",
    "    return splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bgoHYKgdXkNB",
    "outputId": "9e9aa0e6-82ec-4d53-a47c-60cb82f86e7b"
   },
   "outputs": [],
   "source": [
    "chunk_stats = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    cleaned_file = f\"{OUTPUT_CLEAN_FOLDER}/contract_{idx+1}_cleaned.txt\"\n",
    "\n",
    "    with open(cleaned_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    chunks = chunk_text(text)\n",
    "\n",
    "    chunk_data = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_data.append({\n",
    "            \"contract_id\": idx + 1,\n",
    "            \"chunk_id\": i + 1,\n",
    "            \"text\": chunk,\n",
    "            \"char_length\": len(chunk)\n",
    "        })\n",
    "        chunk_stats.append(len(chunk))\n",
    "\n",
    "    out_file = f\"{CHUNKS_FOLDER}/contract_{str(idx+1).zfill(3)}_chunks.json\"\n",
    "    with open(out_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(chunk_data, f, indent=2)\n",
    "\n",
    "print(\"Chunking completed for all contracts.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYCGf2qjXpAB",
    "outputId": "987a3b4c-78cb-47bd-9ba9-5a0ebc26461f"
   },
   "outputs": [],
   "source": [
    "sample_chunk_file = f\"{CHUNKS_FOLDER}/contract_001_chunks.json\"\n",
    "\n",
    "with open(sample_chunk_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    sample_chunks = json.load(f)\n",
    "\n",
    "print(\"Total Chunks:\", len(sample_chunks))\n",
    "sample_chunks[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "7WDDBM3UXq2t",
    "outputId": "a8ed103a-2f8d-4e81-9367-660f4aa1d34b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(chunk_stats, bins=30)\n",
    "plt.title(\"Chunk Length Distribution (Characters)\")\n",
    "plt.xlabel(\"Characters\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "-h4SriRpXtFk",
    "outputId": "8e760c62-335e-454d-9ef6-c3fc8cce98b0"
   },
   "outputs": [],
   "source": [
    "overlap_sizes = []\n",
    "\n",
    "for i in range(1, len(sample_chunks)):\n",
    "    prev_chunk = sample_chunks[i-1][\"text\"][-200:]\n",
    "    curr_chunk = sample_chunks[i][\"text\"][:200]\n",
    "    overlap_sizes.append(len(set(prev_chunk.split()) & set(curr_chunk.split())))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(overlap_sizes)\n",
    "plt.title(\"Chunk Overlap Consistency Check\")\n",
    "plt.xlabel(\"Chunk Index\")\n",
    "plt.ylabel(\"Shared Words\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDziKlNbYB9P"
   },
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efK7c_YVYEsX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model once\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # fast and good quality\n",
    "\n",
    "# Example: function to embed list of texts (chunks)\n",
    "def embed_texts(texts):\n",
    "    embeddings = model.encode(texts, show_progress_bar=True)\n",
    "    return embeddings\n",
    "\n",
    "# Example usage:\n",
    "# Suppose you have your chunks loaded as a list of dicts like [{'text': '...'}, ...]\n",
    "# texts = [chunk['text'] for chunk in chunks]\n",
    "\n",
    "# embeddings = embed_texts(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9vu1TupYIb8"
   },
   "outputs": [],
   "source": [
    "# Set paths - adjust BASE_PATH if needed\n",
    "BASE_PATH = \"/content/gdrive/MyDrive/CLAUSEAI\"\n",
    "CHUNKS_FOLDER = os.path.join(BASE_PATH, \"Data/chunks\")\n",
    "EMBEDDINGS_FOLDER = os.path.join(BASE_PATH, \"Data/embeddings\")\n",
    "os.makedirs(EMBEDDINGS_FOLDER, exist_ok=True)\n",
    "\n",
    "# List chunk files\n",
    "chunk_files = sorted([f for f in os.listdir(CHUNKS_FOLDER) if f.endswith('.json')])\n",
    "print(f\"Found {len(chunk_files)} chunk files.\")\n",
    "\n",
    "# Process ALL files\n",
    "for file in chunk_files:\n",
    "    print(f\"Processing {file}...\")\n",
    "    with open(os.path.join(CHUNKS_FOLDER, file), 'r') as f:\n",
    "        chunks = json.load(f)\n",
    "\n",
    "    texts = [c[\"text\"] for c in chunks]\n",
    "\n",
    "    # Get embeddings\n",
    "    embeddings = embed_texts(texts)\n",
    "\n",
    "    # Prepare data to save\n",
    "    embedding_data = []\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        embedding_data.append({\n",
    "            \"chunk_id\": i,\n",
    "            \"embedding\": emb.tolist(),\n",
    "            \"vector_norm\": float(np.linalg.norm(emb))\n",
    "        })\n",
    "\n",
    "    # Save embeddings JSON\n",
    "    save_path = os.path.join(EMBEDDINGS_FOLDER, file.replace(\"_chunks.json\", \"_embeddings.json\"))\n",
    "    with open(save_path, \"w\") as f:\n",
    "        json.dump(embedding_data, f)\n",
    "\n",
    "    print(f\"Saved embeddings to {save_path}\")\n",
    "\n",
    "# Optional: visualize vector norm distribution of last processed file\n",
    "norms = [e[\"vector_norm\"] for e in embedding_data]\n",
    "plt.hist(norms, bins=30)\n",
    "plt.title(\"Embedding Vector Norm Distribution\")\n",
    "plt.xlabel(\"Vector Norm\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "6qiURWzEYlgh",
    "outputId": "2b005035-5cf1-471d-db1c-d7a0f8a2aee7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load embeddings of one contract (example: first file)\n",
    "example_file = chunk_files[0].replace(\"_chunks.json\", \"_embeddings.json\")\n",
    "with open(os.path.join(EMBEDDINGS_FOLDER, example_file), \"r\") as f:\n",
    "    embedding_data = json.load(f)\n",
    "\n",
    "# Extract vectors as numpy array\n",
    "vectors = np.array([np.array(e[\"embedding\"]) for e in embedding_data])\n",
    "\n",
    "# Compute cosine similarity matrix\n",
    "cos_sim_matrix = cosine_similarity(vectors)\n",
    "\n",
    "# Compute dot product matrix\n",
    "dot_product_matrix = np.dot(vectors, vectors.T)\n",
    "\n",
    "# Print similarity between first two chunks as example\n",
    "print(f\"Cosine similarity between chunk 0 and 1: {cos_sim_matrix[0, 1]:.4f}\")\n",
    "print(f\"Dot product between chunk 0 and 1: {dot_product_matrix[0, 1]:.4f}\")\n",
    "\n",
    "# Optional: Visualize cosine similarity matrix heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cos_sim_matrix, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.title(\"Cosine Similarity Matrix (sample contract chunks)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "UnOX6qwYYncz",
    "outputId": "6e53dae7-1840-4a59-c91a-8ec39b05fe0c"
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install -U pinecone\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LXdOcj8xKxm"
   },
   "outputs": [],
   "source": [
    "import pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ufd6OWXw10VD",
    "outputId": "212342b3-a042-4a97-cd52-add5c5348c01"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_uBxTV_Gibjn6KjaVSDyT5ipaLe7a1kstm7cgmA5SKD9nQcRBv97ws74BF92woYM7WJ8Jt\"\n",
    "\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "\n",
    "index_name = \"cuad-index\"\n",
    "\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,     # MiniLM embedding size\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",\n",
    "            region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    print(\"Index created\")\n",
    "else:\n",
    "    print(\"Index already exists\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "id": "s28WphqIFOrW",
    "outputId": "bd4e1cd5-2f0d-436b-8801-3273e1469ffc"
   },
   "outputs": [],
   "source": [
    "!pip install -U pinecone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asiZIoOLFUUB"
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "import os, json, numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPy4U8joNiP7"
   },
   "outputs": [],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_uBxTV_Gibjn6KjaVSDyT5ipaLe7a1kstm7cgmA5SKD9nQcRBv97ws74BF92woYM7WJ8Jt\"\n",
    "\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "index = pc.Index(\"cuad-index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7jBxAnQWORhV",
    "outputId": "79cc67f6-608c-48ed-993a-68b62d221545"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jNx0IbYgPLQg",
    "outputId": "43e76d21-3392-4d57-df14-0564dfeb520d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"/content/gdrive/MyDrive\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OHGPdOLmPSmT",
    "outputId": "17b0929f-e80c-4e6f-94d8-1649e04fa4a6"
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "\n",
    "BASE_PATH = \"/content/gdrive/MyDrive/CLAUSEAI\"\n",
    "EMBEDDINGS_FOLDER = f\"{BASE_PATH}/Data/embeddings\"\n",
    "\n",
    "embedding_files = sorted(os.listdir(EMBEDDINGS_FOLDER))[:20]  # demo\n",
    "\n",
    "vectors = []\n",
    "\n",
    "for file in embedding_files:\n",
    "    contract_id = file.replace(\"_embeddings.json\", \"\")\n",
    "    with open(os.path.join(EMBEDDINGS_FOLDER, file), \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for item in data:\n",
    "        vectors.append((\n",
    "            f\"{contract_id}_chunk_{item['chunk_id']}\",   # vector id\n",
    "            item[\"embedding\"],                            # vector\n",
    "            {\n",
    "                \"contract_id\": contract_id,\n",
    "                \"chunk_id\": item[\"chunk_id\"]\n",
    "            }\n",
    "        ))\n",
    "\n",
    "print(\"Total vectors prepared:\", len(vectors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46T6lRd7Qmlt",
    "outputId": "1ac82f6a-2e49-4268-96c7-6afce821e0a5"
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "index = pc.Index(\"cuad-index\")\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "for i in range(0, len(vectors), BATCH_SIZE):\n",
    "    batch = vectors[i:i + BATCH_SIZE]\n",
    "    index.upsert(vectors=batch)\n",
    "\n",
    "print(f\"✅ Upsert completed for {len(vectors)} vectors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_0cCXEQQsFs",
    "outputId": "38aed614-6664-4e23-ebb9-14b2fac7bbad"
   },
   "outputs": [],
   "source": [
    "query_vector = vectors[0][1]   # any existing vector for sanity check\n",
    "\n",
    "results = index.query(\n",
    "    vector=query_vector,\n",
    "    top_k=5,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rHIXLtx-Qwdi",
    "outputId": "972b40bc-4904-4ac0-cc28-b3f46c41147b"
   },
   "outputs": [],
   "source": [
    "for i, m in enumerate(results[\"matches\"], start=1):\n",
    "    print(f\"\\nRank {i}\")\n",
    "    print(\"Score:\", round(m[\"score\"], 4))\n",
    "    print(\"Contract:\", m[\"metadata\"][\"contract_id\"])\n",
    "    print(\"Chunk ID:\", m[\"metadata\"][\"chunk_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "YPyPsIx3QzHV",
    "outputId": "b02f152b-da78-4794-d693-45ec7d1d265b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scores = [m[\"score\"] for m in results[\"matches\"]]\n",
    "\n",
    "plt.hist(scores, bins=5)\n",
    "plt.title(\"Top-K Similarity Score Distribution\")\n",
    "plt.xlabel(\"Similarity Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387,
     "referenced_widgets": [
      "caf277d1e03d42f2884e38a2d8862fd7",
      "477b7b9864c3422a8f1ca77795ec5fed",
      "edeba5fbe38442b8a5ecb8bef1b7b025",
      "628eab2e19744cb2a189e3b047f06b68",
      "09f080b935e245d3aef5eec74ee6bee6",
      "856b5b6d6cc34b8b917fda79e364fa80",
      "c3afd19f823d4903927e65fda96059aa",
      "99c8c7eb3a3d4b1b97355881bb24abda",
      "f8c796ea8d754e63859d2e5b93fb4f9e",
      "898925782fd94a9c8420335f97a0e031",
      "4606883c82764dd2a9c22b67ea0e010f",
      "acc0163c54b84532b0c67fb422706db8",
      "429601afc5f9438e9a3f0bec0414b1e4",
      "b4ad6e1ccd824dbea19cf9a00b863e6c",
      "37b0f60db133470ebc858a60712578b8",
      "6fc89ec93a014c2f8eef434c13323f72",
      "bfe6b89d29dd487ba5cacdfb627822ab",
      "889c0bcbfc254e338c1beec568bce8a5",
      "82d4af75694749a48ccdb5d235d22b67",
      "0ad5084f00d147cc82381e6bf2358bd6",
      "9df3572190db4c68977ead050d996a2b",
      "451aa018304c44edb0cff99b2090ec71",
      "5b317ef4b4004bf3af73f45446cc700a",
      "95c2d50f75e34f91b4945011c0f1937c",
      "2dbdea3c959640f0a611100b9dfeb5d0",
      "364f908f48a4481992358aed3940d034",
      "b5d845ceb36246828739a5b32b2063e8",
      "325586fa6fa24fb3b27e544e11086545",
      "37b0f6c5625147c3a4ccccac830488de",
      "a443fe2eaca64582be243835daeb6c9b",
      "0ff32964aeae4d218d55f8ceadf32450",
      "35f62f1435cd4c86b5153d22d22672f3",
      "c2217a0ca965493d8667e99cc3a70e7e",
      "12b24ed39332417c973be0a7a1dcbd8a",
      "a6ca3e89442447a1a818d851988e26ce",
      "f2fb8ecfdbd74ad1a499f4fead3d153f",
      "b1dbb12774d64f0d95cdd7019270ed08",
      "ca9ddd823e4d4e35963f828ba66b90c3",
      "e7470d98d2ee4e33b94f5c64e68d99db",
      "3b23d1e7ed5c4fc3b2b03ab72c263a8d",
      "3946b7342e8148d084d04d3829047f96",
      "78516657104042679a2b56789db77360",
      "93071eb379eb46bba58c37a9c78f98ee",
      "93751ecacba04231b0d349e22fc9aedb",
      "5e2dbb09dc614a38ae2bfc94e31bcfa1",
      "3d26a765cc064ed9bba8a53375ee0202",
      "86b4ebbf06e24be7bcfd267d729ae910",
      "729d702b586348ca81a3cb99cf2ebaaa",
      "bd15536af59a4b87b63e00c230ddbef5",
      "c59464eb897b49c69d5758a72db67d71",
      "d07949ed18e046cd871c0cc8286f02d9",
      "1522635cf352467581d1b214a621512f",
      "5ed77b5fffee4225aa3723b22504e456",
      "22ee9432edc147a9bf6904c87845ad2a",
      "156e67e419a5497bbf81c3bc56b3b49c",
      "71aa140d646044dba05acb197a00167e",
      "79d0ec0cad664c6a97596e00e4fa6fb2",
      "ca292891e27a4e9e9aefacca84c032ee",
      "ce266919bb364cc8b6f8244603370f9d",
      "6861ee5c7ab94d97b3d5233c7a4c4380",
      "5045aea4030c428db3fdf70be3fc7d50",
      "9cb4f28746194fcab65a26b01d892820",
      "528090d23a624a9d96b3880ce3a03ebf",
      "42f0e8f0f4084236a7467b0c7c8084e2",
      "1834c5d51c7441bf8643146adceffb53",
      "d6f5a1620cdf4fd7aa933a3264863de7",
      "3921fcc7cc47459695e6a0d67e8958a6",
      "39b8f431b8964c01a7739f5af6c808da",
      "5397b00fb8424c3daf66c3ceb5f8f5d5",
      "63b16356f90e4967885fe84aff158adb",
      "5006b9481c3540c5bd5e3781e9bc640b",
      "6e3d0982270b4b81b95deffc7394552a",
      "1fbf47256e15494482c7560772cea22e",
      "b6e70c2120ee4b19b7b85b2ab842294b",
      "69c402e08b18468bacf6e5bc4b2ff029",
      "8ad0c9034d5c49bb9ddde0741e5568cd",
      "09532079c72244e494d3e8b8598e0fbc",
      "20fd6fbf4d6a4aedbc9818f45364897d",
      "d2362e6231f3482c821b94287fd52a60",
      "bcff9a887abd4cd4a24052afb4d9f004",
      "1474a4c3f58245ff950482fddfb910db",
      "7ac44032c8b44c3e8ebd9423f28c6d3c",
      "2502361670434851a3ca68a5f11b6221",
      "80802a79f6b94a94816e847ab8301f08",
      "b37e142f5f4a4dd09440655ae3086d72",
      "3b48eabc27a34799b0b9fe8a54a740d7",
      "42b91226fe174daabc06d2bf9bc285be",
      "004da0cd51b2415382359d7774f7fdf3",
      "6a81e21149034392b744fa0b2f5d9dac",
      "08d6eb42652b4337a90b7248f7d8618a",
      "ee7d4a40aee84571be1c8bc6fc85c705",
      "fbf54fefc1b34c0dbe18c7780495d8d2",
      "5699b2025146457a9f3c3e1347586bdc",
      "93556cc71b07423895b4a7acbfe7fde2",
      "07f922f901864ede819352ddf7dbbdc6",
      "5d2e09f068ae4c2db1c5644d755adb9c",
      "a27c60bb1db54448acaff8cd39991f33",
      "eb73e56ac48b49ba9fb7072c29fdcd79",
      "cafaafc1e14b4c24853d642b9f1931eb",
      "e4738827bc4e434599d95d179712abf8",
      "4a20d43be0ba40f592961441c8143573",
      "b9618ceb7451429aa8c494cc85be0f4d",
      "b5dfd096b45b4d5ea68a8091f8e35040",
      "ad5600ce9add4d7da2827c4794959236",
      "feb9e7df91284df4ad3535a4a906cc99",
      "42ee05d32fc347f6bc25e7bd6bf05eb1",
      "26a5b6ca7f36488b8e625eef90bd78fa",
      "9fdc4a1c2b7045dda7134259bc9c2a88",
      "0bff4b8708974d5780770c1cf983b6a6",
      "f0a567187f124bf8a570c6e951c13fcb",
      "6b29762146f643c1a4d8578f4d25d368",
      "c2b04055a50a4806bbd8d223c5f8d582",
      "a760a9812f774c7cb425ef7ea8d0851d",
      "14594f66be2549a791b71c3b5946fcea",
      "5f20e272baeb4f7ab1884f471d2906ad",
      "407dc15f04a149bf94dc45d574a0fa5b",
      "56f1c276d29443a380bd275d9643bc8d",
      "1ef234b313db4248b9dd9562f0ebdc6c",
      "f8c739c85a624be29947178a27213a4f",
      "153319939e9d4b518bd87c9e0c83ce52",
      "8e5797fdcbd1422d888c04f553ed7682"
     ]
    },
    "id": "doD-kC-uTT1s",
    "outputId": "1fe2900c-a866-4ee7-a4c5-d66c89464e69"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PJLFi1H4TenL",
    "outputId": "2704eacf-1d21-46e7-c6b1-0f5ca97e950b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone  # new client\n",
    "\n",
    "# Setup Pinecone API key\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_uBxTV_Gibjn6KjaVSDyT5ipaLe7a1kstm7cgmA5SKD9nQcRBv97ws74BF92woYM7WJ8Jt\"\n",
    "\n",
    "# Initialize Pinecone client instance\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "\n",
    "# Get index instance\n",
    "index_name = \"cuad-index\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Load Sentence Transformer model once\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define embedding function with fix (convert to list)\n",
    "def embed_query(query):\n",
    "    embedding = model.encode([query])[0]\n",
    "    return embedding.tolist()\n",
    "\n",
    "# Function to get chunk text (adjust BASE_PATH & CHUNKS_FOLDER as per your setup)\n",
    "BASE_PATH = \"/content/gdrive/MyDrive/CLAUSEAI\"\n",
    "CHUNKS_FOLDER = os.path.join(BASE_PATH, \"Data/chunks\")\n",
    "\n",
    "def get_chunk_text(contract_id, chunk_id):\n",
    "    file_name = f\"{contract_id}_chunks.json\"\n",
    "    with open(os.path.join(CHUNKS_FOLDER, file_name), 'r', encoding='utf-8') as f:\n",
    "        chunks = json.load(f)\n",
    "    for chunk in chunks:\n",
    "        if chunk['chunk_id'] == chunk_id:\n",
    "            return chunk['text']\n",
    "    return None\n",
    "\n",
    "# Define RAG search function\n",
    "def rag_search(query, top_k=5):\n",
    "    query_vec = embed_query(query)\n",
    "    results = index.query(vector=query_vec, top_k=top_k, include_metadata=True)\n",
    "    matches = []\n",
    "    for match in results['matches']:\n",
    "        contract_id = match['metadata']['contract_id']\n",
    "        chunk_id = match['metadata']['chunk_id']\n",
    "        text = get_chunk_text(contract_id, chunk_id)\n",
    "        matches.append({\n",
    "            'id': match['id'],\n",
    "            'score': match['score'],\n",
    "            'contract_id': contract_id,\n",
    "            'chunk_id': chunk_id,\n",
    "            'text': text\n",
    "        })\n",
    "    return matches\n",
    "\n",
    "# Function to save RAG results to drive\n",
    "def save_rag_results(results, query):\n",
    "    RESULTS_FOLDER = os.path.join(BASE_PATH, \"results\")\n",
    "    os.makedirs(RESULTS_FOLDER, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    safe_query = query.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    filename = f\"rag_results_{safe_query}_{timestamp}.json\"\n",
    "    filepath = os.path.join(RESULTS_FOLDER, filename)\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"RAG search results saved to {filepath}\")\n",
    "\n",
    "# Run query and save results\n",
    "query = \"termination clause liability\"\n",
    "results = rag_search(query, top_k=5)\n",
    "save_rag_results(results, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L3gmheUoThCM",
    "outputId": "29837f88-515d-4081-904d-f5f6f295eedd"
   },
   "outputs": [],
   "source": [
    "# Run query and save results\n",
    "query = \"termination clause liability\"\n",
    "results = rag_search(query, top_k=5)\n",
    "\n",
    "# Print results\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))\n",
    "\n",
    "# Save results to file\n",
    "save_rag_results(results, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4Jl88OMTjQv"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers accelerate torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oxDFiyrlT2qd",
    "outputId": "a1837568-c97a-4593-b6ff-63721fd67d28"
   },
   "outputs": [],
   "source": [
    "!huggingface-cli login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404,
     "referenced_widgets": [
      "514bbd8fac3c442db9241810e733a1e2",
      "968d277b504b459582f91bd921631a5d",
      "4acf1d1dd4ae4c89880e144a98199af4",
      "a0297a2412c6479581a53e3b3cd549cd",
      "18591b8676a741489e523f9f88db6183",
      "f92c855208c04812a0db873cf53a7fff",
      "99a904ada18a4708b6211d27887a2e84",
      "c697e3f8f8aa4550ac0fce6bd735a752",
      "06774c478d514fd798ee4f6a761ad810",
      "963b5cf471314f7aa5434e608fbf8573",
      "ffc804673d6c49a0a16f9f9795341a28",
      "d2be8b2fb9ea4c6ca7ea15d989d23c2f",
      "2726b1002b6b43e9aa6a883593e6fc08",
      "1411242d5c4345918f5f201a0852a9e2",
      "4da3c40dfbd24bf0a974bfe7aa87433f",
      "bb3c263bfdff4ba7befc643539bbe2a8",
      "3fae7c524d74421b9c54186123b08f61",
      "b144b7b8ad9746c0a3f9809e43d977d9",
      "529b038381964edfaab4d9d2d78a9a34",
      "8b2d5b7514204278a3fc51b7415df9fb",
      "3108d47027c447bb824efe8ff9139465",
      "d7b02549e12d4c49b116418d7dae8626",
      "33c6832c9be04017ab5ca124c471e55e",
      "a08fdebd17c34908a9967b98a018f6fe",
      "ca40c8990031462fb06d2cd975475dfe",
      "e53a90d0e1c043b19d67d959fe4e75f2",
      "3e6be15d10a04a69b60e6db5bd682b30",
      "de4ca897791d4b7ebf81f00532b0e660",
      "590bb94e231e490da1ea811777c9c1fc",
      "895af1172cb048aeb9f8406819d524bc",
      "42263f31b5ff4819a7bee652522e1be9",
      "f166cdf26de94d12987fd92e48013831",
      "87969b689b224f43b8edd9e7d8c4e060",
      "67c14a26c45148eea0a4a7d570923e62",
      "f058f193f3e04b0f9f043eedb96f89ca",
      "c034cc23920c4a8b9a78e7ce1b8cd9b1",
      "e8bdf8505bea4ef7a762b4baf91dae22",
      "fcde6bc46cf0431ebbd40c5f2b879848",
      "4ac459db0c31454e961782d23584e86b",
      "d281b2a8782a498cb562ffe0ae01bea0",
      "bda9526f09f04c24a7abbf95353abbab",
      "96d3e68433294a3d97338d52de629f39",
      "f94d62e855d54126905be478087fa21d",
      "0abb2beb8a3b4cf2bd44841fc6d35271",
      "a7ed104335874789a104bef578ca044a",
      "c51dba28fa9c4e9980df27b190b769f6",
      "47c86192cf05468cab490ced2f8b705d",
      "683999dabbd249089b4aa57c260651db",
      "3e6200b039054e7b9a538003ff00fd42",
      "af0b9a08285e403e9a5dfad684a985dd",
      "0945486c11d245c89fb3ce59e4f9093b",
      "29ee5edba2e8411aa87ac096a4bca249",
      "3955eec01b0d4658bd07de36c6797c31",
      "59b398f491a34f469110d6447d2f8d05",
      "812c4d973d8d4376ab4c64dae50408c3",
      "a651dede01ee40b8a8caf610a7e65ee7",
      "1787a24aedbb4920882a0703ce447cb2",
      "d22007c14926405c9c0bfa35159808bd",
      "bd273f6cbfd041fd84cd6a29181c7cf3",
      "369b3ac7d2b44428968423ad2d046616",
      "fa2c535ba288486d928e13a1c500b91c",
      "f04e3378de1646308b9b6daa5d3d589b",
      "ea57d69e8aff4e7d980505bf20304458",
      "cd7738fc94694cccb826f7c6722d2be6",
      "6a58c5d23c044c4da9de2d05f4cc3ae2",
      "1db2518f0a944e50a6fdbfe37c51174a",
      "8089a3c263404feb82e513dc229449f5",
      "d882779f0e1645c19bcb2a0daef41d88",
      "0ff3f33c542e410a83793035ac59e883",
      "4c7dc31640b64175846f94aacccebcba",
      "84b88624f25c4444b8dee0feee4980e9",
      "291562f7fb2e4d8fbd28ae4306236d5c",
      "faba78cc18e74d2b9ef498785c9ce90d",
      "78669104b1b74597916c828ee8a8cb91",
      "d3e5c6c224eb4ae1b76ad202acf0b105",
      "e1fce322ebe247298bac3aa89e4b0997",
      "f38ff026a0c448309a2a4dd63f4c581c",
      "7f7b86e0dfb74cc6aa1ca6a507ea1622",
      "4c0bfecf374f4e28a2a4e8b1fd78ded5",
      "ccbe3dd1d516484ca8e0d561132623af",
      "f9ca9e7527ec41878b5a8420ba27b44b",
      "c2447216c8194a6abfd2adc30b4daf27",
      "2e5658320508425ab00bdcb4f8199331",
      "f62855cedb5545ebb3dfc9831f51ac12",
      "7511d9a436b447dfa3dd6387a30f166c",
      "647c8706e2a34aff8569b787b1068707",
      "bbc948d200b049e3a6658a7a1eff889f",
      "fe7e19396951409baea6a5f6838fb44c",
      "6b6e1ebe13644a11999753e38f5db9e6",
      "8d58e1b778bc4def87c6456065c3de7c",
      "c3b254bcb7cf47d3bb3fa0fe1be9174a",
      "e0b2a5c368c74e90b6b79d92a0e158a2",
      "96c98ecd20374de98496f2f95b31afb9",
      "c154e470be1e47358be743c566535319",
      "90303f24d9914ea0bd17810f710966c9",
      "e34b54c6464d43e88c72180f79a5ecb0",
      "0a429182b6bf4031b0187fff2c8f4eea",
      "d6e3e4f270f446ab938f80fbddfa52e4",
      "c8706c1ec8384912a91270972e2bbbb7",
      "f20aed47b0754ea5a8d4fea7692d34f8",
      "14452a8e9c4448598b7df84f3b354799",
      "799d31ecac7f48a989fc285a2f023a4c",
      "f93a7e76d654480d88d1e443356dd651",
      "36ed3cb484524019aca2635fce0f1259",
      "082e0ddab845485f8b482ceedde8808b",
      "759f9d73a08e427ea4d646828901547f",
      "5ed71952f001410e89c31cb942c844b0",
      "8a7939c69b174631ab352a3f567625d1",
      "ad8634a554f0491884c38eab8c65d343",
      "5560ce874d0f4f75a7442e8db5168bb4",
      "404f84a378df43f6aa7bc0587972de89",
      "f1071a561a084e0289302f17aef26370",
      "2c1e6a7cd1cf4e51a2dbe68c3f4de7b7",
      "638b6189582b4bb28ab1824c60a771ea",
      "77c9ecef3de24b5981713bd1d3621470",
      "6d18394c5a4b4325a491bc04509b5557",
      "f11d5667c1924e9aba34696653b6dc50",
      "7dd56c7d60554fcfb23f8c203f393903",
      "78baf32b0a2941108661975d3de2a97a",
      "ae5370415dc046c0a3687c2c4b7ad474",
      "5ca53a6090ab4166a641bd0ea8f864be"
     ]
    },
    "id": "itMlA_FaT41E",
    "outputId": "048dfa7a-02cd-40aa-876e-4f675a75fd43"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "MODEL_ID = \"google/gemma-2b-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "llm = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mA6finM4T6xx"
   },
   "outputs": [],
   "source": [
    "AGENT_OUTPUT_SCHEMA = {\n",
    "    \"clause_type\": \"\",\n",
    "    \"extracted_clauses\": [],\n",
    "    \"risk_level\": \"unknown\",\n",
    "    \"confidence\": 0.0,\n",
    "    \"evidence\": []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZlYWwvayUXUA"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "class BaseAgent:\n",
    "    def __init__(self, agent_name, clause_type, system_prompt):\n",
    "        self.agent_name = agent_name\n",
    "        self.clause_type = clause_type\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def run(self, context_text):\n",
    "        prompt = f\"\"\"\n",
    "{self.system_prompt}\n",
    "\n",
    "CONTRACT TEXT:\n",
    "{context_text}\n",
    "\n",
    "Return ONLY valid JSON.\n",
    "\"\"\"\n",
    "\n",
    "        response = llm(prompt)[0][\"generated_text\"]\n",
    "\n",
    "        # Extract JSON safely\n",
    "        match = re.search(r\"\\{.*\\}\", response, re.DOTALL)\n",
    "        if not match:\n",
    "            return self.empty_output()\n",
    "\n",
    "        try:\n",
    "            output = json.loads(match.group())\n",
    "            output[\"clause_type\"] = self.clause_type\n",
    "            return output\n",
    "        except json.JSONDecodeError:\n",
    "            return self.empty_output()\n",
    "\n",
    "    def empty_output(self):\n",
    "        return {\n",
    "            \"clause_type\": self.clause_type,\n",
    "            \"extracted_clauses\": [],\n",
    "            \"risk_level\": \"low\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"evidence\": []\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nz3wxmFTUs5t"
   },
   "outputs": [],
   "source": [
    "LEGAL_AGENT_PROMPT = \"\"\"\n",
    "You are a Legal Contract Analysis Agent.\n",
    "\n",
    "Tasks:\n",
    "1. Identify legal clauses such as Termination, Governing Law, Jurisdiction.\n",
    "2. Extract the exact clause text and put it in the \"extracted_clauses\" list.\n",
    "3. Provide supporting context or surrounding text (a few sentences before and after the clause) in the \"evidence\" list.\n",
    "4. Assess the legal risk level (low/medium/high).\n",
    "5. Provide a confidence score between 0.0 and 1.0.\n",
    "\n",
    "Return ONLY valid JSON in this format:\n",
    "\n",
    "{\n",
    "  \"extracted_clauses\": [\n",
    "    \"Exact clause text here.\"\n",
    "  ],\n",
    "  \"risk_level\": \"low\",\n",
    "  \"confidence\": 0.0,\n",
    "  \"evidence\": [\n",
    "    \"Supporting context or surrounding text related to the clause.\"\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "legal_agent = BaseAgent(\n",
    "    agent_name=\"LegalAgent\",\n",
    "    clause_type=\"Legal\",\n",
    "    system_prompt=LEGAL_AGENT_PROMPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZacd3xLLNPL"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "BASE_PATH = \"/content/gdrive/MyDrive/CLAUSEAI\"\n",
    "RAG_RESULTS_PATH = f\"{BASE_PATH}/results\"\n",
    "\n",
    "rag_file = sorted(os.listdir(RAG_RESULTS_PATH))[-1]\n",
    "\n",
    "with open(os.path.join(RAG_RESULTS_PATH, rag_file), \"r\", encoding=\"utf-8\") as f:\n",
    "    legal_context = json.load(f)\n",
    "\n",
    "combined_text = \"\\n\\n\".join(\n",
    "    [c[\"text\"] for c in legal_context if c.get(\"text\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehu5-VxCMt3q"
   },
   "outputs": [],
   "source": [
    "COMPLIANCE_AGENT_PROMPT = \"\"\"\n",
    "You are a Compliance Risk Analysis Agent.\n",
    "\n",
    "Identify clauses related to:\n",
    "- GDPR\n",
    "- HIPAA\n",
    "- SOC2\n",
    "- ISO standards\n",
    "- Regulatory compliance\n",
    "- Audits & reporting\n",
    "\n",
    "Return ONLY valid JSON in this format:\n",
    "{\n",
    "  \"extracted_clauses\": [],\n",
    "  \"risk_level\": \"\",\n",
    "  \"confidence\": 0.0,\n",
    "  \"evidence\": []\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "compliance_agent = BaseAgent(\n",
    "    agent_name=\"ComplianceAgent\",\n",
    "    clause_type=\"Compliance\",\n",
    "    system_prompt=COMPLIANCE_AGENT_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1EGG5-7NugD"
   },
   "outputs": [],
   "source": [
    "def validate_agent_output(output):\n",
    "    required_keys = {\"clause_type\", \"extracted_clauses\", \"risk_level\", \"confidence\", \"evidence\"}\n",
    "    if not isinstance(output, dict):\n",
    "        return False\n",
    "    return all(k in output for k in required_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnZggXZaZfpi"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os, json\n",
    "\n",
    "def save_agent_result(output, contract_id, agent_type):\n",
    "    path = f\"{BASE_PATH}/results/agents/{agent_type.lower()}\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_path = f\"{path}/contract_{contract_id}_{agent_type.lower()}_{ts}.json\"\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"✅ Saved → {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8EsGio0ZiBs"
   },
   "outputs": [],
   "source": [
    "FINANCE_AGENT_PROMPT = \"\"\"\n",
    "You are a Finance Risk Analysis Agent.\n",
    "\n",
    "Your task:\n",
    "1. Identify finance-related clauses:\n",
    "- Payment terms\n",
    "- Fees and invoices\n",
    "- Penalties or late fees\n",
    "- Financial liability\n",
    "2. Extract exact financial obligations\n",
    "3. Assess financial risk (low/medium/high)\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{\n",
    "  \"extracted_clauses\": [],\n",
    "  \"risk_level\": \"\",\n",
    "  \"confidence\": 0.0,\n",
    "  \"evidence\": []\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4q8Vws2ZkxX"
   },
   "outputs": [],
   "source": [
    "#Initialize Finance Agent\n",
    "finance_agent = BaseAgent(\n",
    "    agent_name=\"FinanceAgent\",\n",
    "    clause_type=\"Finance\",\n",
    "    system_prompt=FINANCE_AGENT_PROMPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTnSnGlNZnG-"
   },
   "outputs": [],
   "source": [
    "#Validate Finance Output\n",
    "def validate_agent_output(output):\n",
    "    keys = {\"clause_type\", \"extracted_clauses\", \"risk_level\", \"confidence\", \"evidence\"}\n",
    "    return all(k in output for k in keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2g1gRyFZqWZ"
   },
   "outputs": [],
   "source": [
    "OPERATIONS_AGENT_PROMPT = \"\"\"\n",
    "You are an Operations Risk Analysis Agent.\n",
    "\n",
    "Your task:\n",
    "1. Identify operational clauses:\n",
    "- Deliverables\n",
    "- Timelines and milestones\n",
    "- Service obligations\n",
    "- Performance standards / SLAs\n",
    "2. Extract exact obligation text\n",
    "3. Assess execution risk (low/medium/high)\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{\n",
    "  \"extracted_clauses\": [],\n",
    "  \"risk_level\": \"\",\n",
    "  \"confidence\": 0.0,\n",
    "  \"evidence\": []\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "25kqes5BZsZN"
   },
   "outputs": [],
   "source": [
    "operations_agent = BaseAgent(\n",
    "    agent_name=\"OperationsAgent\",\n",
    "    clause_type=\"Operations\",\n",
    "    system_prompt=OPERATIONS_AGENT_PROMPT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBs-Tf-SfcnI"
   },
   "outputs": [],
   "source": [
    "def load_agent_output(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "legal_output = load_agent_output(\"/content/gdrive/MyDrive/CLAUSEAI/results/agents/legal/legal_agent_output.json\")\n",
    "compliance_output = load_agent_output(\"/content/gdrive/MyDrive/CLAUSEAI/results/agents/compliance/compliance_agent_output.json\")\n",
    "finance_output = load_agent_output(\"/content/gdrive/MyDrive/CLAUSEAI/results/agents/finance/finance_agent_output.json\")\n",
    "operations_output = load_agent_output(\"/content/gdrive/MyDrive/CLAUSEAI/results/agents/operations/operations_agent_output.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SV-Kt4SAffBl",
    "outputId": "7dae1e2b-ed61-44c0-9145-b50a2d05b514"
   },
   "outputs": [],
   "source": [
    "def check_grounding(output, rag_chunks):\n",
    "    \"\"\"\n",
    "    Checks if all evidence and extracted_clauses appear in rag_chunks.\n",
    "    rag_chunks: list of strings (texts from RAG file)\n",
    "    output: dict with keys 'extracted_clauses' and 'evidence'\n",
    "    Returns True if grounded, False otherwise.\n",
    "    \"\"\"\n",
    "    all_text = \"\\n\".join(rag_chunks).lower()\n",
    "\n",
    "    # Check evidence snippets\n",
    "    for snippet in output.get(\"evidence\", []):\n",
    "        if snippet.lower() not in all_text:\n",
    "            print(f\"Evidence snippet NOT found in input:\\n{snippet}\\n\")\n",
    "            return False\n",
    "\n",
    "    # Check extracted clauses\n",
    "    for clause in output.get(\"extracted_clauses\", []):\n",
    "        if clause.lower() not in all_text:\n",
    "            print(f\"Extracted clause NOT found in input:\\n{clause}\\n\")\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Example usage\n",
    "rag_texts = [chunk[\"text\"] for chunk in legal_context if chunk.get(\"text\")]\n",
    "is_grounded = check_grounding(legal_output, rag_texts)\n",
    "is_compliance_grounded = check_grounding(compliance_output, rag_texts)\n",
    "is_finance_grounded = check_grounding(finance_output, rag_texts)\n",
    "is_operations_grounded = check_grounding(operations_output, rag_texts)\n",
    "\n",
    "print(\"Grounding check:\", \"PASS\" if is_grounded else \"FAIL\")\n",
    "print(\"Grounding check:\", \"PASS\" if is_compliance_grounded else \"FAIL\")\n",
    "print(\"Grounding check:\", \"PASS\" if is_finance_grounded else \"FAIL\")\n",
    "print(\"Grounding check:\", \"PASS\" if is_operations_grounded else \"FAIL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d6VCVpZDfhh9",
    "outputId": "56576c24-e2d1-41e8-c988-851ec64dcac4"
   },
   "outputs": [],
   "source": [
    "def check_grounding(output, rag_chunks):\n",
    "    all_text = \"\\n\".join(rag_chunks).lower()\n",
    "    for snippet in output.get(\"evidence\", []):\n",
    "        if snippet.lower() not in all_text:\n",
    "            print(f\"Evidence snippet NOT found in input:\\n{snippet}\\n\")\n",
    "            return False\n",
    "    for clause in output.get(\"extracted_clauses\", []):\n",
    "        if clause.lower() not in all_text:\n",
    "            print(f\"Extracted clause NOT found in input:\\n{clause}\\n\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Dictionary of agents and their outputs\n",
    "agents_outputs = {\n",
    "    \"Legal\": legal_output,\n",
    "    \"Compliance\": compliance_output,\n",
    "    \"Finance\": finance_output,\n",
    "    \"Operations\": operations_output\n",
    "}\n",
    "\n",
    "rag_texts = [chunk[\"text\"] for chunk in legal_context if chunk.get(\"text\")]\n",
    "\n",
    "# Run grounding check for all agents dynamically\n",
    "for agent_name, output in agents_outputs.items():\n",
    "    is_grounded = check_grounding(output, rag_texts)\n",
    "    print(f\"Grounding check for {agent_name} agent:\", \"PASS\" if is_grounded else \"FAIL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6qKwHfDBZpC"
   },
   "outputs": [],
   "source": [
    "def cross_verify_agent_output(agent_output, rag_results):\n",
    "    \"\"\"\n",
    "    Cross-verify agent output with retrieved RAG contract chunks.\n",
    "\n",
    "    agent_output: dict returned by agent\n",
    "    rag_results: list of dicts containing 'text' field from RAG\n",
    "    \"\"\"\n",
    "\n",
    "    verification_report = {\n",
    "        \"verified\": True,\n",
    "        \"verified_extracted_clauses\": [],\n",
    "        \"verified_evidence\": [],\n",
    "        \"missing_extracted_clauses\": [],\n",
    "        \"missing_evidence\": []\n",
    "    }\n",
    "\n",
    "    # Combine all RAG text into one searchable string\n",
    "    combined_rag_text = \"\\n\\n\".join(\n",
    "        chunk[\"text\"] for chunk in rag_results if chunk.get(\"text\")\n",
    "    ).lower()\n",
    "\n",
    "    # 🔍 Verify extracted clauses\n",
    "    for clause in agent_output.get(\"extracted_clauses\", []):\n",
    "        if clause.lower() in combined_rag_text:\n",
    "            verification_report[\"verified_extracted_clauses\"].append(clause)\n",
    "        else:\n",
    "            verification_report[\"missing_extracted_clauses\"].append(clause)\n",
    "            verification_report[\"verified\"] = False\n",
    "\n",
    "    # 🔍 Verify evidence snippets\n",
    "    for evidence in agent_output.get(\"evidence\", []):\n",
    "        if evidence.lower() in combined_rag_text:\n",
    "            verification_report[\"verified_evidence\"].append(evidence)\n",
    "        else:\n",
    "            verification_report[\"missing_evidence\"].append(evidence)\n",
    "            verification_report[\"verified\"] = False\n",
    "\n",
    "    return verification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0Fq48CVBmzY",
    "outputId": "e7ba4827-71a1-46e2-99a4-42703ffe4ea5"
   },
   "outputs": [],
   "source": [
    "verification_result = cross_verify_agent_output(\n",
    "    agent_output=finance_output,\n",
    "    rag_results=legal_context\n",
    ")\n",
    "\n",
    "print(verification_result)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
