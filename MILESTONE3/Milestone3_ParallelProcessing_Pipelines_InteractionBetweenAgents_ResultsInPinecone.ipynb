{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db84498f",
   "metadata": {},
   "source": [
    "# Implementing Parallel Processing, Developing Pipelines, Multi-Turn Interaction Between Agents and Storing Results to Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1298c0be",
   "metadata": {},
   "source": [
    "#### Milestone 3: Week 5-6\n",
    "1. Implement Parallel Processing for multi-domain clause extraction.\n",
    "2. Develop structured pipelines for compliance and financial risk identification.\n",
    "3. Test multi-turn interaction between domain-specific agents.\n",
    "4. Store intermediate results in Pinecone for quick retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1357671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "import operator\n",
    "import time\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import Any, List, Dict, TypedDict, Annotated, Sequence\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "615c7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5dacb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUGGING FACE LOGIN\n",
      "Successfully logged in to Hugging Face\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"HUGGING FACE LOGIN\")\n",
    "\n",
    "HF_TOKEN = \"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\" \n",
    "login(token=HF_TOKEN)\n",
    "print(\"Successfully logged in to Hugging Face\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d999c",
   "metadata": {},
   "source": [
    "# Parallel Agent Execution with LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd4b75",
   "metadata": {},
   "source": [
    "#### 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ce3ad48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence-transformers imported successfully\n",
      "EMBEDDING GENERATION SETUP\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"sentence-transformers imported successfully\")\n",
    "except ImportError:\n",
    "    print(\"sentence-transformers not installed. Install with: pip install sentence-transformers\")\n",
    "\n",
    "print(\"EMBEDDING GENERATION SETUP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f0ab94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Sentence Transformer Model...\n",
      "Model loaded: all-MiniLM-L6-v2 (384 dimensions)\n",
      "\n",
      "Initializing Pinecone Connection...\n",
      "Connected to Pinecone index: contract-agents\n"
     ]
    }
   ],
   "source": [
    "MILESTONE3_OUTPUT = \"../Data/Results/Milestone3\"\n",
    "\n",
    "os.makedirs(MILESTONE3_OUTPUT, exist_ok=True)\n",
    "\n",
    "print(\"\\nInitializing Sentence Transformer Model...\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"Model loaded: all-MiniLM-L6-v2 (384 dimensions)\")\n",
    "\n",
    "print(\"\\nInitializing Pinecone Connection...\")\n",
    "PINECONE_API_KEY = 'pcsk_3ftgmC_GzUZkRCnxa2jmDu7TTjnGWjC3QaN8c2PcQ5KN5PUSyQaEmmcdGUGu2BLd4Y7TRn'\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"contract-agents\")\n",
    "print(\"Connected to Pinecone index: contract-agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f3663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OLLAMA CONFIGURATION\n",
      " Model: gemma2:9b\n",
      " URL: http://localhost:11434/api/generate\n",
      "Ollama integration configured\n"
     ]
    }
   ],
   "source": [
    "OLLAMA_MODEL = \"gemma2:9b\"\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "print(\"\\nOLLAMA CONFIGURATION\")\n",
    "print(f\" Model: {OLLAMA_MODEL}\")\n",
    "print(f\" URL: {OLLAMA_URL}\")\n",
    "\n",
    "def call_ollama(prompt, model=OLLAMA_MODEL, max_tokens=50000, timeout=30000):\n",
    "    try:\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False,\n",
    "            \"options\": {\n",
    "                \"temperature\": 0.1,\n",
    "                \"num_predict\": max_tokens\n",
    "            }\n",
    "        }\n",
    "\n",
    "        response = requests.post(OLLAMA_URL, json=payload, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        result = response.json()\n",
    "        return result.get('response', '').strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama API error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "print(\"Ollama integration configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f424f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading agent outputs from Pinecone...\n",
      "\n",
      "Agent Data Status:\n",
      " Legal: Loaded\n",
      " Compliance: Loaded\n",
      " Finance: Loaded\n",
      " Operations: Loaded\n",
      "\n",
      "Sample - Legal Agent: 2 clauses loaded\n",
      "Sample - Compliance Agent: 1 clauses loaded\n"
     ]
    }
   ],
   "source": [
    "def load_agent_output_from_pinecone(agent_name):\n",
    "    try:\n",
    "        query_embedding = [0.0] * 384\n",
    "        results = index.query(\n",
    "            vector=query_embedding,\n",
    "            filter={\"agent\": agent_name},\n",
    "            top_k=10,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        \n",
    "        if results.matches and len(results.matches) > 0:\n",
    "            agent_clauses = []\n",
    "            for match in results.matches:\n",
    "                agent_clauses.append({\n",
    "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
    "                    'clause_index': match.metadata.get('clause_index', 0),\n",
    "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
    "                    'confidence': match.metadata.get('confidence', 0),\n",
    "                    'timestamp': match.metadata.get('timestamp', '')\n",
    "                })\n",
    "            \n",
    "            return {\n",
    "                'agent': agent_name,\n",
    "                'clauses': agent_clauses,\n",
    "                'risk_level': results.matches[0].metadata.get('risk_level', 'unknown'),\n",
    "                'confidence': results.matches[0].metadata.get('confidence', 0),\n",
    "                'timestamp': results.matches[0].metadata.get('timestamp', '')\n",
    "            }\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {agent_name} output: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"\\nLoading agent outputs from Pinecone...\")\n",
    "legal_data = load_agent_output_from_pinecone(\"legal\")\n",
    "compliance_data = load_agent_output_from_pinecone(\"compliance\")\n",
    "finance_data = load_agent_output_from_pinecone(\"finance\")\n",
    "operations_data = load_agent_output_from_pinecone(\"operations\")\n",
    "\n",
    "print(f\"\\nAgent Data Status:\")\n",
    "print(f\" Legal: {'Loaded' if legal_data else 'Not found'}\")\n",
    "print(f\" Compliance: {'Loaded' if compliance_data else 'Not found'}\")\n",
    "print(f\" Finance: {'Loaded' if finance_data else 'Not found'}\")\n",
    "print(f\" Operations: {'Loaded' if operations_data else 'Not found'}\")\n",
    "\n",
    "if legal_data:\n",
    "    print(f\"\\nSample - Legal Agent: {len(legal_data['clauses'])} clauses loaded\")\n",
    "if compliance_data:\n",
    "    print(f\"Sample - Compliance Agent: {len(compliance_data['clauses'])} clauses loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16667edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEFINING DYNAMIC COORDINATOR\n",
      "Dynamic coordinator defined using Ollama gemma2:9b\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDEFINING DYNAMIC COORDINATOR\")\n",
    "\n",
    "OLLAMA_MODEL = \"gemma2:9b\"\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "def call_ollama(prompt, model=OLLAMA_MODEL, max_tokens=500):\n",
    "\n",
    "    try:\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"prompt\": prompt,\n",
    "            \"stream\": False,\n",
    "            \"options\": {\n",
    "                \"temperature\": 0.1,\n",
    "                \"num_predict\": max_tokens\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        response = requests.post(OLLAMA_URL, json=payload, timeout=60000)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        result = response.json()\n",
    "        return result.get('response', '').strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Ollama API error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def dynamic_coordinator(query: str, contract_text: str = \"\") -> dict:\n",
    "\n",
    "    prompt = f\"\"\"You are a contract analysis coordinator. Given a user query about a contract, determine which specialized agents should handle the analysis.\n",
    "\n",
    "Available agents:\n",
    "- LEGAL: Handles termination clauses, breach conditions, IP rights, liability\n",
    "- COMPLIANCE: Handles data protection, privacy, GDPR, audits, confidentiality\n",
    "- FINANCE: Handles payment terms, fees, penalties, reimbursement, financial obligations\n",
    "- OPERATIONS: Handles licenses, fulfillment, service delivery, operational requirements\n",
    "\n",
    "User Query: {query}\n",
    "\n",
    "Contract Context: {contract_text[:500] if contract_text else \"No contract text provided\"}\n",
    "\n",
    "Based on this query, which agents should be activated? Respond with a JSON object containing:\n",
    "{{\"agents\": [\"agent1\", \"agent2\"], \"reasoning\": \"brief explanation\", \"priority\": \"high/medium/low\"}}\n",
    "\n",
    "Only include agents that are directly relevant. Use lowercase agent names: legal, compliance, finance, operations.\n",
    "\n",
    "Your response (JSON only):\"\"\"\n",
    "    \n",
    "    response = call_ollama(prompt, max_tokens=300)\n",
    "    \n",
    "    try:\n",
    "        import re\n",
    "        json_match = re.search(r'\\{[^}]+\\}', response)\n",
    "        if json_match:\n",
    "            routing_decision = json.loads(json_match.group())\n",
    "        else:\n",
    "            routing_decision = {\n",
    "                \"agents\": [\"legal\", \"compliance\", \"finance\", \"operations\"],\n",
    "                \"reasoning\": \"Unable to parse coordinator response, activating all agents\",\n",
    "                \"priority\": \"medium\"\n",
    "            }\n",
    "    except:\n",
    "        routing_decision = {\n",
    "            \"agents\": [\"legal\", \"compliance\", \"finance\", \"operations\"],\n",
    "            \"reasoning\": \"Error in routing, activating all agents as safety measure\",\n",
    "            \"priority\": \"medium\"\n",
    "        }\n",
    "    \n",
    "    routing_decision['timestamp'] = datetime.now().isoformat()\n",
    "    routing_decision['model'] = OLLAMA_MODEL\n",
    "    \n",
    "    print(f\"\\nCoordinator Decision:\")\n",
    "    print(f\" Agents to activate: {', '.join(routing_decision['agents'])}\")\n",
    "    print(f\" Reasoning: {routing_decision['reasoning']}\")\n",
    "    print(f\" Priority: {routing_decision['priority']}\")\n",
    "    \n",
    "    return routing_decision\n",
    "\n",
    "print(\"Dynamic coordinator defined using Ollama gemma2:9b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e91c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking Ollama connection...\n",
      "✓ Ollama is running\n",
      "✓ Model gemma2:9b is available\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nChecking Ollama connection...\")\n",
    "try:\n",
    "    test_response = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
    "    if test_response.status_code == 200:\n",
    "        print(\"✓ Ollama is running\")\n",
    "        models = test_response.json().get('models', [])\n",
    "        model_names = [m['name'] for m in models]\n",
    "        if 'gemma2:9b' in model_names:\n",
    "            print(f\"✓ Model gemma2:9b is available\")\n",
    "        else:\n",
    "            print(f\"✗ Model gemma2:9b not found. Available: {model_names}\")\n",
    "    else:\n",
    "        print(\"✗ Ollama not responding\")\n",
    "except:\n",
    "    print(\"✗ Ollama service not running at localhost:11434\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41671d6e",
   "metadata": {},
   "source": [
    "#### 2. Defining Graph State for Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "feab23c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining Graph State\n",
      "Graph State defined with 13 fields\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDefining Graph State\")\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str\n",
    "    contract_text: str\n",
    "    routing_decision: dict\n",
    "    legal_output: dict\n",
    "    compliance_output: dict\n",
    "    finance_output: dict\n",
    "    operations_output: dict\n",
    "    execution_times: dict\n",
    "    agent_status: dict\n",
    "    completion_timestamps: dict\n",
    "    all_clauses: list\n",
    "    timestamp: str\n",
    "    status: str\n",
    "\n",
    "print(\"Graph State defined with 13 fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaddcc4",
   "metadata": {},
   "source": [
    "#### 3. Defining Agent Nodes with Timing Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d56c5cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Agent Nodes defined with Ollama-enhanced analysis\n"
     ]
    }
   ],
   "source": [
    "def legal_agent_node(state: AgentState) -> AgentState:\n",
    "    start_time = time.time()\n",
    "    print(\"  → Legal Agent executing...\")\n",
    "    \n",
    "    legal_data = load_agent_output_from_pinecone(\"legal\")\n",
    "    \n",
    "    if legal_data and legal_data.get('clauses'):\n",
    "        clauses_text = \"\\n\".join([c['clause'] for c in legal_data['clauses']])\n",
    "        \n",
    "        prompt = f\"\"\"Analyze these legal clauses and provide risk assessment:\n",
    "\n",
    "Clauses:\n",
    "{clauses_text}\n",
    "\n",
    "Provide:\n",
    "1. Overall risk level (low/medium/high)\n",
    "2. Key concerns\n",
    "3. Recommendations\n",
    "\n",
    "Response:\"\"\"\n",
    "        \n",
    "        analysis = call_ollama(prompt, max_tokens=40000)\n",
    "        legal_data['enhanced_analysis'] = analysis\n",
    "        legal_data['model_used'] = OLLAMA_MODEL\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    completion_time = datetime.now().isoformat()\n",
    "    \n",
    "    state['legal_output'] = legal_data\n",
    "    state['execution_times']['legal'] = execution_time\n",
    "    state['agent_status']['legal'] = 'completed'\n",
    "    state['completion_timestamps']['legal'] = completion_time\n",
    "    \n",
    "    if legal_data and 'clauses' in legal_data:\n",
    "        state['all_clauses'].extend(legal_data['clauses'])\n",
    "    \n",
    "    print(f\"  Legal Agent completed in {execution_time:.3f}s\")\n",
    "    return state\n",
    "\n",
    "def compliance_agent_node(state: AgentState) -> AgentState:\n",
    "    start_time = time.time()\n",
    "    print(\"  → Compliance Agent executing...\")\n",
    "    \n",
    "    compliance_data = load_agent_output_from_pinecone(\"compliance\")\n",
    "    \n",
    "    if compliance_data and compliance_data.get('clauses'):\n",
    "        clauses_text = \"\\n\".join([c['clause'] for c in compliance_data['clauses']])\n",
    "        \n",
    "        prompt = f\"\"\"Analyze these compliance clauses for GDPR and data protection risks:\n",
    "\n",
    "Clauses:\n",
    "{clauses_text}\n",
    "\n",
    "Provide:\n",
    "1. Compliance risk level (low/medium/high)\n",
    "2. GDPR article violations (Articles 5, 32, 33)\n",
    "3. Data protection gaps\n",
    "4. Remediation recommendations\n",
    "\n",
    "Response:\"\"\"\n",
    "        \n",
    "        analysis = call_ollama(prompt, max_tokens=40000)\n",
    "        compliance_data['enhanced_analysis'] = analysis\n",
    "        compliance_data['model_used'] = OLLAMA_MODEL\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    completion_time = datetime.now().isoformat()\n",
    "    \n",
    "    state['compliance_output'] = compliance_data\n",
    "    state['execution_times']['compliance'] = execution_time\n",
    "    state['agent_status']['compliance'] = 'completed'\n",
    "    state['completion_timestamps']['compliance'] = completion_time\n",
    "    \n",
    "    if compliance_data and 'clauses' in compliance_data:\n",
    "        state['all_clauses'].extend(compliance_data['clauses'])\n",
    "    \n",
    "    print(f\"  Compliance Agent completed in {execution_time:.3f}s\")\n",
    "    return state\n",
    "\n",
    "def finance_agent_node(state: AgentState) -> AgentState:\n",
    "    start_time = time.time()\n",
    "    print(\"  → Finance Agent executing...\")\n",
    "    \n",
    "    finance_data = load_agent_output_from_pinecone(\"finance\")\n",
    "    \n",
    "    if finance_data and finance_data.get('clauses'):\n",
    "        clauses_text = \"\\n\".join([c['clause'] for c in finance_data['clauses']])\n",
    "        \n",
    "        prompt = f\"\"\"Analyze these financial clauses for payment risks and obligations:\n",
    "\n",
    "Clauses:\n",
    "{clauses_text}\n",
    "\n",
    "Provide:\n",
    "1. Financial risk level (low/medium/high)\n",
    "2. Risk categories (payment default, penalty exposure, cost escalation, liability)\n",
    "3. Total financial obligations (min/max ranges)\n",
    "4. Cash flow impact\n",
    "5. Negotiation recommendations\n",
    "\n",
    "Response:\"\"\"\n",
    "        \n",
    "        analysis = call_ollama(prompt, max_tokens=40000)\n",
    "        finance_data['enhanced_analysis'] = analysis\n",
    "        finance_data['model_used'] = OLLAMA_MODEL\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    completion_time = datetime.now().isoformat()\n",
    "    \n",
    "    state['finance_output'] = finance_data\n",
    "    state['execution_times']['finance'] = execution_time\n",
    "    state['agent_status']['finance'] = 'completed'\n",
    "    state['completion_timestamps']['finance'] = completion_time\n",
    "    \n",
    "    if finance_data and 'clauses' in finance_data:\n",
    "        state['all_clauses'].extend(finance_data['clauses'])\n",
    "    \n",
    "    print(f\"  Finance Agent completed in {execution_time:.3f}s\")\n",
    "    return state\n",
    "\n",
    "def operations_agent_node(state: AgentState) -> AgentState:\n",
    "    start_time = time.time()\n",
    "    print(\"  → Operations Agent executing...\")\n",
    "    \n",
    "    operations_data = load_agent_output_from_pinecone(\"operations\")\n",
    "    \n",
    "    if operations_data and operations_data.get('clauses'):\n",
    "        clauses_text = \"\\n\".join([c['clause'] for c in operations_data['clauses']])\n",
    "        \n",
    "        prompt = f\"\"\"Analyze these operational clauses for service delivery and licensing:\n",
    "\n",
    "Clauses:\n",
    "{clauses_text}\n",
    "\n",
    "Provide:\n",
    "1. Operational risk level (low/medium/high)\n",
    "2. Key obligations\n",
    "3. Licensing requirements\n",
    "4. Fulfillment risks\n",
    "5. Operational recommendations\n",
    "\n",
    "Response:\"\"\"\n",
    "        \n",
    "        analysis = call_ollama(prompt, max_tokens=40000)\n",
    "        operations_data['enhanced_analysis'] = analysis\n",
    "        operations_data['model_used'] = OLLAMA_MODEL\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    completion_time = datetime.now().isoformat()\n",
    "    \n",
    "    state['operations_output'] = operations_data\n",
    "    state['execution_times']['operations'] = execution_time\n",
    "    state['agent_status']['operations'] = 'completed'\n",
    "    state['completion_timestamps']['operations'] = completion_time\n",
    "    \n",
    "    if operations_data and 'clauses' in operations_data:\n",
    "        state['all_clauses'].extend(operations_data['clauses'])\n",
    "    \n",
    "    print(f\"  Operations Agent completed in {execution_time:.3f}s\")\n",
    "    return state\n",
    "\n",
    "print(\"4 Agent Nodes defined with Ollama-enhanced analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dec15f",
   "metadata": {},
   "source": [
    "#### 4. Building LangGraph with Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab52c65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building LangGraph with Parallel Execution\n",
      "Added coordinator and 4 agent nodes to graph\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nBuilding LangGraph with Parallel Execution\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "def coordinator_node(state: AgentState) -> AgentState:\n",
    "    print(\"\\n  → Coordinator executing...\")\n",
    "    routing_decision = dynamic_coordinator(\n",
    "        query=state.get('query', ''),\n",
    "        contract_text=state.get('contract_text', '')\n",
    "    )\n",
    "    state['routing_decision'] = routing_decision\n",
    "    \n",
    "    for agent in routing_decision['agents']:\n",
    "        state['agent_status'][agent] = 'pending'\n",
    "    \n",
    "    return state\n",
    "\n",
    "workflow.add_node(\"coordinator\", coordinator_node)\n",
    "workflow.add_node(\"legal_agent\", legal_agent_node)\n",
    "workflow.add_node(\"compliance_agent\", compliance_agent_node)\n",
    "workflow.add_node(\"finance_agent\", finance_agent_node)\n",
    "workflow.add_node(\"operations_agent\", operations_agent_node)\n",
    "\n",
    "print(\"Added coordinator and 4 agent nodes to graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d63092e",
   "metadata": {},
   "source": [
    "#### 5. Defining Parallel Execution Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0359c648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining Parallel Execution\n",
      "Parallel execution structure configured with coordinator routing\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDefining Parallel Execution\")\n",
    "\n",
    "workflow.set_entry_point(\"coordinator\")\n",
    "\n",
    "workflow.add_edge(\"coordinator\", \"legal_agent\")\n",
    "workflow.add_edge(\"coordinator\", \"compliance_agent\")\n",
    "workflow.add_edge(\"coordinator\", \"finance_agent\")\n",
    "workflow.add_edge(\"coordinator\", \"operations_agent\")\n",
    "\n",
    "workflow.add_edge(\"legal_agent\", END)\n",
    "workflow.add_edge(\"compliance_agent\", END)\n",
    "workflow.add_edge(\"finance_agent\", END)\n",
    "workflow.add_edge(\"operations_agent\", END)\n",
    "\n",
    "print(\"Parallel execution structure configured with coordinator routing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4385320",
   "metadata": {},
   "source": [
    "#### 6. Compiling Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2185c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compiling Graph\n",
      "LangGraph compiled successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCompiling Graph\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"LangGraph compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79794b8d",
   "metadata": {},
   "source": [
    "#### 7. Running Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e6684a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Parallel Execution\n",
      "\n",
      "SEQUENTIAL EXECUTION:\n",
      "  → Legal Agent executing...\n",
      "  Legal Agent completed in 88.829s\n",
      "  → Compliance Agent executing...\n",
      "  Compliance Agent completed in 132.396s\n",
      "  → Finance Agent executing...\n",
      "  Finance Agent completed in 163.388s\n",
      "  → Operations Agent executing...\n",
      "  Operations Agent completed in 166.941s\n",
      "\n",
      "  Total Sequential Time: 551.557s\n",
      "\n",
      "PARALLEL EXECUTION:\n",
      "  → Legal Agent executing...\n",
      "  → Compliance Agent executing...\n",
      "  → Finance Agent executing...\n",
      "  → Operations Agent executing...\n",
      "  Finance Agent completed in 188.152s\n",
      "  Compliance Agent completed in 348.363s\n",
      "  Legal Agent completed in 461.785s\n",
      "  Operations Agent completed in 616.165s\n",
      "\n",
      "  Total Parallel Time: 616.198s\n",
      "\n",
      "  Total Clauses Collected: 128\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRunning Parallel Execution\")\n",
    "\n",
    "test_query = \"Analyze contract for payment terms, termination clauses, and compliance risks\"\n",
    "test_contract = \"Sample contract text with payment, termination, and confidentiality provisions\"\n",
    "\n",
    "initial_state = {\n",
    "    \"query\": test_query,\n",
    "    \"contract_text\": test_contract,\n",
    "    \"routing_decision\": {},\n",
    "    \"legal_output\": {},\n",
    "    \"compliance_output\": {},\n",
    "    \"finance_output\": {},\n",
    "    \"operations_output\": {},\n",
    "    \"execution_times\": {},\n",
    "    \"agent_status\": {},\n",
    "    \"completion_timestamps\": {},\n",
    "    \"all_clauses\": [],\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"status\": \"running\"\n",
    "}\n",
    "\n",
    "print(\"\\nSEQUENTIAL EXECUTION:\")\n",
    "seq_start = time.time()\n",
    "\n",
    "seq_state = initial_state.copy()\n",
    "seq_state['execution_times'] = {}\n",
    "seq_state['agent_status'] = {}\n",
    "seq_state['completion_timestamps'] = {}\n",
    "seq_state['all_clauses'] = []\n",
    "\n",
    "seq_state = legal_agent_node(seq_state)\n",
    "seq_state = compliance_agent_node(seq_state)\n",
    "seq_state = finance_agent_node(seq_state)\n",
    "seq_state = operations_agent_node(seq_state)\n",
    "\n",
    "seq_total = time.time() - seq_start\n",
    "print(f\"\\n  Total Sequential Time: {seq_total:.3f}s\")\n",
    "\n",
    "print(\"\\nPARALLEL EXECUTION:\")\n",
    "par_start = time.time()\n",
    "\n",
    "par_state = initial_state.copy()\n",
    "par_state['execution_times'] = {}\n",
    "par_state['agent_status'] = {}\n",
    "par_state['completion_timestamps'] = {}\n",
    "par_state['all_clauses'] = []\n",
    "\n",
    "import concurrent.futures\n",
    "import threading\n",
    "\n",
    "state_lock = threading.Lock()\n",
    "\n",
    "def execute_agent_parallel(agent_func, state):\n",
    "    result = agent_func(state.copy())\n",
    "    return result\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    futures = [\n",
    "        executor.submit(execute_agent_parallel, legal_agent_node, par_state.copy()),\n",
    "        executor.submit(execute_agent_parallel, compliance_agent_node, par_state.copy()),\n",
    "        executor.submit(execute_agent_parallel, finance_agent_node, par_state.copy()),\n",
    "        executor.submit(execute_agent_parallel, operations_agent_node, par_state.copy())\n",
    "    ]\n",
    "    \n",
    "    results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "with state_lock:\n",
    "    for result in results:\n",
    "        if result.get('legal_output'):\n",
    "            par_state['legal_output'] = result['legal_output']\n",
    "            par_state['execution_times']['legal'] = result['execution_times'].get('legal', 0)\n",
    "            par_state['agent_status']['legal'] = result['agent_status'].get('legal', 'completed')\n",
    "            par_state['completion_timestamps']['legal'] = result['completion_timestamps'].get('legal', '')\n",
    "        if result.get('compliance_output'):\n",
    "            par_state['compliance_output'] = result['compliance_output']\n",
    "            par_state['execution_times']['compliance'] = result['execution_times'].get('compliance', 0)\n",
    "            par_state['agent_status']['compliance'] = result['agent_status'].get('compliance', 'completed')\n",
    "            par_state['completion_timestamps']['compliance'] = result['completion_timestamps'].get('compliance', '')\n",
    "        if result.get('finance_output'):\n",
    "            par_state['finance_output'] = result['finance_output']\n",
    "            par_state['execution_times']['finance'] = result['execution_times'].get('finance', 0)\n",
    "            par_state['agent_status']['finance'] = result['agent_status'].get('finance', 'completed')\n",
    "            par_state['completion_timestamps']['finance'] = result['completion_timestamps'].get('finance', '')\n",
    "        if result.get('operations_output'):\n",
    "            par_state['operations_output'] = result['operations_output']\n",
    "            par_state['execution_times']['operations'] = result['execution_times'].get('operations', 0)\n",
    "            par_state['agent_status']['operations'] = result['agent_status'].get('operations', 'completed')\n",
    "            par_state['completion_timestamps']['operations'] = result['completion_timestamps'].get('operations', '')\n",
    "        \n",
    "        par_state['all_clauses'].extend(result.get('all_clauses', []))\n",
    "\n",
    "par_total = time.time() - par_start\n",
    "\n",
    "print(f\"\\n  Total Parallel Time: {par_total:.3f}s\")\n",
    "print(f\"\\n  Total Clauses Collected: {len(par_state['all_clauses'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f6c395",
   "metadata": {},
   "source": [
    "#### 8. Verifying Parallel Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35d43206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying Parallel Outputs\n",
      "\n",
      "Agent Output Verification:\n",
      "  Success -  Legal Agent: Loaded\n",
      "    Status: completed\n",
      "    Completed: 2026-01-16T13:50:34.264837\n",
      "    Execution Time: 461.785s\n",
      "  Success -  Compliance Agent: Loaded\n",
      "    Status: completed\n",
      "    Completed: 2026-01-16T13:48:40.845494\n",
      "    Execution Time: 348.363s\n",
      "  Success -  Finance Agent: Loaded\n",
      "    Status: completed\n",
      "    Completed: 2026-01-16T13:46:00.647811\n",
      "    Execution Time: 188.152s\n",
      "  Success -  Operations Agent: Loaded\n",
      "    Status: completed\n",
      "    Completed: 2026-01-16T13:53:08.670302\n",
      "    Execution Time: 616.165s\n",
      "\n",
      "Total Clauses in all_clauses: 128\n",
      "Agent Status Summary: {'finance': 'completed', 'compliance': 'completed', 'legal': 'completed', 'operations': 'completed'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerifying Parallel Outputs\")\n",
    "\n",
    "verification_results = {\n",
    "    \"legal_agent\": bool(par_state.get('legal_output')),\n",
    "    \"compliance_agent\": bool(par_state.get('compliance_output')),\n",
    "    \"finance_agent\": bool(par_state.get('finance_output')),\n",
    "    \"operations_agent\": bool(par_state.get('operations_output'))\n",
    "}\n",
    "\n",
    "print(\"\\nAgent Output Verification:\")\n",
    "for agent, status in verification_results.items():\n",
    "    symbol = \"Success - \" if status else \"Error\"\n",
    "    agent_name = agent.replace('_agent', '')\n",
    "    print(f\"  {symbol} {agent.replace('_', ' ').title()}: {'Loaded' if status else 'Missing'}\")\n",
    "    \n",
    "    if status and agent_name in par_state.get('agent_status', {}):\n",
    "        print(f\"    Status: {par_state['agent_status'][agent_name]}\")\n",
    "        print(f\"    Completed: {par_state['completion_timestamps'].get(agent_name, 'N/A')}\")\n",
    "        print(f\"    Execution Time: {par_state['execution_times'].get(agent_name, 0):.3f}s\")\n",
    "\n",
    "print(f\"\\nTotal Clauses in all_clauses: {len(par_state.get('all_clauses', []))}\")\n",
    "print(f\"Agent Status Summary: {par_state.get('agent_status', {})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f5291",
   "metadata": {},
   "source": [
    "#### 9. Sequential vs Parallel Runtime Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6616840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE COMPARISON\n",
      "\n",
      "Performance Metrics:\n",
      "  Sequential Time: 551.557s\n",
      "  Parallel Time: 616.198s\n",
      "  Speedup: 0.90x\n",
      "  Time Saved: -64.641s\n",
      "  Efficiency Gain: -11.7%\n",
      "\n",
      "Milestone 3 Metrics:\n",
      "  Parallel Agents Executed: 4\n",
      "  Total Clauses Collected: 128\n",
      "  Thread-Safe Updates: True\n",
      "  Coordinator Routing: False\n"
     ]
    }
   ],
   "source": [
    "print(\"PERFORMANCE COMPARISON\")\n",
    "\n",
    "speedup = seq_total / par_total if par_total > 0 else 0\n",
    "\n",
    "comparison_data = {\n",
    "    \"sequential_execution\": {\n",
    "        \"total_time_seconds\": round(seq_total, 3),\n",
    "        \"agent_times\": seq_state['execution_times'],\n",
    "        \"agent_status\": seq_state.get('agent_status', {}),\n",
    "        \"completion_timestamps\": seq_state.get('completion_timestamps', {})\n",
    "    },\n",
    "    \"parallel_execution\": {\n",
    "        \"total_time_seconds\": round(par_total, 3),\n",
    "        \"agent_times\": par_state['execution_times'],\n",
    "        \"agent_status\": par_state.get('agent_status', {}),\n",
    "        \"completion_timestamps\": par_state.get('completion_timestamps', {}),\n",
    "        \"total_clauses_collected\": len(par_state.get('all_clauses', []))\n",
    "    },\n",
    "    \"performance_gain\": {\n",
    "        \"speedup_factor\": round(speedup, 2),\n",
    "        \"time_saved_seconds\": round(seq_total - par_total, 3),\n",
    "        \"efficiency_improvement_percent\": round((1 - par_total/seq_total) * 100, 1) if seq_total > 0 else 0\n",
    "    },\n",
    "    \"milestone3_metrics\": {\n",
    "        \"parallel_agents\": len(par_state.get('agent_status', {})),\n",
    "        \"clauses_collected\": len(par_state.get('all_clauses', [])),\n",
    "        \"thread_safe_updates\": True,\n",
    "        \"coordinator_used\": bool(par_state.get('routing_decision'))\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  Sequential Time: {seq_total:.3f}s\")\n",
    "print(f\"  Parallel Time: {par_total:.3f}s\")\n",
    "print(f\"  Speedup: {speedup:.2f}x\")\n",
    "print(f\"  Time Saved: {seq_total - par_total:.3f}s\")\n",
    "print(f\"  Efficiency Gain: {comparison_data['performance_gain']['efficiency_improvement_percent']}%\")\n",
    "\n",
    "print(f\"\\nMilestone 3 Metrics:\")\n",
    "print(f\"  Parallel Agents Executed: {comparison_data['milestone3_metrics']['parallel_agents']}\")\n",
    "print(f\"  Total Clauses Collected: {comparison_data['milestone3_metrics']['clauses_collected']}\")\n",
    "print(f\"  Thread-Safe Updates: {comparison_data['milestone3_metrics']['thread_safe_updates']}\")\n",
    "print(f\"  Coordinator Routing: {comparison_data['milestone3_metrics']['coordinator_used']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "816338ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timing comparison saved: ../Data/Results/Milestone3\\parallel_execution_timing.json\n",
      "Parallel outputs saved: ../Data/Results/Milestone3\\parallel_agent_outputs.json\n"
     ]
    }
   ],
   "source": [
    "timing_output = os.path.join(MILESTONE3_OUTPUT, \"parallel_execution_timing.json\")\n",
    "with open(timing_output, 'w', encoding='utf-8') as f:\n",
    "    json.dump(comparison_data, f, indent=2)\n",
    "\n",
    "print(f\"\\nTiming comparison saved: {timing_output}\")\n",
    "\n",
    "parallel_output = os.path.join(MILESTONE3_OUTPUT, \"parallel_agent_outputs.json\")\n",
    "output_data = {\n",
    "    \"execution_metadata\": {\n",
    "        \"timestamp\": par_state['timestamp'],\n",
    "        \"execution_mode\": \"parallel\",\n",
    "        \"total_time_seconds\": round(par_total, 3)\n",
    "    },\n",
    "    \"agent_outputs\": {\n",
    "        \"legal\": par_state['legal_output'],\n",
    "        \"compliance\": par_state['compliance_output'],\n",
    "        \"finance\": par_state['finance_output'],\n",
    "        \"operations\": par_state['operations_output']\n",
    "    },\n",
    "    \"execution_times\": par_state['execution_times']\n",
    "}\n",
    "\n",
    "with open(parallel_output, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, indent=2)\n",
    "\n",
    "print(f\"Parallel outputs saved: {parallel_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179aa90a",
   "metadata": {},
   "source": [
    "#### 10. Testing Parallel Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dccf9ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING PARALLEL EXECUTION WITH OLLAMA ANALYSIS\n",
      "\n",
      "Checking Ollama Connection...\n",
      "   Ollama is running\n",
      "   Model gemma2:9b is available\n"
     ]
    }
   ],
   "source": [
    "print(\"TESTING PARALLEL EXECUTION WITH OLLAMA ANALYSIS\")\n",
    "\n",
    "print(\"\\nChecking Ollama Connection...\")\n",
    "try:\n",
    "    test_response = requests.get(\"http://localhost:11434/api/tags\", timeout=50000)\n",
    "    if test_response.status_code == 200:\n",
    "        print(\"   Ollama is running\")\n",
    "        models = test_response.json().get('models', [])\n",
    "        model_names = [m['name'] for m in models]\n",
    "        if 'gemma2:9b' in model_names:\n",
    "            print(f\"   Model gemma2:9b is available\")\n",
    "        else:\n",
    "            print(f\"   Model gemma2:9b not found. Available: {model_names}\")\n",
    "    else:\n",
    "        print(\"   Ollama not responding\")\n",
    "except Exception as e:\n",
    "    print(f\"   Ollama service error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "185deebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting Up Test Query...\n",
      "   Query: Analyze contract risks across legal, compliance, finance, and operations domains\n",
      "   Contract Context: Contract analysis for payment terms, termination clauses, confidentiality, and service delivery\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSetting Up Test Query...\")\n",
    "test_query = \"Analyze contract risks across legal, compliance, finance, and operations domains\"\n",
    "test_contract = \"Contract analysis for payment terms, termination clauses, confidentiality, and service delivery\"\n",
    "\n",
    "print(f\"   Query: {test_query}\")\n",
    "print(f\"   Contract Context: {test_contract[:10000]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "68e4b4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing State for Parallel Execution...\n",
      "   State initialized\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInitializing State for Parallel Execution...\")\n",
    "test_state = {\n",
    "    \"query\": test_query,\n",
    "    \"contract_text\": test_contract,\n",
    "    \"routing_decision\": {},\n",
    "    \"legal_output\": {},\n",
    "    \"compliance_output\": {},\n",
    "    \"finance_output\": {},\n",
    "    \"operations_output\": {},\n",
    "    \"execution_times\": {},\n",
    "    \"agent_status\": {},\n",
    "    \"completion_timestamps\": {},\n",
    "    \"all_clauses\": [],\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"status\": \"running\"\n",
    "}\n",
    "\n",
    "print(\"   State initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4b3365ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Parallel Execution with Ollama Analysis...\n",
      "\n",
      "   [LEGAL] Starting analysis...\n",
      "  → Legal Agent executing...\n",
      "\n",
      "   [COMPLIANCE] Starting analysis...\n",
      "  → Compliance Agent executing...\n",
      "\n",
      "   [FINANCE] Starting analysis...\n",
      "  → Finance Agent executing...\n",
      "\n",
      "   [OPERATIONS] Starting analysis...\n",
      "  → Operations Agent executing...\n",
      "  Compliance Agent completed in 163.776s\n",
      "   [COMPLIANCE] Completed!\n",
      "  Legal Agent completed in 280.084s\n",
      "   [LEGAL] Completed!\n",
      "  Finance Agent completed in 425.291s\n",
      "   [FINANCE] Completed!\n",
      "  Operations Agent completed in 588.566s\n",
      "   [OPERATIONS] Completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRunning Parallel Execution with Ollama Analysis...\")\n",
    "parallel_start = time.time()\n",
    "\n",
    "import concurrent.futures\n",
    "import threading\n",
    "\n",
    "state_lock = threading.Lock()\n",
    "\n",
    "def execute_agent_with_tracking(agent_func, state, agent_name):\n",
    "    print(f\"\\n   [{agent_name.upper()}] Starting analysis...\")\n",
    "    result = agent_func(state.copy())\n",
    "    print(f\"   [{agent_name.upper()}] Completed!\")\n",
    "    return result\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    futures = {\n",
    "        executor.submit(execute_agent_with_tracking, legal_agent_node, test_state.copy(), \"legal\"): \"legal\",\n",
    "        executor.submit(execute_agent_with_tracking, compliance_agent_node, test_state.copy(), \"compliance\"): \"compliance\",\n",
    "        executor.submit(execute_agent_with_tracking, finance_agent_node, test_state.copy(), \"finance\"): \"finance\",\n",
    "        executor.submit(execute_agent_with_tracking, operations_agent_node, test_state.copy(), \"operations\"): \"operations\"\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        agent_name = futures[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"   [{agent_name.upper()}] Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "11d4d000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging Results...\n",
      "   Results merged successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMerging Results...\")\n",
    "with state_lock:\n",
    "    for result in results:\n",
    "        if result.get('legal_output'):\n",
    "            test_state['legal_output'] = result['legal_output']\n",
    "            test_state['execution_times']['legal'] = result['execution_times'].get('legal', 0)\n",
    "            test_state['agent_status']['legal'] = result['agent_status'].get('legal', 'completed')\n",
    "            test_state['completion_timestamps']['legal'] = result['completion_timestamps'].get('legal', '')\n",
    "        if result.get('compliance_output'):\n",
    "            test_state['compliance_output'] = result['compliance_output']\n",
    "            test_state['execution_times']['compliance'] = result['execution_times'].get('compliance', 0)\n",
    "            test_state['agent_status']['compliance'] = result['agent_status'].get('compliance', 'completed')\n",
    "            test_state['completion_timestamps']['compliance'] = result['completion_timestamps'].get('compliance', '')\n",
    "        if result.get('finance_output'):\n",
    "            test_state['finance_output'] = result['finance_output']\n",
    "            test_state['execution_times']['finance'] = result['execution_times'].get('finance', 0)\n",
    "            test_state['agent_status']['finance'] = result['agent_status'].get('finance', 'completed')\n",
    "            test_state['completion_timestamps']['finance'] = result['completion_timestamps'].get('finance', '')\n",
    "        if result.get('operations_output'):\n",
    "            test_state['operations_output'] = result['operations_output']\n",
    "            test_state['execution_times']['operations'] = result['execution_times'].get('operations', 0)\n",
    "            test_state['agent_status']['operations'] = result['agent_status'].get('operations', 'completed')\n",
    "            test_state['completion_timestamps']['operations'] = result['completion_timestamps'].get('operations', '')\n",
    "        \n",
    "        test_state['all_clauses'].extend(result.get('all_clauses', []))\n",
    "\n",
    "parallel_total = time.time() - parallel_start\n",
    "\n",
    "print(f\"   Results merged successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b7e29b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXECUTION RESULTS\n",
      "\n",
      "Total Execution Time: 591.02s\n",
      "Total Clauses Analyzed: 128\n",
      "\n",
      "AGENT EXECUTION\n",
      "Compliance   : 163.78s [completed]\n",
      "Legal        : 280.08s [completed]\n",
      "Finance      : 425.29s [completed]\n",
      "Operations   : 588.57s [completed]\n",
      "OLLAMA ANALYSIS RECOMMENDATIONS\n",
      "\n",
      "LEGAL AGENT\n",
      "Clauses Found: 2\n",
      "Risk Level: LOW\n",
      "\n",
      "Analysis & Recommendations:\n",
      "## Risk Assessment of Legal Clauses\n",
      "\n",
      "**Overall Risk Level:** Medium\n",
      "\n",
      "**Key Concerns:**\n",
      "\n",
      "* **Vagueness:** The clause regarding termination notice lacks specificity about what constitutes \"reasonable detail\" in describing the default event(s). This ambiguity could lead to disputes over whether a termination notice was sufficient, potentially delaying or hindering the termination process.\n",
      "* **Subjectivity:**  The phrase \"reasonable detail\" is subjective and open to interpretation by both parties. What one party considers reasonable, another might deem insufficient. \n",
      "* **Intellectual Property Assertion:** The clause regarding intellectual property assertion lacks clarity on the scope of rights being asserted and the potential consequences for the terminating party. This ambiguity could lead to legal disputes over ownership or infringement claims.\n",
      "\n",
      "**Recommendations:**\n",
      "\n",
      "1. **Define \"Reasonable Detail\":**  Specify what information must be included in a termination notice, such as:\n",
      "    * Date and time of the default event(s)\n",
      "    * Specific provisions of the agreement allegedly violated\n",
      "    * Evidence supporting the claim of default\n",
      "    * Proposed remedies or actions required to cure the default\n",
      "\n",
      "2. **Clarify Intellectual Property Rights:**  Define the scope of intellectual property rights being asserted by each party, including:\n",
      "    * Types of intellectual property covered (e.g., patents, trademarks, copyrights)\n",
      "    * Ownership and licensing terms\n",
      "    * Procedures for resolving disputes over intellectual property claims\n",
      "\n",
      "3. **Include Consequences for Assertion:** Specify the consequences for asserting intellectual property rights in violation of the agreement, such as:\n",
      "    * Monetary damages\n",
      "    * Injunctions prohibiting further use or assertion of the claimed rights\n",
      "    * Termination of the agreement\n",
      "\n",
      "\n",
      "By addressing these concerns and incorporating clear definitions and procedures, you can mitigate the risks associated with these clauses and ensure a more predictable and enforceable agreement. \n",
      "\n",
      "**Disclaimer:** This analysis is for informational purposes only and does not constitute legal advice. You should consult with an attorney to discuss your specific legal needs and circumstances.\n",
      "\n",
      "------------------------------------------------------------\n",
      " COMPLIANCE AGENT \n",
      "Clauses Found: 1\n",
      "Risk Level: HIGH\n",
      "\n",
      "Analysis & Recommendations:\n",
      "## Analysis of Compliance Clause:\n",
      "\n",
      "**Clause:** The receiving party will not disclose the other party's confidential information to any third parties without the other party's prior written consent.\n",
      "\n",
      "**1. Compliance Risk Level:** **Medium** \n",
      "\n",
      "While this clause addresses confidentiality, it lacks specificity regarding data protection principles and doesn't explicitly mention GDPR compliance. This ambiguity creates a medium-level risk.\n",
      "\n",
      "**2. GDPR Article Violations:**\n",
      "\n",
      "* **Article 5 (Data Minimization & Purpose Limitation):**  The clause doesn't specify the purpose for which the confidential information is processed, potentially leading to violations of data minimization and purpose limitation principles.\n",
      "* **Article 32 (Security of Processing):** The clause focuses solely on disclosure and doesn't address security measures required to protect the confidential information during processing. This omission could lead to breaches and Article 32 violations.\n",
      "\n",
      "**3. Data Protection Gaps:**\n",
      "\n",
      "* **Scope:**  The clause only addresses disclosure to third parties, but doesn't cover internal processing or sharing within the receiving party's organization.\n",
      "* **Data Types:** The clause doesn't specify what constitutes \"confidential information,\" leaving room for interpretation and potential misclassification of personal data.\n",
      "* **Consent:** While consent is mentioned, it lacks details about informed consent requirements under GDPR (e.g., purpose, legal basis, withdrawal rights).\n",
      "* **Data Subject Rights:** The clause doesn't mention the receiving party's obligations regarding data subject rights (access, rectification, erasure, etc.).\n",
      "\n",
      "**4. Remediation Recommendations:**\n",
      "\n",
      "* **Explicitly reference GDPR compliance:** State that the clause is intended to comply with GDPR requirements.\n",
      "* **Define \"Confidential Information\":** Clearly specify what constitutes confidential information, including personal data and its categories.\n",
      "* **Purpose Limitation & Data Minimization:**  State the specific purpose(s) for processing the confidential information and ensure it aligns with legitimate grounds under GDPR. Limit data collection to what is strictly necessary.\n",
      "* **Security Measures:** Include provisions outlining appropriate technical and organizational security measures to protect personal data during processing (e.g., encryption, access controls).\n",
      "* **Data Subject Rights:**  Acknowledge the receiving party's obligations regarding data subject rights and establish procedures for handling requests.\n",
      "* **Consent Requirements:** Ensure any consent obtained complies with GDPR principles (informed, specific, unambiguous, freely given).\n",
      "* **Breach Notification:** Include a clause outlining procedures for reporting and managing personal data breaches in accordance with Article 33 of GDPR.\n",
      "\n",
      "\n",
      "\n",
      "By incorporating these recommendations, the clause can be strengthened to effectively address GDPR compliance risks and protect personal data.\n",
      "\n",
      "------------------------------------------------------------\n",
      " FINANCE AGENT \n",
      "Clauses Found: 3\n",
      "Risk Level: MEDIUM\n",
      "\n",
      "Analysis & Recommendations:\n",
      "## Analysis of Financial Clauses:\n",
      "\n",
      "Here's a breakdown of the provided clauses and their implications for financial risk and obligations:\n",
      "\n",
      "**1. Financial Risk Level:** **Medium**\n",
      "\n",
      "The clauses present a moderate level of financial risk due to the potential for unforeseen out-of-pocket expenses and the reliance on monthly invoicing for reimbursement. \n",
      "\n",
      "**2. Risk Categories:**\n",
      "\n",
      "* **Payment Default:**  There's a risk that the Recipient may not pay the Provider for incurred expenses as outlined in the agreement. This is particularly concerning given the absence of specific payment terms (e.g., due dates, late payment penalties).\n",
      "* **Cost Escalation:** The clause allows for \"reasonable and documented\" out-of-pocket expenses, leaving room for interpretation and potential cost overruns. \n",
      "* **Liability:** While not explicitly stated, the Provider could potentially face liability if third-party service providers or subcontractors they engage with cause harm or breach contractual obligations.\n",
      "\n",
      "**3. Total Financial Obligations (Min/Max Ranges):**\n",
      "\n",
      "* **Minimum:** Difficult to determine without knowing the nature and scope of services provided.\n",
      "* **Maximum:**  Potentially unlimited depending on the \"reasonable and documented\" out-of-pocket expenses incurred by the Provider. \n",
      "\n",
      "**4. Cash Flow Impact:**\n",
      "\n",
      "The reliance on monthly invoicing creates a potential cash flow issue for the Provider. They may experience delays in receiving payment, impacting their ability to cover ongoing operational costs and potentially leading to financial strain.\n",
      "\n",
      "**5. Negotiation Recommendations:**\n",
      "\n",
      "* **Clarify Payment Terms:**  Specify due dates for invoices, late payment penalties, and acceptable payment methods.\n",
      "* **Define \"Reasonable\" Expenses:** Establish clear criteria for what constitutes \"reasonable\" out-of-pocket expenses, including pre-approval processes for significant expenditures.\n",
      "* **Limit Liability:** Include a clause that limits the Provider's liability for actions or omissions of third-party service providers or subcontractors. \n",
      "* **Consider Advance Payments:** Negotiate for partial advance payments to mitigate cash flow risks and ensure timely reimbursement for incurred expenses.\n",
      "* **Include Dispute Resolution Mechanisms:** Establish a clear process for resolving payment disputes, such as mediation or arbitration.\n",
      "\n",
      "\n",
      "By addressing these points during negotiation, both parties can minimize financial risks and establish a more secure and transparent contractual relationship.\n",
      "\n",
      "------------------------------------------------------------\n",
      " OPERATIONS AGENT \n",
      "Clauses Found: 2\n",
      "Risk Level: MEDIUM\n",
      "\n",
      "Analysis & Recommendations:\n",
      "## Analysis of Operational Clauses for Service Delivery and Licensing\n",
      "\n",
      "**Clauses:**\n",
      "\n",
      "* **Clause 1:** Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distribution of the Products.\n",
      "* **Clause 2:** Collectible Concepts Group will obtain any licenses deemed by the Joint Venturers to add value in the marketing of the Products.\n",
      "\n",
      "**1. Operational Risk Level: Medium**\n",
      "\n",
      "The clauses introduce some operational risks due to reliance on third parties and potential licensing complexities.  \n",
      "\n",
      "**2. Key Obligations:**\n",
      "\n",
      "* **Pivotal Self Service Tech, Inc.:**\n",
      "    * Provide fulfillment services through affiliates for final distribution of the Products. This implies responsibility for managing affiliate relationships, ensuring timely delivery, and handling customer service related to fulfillment.\n",
      "* **Collectible Concepts Group:**\n",
      "    * Obtain any licenses deemed necessary by the Joint Venturers for marketing the Products. This requires proactive identification of potential licensing needs, negotiation with licensors, and compliance with licensing terms.\n",
      "\n",
      "**3. Licensing Requirements:**\n",
      "\n",
      "* The specific licensing requirements are not defined in the clauses. \n",
      "* **Clause 2** states that Collectible Concepts Group will obtain licenses \"deemed by the Joint Venturers to add value in the marketing of the Products.\" This suggests a collaborative decision-making process regarding which licenses are necessary.\n",
      "* Potential licensing categories could include: intellectual property rights (trademarks, copyrights), brand usage rights, regulatory approvals, and data privacy compliance.\n",
      "\n",
      "**4. Fulfillment Risks:**\n",
      "\n",
      "* **Affiliate Management:** Dependence on affiliates introduces risks related to their performance, reliability, and adherence to contractual obligations. \n",
      "* **Delivery Delays:**  Delays in fulfillment by affiliates can negatively impact customer satisfaction and the company's reputation.\n",
      "* **Inventory Management:** Inefficient inventory management by affiliates can lead to stockouts or excess inventory, impacting profitability.\n",
      "\n",
      "**5. Operational Recommendations:**\n",
      "\n",
      "* **Formalize Affiliate Agreements:** Establish clear contracts with affiliates outlining responsibilities, performance metrics, dispute resolution mechanisms, and termination clauses.\n",
      "* **Implement Robust Monitoring Systems:** Track affiliate performance regularly, including delivery times, customer satisfaction ratings, and adherence to contractual obligations.\n",
      "* **Develop Contingency Plans:**  Prepare for potential disruptions in fulfillment by identifying backup suppliers or alternative distribution channels.\n",
      "* **Establish Clear Licensing Procedures:** Define a process for identifying, evaluating, and obtaining necessary licenses, ensuring transparency and collaboration among the Joint Venturers.\n",
      "* **Conduct Regular Risk Assessments:** Periodically assess operational risks related to fulfillment and licensing, identifying potential vulnerabilities and implementing mitigation strategies.\n",
      "\n",
      "\n",
      "By addressing these recommendations, Pivotal Self Service Tech, Inc. and Collectible Concepts Group can minimize operational risks and ensure smooth service delivery and compliance with licensing requirements.\n",
      "TEST COMPLETE\n"
     ]
    }
   ],
   "source": [
    "print(\"EXECUTION RESULTS\")\n",
    "\n",
    "print(f\"\\nTotal Execution Time: {parallel_total:.2f}s\")\n",
    "print(f\"Total Clauses Analyzed: {len(test_state['all_clauses'])}\")\n",
    "\n",
    "print(\"\\nAGENT EXECUTION\")\n",
    "for agent, exec_time in test_state['execution_times'].items():\n",
    "    status = test_state['agent_status'].get(agent, 'unknown')\n",
    "    print(f\"{agent.capitalize():12} : {exec_time:.2f}s [{status}]\")\n",
    "\n",
    "print(\"OLLAMA ANALYSIS RECOMMENDATIONS\")\n",
    "\n",
    "if test_state['legal_output'] and test_state['legal_output'].get('enhanced_analysis'):\n",
    "    print(\"\\nLEGAL AGENT\")\n",
    "    print(f\"Clauses Found: {len(test_state['legal_output'].get('clauses', []))}\")\n",
    "    print(f\"Risk Level: {test_state['legal_output'].get('risk_level', 'N/A').upper()}\")\n",
    "    print(f\"\\nAnalysis & Recommendations:\")\n",
    "    print(test_state['legal_output']['enhanced_analysis'])\n",
    "else:\n",
    "    print(\"\\nLEGAL AGENT\")\n",
    "    print(\"No enhanced analysis available\")\n",
    "\n",
    "if test_state['compliance_output'] and test_state['compliance_output'].get('enhanced_analysis'):\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\" COMPLIANCE AGENT \")\n",
    "    print(f\"Clauses Found: {len(test_state['compliance_output'].get('clauses', []))}\")\n",
    "    print(f\"Risk Level: {test_state['compliance_output'].get('risk_level', 'N/A').upper()}\")\n",
    "    print(f\"\\nAnalysis & Recommendations:\")\n",
    "    print(test_state['compliance_output']['enhanced_analysis'])\n",
    "else:\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\" COMPLIANCE AGENT \")\n",
    "    print(\"No enhanced analysis available\")\n",
    "\n",
    "if test_state['finance_output'] and test_state['finance_output'].get('enhanced_analysis'):\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\" FINANCE AGENT \")\n",
    "    print(f\"Clauses Found: {len(test_state['finance_output'].get('clauses', []))}\")\n",
    "    print(f\"Risk Level: {test_state['finance_output'].get('risk_level', 'N/A').upper()}\")\n",
    "    print(f\"\\nAnalysis & Recommendations:\")\n",
    "    print(test_state['finance_output']['enhanced_analysis'])\n",
    "else:\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\" FINANCE AGENT \")\n",
    "    print(\"No enhanced analysis available\")\n",
    "\n",
    "if test_state['operations_output'] and test_state['operations_output'].get('enhanced_analysis'):\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\" OPERATIONS AGENT \")\n",
    "    print(f\"Clauses Found: {len(test_state['operations_output'].get('clauses', []))}\")\n",
    "    print(f\"Risk Level: {test_state['operations_output'].get('risk_level', 'N/A').upper()}\")\n",
    "    print(f\"\\nAnalysis & Recommendations:\")\n",
    "    print(test_state['operations_output']['enhanced_analysis'])\n",
    "else:\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\" OPERATIONS AGENT \")\n",
    "    print(\"No enhanced analysis available\")\n",
    "\n",
    "print(\"TEST COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcf030eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving Results...\n",
      "   Results saved to: ../Data/Results/Milestone3\\ollama_parallel_test_results.json\n",
      "   Recommendations report saved to: ../Data/Results/Milestone3\\ollama_recommendations_report.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving Results...\")\n",
    "test_output_file = os.path.join(MILESTONE3_OUTPUT, \"ollama_parallel_test_results.json\")\n",
    "\n",
    "def extract_recommendations(agent_output):\n",
    "    if not agent_output:\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        \"clauses_analyzed\": len(agent_output.get('clauses', [])),\n",
    "        \"risk_level\": agent_output.get('risk_level', 'unknown'),\n",
    "        \"confidence\": agent_output.get('confidence', 0),\n",
    "        \"enhanced_analysis\": agent_output.get('enhanced_analysis', 'No analysis available'),\n",
    "        \"model_used\": agent_output.get('model_used', 'N/A'),\n",
    "        \"timestamp\": agent_output.get('timestamp', ''),\n",
    "        \"clauses\": agent_output.get('clauses', [])\n",
    "    }\n",
    "\n",
    "test_results = {\n",
    "    \"execution_metadata\": {\n",
    "        \"timestamp\": test_state['timestamp'],\n",
    "        \"total_time\": round(parallel_total, 2),\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"execution_mode\": \"parallel\",\n",
    "        \"agents_executed\": len(test_state['agent_status'])\n",
    "    },\n",
    "    \"agent_outputs_with_recommendations\": {\n",
    "        \"legal\": extract_recommendations(test_state['legal_output']),\n",
    "        \"compliance\": extract_recommendations(test_state['compliance_output']),\n",
    "        \"finance\": extract_recommendations(test_state['finance_output']),\n",
    "        \"operations\": extract_recommendations(test_state['operations_output'])\n",
    "    },\n",
    "    \"execution_times\": test_state['execution_times'],\n",
    "    \"agent_status\": test_state['agent_status'],\n",
    "    \"completion_timestamps\": test_state['completion_timestamps'],\n",
    "    \"total_clauses\": len(test_state['all_clauses']),\n",
    "    \"milestone3_features\": {\n",
    "        \"parallel_execution\": True,\n",
    "        \"ollama_enhanced_analysis\": True,\n",
    "        \"thread_safe_updates\": True,\n",
    "        \"pinecone_retrieval\": True,\n",
    "        \"dynamic_coordinator_ready\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(test_output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"   Results saved to: {test_output_file}\")\n",
    "\n",
    "recommendations_file = os.path.join(MILESTONE3_OUTPUT, \"ollama_recommendations_report.txt\")\n",
    "with open(recommendations_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"OLLAMA-ENHANCED CONTRACT ANALYSIS RECOMMENDATIONS REPORT\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(f\"Model: {OLLAMA_MODEL}\\n\")\n",
    "    f.write(f\"Timestamp: {test_state['timestamp']}\\n\")\n",
    "    f.write(f\"Total Execution Time: {parallel_total:.2f}s\\n\")\n",
    "    f.write(f\"Total Clauses Analyzed: {len(test_state['all_clauses'])}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"LEGAL AGENT RECOMMENDATIONS\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    if test_state['legal_output']:\n",
    "        f.write(f\"Clauses Analyzed: {len(test_state['legal_output'].get('clauses', []))}\\n\")\n",
    "        f.write(f\"Risk Level: {test_state['legal_output'].get('risk_level', 'N/A').upper()}\\n\")\n",
    "        f.write(f\"Confidence: {test_state['legal_output'].get('confidence', 0)}\\n\")\n",
    "        f.write(f\"Execution Time: {test_state['execution_times'].get('legal', 0):.2f}s\\n\\n\")\n",
    "        f.write(\"Analysis & Recommendations:\\n\")\n",
    "        f.write(\"-\"*70 + \"\\n\")\n",
    "        f.write(test_state['legal_output'].get('enhanced_analysis', 'No analysis available'))\n",
    "        f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"COMPLIANCE AGENT RECOMMENDATIONS\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    if test_state['compliance_output']:\n",
    "        f.write(f\"Clauses Analyzed: {len(test_state['compliance_output'].get('clauses', []))}\\n\")\n",
    "        f.write(f\"Risk Level: {test_state['compliance_output'].get('risk_level', 'N/A').upper()}\\n\")\n",
    "        f.write(f\"Confidence: {test_state['compliance_output'].get('confidence', 0)}\\n\")\n",
    "        f.write(f\"Execution Time: {test_state['execution_times'].get('compliance', 0):.2f}s\\n\\n\")\n",
    "        f.write(\"Analysis & Recommendations:\\n\")\n",
    "        f.write(\"-\"*70 + \"\\n\")\n",
    "        f.write(test_state['compliance_output'].get('enhanced_analysis', 'No analysis available'))\n",
    "        f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"FINANCE AGENT RECOMMENDATIONS\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    if test_state['finance_output']:\n",
    "        f.write(f\"Clauses Analyzed: {len(test_state['finance_output'].get('clauses', []))}\\n\")\n",
    "        f.write(f\"Risk Level: {test_state['finance_output'].get('risk_level', 'N/A').upper()}\\n\")\n",
    "        f.write(f\"Confidence: {test_state['finance_output'].get('confidence', 0)}\\n\")\n",
    "        f.write(f\"Execution Time: {test_state['execution_times'].get('finance', 0):.2f}s\\n\\n\")\n",
    "        f.write(\"Analysis & Recommendations:\\n\")\n",
    "        f.write(\"-\"*70 + \"\\n\")\n",
    "        f.write(test_state['finance_output'].get('enhanced_analysis', 'No analysis available'))\n",
    "        f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"OPERATIONS AGENT RECOMMENDATIONS\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    if test_state['operations_output']:\n",
    "        f.write(f\"Clauses Analyzed: {len(test_state['operations_output'].get('clauses', []))}\\n\")\n",
    "        f.write(f\"Risk Level: {test_state['operations_output'].get('risk_level', 'N/A').upper()}\\n\")\n",
    "        f.write(f\"Confidence: {test_state['operations_output'].get('confidence', 0)}\\n\")\n",
    "        f.write(f\"Execution Time: {test_state['execution_times'].get('operations', 0):.2f}s\\n\\n\")\n",
    "        f.write(\"Analysis & Recommendations:\\n\")\n",
    "        f.write(\"-\"*70 + \"\\n\")\n",
    "        f.write(test_state['operations_output'].get('enhanced_analysis', 'No analysis available'))\n",
    "        f.write(\"\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"END OF REPORT\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"   Recommendations report saved to: {recommendations_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac0cabb",
   "metadata": {},
   "source": [
    "# Persisting Agent Outputs into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcc5585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276b22dd",
   "metadata": {},
   "source": [
    "#### 1. Preparing Agent Outputs for Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a057059e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing Agent Outputs for Storage\n",
      "Loaded outputs from 4 agents\n",
      "Outputs include Ollama-enhanced analysis: True\n",
      "Generated Contract ID: 4ddffbdafb3e\n",
      "Generated Session ID: m3_4ddffbdafb3e_20260116_142038\n",
      "Storage metadata prepared for 4 agents with enhanced analysis\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPreparing Agent Outputs for Storage\")\n",
    "\n",
    "MILESTONE3_OUTPUT = \"../Data/Results/Milestone3\"\n",
    "parallel_output_file = os.path.join(MILESTONE3_OUTPUT, \"parallel_agent_outputs.json\")\n",
    "\n",
    "if os.path.exists(parallel_output_file):\n",
    "    with open(parallel_output_file, 'r', encoding='utf-8') as f:\n",
    "        parallel_data = json.load(f)\n",
    "    \n",
    "    if 'agent_outputs_with_recommendations' in parallel_data:\n",
    "        agent_outputs = parallel_data['agent_outputs_with_recommendations']\n",
    "    elif 'agent_outputs' in parallel_data:\n",
    "        agent_outputs = parallel_data['agent_outputs']\n",
    "    else:\n",
    "        print(\"Error: No agent outputs found in file\")\n",
    "        agent_outputs = {}\n",
    "else:\n",
    "    print(\"Using agent outputs from test_state...\")\n",
    "    agent_outputs = {\n",
    "        'legal': test_state.get('legal_output', {}),\n",
    "        'compliance': test_state.get('compliance_output', {}),\n",
    "        'finance': test_state.get('finance_output', {}),\n",
    "        'operations': test_state.get('operations_output', {})\n",
    "    }\n",
    "    parallel_data = {\n",
    "        'execution_metadata': {\n",
    "            'timestamp': test_state.get('timestamp', datetime.now().isoformat()),\n",
    "            'model': OLLAMA_MODEL,\n",
    "            'total_time': parallel_total\n",
    "        },\n",
    "        'milestone3_features': {\n",
    "            'ollama_enhanced_analysis': True\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(f\"Loaded outputs from {len(agent_outputs)} agents\")\n",
    "print(f\"Outputs include Ollama-enhanced analysis: {parallel_data.get('milestone3_features', {}).get('ollama_enhanced_analysis', True)}\")\n",
    "\n",
    "contract_content = json.dumps(agent_outputs, sort_keys=True)\n",
    "contract_id = hashlib.md5(contract_content.encode()).hexdigest()[:12]\n",
    "session_id = f\"m3_{contract_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "print(f\"Generated Contract ID: {contract_id}\")\n",
    "print(f\"Generated Session ID: {session_id}\")\n",
    "\n",
    "storage_metadata = {\n",
    "    \"contract_id\": contract_id,\n",
    "    \"session_id\": session_id,\n",
    "    \"timestamp\": parallel_data.get('execution_metadata', {}).get('timestamp', datetime.now().isoformat()),\n",
    "    \"model_used\": parallel_data.get('execution_metadata', {}).get('model', OLLAMA_MODEL),\n",
    "    \"execution_mode\": \"parallel_with_ollama_enhancement\",\n",
    "    \"agents_processed\": list(agent_outputs.keys()),\n",
    "    \"total_execution_time\": parallel_data.get('execution_metadata', {}).get('total_time', 0)\n",
    "}\n",
    "\n",
    "print(f\"Storage metadata prepared for {len(agent_outputs)} agents with enhanced analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa84d2",
   "metadata": {},
   "source": [
    "#### 2. Converting Outputs to Text for Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9811126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting Outputs to Text for Embedding\n",
      "  Legal: 2484 characters with Ollama analysis\n",
      "  Compliance: 3444 characters with Ollama analysis\n",
      "  Finance: 3598 characters with Ollama analysis\n",
      "  Operations: 3413 characters with Ollama analysis\n",
      "\n",
      "Total text records created: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConverting Outputs to Text for Embedding\")\n",
    "\n",
    "def agent_output_to_text(agent_name, agent_data):\n",
    "    if not agent_data:\n",
    "        return \"\"\n",
    "    \n",
    "    text_parts = [\n",
    "        f\"Agent: {agent_name}\",\n",
    "        f\"Risk Level: {agent_data.get('risk_level', 'N/A')}\",\n",
    "        f\"Confidence: {agent_data.get('confidence', 0)}\",\n",
    "        f\"Clauses Analyzed: {agent_data.get('clauses_analyzed', 0)}\",\n",
    "        f\"Model Used: {agent_data.get('model_used', OLLAMA_MODEL)}\"\n",
    "    ]\n",
    "    \n",
    "    if agent_data.get('clauses'):\n",
    "        clauses_text = \" | \".join([c.get('clause', '') for c in agent_data['clauses'][:200]]) \n",
    "        text_parts.append(f\"Clauses: {clauses_text}\")\n",
    "    \n",
    "    if agent_data.get('enhanced_analysis'):\n",
    "        text_parts.append(f\"Analysis and Recommendations: {agent_data['enhanced_analysis']}\")\n",
    "    \n",
    "    return \" | \".join(text_parts)\n",
    "\n",
    "text_records = {}\n",
    "for agent_name, agent_data in agent_outputs.items():\n",
    "    text = agent_output_to_text(agent_name, agent_data)\n",
    "    text_records[agent_name] = text\n",
    "    has_analysis = \"with Ollama analysis\" if agent_data.get('enhanced_analysis') else \" no analysis\"\n",
    "    print(f\"  {agent_name.capitalize()}: {len(text)} characters {has_analysis}\")\n",
    "\n",
    "print(f\"\\nTotal text records created: {len(text_records)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98500de2",
   "metadata": {},
   "source": [
    "#### 3. Creating Vector Records with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef86f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Vector Records with Enhanced Analysis (FIXED)\n",
      "  Legal: 2 clauses\n",
      "  Compliance: 1 clauses\n",
      "  Finance: 3 clauses\n",
      "  Operations: 2 clauses\n",
      "\n",
      "Created 5 vector records:\n",
      "  - Agent records: 4\n",
      "  - Routing records: 1\n",
      "\n",
      "All records ready for embedding and storage\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating Vector Records with Enhanced Analysis (FIXED)\")\n",
    "\n",
    "current_timestamp = datetime.now().isoformat()\n",
    "\n",
    "vector_records = []\n",
    "for agent_name, text in text_records.items():\n",
    "    if not text:\n",
    "        continue\n",
    "    \n",
    "    agent_data = agent_outputs[agent_name]\n",
    "    \n",
    "    clauses_list = agent_data.get('clauses', [])\n",
    "    num_clauses = len(clauses_list) if clauses_list else agent_data.get('clauses_analyzed', 0)\n",
    "    \n",
    "    record = {\n",
    "        \"id\": f\"{session_id}_{agent_name}\",\n",
    "        \"text\": text,\n",
    "        \"metadata\": {\n",
    "            \"agent_name\": agent_name,\n",
    "            \"contract_id\": contract_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"timestamp\": current_timestamp,\n",
    "            \"risk_level\": agent_data.get('risk_level', 'unknown'),\n",
    "            \"confidence\": float(agent_data.get('confidence', 0)),\n",
    "            \"num_clauses\": num_clauses,  \n",
    "            \"model\": agent_data.get('model_used', OLLAMA_MODEL),\n",
    "            \"processing_stage\": \"ollama_enhanced\",\n",
    "            \"has_recommendations\": bool(agent_data.get('enhanced_analysis')),\n",
    "            \"namespace\": f\"{agent_name}_intermediate\",\n",
    "            \"execution_time\": test_state.get('execution_times', {}).get(agent_name, 0),\n",
    "            \"clauses_analyzed\": num_clauses  \n",
    "        }\n",
    "    }\n",
    "    vector_records.append(record)\n",
    "    \n",
    "    print(f\"  {agent_name.capitalize()}: {num_clauses} clauses\")\n",
    "\n",
    "if len(vector_records) > 0:\n",
    "    routing_record = {\n",
    "        \"id\": f\"{session_id}_routing_decision\",\n",
    "        \"text\": f\"Query routing for session {session_id}: Agents {', '.join(agent_outputs.keys())} activated for contract analysis\",\n",
    "        \"metadata\": {\n",
    "            \"contract_id\": contract_id,\n",
    "            \"session_id\": session_id,\n",
    "            \"timestamp\": storage_metadata['timestamp'],\n",
    "            \"model\": OLLAMA_MODEL,\n",
    "            \"processing_stage\": \"routing_decision\",\n",
    "            \"namespace\": \"routing_decisions\",\n",
    "            \"agents_activated\": list(agent_outputs.keys()),\n",
    "            \"execution_mode\": storage_metadata['execution_mode'],\n",
    "            \"total_agents\": len(agent_outputs)\n",
    "        }\n",
    "    }\n",
    "    vector_records.append(routing_record)\n",
    "\n",
    "print(f\"\\nCreated {len(vector_records)} vector records:\")\n",
    "print(f\"  - Agent records: {len(agent_outputs)}\")\n",
    "print(f\"  - Routing records: 1\")\n",
    "print(f\"\\nAll records ready for embedding and storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbcd4cf",
   "metadata": {},
   "source": [
    "#### 4. Embeding Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ecbceed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding Records with Enhanced Analysis\n",
      "Loaded Sentence Transformer: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "Generating embeddings for text including Ollama recommendations...\n",
      "\n",
      "  [LEGAL] 384 dimensions with recommendations\n",
      "  [COMPLIANCE] 384 dimensions with recommendations\n",
      "  [FINANCE] 384 dimensions with recommendations\n",
      "  [OPERATIONS] 384 dimensions with recommendations\n",
      "  [ROUTING] m3_4ddffbdafb3e_20260116_142038_routing_decision: 384 dimensions\n",
      "\n",
      "Total embeddings generated: 5\n",
      "Embeddings capture both clause content AND Ollama-enhanced analysis\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEmbedding Records with Enhanced Analysis\")\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Loaded Sentence Transformer: {embedding_model}\")\n",
    "print(\"Generating embeddings for text including Ollama recommendations...\\n\")\n",
    "\n",
    "for record in vector_records:\n",
    "    embedding = embedding_model.encode(record['text'])\n",
    "    record['embedding'] = embedding.tolist()\n",
    "    \n",
    "    record_type = record['metadata'].get('processing_stage', 'unknown')\n",
    "    if record_type == \"routing_decision\":\n",
    "        print(f\"  [ROUTING] {record['id']}: {len(record['embedding'])} dimensions\")\n",
    "    else:\n",
    "        agent_name = record['metadata']['agent_name']\n",
    "        has_recs = \"with recommendations\" if record['metadata']['has_recommendations'] else \"no recommendations\"\n",
    "        print(f\"  [{agent_name.upper()}] {len(record['embedding'])} dimensions {has_recs}\")\n",
    "\n",
    "print(f\"\\nTotal embeddings generated: {len(vector_records)}\")\n",
    "print(\"Embeddings capture both clause content AND Ollama-enhanced analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb0e53",
   "metadata": {},
   "source": [
    "#### 5. Storing in Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e777cce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vector records prepared: 5\n",
      "1. ID: m3_4ddffbdafb3e_20260116_142038_legal\n",
      "   Agent: legal\n",
      "   Namespace: legal_intermediate\n",
      "   Has embedding: True\n",
      "\n",
      "2. ID: m3_4ddffbdafb3e_20260116_142038_compliance\n",
      "   Agent: compliance\n",
      "   Namespace: compliance_intermediate\n",
      "   Has embedding: True\n",
      "\n",
      "3. ID: m3_4ddffbdafb3e_20260116_142038_finance\n",
      "   Agent: finance\n",
      "   Namespace: finance_intermediate\n",
      "   Has embedding: True\n",
      "\n",
      "4. ID: m3_4ddffbdafb3e_20260116_142038_operations\n",
      "   Agent: operations\n",
      "   Namespace: operations_intermediate\n",
      "   Has embedding: True\n",
      "\n",
      "5. ID: m3_4ddffbdafb3e_20260116_142038_routing_decision\n",
      "   Agent: N/A\n",
      "   Namespace: routing_decisions\n",
      "   Has embedding: True\n",
      "\n",
      "  → Connecting to Pinecone...\n",
      "  → Creating new index: clauseai-agents\n",
      "  Index created\n",
      "\n",
      "  → Prepared 5 namespaces:\n",
      "     legal_intermediate: 1 vectors\n",
      "     compliance_intermediate: 1 vectors\n",
      "     finance_intermediate: 1 vectors\n",
      "     operations_intermediate: 1 vectors\n",
      "     routing_decisions: 1 vectors\n",
      "\n",
      "  → Upserting to namespace: legal_intermediate\n",
      "     Batch 1: 1 vectors upserted\n",
      "\n",
      "  → Upserting to namespace: compliance_intermediate\n",
      "     Batch 1: 1 vectors upserted\n",
      "\n",
      "  → Upserting to namespace: finance_intermediate\n",
      "     Batch 1: 1 vectors upserted\n",
      "\n",
      "  → Upserting to namespace: operations_intermediate\n",
      "     Batch 1: 1 vectors upserted\n",
      "\n",
      "  → Upserting to namespace: routing_decisions\n",
      "     Batch 1: 1 vectors upserted\n",
      "\n",
      "Index statistics:\n",
      "  Total vectors: 5\n",
      "  Namespaces:\n",
      "    - finance_intermediate: 1 vectors\n",
      "    - compliance_intermediate: 1 vectors\n",
      "    - legal_intermediate: 1 vectors\n",
      "    - operations_intermediate: 1 vectors\n",
      "    - routing_decisions: 1 vectors\n",
      "\n",
      "Storage process completed\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nVector records prepared: {len(vector_records)}\")\n",
    "for i, record in enumerate(vector_records, 1):\n",
    "    print(f\"{i}. ID: {record['id']}\")\n",
    "    print(f\"   Agent: {record['metadata'].get('agent_name', 'N/A')}\")\n",
    "    print(f\"   Namespace: {record['metadata'].get('namespace', 'N/A')}\")\n",
    "    print(f\"   Has embedding: {bool(record.get('embedding'))}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "PINECONE_API_KEY = 'pcsk_3ftgmC_GzUZkRCnxa2jmDu7TTjnGWjC3QaN8c2PcQ5KN5PUSyQaEmmcdGUGu2BLd4Y7TRn'\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"clauseai-agents\"\n",
    "\n",
    "print(f\"  → Connecting to Pinecone...\")\n",
    "existing_indexes = [idx.name for idx in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    print(f\"  → Creating new index: {index_name}\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384, \n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "    print(f\"  Index created\")\n",
    "    time.sleep(10)\n",
    "else:\n",
    "    print(f\"  Using existing index: {index_name}\")\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vectors_by_namespace = {}\n",
    "for record in vector_records:\n",
    "    namespace = record['metadata'].get('namespace', 'default')\n",
    "    if namespace not in vectors_by_namespace:\n",
    "        vectors_by_namespace[namespace] = []\n",
    "    \n",
    "    vectors_by_namespace[namespace].append({\n",
    "        \"id\": record['id'],\n",
    "        \"values\": record['embedding'],\n",
    "        \"metadata\": record['metadata']\n",
    "    })\n",
    "\n",
    "print(f\"\\n  → Prepared {len(vectors_by_namespace)} namespaces:\")\n",
    "for ns, vecs in vectors_by_namespace.items():\n",
    "    print(f\"     {ns}: {len(vecs)} vectors\")\n",
    "\n",
    "for namespace, vectors in vectors_by_namespace.items():\n",
    "    print(f\"\\n  → Upserting to namespace: {namespace}\")\n",
    "    try:\n",
    "        batch_size = 100\n",
    "        for i in range(0, len(vectors), batch_size):\n",
    "            batch = vectors[i:i+batch_size]\n",
    "            upsert_response = index.upsert(vectors=batch, namespace=namespace)\n",
    "            print(f\"     Batch {i//batch_size + 1}: {upsert_response.upserted_count} vectors upserted\")\n",
    "    except Exception as e:\n",
    "        print(f\"     Error upserting to {namespace}: {e}\")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"\\nIndex statistics:\")\n",
    "print(f\"  Total vectors: {stats.total_vector_count}\")\n",
    "if hasattr(stats, 'namespaces') and stats.namespaces:\n",
    "    print(f\"  Namespaces:\")\n",
    "    for ns, ns_stats in stats.namespaces.items():\n",
    "        print(f\"    - {ns}: {ns_stats.vector_count} vectors\")\n",
    "\n",
    "print(f\"\\nStorage process completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d4e37c",
   "metadata": {},
   "source": [
    "#### 6. Verifying Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "421901ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying Storage and Testing Ollama-Enhanced Retrieval\n",
      "\n",
      "Pinecone Index Statistics:\n",
      "  Total Vectors: 5\n",
      "  Dimension: 384\n",
      "  Index Fullness: 0.0\n",
      "\n",
      "  Namespaces:\n",
      "    - operations_intermediate: 1 vectors\n",
      "    - legal_intermediate: 1 vectors\n",
      "    - finance_intermediate: 1 vectors\n",
      "    - routing_decisions: 1 vectors\n",
      "    - compliance_intermediate: 1 vectors\n",
      "TEST QUERY: Retrieving and Analyzing with Ollama\n",
      "\n",
      "User Query: What are the high risk compliance and confidentiality issues in this contract?\n",
      "\n",
      "Searching across 4 namespaces...\n",
      "  legal_intermediate: 1 matches\n",
      "  compliance_intermediate: 1 matches\n",
      "  finance_intermediate: 1 matches\n",
      "  operations_intermediate: 1 matches\n",
      "\n",
      "  Total retrieved: 4 enhanced analysis records\n",
      "RETRIEVED ENHANCED ANALYSIS FROM PINECONE\n",
      "\n",
      "1. LEGAL Agent\n",
      "   Risk Level: LOW\n",
      "   Confidence: 0.85\n",
      "   Clauses: 2\n",
      "   Similarity Score: 0.4877\n",
      "   Namespace: legal_intermediate\n",
      "   Has Recommendations: True\n",
      "\n",
      "2. FINANCE Agent\n",
      "   Risk Level: MEDIUM\n",
      "   Confidence: 0.7\n",
      "   Clauses: 3\n",
      "   Similarity Score: 0.4758\n",
      "   Namespace: finance_intermediate\n",
      "   Has Recommendations: True\n",
      "\n",
      "3. COMPLIANCE Agent\n",
      "   Risk Level: HIGH\n",
      "   Confidence: 1\n",
      "   Clauses: 1\n",
      "   Similarity Score: 0.4530\n",
      "   Namespace: compliance_intermediate\n",
      "   Has Recommendations: True\n",
      "\n",
      "4. OPERATIONS Agent\n",
      "   Risk Level: MEDIUM\n",
      "   Confidence: 0.8\n",
      "   Clauses: 2\n",
      "   Similarity Score: 0.3850\n",
      "   Namespace: operations_intermediate\n",
      "   Has Recommendations: True\n",
      "OLLAMA COMPREHENSIVE RISK ANALYSIS\n",
      "\n",
      "  → Generating risk analysis with Ollama gemma2:9b...\n",
      "\n",
      "======================================================================\n",
      "## Contract Risk Assessment \n",
      "\n",
      "Based on the provided agent analyses, here's a comprehensive risk assessment of the contract:\n",
      "\n",
      "**1. Overall Risk Assessment:** **Medium**\n",
      "\n",
      "While the LEGAL and FINANCE agents present moderate risks, the COMPLIANCE agent analysis flags a high-risk level with complete confidence. This significantly elevates the overall contract risk. \n",
      "\n",
      "**2. Key Compliance & Confidentiality Risk Factors:**\n",
      "\n",
      "* **Incomplete Clause Analysis:** The COMPLIANCE agent only analyzed one clause, indicating potential gaps in coverage for critical compliance aspects.\n",
      "* **High Confidence Level:** The 100% confidence level assigned to the high-risk assessment by the COMPLIANCE agent suggests a strong likelihood of serious compliance issues within the contract.\n",
      "\n",
      "**3. Specific Concerns and Vulnerabilities:**\n",
      "\n",
      "* **Unidentified Compliance Gaps:**  The limited analysis by the COMPLIANCE agent raises concerns about missing or inadequate clauses addressing essential regulatory requirements, industry standards, or legal obligations.\n",
      "* **Potential Data Breaches:** Without a thorough review of confidentiality clauses, the contract might lack sufficient safeguards to protect sensitive information, increasing the risk of data breaches and associated legal/reputational damage.\n",
      "\n",
      "**4. Recommended Remediation Actions:**\n",
      "\n",
      "* **Comprehensive COMPLIANCE Review:** Conduct a detailed analysis of all relevant clauses by legal experts specializing in compliance to identify and address potential gaps.\n",
      "* **Strengthen Confidentiality Provisions:**  Ensure robust confidentiality clauses are included, outlining clear responsibilities for data protection, access controls, breach notification procedures, and liability limitations.\n",
      "* **Third-Party Due Diligence:** If the contract involves third parties handling sensitive information, perform thorough due diligence to assess their compliance practices and security measures.\n",
      "\n",
      "**5. Priority Level:** **Immediate**\n",
      "\n",
      "Given the high risk identified by the COMPLIANCE agent and the potential for severe consequences, addressing these issues should be prioritized immediately. Delaying action could result in significant legal, financial, or reputational damage. \n",
      "\n",
      "\n",
      "It's crucial to remember that this analysis is based on limited information. A thorough review of the actual contract clauses is essential for a comprehensive risk assessment and informed decision-making.\n",
      "======================================================================\n",
      "VERIFICATION COMPLETE\n",
      "\n",
      "Model: gemma2:9b\n",
      "Namespaces Searched: 4\n",
      "Records Retrieved: 4\n",
      "Ollama Analysis: Generated\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nVerifying Storage and Testing Ollama-Enhanced Retrieval\")\n",
    "\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"\\nPinecone Index Statistics:\")\n",
    "print(f\"  Total Vectors: {stats.total_vector_count}\")\n",
    "print(f\"  Dimension: {stats.dimension}\")\n",
    "print(f\"  Index Fullness: {stats.index_fullness}\")\n",
    "\n",
    "if hasattr(stats, 'namespaces') and stats.namespaces:\n",
    "    print(f\"\\n  Namespaces:\")\n",
    "    for ns, ns_stats in stats.namespaces.items():\n",
    "        print(f\"    - {ns}: {ns_stats.vector_count} vectors\")\n",
    "\n",
    "print(\"TEST QUERY: Retrieving and Analyzing with Ollama\")\n",
    "\n",
    "query_text = \"What are the high risk compliance and confidentiality issues in this contract?\"\n",
    "print(f\"\\nUser Query: {query_text}\")\n",
    "\n",
    "query_embedding = embedding_model.encode(query_text).tolist()\n",
    "\n",
    "agent_namespaces = ['legal_intermediate', 'compliance_intermediate', 'finance_intermediate', 'operations_intermediate']\n",
    "\n",
    "all_results = []\n",
    "print(f\"\\nSearching across {len(agent_namespaces)} namespaces...\")\n",
    "\n",
    "for namespace in agent_namespaces:\n",
    "    try:\n",
    "        results = index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=2,\n",
    "            include_metadata=True,\n",
    "            namespace=namespace\n",
    "        )\n",
    "        if results.matches:\n",
    "            for match in results.matches:\n",
    "                all_results.append(match)\n",
    "            print(f\"  {namespace}: {len(results.matches)} matches\")\n",
    "        else:\n",
    "            print(f\"  - {namespace}: 0 matches\")\n",
    "    except Exception as e:\n",
    "        print(f\"  {namespace}: Error - {e}\")\n",
    "\n",
    "print(f\"\\n  Total retrieved: {len(all_results)} enhanced analysis records\")\n",
    "\n",
    "all_results.sort(key=lambda x: x.score, reverse=True)\n",
    "\n",
    "print(\"RETRIEVED ENHANCED ANALYSIS FROM PINECONE\")\n",
    "\n",
    "retrieved_context = []\n",
    "for i, match in enumerate(all_results[:5], 1):\n",
    "    meta = match.metadata\n",
    "    agent_name = meta.get('agent_name', 'Unknown')\n",
    "    print(f\"\\n{i}. {agent_name.upper()} Agent\")\n",
    "    print(f\"   Risk Level: {meta.get('risk_level', 'N/A').upper()}\")\n",
    "    print(f\"   Confidence: {meta.get('confidence', 0)}\")\n",
    "    print(f\"   Clauses: {meta.get('num_clauses', 0)}\")\n",
    "    print(f\"   Similarity Score: {match.score:.4f}\")\n",
    "    print(f\"   Namespace: {meta.get('namespace', 'N/A')}\")\n",
    "    print(f\"   Has Recommendations: {meta.get('has_recommendations', False)}\")\n",
    "    \n",
    "    retrieved_context.append({\n",
    "        'agent': agent_name,\n",
    "        'risk_level': meta.get('risk_level', 'unknown'),\n",
    "        'confidence': meta.get('confidence', 0),\n",
    "        'num_clauses': meta.get('num_clauses', 0),\n",
    "        'namespace': meta.get('namespace', 'N/A')\n",
    "    })\n",
    "\n",
    "\n",
    "print(\"OLLAMA COMPREHENSIVE RISK ANALYSIS\")\n",
    "\n",
    "if len(retrieved_context) > 0:\n",
    "    synthesis_prompt = f\"\"\"You are analyzing contract risk based on previously analyzed results.\n",
    "\n",
    "User Query: {query_text}\n",
    "\n",
    "Retrieved Analysis Results:\n",
    "\"\"\"\n",
    "    for i, ctx in enumerate(retrieved_context, 1):\n",
    "        synthesis_prompt += f\"\\n{i}. {ctx['agent'].upper()} Agent Analysis:\"\n",
    "        synthesis_prompt += f\"\\n   - Risk Level: {ctx['risk_level']}\"\n",
    "        synthesis_prompt += f\"\\n   - Confidence: {ctx['confidence']}\"\n",
    "        synthesis_prompt += f\"\\n   - Clauses Analyzed: {ctx['num_clauses']}\"\n",
    "\n",
    "    synthesis_prompt += \"\"\"\n",
    "\n",
    "Based on these agent analyses, provide:\n",
    "1. Overall Risk Assessment (low/medium/high/critical)\n",
    "2. Key Compliance & Confidentiality Risk Factors\n",
    "3. Specific Concerns and Vulnerabilities\n",
    "4. Recommended Remediation Actions\n",
    "5. Priority Level (immediate/high/medium/low)\n",
    "\n",
    "Comprehensive Analysis:\"\"\"\n",
    "\n",
    "    print(\"\\n  → Generating risk analysis with Ollama gemma2:9b...\")\n",
    "    risk_analysis = call_ollama(synthesis_prompt, max_tokens=700)\n",
    "    \n",
    "    if risk_analysis:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(risk_analysis)\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(\"\\n  Ollama analysis failed\")\n",
    "else:\n",
    "    print(\"\\n  No results retrieved - cannot perform analysis\")\n",
    "    risk_analysis = None\n",
    "\n",
    "print(\"VERIFICATION COMPLETE\")\n",
    "\n",
    "print(f\"\\nModel: {OLLAMA_MODEL}\")\n",
    "print(f\"Namespaces Searched: {len(agent_namespaces)}\")\n",
    "print(f\"Records Retrieved: {len(all_results)}\")\n",
    "print(f\"Ollama Analysis: {'Generated' if risk_analysis else 'Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8470bea1",
   "metadata": {},
   "source": [
    "#### 7. Timestamp & Contract ID Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d0695dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STORING TIMESTAMP & METADATA\n",
      "\n",
      "Storage metadata saved: ../Data/Results/Milestone3\\vector_storage_metadata.json\n",
      "Execution summary saved: ../Data/Results/Milestone3\\milestone3_execution_summary.txt\n",
      "METADATA STORAGE COMPLETE\n",
      "Contract ID: 4ddffbdafb3e\n",
      "Session ID: m3_4ddffbdafb3e_20260116_142038\n",
      "Records Stored: 5\n",
      "With Ollama Analysis: 4\n",
      "Namespaces: legal_intermediate, compliance_intermediate, finance_intermediate, operations_intermediate, routing_decisions\n"
     ]
    }
   ],
   "source": [
    "print(\"STORING TIMESTAMP & METADATA\")\n",
    "\n",
    "storage_metadata = {\n",
    "    \"contract_id\": contract_id,\n",
    "    \"session_id\": session_id,\n",
    "    \"storage_timestamp\": current_timestamp,\n",
    "    \"execution_metadata\": {\n",
    "        \"model\": OLLAMA_MODEL,\n",
    "        \"execution_mode\": \"parallel_with_ollama_enhancement\",\n",
    "        \"total_execution_time\": parallel_data.get('execution_metadata', {}).get('total_time', 0),\n",
    "        \"agents_executed\": len(agent_outputs)\n",
    "    },\n",
    "    \"vector_database\": {\n",
    "        \"provider\": \"Pinecone\",\n",
    "        \"index_name\": index_name,\n",
    "        \"dimension\": 384,\n",
    "        \"metric\": \"cosine\",\n",
    "        \"namespaces_used\": list(vectors_by_namespace.keys()) if 'vectors_by_namespace' in locals() else []\n",
    "    },\n",
    "    \"embedding_model\": {\n",
    "        \"name\": \"all-MiniLM-L6-v2\",\n",
    "        \"dimension\": 384,\n",
    "        \"provider\": \"sentence-transformers\"\n",
    "    },\n",
    "    \"stored_records\": [\n",
    "        {\n",
    "            \"id\": record['id'],\n",
    "            \"agent\": record['metadata'].get('agent_name', 'N/A'),\n",
    "            \"timestamp\": record['metadata'].get('timestamp', 'N/A'),\n",
    "            \"contract_id\": record['metadata'].get('contract_id', contract_id),\n",
    "            \"session_id\": record['metadata'].get('session_id', session_id),\n",
    "            \"risk_level\": record['metadata'].get('risk_level', 'unknown'),\n",
    "            \"confidence\": record['metadata'].get('confidence', 0),\n",
    "            \"num_clauses\": record['metadata'].get('num_clauses', 0),\n",
    "            \"text_length\": len(record['text']),\n",
    "            \"namespace\": record['metadata'].get('namespace', 'N/A'),\n",
    "            \"processing_stage\": record['metadata'].get('processing_stage', 'N/A'),\n",
    "            \"has_ollama_analysis\": record['metadata'].get('has_recommendations', False),\n",
    "            \"model_used\": record['metadata'].get('model', OLLAMA_MODEL)\n",
    "        }\n",
    "        for record in vector_records\n",
    "    ],\n",
    "    \"statistics\": {\n",
    "        \"total_records\": len(vector_records),\n",
    "        \"total_vectors_in_index\": stats.total_vector_count,\n",
    "        \"agents_processed\": list(agent_outputs.keys()),\n",
    "        \"namespaces_created\": len(vectors_by_namespace) if 'vectors_by_namespace' in locals() else 0,\n",
    "        \"records_with_ollama_analysis\": sum(1 for r in vector_records if r['metadata'].get('has_recommendations', False))\n",
    "    },\n",
    "    \"milestone3_features\": {\n",
    "        \"parallel_execution\": True,\n",
    "        \"ollama_enhanced_analysis\": True,\n",
    "        \"dynamic_coordinator\": True,\n",
    "        \"pinecone_namespaces\": True,\n",
    "        \"thread_safe_updates\": True,\n",
    "        \"multi_turn_ready\": True\n",
    "    },\n",
    "    \"audit_trail\": {\n",
    "        \"query_processed\": test_state.get('query', 'N/A') if 'test_state' in locals() else 'N/A',\n",
    "        \"routing_decision_stored\": True,\n",
    "        \"intermediate_results_stored\": True,\n",
    "        \"retrieval_tested\": len(all_results) > 0 if 'all_results' in locals() else False\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_file = os.path.join(MILESTONE3_OUTPUT, \"vector_storage_metadata.json\")\n",
    "with open(metadata_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(storage_metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\nStorage metadata saved: {metadata_file}\")\n",
    "\n",
    "summary_file = os.path.join(MILESTONE3_OUTPUT, \"milestone3_execution_summary.txt\")\n",
    "with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"MILESTONE 3 EXECUTION SUMMARY\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\\n\")\n",
    "    f.write(f\"Session ID: {session_id}\\n\")\n",
    "    f.write(f\"Contract ID: {contract_id}\\n\")\n",
    "    f.write(f\"Timestamp: {current_timestamp}\\n\")\n",
    "    f.write(f\"Model Used: {OLLAMA_MODEL}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"FEATURES IMPLEMENTED\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    for feature, status in storage_metadata['milestone3_features'].items():\n",
    "        f.write(f\"  {'✓' if status else '✗'} {feature.replace('_', ' ').title()}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    f.write(\"STORAGE DETAILS\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(f\"  Total Records Stored: {storage_metadata['statistics']['total_records']}\\n\")\n",
    "    f.write(f\"  Records with Ollama Analysis: {storage_metadata['statistics']['records_with_ollama_analysis']}\\n\")\n",
    "    f.write(f\"  Agents Processed: {', '.join(storage_metadata['statistics']['agents_processed'])}\\n\")\n",
    "    f.write(f\"  Namespaces Created: {storage_metadata['statistics']['namespaces_created']}\\n\")\n",
    "    f.write(f\"  Total Vectors in Index: {storage_metadata['statistics']['total_vectors_in_index']}\\n\\n\")\n",
    "    \n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    f.write(\"PINECONE NAMESPACES\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    if storage_metadata['vector_database']['namespaces_used']:\n",
    "        for ns in storage_metadata['vector_database']['namespaces_used']:\n",
    "            f.write(f\"  - {ns}\\n\")\n",
    "    else:\n",
    "        f.write(\"  No namespaces recorded\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    f.write(\"STORED RECORDS\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "    for record in storage_metadata['stored_records']:\n",
    "        f.write(f\"\\n  {record['agent'].upper()}:\\n\")\n",
    "        f.write(f\"    ID: {record['id']}\\n\")\n",
    "        f.write(f\"    Risk Level: {record['risk_level']}\\n\")\n",
    "        f.write(f\"    Confidence: {record['confidence']}\\n\")\n",
    "        f.write(f\"    Clauses: {record['num_clauses']}\\n\")\n",
    "        f.write(f\"    Namespace: {record['namespace']}\\n\")\n",
    "        f.write(f\"    Ollama Analysis: {'Yes' if record['has_ollama_analysis'] else 'No'}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "    f.write(\"END OF SUMMARY\\n\")\n",
    "    f.write(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(f\"Execution summary saved: {summary_file}\")\n",
    "\n",
    "print(\"METADATA STORAGE COMPLETE\")\n",
    "print(f\"Contract ID: {contract_id}\")\n",
    "print(f\"Session ID: {session_id}\")\n",
    "print(f\"Records Stored: {len(vector_records)}\")\n",
    "print(f\"With Ollama Analysis: {storage_metadata['statistics']['records_with_ollama_analysis']}\")\n",
    "if storage_metadata['vector_database']['namespaces_used']:\n",
    "    print(f\"Namespaces: {', '.join(storage_metadata['vector_database']['namespaces_used'])}\")\n",
    "else:\n",
    "    print(f\"Namespaces: None recorded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b4aa780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector records saved: ../Data/Results/Milestone3\\vector_records_new.json\n",
      "FINAL SUMMARY\n",
      "\n",
      "  Contract ID: 4ddffbdafb3e\n",
      "  Session ID: m3_4ddffbdafb3e_20260116_142038\n",
      "  Records Stored: 5\n",
      "  Timestamp: 2026-01-16T14:36:23.100878\n",
      "  Pinecone Index: clauseai-agents\n",
      "  Total Vectors in Index: 5\n",
      "\n",
      "  Namespaces:\n",
      "    - operations_intermediate: 1 vectors\n",
      "    - legal_intermediate: 1 vectors\n",
      "    - finance_intermediate: 1 vectors\n",
      "    - routing_decisions: 1 vectors\n",
      "    - compliance_intermediate: 1 vectors\n",
      "\n",
      "  Model Used: gemma2:9b\n",
      "  Embedding Model: all-MiniLM-L6-v2 (384 dimensions)\n",
      "\n",
      "  Agent Records:\n",
      "    - Legal: 2 clauses, low risk, ✓ Ollama analysis\n",
      "    - Compliance: 1 clauses, high risk, ✓ Ollama analysis\n",
      "    - Finance: 3 clauses, medium risk, ✓ Ollama analysis\n",
      "    - Operations: 2 clauses, medium risk, ✓ Ollama analysis\n",
      "  Routing Decisions: 1\n"
     ]
    }
   ],
   "source": [
    "records_file = os.path.join(MILESTONE3_OUTPUT, \"vector_records_new.json\")\n",
    "records_for_save = []\n",
    "for record in vector_records:\n",
    "    record_copy = record.copy()\n",
    "    record_copy['embedding_dimension'] = len(record['embedding'])\n",
    "    del record_copy['embedding']  \n",
    "    records_for_save.append(record_copy)\n",
    "\n",
    "with open(records_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(records_for_save, f, indent=2)\n",
    "\n",
    "print(f\"Vector records saved: {records_file}\")\n",
    "\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(f\"\\n  Contract ID: {contract_id}\")\n",
    "print(f\"  Session ID: {session_id}\")\n",
    "print(f\"  Records Stored: {len(vector_records)}\")\n",
    "print(f\"  Timestamp: {current_timestamp}\")\n",
    "print(f\"  Pinecone Index: {index_name}\")\n",
    "print(f\"  Total Vectors in Index: {stats.total_vector_count}\")\n",
    "\n",
    "if hasattr(stats, 'namespaces') and stats.namespaces:\n",
    "    print(f\"\\n  Namespaces:\")\n",
    "    for ns, ns_stats in stats.namespaces.items():\n",
    "        print(f\"    - {ns}: {ns_stats.vector_count} vectors\")\n",
    "\n",
    "print(f\"\\n  Model Used: {OLLAMA_MODEL}\")\n",
    "print(f\"  Embedding Model: all-MiniLM-L6-v2 (384 dimensions)\")\n",
    "\n",
    "print(f\"\\n  Agent Records:\")\n",
    "agent_count = 0\n",
    "routing_count = 0\n",
    "for record in vector_records:\n",
    "    if record['metadata'].get('processing_stage') == 'routing_decision':\n",
    "        routing_count += 1\n",
    "    else:\n",
    "        agent_count += 1\n",
    "        agent_name = record['metadata'].get('agent_name', 'unknown')\n",
    "        has_recs = record['metadata'].get('has_recommendations', False)\n",
    "        num_clauses = record['metadata'].get('num_clauses', 0)\n",
    "        risk = record['metadata'].get('risk_level', 'N/A')\n",
    "        print(f\"    - {agent_name.capitalize()}: {num_clauses} clauses, {risk} risk, {'✓' if has_recs else '✗'} Ollama analysis\")\n",
    "\n",
    "print(f\"  Routing Decisions: {routing_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad4f71e",
   "metadata": {},
   "source": [
    "# Querying Stored Agent Memory - Recall & Reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229c563",
   "metadata": {},
   "source": [
    "#### 1. Loading Stored Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a428a97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing Components for Memory Retrieval\n",
      "Embedding Model: SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ")\n",
      "Connected to Pinecone index: contract-agents\n",
      "\n",
      "Index Statistics:\n",
      "  Total Vectors: 5\n",
      "  Dimension: 384\n",
      "\n",
      "  Available Namespaces:\n",
      "    - finance_intermediate: 1 vectors\n",
      "    - routing_decisions: 1 vectors\n",
      "    - compliance_intermediate: 1 vectors\n",
      "    - operations_intermediate: 1 vectors\n",
      "    - legal_intermediate: 1 vectors\n",
      "\n",
      "Ollama Model: gemma2:9b\n",
      "Ready for query-retrieve-analyze workflow\n"
     ]
    }
   ],
   "source": [
    "MILESTONE3_OUTPUT = \"../Data/Results/Milestone3\"\n",
    "PINECONE_API_KEY = 'pcsk_3ftgmC_GzUZkRCnxa2jmDu7TTjnGWjC3QaN8c2PcQ5KN5PUSyQaEmmcdGUGu2BLd4Y7TRn'\n",
    "\n",
    "print(\"\\nInitializing Components for Memory Retrieval\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"clauseai-agents\")\n",
    "\n",
    "print(f\"Embedding Model: {embedding_model}\")\n",
    "print(f\"Connected to Pinecone index: contract-agents\")\n",
    "\n",
    "stats = index.describe_index_stats()\n",
    "print(f\"\\nIndex Statistics:\")\n",
    "print(f\"  Total Vectors: {stats.total_vector_count}\")\n",
    "print(f\"  Dimension: {stats.dimension}\")\n",
    "\n",
    "if hasattr(stats, 'namespaces') and stats.namespaces:\n",
    "    print(f\"\\n  Available Namespaces:\")\n",
    "    for ns, ns_stats in stats.namespaces.items():\n",
    "        print(f\"    - {ns}: {ns_stats.vector_count} vectors\")\n",
    "else:\n",
    "    print(\"\\n  No namespaces found\")\n",
    "\n",
    "print(f\"\\nOllama Model: {OLLAMA_MODEL}\")\n",
    "print(f\"Ready for query-retrieve-analyze workflow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f333cb8",
   "metadata": {},
   "source": [
    "#### 2. Defining Memory Query Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ac240a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining Memory Query Function with Multi-Namespace Support\n",
      "Memory query functions defined\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDefining Memory Query Function with Multi-Namespace Support\")\n",
    "\n",
    "def query_agent_memory(query_text, agent_filter=None, top_k=5, min_score=0.5, namespaces=None):\n",
    "   \n",
    "    query_embedding = embedding_model.encode(query_text).tolist()\n",
    "    \n",
    "    if namespaces is None:\n",
    "        namespaces = [\n",
    "            'legal_intermediate',\n",
    "            'compliance_intermediate', \n",
    "            'finance_intermediate',\n",
    "            'operations_intermediate',\n",
    "            'routing_decisions'\n",
    "        ]\n",
    "    \n",
    "    all_matches = []\n",
    "    \n",
    "    for namespace in namespaces:\n",
    "        try:\n",
    "            filter_dict = {}\n",
    "            if agent_filter:\n",
    "                filter_dict[\"agent_name\"] = agent_filter\n",
    "            \n",
    "            results = index.query(\n",
    "                vector=query_embedding,\n",
    "                top_k=top_k,\n",
    "                include_metadata=True,\n",
    "                filter=filter_dict if filter_dict else None,\n",
    "                namespace=namespace\n",
    "            )\n",
    "            \n",
    "            for match in results.matches:\n",
    "                if match.score >= min_score:\n",
    "                    match.metadata['retrieved_namespace'] = namespace\n",
    "                    all_matches.append(match)\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not query namespace {namespace}: {e}\")\n",
    "    \n",
    "    all_matches.sort(key=lambda x: x.score, reverse=True)\n",
    "    \n",
    "    return all_matches[:top_k]\n",
    "\n",
    "def format_memory_result(match):\n",
    "    meta = match.metadata\n",
    "    return {\n",
    "        \"agent\": meta.get('agent_name', 'Unknown'),\n",
    "        \"risk_level\": meta.get('risk_level', 'N/A'),\n",
    "        \"confidence\": meta.get('confidence', 0),\n",
    "        \"num_clauses\": meta.get('num_clauses', 0),\n",
    "        \"similarity_score\": round(match.score, 4),\n",
    "        \"timestamp\": meta.get('timestamp', 'N/A'),\n",
    "        \"contract_id\": meta.get('contract_id', 'N/A'),\n",
    "        \"session_id\": meta.get('session_id', 'N/A'),\n",
    "        \"namespace\": meta.get('retrieved_namespace', meta.get('namespace', 'N/A')),\n",
    "        \"has_ollama_analysis\": meta.get('has_recommendations', False),\n",
    "        \"processing_stage\": meta.get('processing_stage', 'N/A'),\n",
    "        \"model_used\": meta.get('model', 'N/A'),\n",
    "        \"execution_time\": meta.get('execution_time', 0)\n",
    "    }\n",
    "\n",
    "def analyze_with_ollama(query_text, retrieved_matches):\n",
    "\n",
    "    if not retrieved_matches:\n",
    "        return \"No relevant memories found to analyze.\"\n",
    "    \n",
    "    context = f\"User Query: {query_text}\\n\\nRetrieved Contract Analysis:\\n\"\n",
    "    \n",
    "    for i, match in enumerate(retrieved_matches, 1):\n",
    "        meta = match.metadata\n",
    "        context += f\"\\n{i}. {meta.get('agent_name', 'Unknown').upper()} Agent:\"\n",
    "        context += f\"\\n   Risk Level: {meta.get('risk_level', 'N/A')}\"\n",
    "        context += f\"\\n   Confidence: {meta.get('confidence', 0)}\"\n",
    "        context += f\"\\n   Clauses Analyzed: {meta.get('num_clauses', 0)}\"\n",
    "        context += f\"\\n   From Namespace: {meta.get('retrieved_namespace', 'N/A')}\"\n",
    "    \n",
    "    prompt = f\"\"\"{context}\n",
    "\n",
    "Based on these retrieved contract analysis results, provide:\n",
    "1. Direct answer to the user's query\n",
    "2. Risk assessment and key concerns\n",
    "3. Specific recommendations\n",
    "4. Action items with priority\n",
    "\n",
    "Analysis and Recommendations:\"\"\"\n",
    "    \n",
    "    print(\"  → Analyzing with Ollama gemma2:9b...\")\n",
    "    analysis = call_ollama(prompt, max_tokens=60000)\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "print(\"Memory query functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b43a11",
   "metadata": {},
   "source": [
    "#### 3. Querying Legal Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f9cb0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Querying Legal Memory with Ollama Analysis\n",
      "Query: 'termination clauses intellectual property breach conditions'\n",
      "Filter: legal agent only\n",
      "Searching: legal_intermediate namespace\n",
      "\n",
      "Retrieved 1 legal memory records\n",
      "\n",
      "RETRIEVED LEGAL MEMORIES\n",
      "\n",
      "1. Legal Agent Memory\n",
      "   Risk Level: LOW\n",
      "   Confidence: 0.85\n",
      "   Clauses Found: 2\n",
      "   Similarity Score: 0.6944\n",
      "   Namespace: legal_intermediate\n",
      "   Session ID: m3_4ddffbdafb3e_20260116_142038\n",
      "   Has Ollama Analysis: Yes\n",
      "   Model Used: gemma2:9b\n",
      "OLLAMA ANALYSIS OF RETRIEVED LEGAL MEMORIES\n",
      "  → Analyzing with Ollama gemma2:9b...\n",
      "\n",
      "## Analysis of User Query: \"termination clauses intellectual property breach conditions\"\n",
      "\n",
      "**1. Direct Answer:**\n",
      "\n",
      "The contract analysis indicates the presence of two clauses related to termination and intellectual property (IP) breaches. However, without access to the actual contract text, it's impossible to provide specific details about the conditions outlined within these clauses. \n",
      "\n",
      "**2. Risk Assessment and Key Concerns:**\n",
      "\n",
      "* **Low Risk Level:** The identified risk level is \"low,\" suggesting that the analyzed clauses might not pose a significant immediate threat. However, this doesn't mean there are no concerns.\n",
      "* **Limited Information:**  The confidence level of 0.85 indicates some uncertainty in the analysis. Accessing the full contract text is crucial to accurately assess the risks and implications.\n",
      "* **Potential for Misinterpretation:** Without seeing the specific wording, it's difficult to determine if the clauses are clear, comprehensive, and effectively protect against IP breaches. Ambiguity could lead to disputes or legal challenges later on.\n",
      "\n",
      "**3. Specific Recommendations:**\n",
      "\n",
      "* **Review Full Contract Text:**  Immediately obtain the full contract text for a thorough review of the termination clauses and IP breach conditions.\n",
      "* **Seek Legal Counsel:** Consult with an experienced attorney specializing in contract law and intellectual property to:\n",
      "    * Analyze the specific wording of the clauses.\n",
      "    * Identify potential weaknesses or ambiguities.\n",
      "    * Ensure the clauses adequately protect your interests.\n",
      "    * Advise on any necessary revisions or additions.\n",
      "* **Document Findings:**  Create a detailed summary of the analyzed clauses, including identified risks and recommendations for action.\n",
      "\n",
      "**4. Action Items with Priority:**\n",
      "\n",
      "* **High Priority:** Obtain full contract text immediately.\n",
      "* **High Priority:** Schedule consultation with legal counsel within [ timeframe, e.g., 1 week].\n",
      "* **Medium Priority:** Document findings from initial analysis.\n",
      "\n",
      "\n",
      "Remember, this analysis is based on limited information. A comprehensive review by a qualified professional is essential to fully understand the implications of these clauses and mitigate potential risks.\n",
      "Query: 'termination clauses intellectual property breach conditions'\n",
      "Retrieved: 1 records\n",
      "Analysis: Generated with gemma2:9b\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQuerying Legal Memory with Ollama Analysis\")\n",
    "\n",
    "legal_query = \"termination clauses intellectual property breach conditions\"\n",
    "print(f\"Query: '{legal_query}'\")\n",
    "print(f\"Filter: legal agent only\")\n",
    "print(f\"Searching: legal_intermediate namespace\\n\")\n",
    "\n",
    "legal_memories = query_agent_memory(\n",
    "    query_text=legal_query,\n",
    "    agent_filter=\"legal\",\n",
    "    top_k=3,\n",
    "    namespaces=['legal_intermediate']\n",
    ")\n",
    "\n",
    "print(f\"Retrieved {len(legal_memories)} legal memory records\\n\")\n",
    "\n",
    "if len(legal_memories) > 0:\n",
    "\n",
    "    print(\"RETRIEVED LEGAL MEMORIES\")\n",
    "\n",
    "    legal_results = []\n",
    "    for i, match in enumerate(legal_memories, 1):\n",
    "        result = format_memory_result(match)\n",
    "        legal_results.append(result)\n",
    "        \n",
    "        print(f\"\\n{i}. Legal Agent Memory\")\n",
    "        print(f\"   Risk Level: {result['risk_level'].upper()}\")\n",
    "        print(f\"   Confidence: {result['confidence']}\")\n",
    "        print(f\"   Clauses Found: {result['num_clauses']}\")\n",
    "        print(f\"   Similarity Score: {result['similarity_score']}\")\n",
    "        print(f\"   Namespace: {result['namespace']}\")\n",
    "        print(f\"   Session ID: {result['session_id']}\")\n",
    "        print(f\"   Has Ollama Analysis: {'Yes' if result['has_ollama_analysis'] else 'No'}\")\n",
    "        print(f\"   Model Used: {result['model_used']}\")\n",
    "    \n",
    "\n",
    "    print(\"OLLAMA ANALYSIS OF RETRIEVED LEGAL MEMORIES\")\n",
    "\n",
    "    legal_analysis = analyze_with_ollama(legal_query, legal_memories)\n",
    "    \n",
    "    if legal_analysis:\n",
    "        print(f\"\\n{legal_analysis}\")\n",
    "    else:\n",
    "        print(\"\\nOllama analysis failed\")\n",
    "    \n",
    "    print(f\"Query: '{legal_query}'\")\n",
    "    print(f\"Retrieved: {len(legal_memories)} records\")\n",
    "    print(f\"Analysis: Generated with {OLLAMA_MODEL}\")\n",
    "\n",
    "else:\n",
    "    print(\"No legal memories found matching the query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0809a4",
   "metadata": {},
   "source": [
    "#### 4. Inspecting Retrieved Legal Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bbe5d0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting Retrieved Memory Details\n",
      "TOP LEGAL MEMORY DETAILS\n",
      "\n",
      "  ID: m3_4ddffbdafb3e_20260116_142038_legal\n",
      "  Agent: legal\n",
      "  Contract ID: 4ddffbdafb3e\n",
      "  Session ID: m3_4ddffbdafb3e_20260116_142038\n",
      "  Timestamp: 2026-01-16T14:36:23.100878\n",
      "  Model Used: gemma2:9b\n",
      "  Risk Assessment: low (confidence: 0.85)\n",
      "  Number of Clauses: 2\n",
      "  Similarity Score: 0.6944\n",
      "  Namespace: legal_intermediate\n",
      "  Processing Stage: ollama_enhanced\n",
      "  Has Ollama Analysis: True\n",
      "  Execution Time: 280.08s\n",
      "\n",
      "  Memory Persistence: Stored on 2026-01-16\n",
      "  This record contains Ollama-enhanced analysis from gemma2:9b\n"
     ]
    }
   ],
   "source": [
    "print(\"Inspecting Retrieved Memory Details\")\n",
    "\n",
    "if legal_memories:\n",
    "    top_legal = legal_memories[0]\n",
    "    meta = top_legal.metadata\n",
    "    \n",
    "    print(\"TOP LEGAL MEMORY DETAILS\")\n",
    " \n",
    "    print(f\"\\n  ID: {top_legal.id}\")\n",
    "    print(f\"  Agent: {meta.get('agent_name', 'N/A')}\")\n",
    "    print(f\"  Contract ID: {meta.get('contract_id', 'N/A')}\")\n",
    "    print(f\"  Session ID: {meta.get('session_id', 'N/A')}\")\n",
    "    print(f\"  Timestamp: {meta.get('timestamp', 'N/A')}\")\n",
    "    print(f\"  Model Used: {meta.get('model', 'N/A')}\")\n",
    "    print(f\"  Risk Assessment: {meta.get('risk_level', 'N/A')} (confidence: {meta.get('confidence', 0)})\")\n",
    "    print(f\"  Number of Clauses: {meta.get('num_clauses', 0)}\")\n",
    "    print(f\"  Similarity Score: {top_legal.score:.4f}\")\n",
    "    print(f\"  Namespace: {meta.get('retrieved_namespace', meta.get('namespace', 'N/A'))}\")\n",
    "    print(f\"  Processing Stage: {meta.get('processing_stage', 'N/A')}\")\n",
    "    print(f\"  Has Ollama Analysis: {meta.get('has_recommendations', False)}\")\n",
    "    print(f\"  Execution Time: {meta.get('execution_time', 0):.2f}s\")\n",
    "    \n",
    "    print(f\"\\n  Memory Persistence: Stored on {meta.get('timestamp', 'N/A')[:10]}\")\n",
    "    \n",
    "    if meta.get('has_recommendations', False):\n",
    "        print(f\"  This record contains Ollama-enhanced analysis from {meta.get('model', 'gemma2:9b')}\")\n",
    "    else:\n",
    "        print(f\"  This record does not contain enhanced analysis\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nNo legal memories found to inspect\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09cdee6",
   "metadata": {},
   "source": [
    "#### 5. Retrieving Finance Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3c3544f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieving Finance Memory with Ollama Analysis\n",
      "Query: 'payment terms reimbursement out-of-pocket costs invoices'\n",
      "Filter: finance agent only\n",
      "Searching: finance_intermediate namespace\n",
      "\n",
      "Retrieved 1 finance memory records\n",
      "\n",
      "RETRIEVED FINANCE MEMORIES\n",
      "\n",
      "1. Finance Agent Memory\n",
      "   Risk Level: MEDIUM\n",
      "   Confidence: 0.7\n",
      "   Clauses Found: 3\n",
      "   Similarity Score: 0.5508\n",
      "   Namespace: finance_intermediate\n",
      "   Session ID: m3_4ddffbdafb3e_20260116_142038\n",
      "   Has Ollama Analysis: Yes\n",
      "   Model Used: gemma2:9b\n",
      "OLLAMA ANALYSIS OF RETRIEVED FINANCE MEMORIES\n",
      "  → Analyzing with Ollama gemma2:9b...\n",
      "\n",
      "## Analysis of User Query: \"payment terms reimbursement out-of-pocket costs invoices\"\n",
      "\n",
      "**1. Direct Answer:**\n",
      "\n",
      "The contract analysis suggests that the contract likely contains clauses related to payment terms, reimbursement of out-of-pocket expenses, and invoicing procedures. However, without access to the full contract text, it's impossible to provide specific details about these terms. \n",
      "\n",
      "**2. Risk Assessment and Key Concerns:**\n",
      "\n",
      "* **Medium Risk Level:** The \"medium\" risk level indicates that there are potential areas of concern within the contract regarding payment terms, reimbursement, and invoicing.  \n",
      "* **Potential Issues:**\n",
      "    * **Ambiguous Payment Terms:** The contract might lack clarity on payment schedules, due dates, acceptable payment methods, or late payment penalties. This can lead to disputes and delays in receiving payments.\n",
      "    * **Unclear Reimbursement Process:** The contract may not clearly define which out-of-pocket expenses are eligible for reimbursement, the required documentation, or the reimbursement timeline. This can result in confusion and frustration for parties incurring expenses.\n",
      "    * **Complex Invoicing Procedures:**  The contract might specify intricate invoicing requirements that are difficult to comply with, leading to rejected invoices and further delays.\n",
      "\n",
      "**3. Specific Recommendations:**\n",
      "\n",
      "* **Review Contract Clauses:** Carefully examine the clauses related to payment terms, reimbursement, and invoicing. Pay close attention to details like due dates, payment methods, eligible expenses, documentation requirements, and dispute resolution procedures.\n",
      "* **Seek Legal Counsel:** If you encounter any ambiguities or concerns regarding these clauses, consult with a legal professional specializing in contract law. They can provide expert advice and help negotiate favorable terms.\n",
      "* **Clarify Terms Through Communication:**  Engage in open communication with the other party to ensure mutual understanding of the payment terms, reimbursement process, and invoicing procedures.\n",
      "\n",
      "**4. Action Items with Priority:**\n",
      "\n",
      "* **High Priority:** \n",
      "    * Review contract clauses related to payment terms, reimbursement, and invoicing immediately.\n",
      "    * Identify any potential ambiguities or concerns that require clarification.\n",
      "* **Medium Priority:**\n",
      "    * Schedule a meeting with the other party to discuss any unclear points and seek mutual agreement on specific terms.\n",
      "* **Low Priority:** \n",
      "    * Consult with legal counsel if necessary to ensure the contract adequately protects your interests.\n",
      "\n",
      "\n",
      "By taking these proactive steps, you can mitigate potential risks and establish clear expectations regarding payment terms, reimbursement, and invoicing within the contract.\n",
      "Query: 'payment terms reimbursement out-of-pocket costs invoices'\n",
      "Retrieved: 1 records\n",
      "Analysis: Generated with gemma2:9b\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRetrieving Finance Memory with Ollama Analysis\")\n",
    "\n",
    "finance_query = \"payment terms reimbursement out-of-pocket costs invoices\"\n",
    "print(f\"Query: '{finance_query}'\")\n",
    "print(f\"Filter: finance agent only\")\n",
    "print(f\"Searching: finance_intermediate namespace\\n\")\n",
    "\n",
    "finance_memories = query_agent_memory(\n",
    "    query_text=finance_query,\n",
    "    agent_filter=\"finance\",\n",
    "    top_k=3,\n",
    "    namespaces=['finance_intermediate']\n",
    ")\n",
    "\n",
    "print(f\"Retrieved {len(finance_memories)} finance memory records\\n\")\n",
    "\n",
    "if len(finance_memories) > 0:\n",
    "\n",
    "    print(\"RETRIEVED FINANCE MEMORIES\")\n",
    "\n",
    "    finance_results = []\n",
    "    for i, match in enumerate(finance_memories, 1):\n",
    "        result = format_memory_result(match)\n",
    "        finance_results.append(result)\n",
    "        \n",
    "        print(f\"\\n{i}. Finance Agent Memory\")\n",
    "        print(f\"   Risk Level: {result['risk_level'].upper()}\")\n",
    "        print(f\"   Confidence: {result['confidence']}\")\n",
    "        print(f\"   Clauses Found: {result['num_clauses']}\")\n",
    "        print(f\"   Similarity Score: {result['similarity_score']}\")\n",
    "        print(f\"   Namespace: {result['namespace']}\")\n",
    "        print(f\"   Session ID: {result['session_id']}\")\n",
    "        print(f\"   Has Ollama Analysis: {'Yes' if result['has_ollama_analysis'] else 'No'}\")\n",
    "        print(f\"   Model Used: {result['model_used']}\")\n",
    "    \n",
    "    \n",
    "    print(\"OLLAMA ANALYSIS OF RETRIEVED FINANCE MEMORIES\")\n",
    "\n",
    "    finance_analysis = analyze_with_ollama(finance_query, finance_memories)\n",
    "    \n",
    "    if finance_analysis:\n",
    "        print(f\"\\n{finance_analysis}\")\n",
    "    else:\n",
    "        print(\"\\nOllama analysis failed\")\n",
    "    \n",
    "    print(f\"Query: '{finance_query}'\")\n",
    "    print(f\"Retrieved: {len(finance_memories)} records\")\n",
    "    print(f\"Analysis: Generated with {OLLAMA_MODEL}\")\n",
    "\n",
    "else:\n",
    "    print(\"No finance memories found matching the query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1f128c",
   "metadata": {},
   "source": [
    "#### 6. Combining Memory Responses - Legal and Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5754b79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining Memory Responses with Multi-Namespace Search\n",
      "Combined Query: 'contract risks termination and payment obligations'\n",
      "Filter: All agents\n",
      "Searching: All intermediate namespaces\n",
      "\n",
      "Pinecone multi-namespace query successful: 3 results\n",
      "CROSS-AGENT MEMORY RETRIEVAL\n",
      "\n",
      "LEGAL Agent: 1 records\n",
      "  1. Risk: low | Confidence: 0.85 | Score: 0.538 | Namespace: legal_intermediate\n",
      "\n",
      "FINANCE Agent: 1 records\n",
      "  1. Risk: medium | Confidence: 0.7 | Score: 0.466 | Namespace: finance_intermediate\n",
      "\n",
      "OPERATIONS Agent: 1 records\n",
      "  1. Risk: medium | Confidence: 0.8 | Score: 0.3039 | Namespace: operations_intermediate\n",
      "Total memories retrieved: 3\n",
      "Agents represented: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCombining Memory Responses with Multi-Namespace Search\")\n",
    "\n",
    "combined_query = \"contract risks termination and payment obligations\"\n",
    "print(f\"Combined Query: '{combined_query}'\")\n",
    "print(f\"Filter: All agents\")\n",
    "print(f\"Searching: All intermediate namespaces\\n\")\n",
    "\n",
    "try:\n",
    "    all_memories = query_agent_memory(\n",
    "        query_text=combined_query,\n",
    "        agent_filter=None,\n",
    "        top_k=10,\n",
    "        min_score=0.2,\n",
    "        namespaces=['legal_intermediate', 'compliance_intermediate', \n",
    "                    'finance_intermediate', 'operations_intermediate', \n",
    "                    'routing_decisions']\n",
    "    )\n",
    "    print(f\"Pinecone multi-namespace query successful: {len(all_memories)} results\")\n",
    "except Exception as e:\n",
    "    print(f\"Pinecone query failed: {e}\")\n",
    "    all_memories = []\n",
    "\n",
    "if len(all_memories) == 0:\n",
    "    print(\"\\nNo results from Pinecone - Loading from local storage\\n\")\n",
    "    \n",
    "    records_file = os.path.join(MILESTONE3_OUTPUT, \"vector_records_new.json\")\n",
    "    if os.path.exists(records_file):\n",
    "        with open(records_file, 'r', encoding='utf-8') as f:\n",
    "            vector_records = json.load(f)\n",
    "        \n",
    "        class LocalMatch:\n",
    "            def __init__(self, record):\n",
    "                self.id = record['id']\n",
    "                self.score = 0.85\n",
    "                self.metadata = record['metadata']\n",
    "                if 'namespace' not in self.metadata:\n",
    "                    agent = self.metadata.get('agent_name', 'unknown')\n",
    "                    self.metadata['namespace'] = f\"{agent}_intermediate\"\n",
    "                if 'retrieved_namespace' not in self.metadata:\n",
    "                    self.metadata['retrieved_namespace'] = self.metadata.get('namespace', 'local')\n",
    "        \n",
    "        all_memories = [LocalMatch(r) for r in vector_records]\n",
    "        print(f\"Loaded {len(all_memories)} records from vector_records.json\")\n",
    "    \n",
    "    else:\n",
    "        parallel_file = os.path.join(MILESTONE3_OUTPUT, \"parallel_agent_outputs.json\")\n",
    "        if os.path.exists(parallel_file):\n",
    "            with open(parallel_file, 'r', encoding='utf-8') as f:\n",
    "                parallel_data = json.load(f)\n",
    "            \n",
    "            agent_outputs = parallel_data.get('agent_outputs', {})\n",
    "            \n",
    "            class DirectMatch:\n",
    "                def __init__(self, agent_name, agent_data):\n",
    "                    output = agent_data.get('output', {})\n",
    "                    self.id = f\"direct_{agent_name}\"\n",
    "                    self.score = 0.90\n",
    "                    self.metadata = {\n",
    "                        'agent_name': agent_name,\n",
    "                        'risk_level': output.get('risk_level', 'N/A'),\n",
    "                        'confidence': output.get('confidence', 0),\n",
    "                        'num_clauses': len(output.get('extracted_clauses', [])),\n",
    "                        'contract_id': 'direct_load',\n",
    "                        'timestamp': datetime.now().isoformat(),\n",
    "                        'session_id': parallel_data.get('session_id', 'direct_load'),\n",
    "                        'namespace': f\"{agent_name}_intermediate\",\n",
    "                        'retrieved_namespace': 'local_fallback',\n",
    "                        'has_recommendations': 'recommendations' in output,\n",
    "                        'model': output.get('model', 'N/A'),\n",
    "                        'processing_stage': 'intermediate'\n",
    "                    }\n",
    "            \n",
    "            all_memories = [DirectMatch(name, data) for name, data in agent_outputs.items() if data]\n",
    "            print(f\"Loaded {len(all_memories)} records from parallel_agent_outputs.json\")\n",
    "        else:\n",
    "            print(\"No local data files found\")\n",
    "\n",
    "if all_memories:\n",
    "    print(\"CROSS-AGENT MEMORY RETRIEVAL\")\n",
    "\n",
    "    agent_groups = {}\n",
    "    for match in all_memories:\n",
    "        agent = match.metadata.get('agent_name', 'unknown')\n",
    "        if agent not in agent_groups:\n",
    "            agent_groups[agent] = []\n",
    "        agent_groups[agent].append(match)\n",
    "    \n",
    "    for agent, matches in agent_groups.items():\n",
    "        print(f\"\\n{agent.upper()} Agent: {len(matches)} records\")\n",
    "        for i, match in enumerate(matches, 1):\n",
    "            result = format_memory_result(match)\n",
    "            print(f\"  {i}. Risk: {result['risk_level']} | \"\n",
    "                  f\"Confidence: {result['confidence']} | \"\n",
    "                  f\"Score: {result['similarity_score']} | \"\n",
    "                  f\"Namespace: {result['namespace']}\")\n",
    "    \n",
    "    print(f\"Total memories retrieved: {len(all_memories)}\")\n",
    "    print(f\"Agents represented: {len(agent_groups)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bba1a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS-AGENT MEMORY ANALYSIS\n",
      "\n",
      "Retrieved 3 memories across all agents\n",
      "\n",
      "MEMORY BREAKDOWN BY AGENT:\n",
      "\n",
      "FINANCE Agent (1 records):\n",
      "   → Risk: medium, Confidence: 0.7, Score: 0.466, Namespace: finance_intermediate\n",
      "      Contains Ollama analysis from gemma2:9b\n",
      "\n",
      "LEGAL Agent (1 records):\n",
      "   → Risk: low, Confidence: 0.85, Score: 0.538, Namespace: legal_intermediate\n",
      "      Contains Ollama analysis from gemma2:9b\n",
      "\n",
      "OPERATIONS Agent (1 records):\n",
      "   → Risk: medium, Confidence: 0.8, Score: 0.3039, Namespace: operations_intermediate\n",
      "      Contains Ollama analysis from gemma2:9b\n",
      "COMBINED MEMORY SUMMARY\n",
      "   Total Memories Retrieved: 3\n",
      "   Agents Represented: 3\n",
      "   Agent Distribution: finance: 1, legal: 1, operations: 1\n",
      "   Query: 'contract risks termination and payment obligations'\n",
      "OLLAMA CROSS-AGENT SYNTHESIS\n",
      "  → Analyzing with Ollama gemma2:9b...\n",
      "\n",
      "## Contract Risks: Termination & Payment Obligations \n",
      "\n",
      "Here's a breakdown of the contract risks related to termination and payment obligations based on the provided analysis:\n",
      "\n",
      "**1. Direct Answer:**\n",
      "\n",
      "The contract analysis highlights potential risks concerning termination and payment obligations.  While the LEGAL Agent identifies a low risk, FINANCE and OPERATIONS Agents flag medium-level risks requiring closer attention. \n",
      "\n",
      "**2. Risk Assessment & Key Concerns:**\n",
      "\n",
      "* **FINANCE Agent (Medium Risk):** This suggests potential issues with payment terms, late fees, dispute resolution mechanisms, or currency fluctuations that could impact financial stability.\n",
      "* **OPERATIONS Agent (Medium Risk):**  This indicates possible challenges related to contract performance, service level agreements, termination procedures, or logistical complexities impacting operational efficiency.\n",
      "\n",
      "**3. Specific Recommendations:**\n",
      "\n",
      "* **Review Finance Clauses:** Carefully examine clauses concerning payment schedules, late penalties, currency conversions, and dispute resolution processes. Ensure clarity and fairness in these terms.\n",
      "* **Clarify Termination Procedures:**  Scrutinize the contract's termination provisions, including notice periods, grounds for termination, and any associated financial obligations. Seek legal counsel to ensure they are comprehensive and protect your interests.\n",
      "* **Define Service Level Agreements (SLAs):** If applicable, establish clear SLAs outlining performance expectations, deliverables, and consequences for non-compliance. This helps mitigate operational risks.\n",
      "* **Seek Legal Counsel:**  Given the medium-level risk flagged by FINANCE and OPERATIONS Agents, it's highly recommended to consult with legal counsel specializing in contract law. They can provide expert guidance on mitigating potential risks and negotiating favorable terms.\n",
      "\n",
      "**4. Action Items with Priority:**\n",
      "\n",
      "**High Priority:**\n",
      "\n",
      "1. **Schedule Legal Review:**  Engage legal counsel immediately to review the contract clauses related to termination, payment obligations, and operational responsibilities.\n",
      "2. **Clarify Finance Clauses:** Request clarification from the counterparty on any ambiguous or concerning finance-related terms. \n",
      "\n",
      "**Medium Priority:**\n",
      "\n",
      "3. **Define SLAs (if applicable):**  Work with relevant stakeholders to establish clear and measurable service level agreements.\n",
      "4. **Document Contractual Risks:** Maintain a detailed record of identified risks, mitigation strategies, and action items for future reference.\n",
      "\n",
      "\n",
      "By taking these proactive steps, you can effectively manage contract risks related to termination and payment obligations, ensuring a smoother and more successful business relationship.\n",
      "Cross-agent analysis complete\n",
      "Synthesized insights from 3 agents\n",
      "Analysis generated with gemma2:9b\n"
     ]
    }
   ],
   "source": [
    "print(f\"CROSS-AGENT MEMORY ANALYSIS\")\n",
    "\n",
    "print(f\"\\nRetrieved {len(all_memories)} memories across all agents\\n\")\n",
    "\n",
    "memories_by_agent = {}\n",
    "combined_results = []\n",
    "\n",
    "for match in all_memories:\n",
    "    result = format_memory_result(match)\n",
    "    combined_results.append(result)\n",
    "    \n",
    "    agent = result['agent']\n",
    "    if agent not in memories_by_agent:\n",
    "        memories_by_agent[agent] = []\n",
    "    memories_by_agent[agent].append(result)\n",
    "\n",
    "print(\"MEMORY BREAKDOWN BY AGENT:\")\n",
    "\n",
    "for agent, memories in sorted(memories_by_agent.items()):\n",
    "    print(f\"\\n{agent.upper()} Agent ({len(memories)} records):\")\n",
    "    for mem in memories:\n",
    "        print(f\"   → Risk: {mem['risk_level']}, \"\n",
    "              f\"Confidence: {mem['confidence']}, \"\n",
    "              f\"Score: {mem['similarity_score']}, \"\n",
    "              f\"Namespace: {mem['namespace']}\")\n",
    "        if mem['has_ollama_analysis']:\n",
    "            print(f\"      Contains Ollama analysis from {mem['model_used']}\")\n",
    "\n",
    "print(\"COMBINED MEMORY SUMMARY\")\n",
    "print(f\"   Total Memories Retrieved: {len(all_memories)}\")\n",
    "print(f\"   Agents Represented: {len(memories_by_agent)}\")\n",
    "print(f\"   Agent Distribution: {', '.join([f'{k}: {len(v)}' for k, v in sorted(memories_by_agent.items())])}\")\n",
    "print(f\"   Query: '{combined_query}'\")\n",
    "print(\"OLLAMA CROSS-AGENT SYNTHESIS\")\n",
    "\n",
    "if all_memories:\n",
    "    combined_analysis = analyze_with_ollama(combined_query, all_memories)\n",
    "    \n",
    "    if combined_analysis:\n",
    "        print(f\"\\n{combined_analysis}\")\n",
    "    else:\n",
    "        print(\"\\nOllama analysis failed\")\n",
    "    \n",
    "    print(f\"Cross-agent analysis complete\")\n",
    "    print(f\"Synthesized insights from {len(memories_by_agent)} agents\")\n",
    "    print(f\"Analysis generated with {OLLAMA_MODEL}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nNo memories to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce49c84",
   "metadata": {},
   "source": [
    "#### 7. Using Memory Instead of Re-running Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3fabecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using Memory with Model Analysis\n",
      "Risk Query: 'high risk compliance confidentiality data protection'\n",
      "\n",
      "Retrieved risk findings from memory:\n",
      "\n",
      "HIGH RISK (1 findings):\n",
      "   • Compliance Agent: confidence 1, relevance 0.549\n",
      "\n",
      "MODEL-BASED RISK SYNTHESIS (USING MEMORY CONTEXT)\n",
      "  → Analyzing with Ollama gemma2:9b...\n",
      "\n",
      "Synthesized Risk Assessment and Recommendations:\n",
      "\n",
      "## Analysis of User Query: \"high risk compliance confidentiality data protection\"\n",
      "\n",
      "**1. Direct Answer:**\n",
      "\n",
      "The contract analysis indicates a **high-risk clause related to compliance, confidentiality, and data protection**. This suggests the contract may contain provisions that pose significant legal or operational risks if not carefully managed. \n",
      "\n",
      "**2. Risk Assessment and Key Concerns:**\n",
      "\n",
      "* **High Risk Level:** The identified risk level is \"high,\" signifying a substantial potential for negative consequences if the clause is not properly addressed.\n",
      "* **Confidentiality & Data Protection:**  The analysis highlights concerns related to confidentiality and data protection, implying the contract may involve sensitive information requiring strict safeguards. \n",
      "* **Compliance:** The mention of \"compliance\" suggests the contract might fail to meet relevant legal or regulatory requirements regarding data handling, potentially leading to fines, lawsuits, or reputational damage.\n",
      "\n",
      "**3. Specific Recommendations:**\n",
      "\n",
      "* **Thorough Review:** Conduct a comprehensive review of the identified clause and its surrounding context within the contract.\n",
      "* **Legal Counsel Consultation:** Engage legal counsel specializing in data protection and contract law to assess the risks and provide guidance on mitigating them.\n",
      "* **Strengthen Confidentiality Provisions:** Ensure the contract includes robust confidentiality clauses that clearly define the scope of protected information, obligations of parties involved, and consequences for breaches.\n",
      "* **Data Protection Compliance:** Verify the contract aligns with applicable data protection regulations (e.g., GDPR, CCPA) and implement necessary safeguards to ensure compliance.\n",
      "* **Risk Mitigation Strategies:** Develop and implement risk mitigation strategies to minimize potential negative impacts arising from the identified clause.\n",
      "\n",
      "**4. Action Items with Priority:**\n",
      "\n",
      "**High Priority:**\n",
      "\n",
      "* **Engage Legal Counsel:** Immediately consult legal counsel specializing in data protection and contract law to assess the identified clause and provide guidance on mitigating risks.\n",
      "* **Review Identified Clause:** Conduct a thorough review of the specific clause flagged by the analysis, paying close attention to its wording and implications.\n",
      "\n",
      "**Medium Priority:**\n",
      "\n",
      "* **Gather Contract Context:**  Analyze the surrounding clauses within the contract to understand the broader context of the identified risk.\n",
      "* **Identify Applicable Regulations:** Determine which data protection regulations apply to the contract and ensure compliance.\n",
      "\n",
      "**Low Priority:**\n",
      "\n",
      "* **Develop Risk Mitigation Strategies:** Once legal counsel has provided guidance, develop and implement strategies to minimize potential negative impacts arising from the clause.\n",
      "\n",
      "\n",
      "By taking these actions, you can effectively address the high-risk identified in the contract analysis and protect your organization's interests.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUsing Memory with Model Analysis\")\n",
    "\n",
    "risk_query = \"high risk compliance confidentiality data protection\"\n",
    "print(f\"Risk Query: '{risk_query}'\\n\")\n",
    "\n",
    "high_risk_memories = query_agent_memory(\n",
    "    query_text=risk_query,\n",
    "    agent_filter=None,\n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "if not high_risk_memories:\n",
    "    print(\"No relevant memories found for this risk query.\")\n",
    "else:\n",
    "    risk_analysis = {\n",
    "        \"high\": [],\n",
    "        \"medium\": [],\n",
    "        \"low\": []\n",
    "    }\n",
    "\n",
    "    for match in high_risk_memories:\n",
    "        risk_level = match.metadata.get('risk_level', 'unknown')\n",
    "        agent = match.metadata.get('agent_name', 'unknown')\n",
    "        confidence = match.metadata.get('confidence', 0)\n",
    "\n",
    "        if risk_level in risk_analysis:\n",
    "            risk_analysis[risk_level].append({\n",
    "                \"agent\": agent,\n",
    "                \"confidence\": confidence,\n",
    "                \"score\": match.score\n",
    "            })\n",
    "\n",
    "    print(\"Retrieved risk findings from memory:\\n\")\n",
    "\n",
    "    for risk_level in [\"high\", \"medium\", \"low\"]:\n",
    "        items = risk_analysis[risk_level]\n",
    "        if items:\n",
    "            print(f\"{risk_level.upper()} RISK ({len(items)} findings):\")\n",
    "            for item in items:\n",
    "                print(\n",
    "                    f\"   • {item['agent'].capitalize()} Agent: \"\n",
    "                    f\"confidence {item['confidence']}, relevance {item['score']:.3f}\"\n",
    "                )\n",
    "            print()\n",
    "\n",
    "    print(\"MODEL-BASED RISK SYNTHESIS (USING MEMORY CONTEXT)\")\n",
    "\n",
    "\n",
    "    cross_agent_risk_analysis = analyze_with_ollama(risk_query, high_risk_memories)\n",
    "\n",
    "    if cross_agent_risk_analysis:\n",
    "        print(\"\\nSynthesized Risk Assessment and Recommendations:\\n\")\n",
    "        print(cross_agent_risk_analysis)\n",
    "    else:\n",
    "        print(\"\\nModel analysis failed; falling back to raw memory view only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d51966",
   "metadata": {},
   "source": [
    "#### 8. Querying Without Agent Filter & Compare Risks Across Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fac2d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERYING WITHOUT AGENT FILTER\n",
      "\n",
      "Query: 'obligations responsibilities requirements'\n",
      "Filter: None (all agents)\n",
      "\n",
      "Attempting Pinecone retrieval\n",
      "Pinecone: Retrieved 5 memories\n",
      "\n",
      "Retrieved 5 memories from all agents\n",
      "Retrieval Method: Pinecone Vector Search\n",
      "\n",
      "Memory Records Retrieved:\n",
      "\n",
      "1. LEGAL Agent\n",
      "   Risk: low, Confidence: 0.85, Score: 0.321, Clauses: 2\n",
      "   Namespace: legal_intermediate\n",
      "\n",
      "2. COMPLIANCE Agent\n",
      "   Risk: high, Confidence: 1, Score: 0.316, Clauses: 1\n",
      "   Namespace: compliance_intermediate\n",
      "\n",
      "3. FINANCE Agent\n",
      "   Risk: medium, Confidence: 0.7, Score: 0.314, Clauses: 3\n",
      "   Namespace: finance_intermediate\n",
      "\n",
      "4. OPERATIONS Agent\n",
      "   Risk: medium, Confidence: 0.8, Score: 0.313, Clauses: 2\n",
      "   Namespace: operations_intermediate\n",
      "\n",
      "5. UNKNOWN Agent\n",
      "   Risk: N/A, Confidence: 0, Score: 0.107, Clauses: 0\n",
      "   Namespace: routing_decisions\n",
      "\n",
      "Cross-Agent Memory Distribution:\n",
      "  Compliance: 1 (20.0%)\n",
      "  Finance: 1 (20.0%)\n",
      "  Legal: 1 (20.0%)\n",
      "  Operations: 1 (20.0%)\n",
      "  Unknown: 1 (20.0%)\n",
      "MODEL CROSS-AGENT SYNTHESIS\n",
      "  → Analyzing with Ollama gemma2:9b...\n",
      "\n",
      "Synthesized Obligations/Responsibilities Assessment:\n",
      "\n",
      "## Analysis of User Query: Obligations, Responsibilities, Requirements\n",
      "\n",
      "**1. Direct Answer to User Query:**\n",
      "\n",
      "The contract analysis reveals potential obligations, responsibilities, and requirements related to **legal compliance**, **financial matters**, and **operational procedures**.  Specific details about these obligations are embedded within the analyzed clauses. \n",
      "\n",
      "**2. Risk Assessment and Key Concerns:**\n",
      "\n",
      "* **High Risk:** The \"COMPLIANCE Agent\" indicates a high risk level associated with potential non-compliance issues. This suggests the contract contains clauses requiring adherence to specific regulations or standards. Failure to comply could lead to legal penalties or reputational damage.\n",
      "* **Medium Risk:** Both \"FINANCE Agent\" and \"OPERATIONS Agent\" present medium risk levels.  This implies potential financial implications (e.g., payment terms, liabilities) and operational challenges (e.g., performance metrics, service level agreements).\n",
      "\n",
      "**3. Specific Recommendations:**\n",
      "\n",
      "* **Prioritize Compliance Review:** Conduct a thorough review of the clauses analyzed by the \"COMPLIANCE Agent\" to ensure full understanding and adherence to all regulatory requirements. Consult with legal counsel if necessary.\n",
      "* **Financial Due Diligence:** Carefully examine the clauses analyzed by the \"FINANCE Agent\" to understand financial obligations, payment terms, and potential liabilities. Seek clarification on any ambiguous points.\n",
      "* **Operational Clarity:** Analyze the clauses identified by the \"OPERATIONS Agent\" to define clear expectations regarding service delivery, performance metrics, and operational procedures.\n",
      "\n",
      "**4. Action Items with Priority:**\n",
      "\n",
      "**High Priority:**\n",
      "\n",
      "* **Review Compliance Clauses:** Schedule a meeting with legal counsel to discuss the analyzed compliance clauses and develop a plan for ensuring adherence.\n",
      "* **Identify Key Financial Terms:**  Highlight and analyze all financial terms within the contract, including payment schedules, penalties, and liabilities.\n",
      "\n",
      "**Medium Priority:**\n",
      "\n",
      "* **Operational Procedure Review:** Analyze the operational clauses and identify any potential bottlenecks or areas requiring further clarification. \n",
      "* **Develop Risk Mitigation Plan:** Based on the identified risks, create a plan to mitigate potential negative consequences related to compliance, finance, and operations.\n",
      "\n",
      "\n",
      "By prioritizing these action items, you can effectively address the user's query regarding obligations, responsibilities, and requirements within the contract. Remember, seeking professional advice from legal and financial experts is crucial for navigating complex contractual agreements.\n"
     ]
    }
   ],
   "source": [
    "print(\"QUERYING WITHOUT AGENT FILTER\")\n",
    "\n",
    "unfiltered_query = \"obligations responsibilities requirements\"\n",
    "print(f\"\\nQuery: '{unfiltered_query}'\")\n",
    "print(\"Filter: None (all agents)\\n\")\n",
    "\n",
    "unfiltered_memories = []\n",
    "retrieval_method = None\n",
    "\n",
    "print(\"Attempting Pinecone retrieval\")\n",
    "try:\n",
    "    unfiltered_memories = query_agent_memory(\n",
    "        query_text=unfiltered_query,\n",
    "        agent_filter=None,\n",
    "        top_k=8,\n",
    "        min_score=0.1\n",
    "    )\n",
    "    if len(unfiltered_memories) > 0:\n",
    "        retrieval_method = \"Pinecone Vector Search\"\n",
    "        print(f\"Pinecone: Retrieved {len(unfiltered_memories)} memories\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"Pinecone retrieval failed: {e}\\n\")\n",
    "\n",
    "if len(unfiltered_memories) == 0:\n",
    "    print(\"Trying broader query terms\")\n",
    "    try:\n",
    "        broader_query = \"contract agreement clause\"\n",
    "        unfiltered_memories = query_agent_memory(\n",
    "            query_text=broader_query,\n",
    "            agent_filter=None,\n",
    "            top_k=8,\n",
    "            min_score=0.1\n",
    "        )\n",
    "        if len(unfiltered_memories) > 0:\n",
    "            retrieval_method = \"Pinecone with Broader Terms\"\n",
    "            print(f\"Broader query: Retrieved {len(unfiltered_memories)} memories\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Broader query failed: {e}\\n\")\n",
    "\n",
    "if len(unfiltered_memories) == 0:\n",
    "    print(\"Loading from vector_records.json...\")\n",
    "    records_file = os.path.join(MILESTONE3_OUTPUT, \"vector_records.json\")\n",
    "\n",
    "    if os.path.exists(records_file):\n",
    "        with open(records_file, 'r', encoding='utf-8') as f:\n",
    "            vector_records = json.load(f)\n",
    "\n",
    "        class LocalMatch:\n",
    "            def __init__(self, record, query_relevance):\n",
    "                self.id = record['id']\n",
    "                self.score = query_relevance\n",
    "                self.metadata = record['metadata']\n",
    "                if 'namespace' not in self.metadata:\n",
    "                    agent = self.metadata.get('agent_name', 'unknown')\n",
    "                    self.metadata['namespace'] = f\"{agent}_intermediate\"\n",
    "                if 'retrieved_namespace' not in self.metadata:\n",
    "                    self.metadata['retrieved_namespace'] = self.metadata.get('namespace')\n",
    "                if 'session_id' not in self.metadata:\n",
    "                    self.metadata['session_id'] = 'local_fallback'\n",
    "                if 'has_recommendations' not in self.metadata:\n",
    "                    self.metadata['has_recommendations'] = False\n",
    "\n",
    "        query_keywords = set(unfiltered_query.lower().split())\n",
    "\n",
    "        for record in vector_records:\n",
    "            text_keywords = set(record['text'].lower().split())\n",
    "            overlap = len(query_keywords.intersection(text_keywords))\n",
    "            relevance = min(0.9, 0.5 + (overlap * 0.1))\n",
    "\n",
    "            unfiltered_memories.append(LocalMatch(record, relevance))\n",
    "\n",
    "        retrieval_method = \"Local File Storage\"\n",
    "        print(f\"Local file: Loaded {len(unfiltered_memories)} records\\n\")\n",
    "    else:\n",
    "        print(f\"File not found: {records_file}\\n\")\n",
    "\n",
    "if len(unfiltered_memories) == 0:\n",
    "    print(\"Loading from parallel_agent_outputs.json...\")\n",
    "    parallel_file = os.path.join(MILESTONE3_OUTPUT, \"parallel_agent_outputs.json\")\n",
    "\n",
    "    if os.path.exists(parallel_file):\n",
    "        with open(parallel_file, 'r', encoding='utf-8') as f:\n",
    "            parallel_data = json.load(f)\n",
    "\n",
    "        agent_outputs = parallel_data.get('agent_outputs', {})\n",
    "\n",
    "        class DirectMatch:\n",
    "            def __init__(self, agent_name, agent_data, relevance):\n",
    "                output = agent_data.get('output', {})\n",
    "                self.id = f\"direct_{agent_name}\"\n",
    "                self.score = relevance\n",
    "                self.metadata = {\n",
    "                    'agent_name': agent_name,\n",
    "                    'risk_level': output.get('risk_level', 'N/A'),\n",
    "                    'confidence': output.get('confidence', 0),\n",
    "                    'num_clauses': len(output.get('extracted_clauses', [])),\n",
    "                    'contract_id': 'direct_load',\n",
    "                    'timestamp': datetime.now().isoformat(),\n",
    "                    'model': agent_data.get('model', 'N/A'),\n",
    "                    'session_id': parallel_data.get('execution_metadata', {}).get('timestamp', 'direct_session'),\n",
    "                    'namespace': f\"{agent_name}_intermediate\",\n",
    "                    'retrieved_namespace': 'local_fallback',\n",
    "                    'has_recommendations': 'recommendations' in output,\n",
    "                    'processing_stage': 'intermediate'\n",
    "                }\n",
    "\n",
    "        relevance_scores = {\n",
    "            'legal': 0.88,\n",
    "            'compliance': 0.92,\n",
    "            'finance': 0.85,\n",
    "            'operations': 0.90\n",
    "        }\n",
    "\n",
    "        for agent_name, agent_data in agent_outputs.items():\n",
    "            if agent_data:\n",
    "                relevance = relevance_scores.get(agent_name, 0.80)\n",
    "                unfiltered_memories.append(DirectMatch(agent_name, agent_data, relevance))\n",
    "\n",
    "        retrieval_method = \"Direct Agent Output Files\"\n",
    "        print(f\"Direct load: Retrieved {len(unfiltered_memories)} agent outputs\\n\")\n",
    "    else:\n",
    "        print(f\"File not found: {parallel_file}\\n\")\n",
    "\n",
    "if not unfiltered_memories:\n",
    "    print(\"No memories available from any source.\")\n",
    "else:\n",
    "    print(f\"Retrieved {len(unfiltered_memories)} memories from all agents\")\n",
    "    print(f\"Retrieval Method: {retrieval_method}\\n\")\n",
    "\n",
    "    agent_distribution = {}\n",
    "    for match in unfiltered_memories:\n",
    "        agent = match.metadata.get('agent_name', 'unknown')\n",
    "        agent_distribution[agent] = agent_distribution.get(agent, 0) + 1\n",
    "\n",
    "    print(\"Memory Records Retrieved:\\n\")\n",
    "    for i, match in enumerate(unfiltered_memories[:8], 1):\n",
    "        meta = match.metadata\n",
    "        print(f\"{i}. {meta.get('agent_name', 'UNKNOWN').upper()} Agent\")\n",
    "        print(f\"   Risk: {meta.get('risk_level', 'N/A')}, \"\n",
    "              f\"Confidence: {meta.get('confidence', 0)}, \"\n",
    "              f\"Score: {match.score:.3f}, \"\n",
    "              f\"Clauses: {meta.get('num_clauses', 0)}\")\n",
    "        print(f\"   Namespace: {meta.get('retrieved_namespace', meta.get('namespace', 'N/A'))}\")\n",
    "        print()\n",
    "\n",
    "    print(\"Cross-Agent Memory Distribution:\")\n",
    "    total_memories = len(unfiltered_memories)\n",
    "    for agent, count in sorted(agent_distribution.items()):\n",
    "        percentage = (count / total_memories) * 100\n",
    "        print(f\"  {agent.capitalize()}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "\n",
    "    print(\"MODEL CROSS-AGENT SYNTHESIS\")\n",
    " \n",
    "    cross_agent_analysis = analyze_with_ollama(unfiltered_query, unfiltered_memories)\n",
    "\n",
    "    if cross_agent_analysis:\n",
    "        print(\"\\nSynthesized Obligations/Responsibilities Assessment:\\n\")\n",
    "        print(cross_agent_analysis)\n",
    "    else:\n",
    "        print(\"\\nModel analysis failed; only raw memory statistics shown above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a7643728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 5 memories from all agents:\n",
      "   Retrieval Method: Pinecone Vector Search\n",
      "\n",
      "Memory Records Retrieved:\n",
      "\n",
      "1. LEGAL Agent\n",
      "   Risk: low, Confidence: 0.85, Score: 0.321\n",
      "   Clauses: 2, Namespace: legal_intermediate\n",
      "   Has Ollama Analysis: yes (N/A)\n",
      "\n",
      "2. COMPLIANCE Agent\n",
      "   Risk: high, Confidence: 1, Score: 0.316\n",
      "   Clauses: 1, Namespace: compliance_intermediate\n",
      "   Has Ollama Analysis: yes (N/A)\n",
      "\n",
      "3. FINANCE Agent\n",
      "   Risk: medium, Confidence: 0.7, Score: 0.314\n",
      "   Clauses: 3, Namespace: finance_intermediate\n",
      "   Has Ollama Analysis: yes (N/A)\n",
      "\n",
      "4. OPERATIONS Agent\n",
      "   Risk: medium, Confidence: 0.8, Score: 0.313\n",
      "   Clauses: 2, Namespace: operations_intermediate\n",
      "   Has Ollama Analysis: yes (N/A)\n",
      "\n",
      "5. UNKNOWN Agent\n",
      "   Risk: N/A, Confidence: 0, Score: 0.107\n",
      "   Clauses: 0, Namespace: routing_decisions\n",
      "   Has Ollama Analysis: no (N/A)\n",
      "\n",
      "Cross-Agent Memory Distribution:\n",
      "   Compliance   ████░░░░░░░░░░░░░░░░ 1 (20.0%)\n",
      "   Finance      ████░░░░░░░░░░░░░░░░ 1 (20.0%)\n",
      "   Legal        ████░░░░░░░░░░░░░░░░ 1 (20.0%)\n",
      "   Operations   ████░░░░░░░░░░░░░░░░ 1 (20.0%)\n",
      "   Unknown      ████░░░░░░░░░░░░░░░░ 1 (20.0%)\n",
      "\n",
      "Insights:\n",
      "   • Memory query spans 5 different agent types\n",
      "   • Total memories accessible: 5\n",
      "\n",
      "Aggregate Metrics:\n",
      "   • Average Confidence: 0.67\n",
      "   • Risk Distribution: {'low': 1, 'high': 1, 'medium': 2, 'unknown': 1}\n",
      "   • Enhanced Memories (Ollama): 4/5\n",
      "\n",
      "Most Relevant Memory:\n",
      "   Agent: LEGAL\n",
      "   Risk: low\n",
      "   Relevance Score: 0.321\n",
      "   Confidence: 0.85\n",
      "   Session: m3_4ddffbdafb3e_20260116_142038\n",
      "MODEL CROSS-AGENT SYNTHESIS\n",
      "  → Analyzing with Ollama gemma2:9b...\n",
      "\n",
      "Synthesized Obligations/Responsibilities Assessment:\n",
      "\n",
      "## Analysis of User Query: Obligations, Responsibilities, Requirements\n",
      "\n",
      "**1. Direct Answer:**\n",
      "\n",
      "The contract analysis reveals potential obligations, responsibilities, and requirements related to **legal compliance**, **financial matters**, and **operational procedures**.  Specific details about these obligations are embedded within the analyzed clauses. \n",
      "\n",
      "**2. Risk Assessment and Key Concerns:**\n",
      "\n",
      "* **High Risk:** The \"COMPLIANCE Agent\" indicates a high risk level associated with potential non-compliance issues. This suggests the contract contains clauses requiring adherence to specific regulations or standards. Failure to comply could lead to legal penalties or reputational damage.\n",
      "* **Medium Risk:** Both \"FINANCE Agent\" and \"OPERATIONS Agent\" present medium risk levels.  This implies potential financial implications (e.g., payment terms, liabilities) and operational challenges (e.g., performance metrics, service level agreements). \n",
      "\n",
      "**3. Specific Recommendations:**\n",
      "\n",
      "* **Prioritize Compliance Review:** Conduct a thorough review of the clauses analyzed by the \"COMPLIANCE Agent\" to ensure full understanding and adherence to all regulatory requirements. Consult with legal counsel if necessary.\n",
      "* **Financial Due Diligence:** Carefully examine the clauses analyzed by the \"FINANCE Agent\" to understand financial obligations, payment terms, and potential liabilities.  Negotiate favorable terms and seek clarification on any ambiguous points.\n",
      "* **Operational Clarity:** Analyze the clauses analyzed by the \"OPERATIONS Agent\" to define clear operational procedures, performance expectations, and responsibilities. Establish mechanisms for monitoring compliance and addressing potential issues proactively.\n",
      "\n",
      "**4. Action Items with Priority:**\n",
      "\n",
      "**High Priority:**\n",
      "\n",
      "1. **Schedule a meeting with legal counsel to review the clauses identified by the \"COMPLIANCE Agent\".**\n",
      "2. **Develop a plan to ensure full compliance with all relevant regulations and standards.**\n",
      "\n",
      "**Medium Priority:**\n",
      "\n",
      "3. **Conduct a detailed analysis of the clauses analyzed by the \"FINANCE Agent\" and negotiate favorable financial terms.**\n",
      "4. **Review the clauses analyzed by the \"OPERATIONS Agent\" and establish clear operational procedures and performance metrics.**\n",
      "\n",
      "\n",
      "By addressing these action items, you can mitigate potential risks and ensure a successful outcome from this contract. Remember to continuously monitor the contract's implementation and seek clarification on any emerging concerns.\n",
      "\n",
      "Results saved to: ../Data/Results/Milestone3\\memory_query_results_new.json\n",
      "Model synthesis included in saved results\n"
     ]
    }
   ],
   "source": [
    "print(f\"Retrieved {len(unfiltered_memories)} memories from all agents:\")\n",
    "print(f\"   Retrieval Method: {retrieval_method}\\n\")\n",
    "\n",
    "if len(unfiltered_memories) == 0:\n",
    "    print(\"No memories found. Please ensure Task 2 completed successfully.\")\n",
    "else:\n",
    "    agent_distribution = {}\n",
    "    for match in unfiltered_memories:\n",
    "        agent = match.metadata.get('agent_name', 'unknown')\n",
    "        agent_distribution[agent] = agent_distribution.get(agent, 0) + 1\n",
    "    \n",
    "    print(\"Memory Records Retrieved:\\n\")\n",
    "    for i, match in enumerate(unfiltered_memories[:8], 1): \n",
    "        meta = match.metadata\n",
    "        print(f\"{i}. {meta.get('agent_name', 'UNKNOWN').upper()} Agent\")\n",
    "        print(f\"   Risk: {meta.get('risk_level', 'N/A')}, \"\n",
    "              f\"Confidence: {meta.get('confidence', 0)}, \"\n",
    "              f\"Score: {match.score:.3f}\")\n",
    "        print(f\"   Clauses: {meta.get('num_clauses', 0)}, \"\n",
    "              f\"Namespace: {meta.get('retrieved_namespace', meta.get('namespace', 'N/A'))}\")\n",
    "        print(f\"   Has Ollama Analysis: {'yes' if meta.get('has_recommendations', False) else 'no'} \"\n",
    "              f\"({meta.get('model_used', 'N/A')})\")\n",
    "        print()\n",
    "    \n",
    "    print(\"Cross-Agent Memory Distribution:\")\n",
    "    total_memories = len(unfiltered_memories)\n",
    "    \n",
    "    for agent, count in sorted(agent_distribution.items()):\n",
    "        percentage = (count / total_memories) * 100\n",
    "        bar_length = int(percentage / 5)\n",
    "        bar = \"█\" * bar_length + \"░\" * (20 - bar_length)\n",
    "        print(f\"   {agent.capitalize():12} {bar} {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nInsights:\")\n",
    "    print(f\"   • Memory query spans {len(agent_distribution)} different agent types\")\n",
    "    print(f\"   • Total memories accessible: {total_memories}\")\n",
    "\n",
    "    risk_levels = {}\n",
    "    total_confidence = 0\n",
    "    enhanced_count = 0\n",
    "    for match in unfiltered_memories:\n",
    "        risk = match.metadata.get('risk_level', 'unknown')\n",
    "        risk_levels[risk] = risk_levels.get(risk, 0) + 1\n",
    "        total_confidence += match.metadata.get('confidence', 0)\n",
    "        if match.metadata.get('has_recommendations', False):\n",
    "            enhanced_count += 1\n",
    "    \n",
    "    avg_confidence = total_confidence / len(unfiltered_memories) if unfiltered_memories else 0\n",
    "    \n",
    "    print(f\"\\nAggregate Metrics:\")\n",
    "    print(f\"   • Average Confidence: {avg_confidence:.2f}\")\n",
    "    print(f\"   • Risk Distribution: {dict(risk_levels)}\")\n",
    "    print(f\"   • Enhanced Memories (Ollama): {enhanced_count}/{total_memories}\")\n",
    "    \n",
    "    top_match = max(unfiltered_memories, key=lambda x: x.score)\n",
    "    print(f\"\\nMost Relevant Memory:\")\n",
    "    print(f\"   Agent: {top_match.metadata.get('agent_name', 'UNKNOWN').upper()}\")\n",
    "    print(f\"   Risk: {top_match.metadata.get('risk_level', 'N/A')}\")\n",
    "    print(f\"   Relevance Score: {top_match.score:.3f}\")\n",
    "    print(f\"   Confidence: {top_match.metadata.get('confidence', 0)}\")\n",
    "    print(f\"   Session: {top_match.metadata.get('session_id', 'N/A')}\")\n",
    "\n",
    "    print(\"MODEL CROSS-AGENT SYNTHESIS\")\n",
    "\n",
    "    cross_agent_analysis = analyze_with_ollama(unfiltered_query, unfiltered_memories)\n",
    "\n",
    "    if cross_agent_analysis:\n",
    "        print(\"\\nSynthesized Obligations/Responsibilities Assessment:\\n\")\n",
    "        print(cross_agent_analysis)\n",
    "    else:\n",
    "        print(\"\\nModel synthesis failed; using raw memory statistics above.\")\n",
    "\n",
    "    unfiltered_results = {\n",
    "        \"query\": unfiltered_query,\n",
    "        \"retrieval_method\": retrieval_method,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_results\": len(unfiltered_memories),\n",
    "        \"agent_distribution\": agent_distribution,\n",
    "        \"avg_confidence\": round(avg_confidence, 2),\n",
    "        \"risk_distribution\": risk_levels,\n",
    "        \"enhanced_memories\": enhanced_count,\n",
    "        \"memories\": [\n",
    "            {\n",
    "                \"id\": match.id,\n",
    "                \"agent\": match.metadata.get('agent_name'),\n",
    "                \"risk_level\": match.metadata.get('risk_level'),\n",
    "                \"confidence\": match.metadata.get('confidence'),\n",
    "                \"similarity_score\": round(match.score, 4),\n",
    "                \"num_clauses\": match.metadata.get('num_clauses'),\n",
    "                \"namespace\": match.metadata.get('retrieved_namespace', match.metadata.get('namespace')),\n",
    "                \"session_id\": match.metadata.get('session_id'),\n",
    "                \"has_recommendations\": match.metadata.get('has_recommendations', False),\n",
    "                \"model_used\": match.metadata.get('model_used')\n",
    "            }\n",
    "            for match in unfiltered_memories\n",
    "        ],\n",
    "        \"model_synthesis\": cross_agent_analysis if cross_agent_analysis else \"Failed\"\n",
    "    }\n",
    "\n",
    "    query_results_file = os.path.join(MILESTONE3_OUTPUT, \"memory_query_results_new.json\")\n",
    "    if os.path.exists(query_results_file):\n",
    "        with open(query_results_file, 'r', encoding='utf-8') as f:\n",
    "            all_query_results = json.load(f)\n",
    "    else:\n",
    "        all_query_results = {}\n",
    "\n",
    "    all_query_results[f'{unfiltered_query}_detailed'] = unfiltered_results\n",
    "\n",
    "    with open(query_results_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_query_results, f, indent=2)\n",
    "\n",
    "    print(f\"\\nResults saved to: {query_results_file}\")\n",
    "    print(f\"Model synthesis included in saved results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e66bc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Agent Risk Comparison\n",
      "\n",
      "Attempting to retrieve agent risk assessments...\n",
      "\n",
      "Legal: Retrieved from Pinecone (legal_intermediate)\n",
      "Compliance: Retrieved from Pinecone (compliance_intermediate)\n",
      "Finance: Retrieved from Pinecone (finance_intermediate)\n",
      "Operations: Retrieved from Pinecone (operations_intermediate)\n",
      "\n",
      "Successfully loaded data for 4 agents\n",
      "\n",
      "MODEL CROSS-AGENT RISK SYNTHESIS\n",
      "No relevant memories found to analyze.\n",
      "\n",
      "Agent Risk Assessment Table:\n",
      "┌─────────────┬────────────┬────────────┬────────────┬──────────────┬──────────────┐\n",
      "│ Agent       │ Risk Level │ Confidence │ Clauses    │ Namespace    │ Model        │\n",
      "├─────────────┼────────────┼────────────┼────────────┼──────────────┼──────────────┤\n",
      "│ Legal       │ Low        │       0.85 │          2 │ legal_interm │ N/A          │\n",
      "│ Compliance  │ High       │       1.00 │          1 │ compliance_i │ N/A          │\n",
      "│ Finance     │ Medium     │       0.70 │          3 │ finance_inte │ N/A          │\n",
      "│ Operations  │ Medium     │       0.80 │          2 │ operations_i │ N/A          │\n",
      "└─────────────┴────────────┴────────────┴────────────┴──────────────┴──────────────┘\n",
      "\n",
      "Aggregate Risk Analysis:\n",
      "   Total Risk Score: 6.85\n",
      "   Average Risk Score: 1.71\n",
      "   Overall Contract Risk: MEDIUM\n",
      "\n",
      "Enhanced risk comparison saved: ../Data/Results/Milestone3\\risk_comparison_analysis_new.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCross-Agent Risk Comparison\\n\")\n",
    "\n",
    "agents = [\"legal\", \"compliance\", \"finance\", \"operations\"]\n",
    "risk_comparison = []\n",
    "\n",
    "print(\"Attempting to retrieve agent risk assessments...\\n\")\n",
    "\n",
    "for agent in agents:\n",
    "    try:\n",
    "        agent_memories = query_agent_memory(\n",
    "            query_text=\"risk assessment analysis\",\n",
    "            agent_filter=agent,\n",
    "            top_k=1,\n",
    "            min_score=0.1 \n",
    "        )\n",
    "        \n",
    "        if agent_memories:\n",
    "            match = agent_memories[0]\n",
    "            meta = match.metadata\n",
    "            risk_comparison.append({\n",
    "                \"agent\": agent,\n",
    "                \"risk_level\": meta.get('risk_level', 'unknown'),\n",
    "                \"confidence\": meta.get('confidence', 0),\n",
    "                \"num_clauses\": meta.get('num_clauses', 0),\n",
    "                \"namespace\": meta.get('retrieved_namespace', meta.get('namespace', 'N/A')),\n",
    "                \"session_id\": meta.get('session_id', 'N/A'),\n",
    "                \"model_used\": meta.get('model_used', 'N/A'),\n",
    "                \"has_recommendations\": meta.get('has_recommendations', False)\n",
    "            })\n",
    "            print(f\"{agent.capitalize()}: Retrieved from Pinecone ({meta.get('retrieved_namespace', 'default')})\")\n",
    "        else:\n",
    "            print(f\"  {agent.capitalize()}: No memories found\")\n",
    "    except Exception as e:\n",
    "        print(f\"{agent.capitalize()}: Pinecone retrieval failed: {e}\")\n",
    "\n",
    "if len(risk_comparison) == 0:\n",
    "    print(\"\\nLoading agent data from local files...\\n\")\n",
    "    \n",
    "    parallel_file = os.path.join(MILESTONE3_OUTPUT, \"parallel_agent_outputs.json\")\n",
    "    \n",
    "    if os.path.exists(parallel_file):\n",
    "        with open(parallel_file, 'r', encoding='utf-8') as f:\n",
    "            parallel_data = json.load(f)\n",
    "        \n",
    "        agent_outputs = parallel_data.get('agent_outputs', {})\n",
    "        \n",
    "        for agent in agents:\n",
    "            agent_data = agent_outputs.get(agent)\n",
    "            if agent_data and 'output' in agent_data:\n",
    "                output = agent_data['output']\n",
    "                risk_comparison.append({\n",
    "                    \"agent\": agent,\n",
    "                    \"risk_level\": output.get('risk_level', 'unknown'),\n",
    "                    \"confidence\": output.get('confidence', 0),\n",
    "                    \"num_clauses\": len(output.get('extracted_clauses', [])),\n",
    "                    \"namespace\": f\"{agent}_intermediate\",\n",
    "                    \"session_id\": parallel_data.get('execution_metadata', {}).get('timestamp', 'direct_session'),\n",
    "                    \"model_used\": agent_data.get('model', 'gemma2:9b'),\n",
    "                    \"has_recommendations\": 'recommendations' in output\n",
    "                })\n",
    "                print(f\"{agent.capitalize()}: Loaded from parallel_agent_outputs.json\")\n",
    "\n",
    "if len(risk_comparison) == 0:\n",
    "    print(\"\\nERROR: No agent data found!\")\n",
    "    print(\"   Please ensure Task 1 and Task 2 completed successfully.\")\n",
    "else:\n",
    "    print(f\"\\nSuccessfully loaded data for {len(risk_comparison)} agents\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"MODEL CROSS-AGENT RISK SYNTHESIS\")\n",
    " \n",
    "    \n",
    "    model_context = f\"Cross-agent risk comparison query.\\n\\nRetrieved {len(risk_comparison)} agents:\\n\"\n",
    "    for comp in risk_comparison:\n",
    "        model_context += f\"- {comp['agent'].upper()}: {comp['risk_level']} risk, {comp['confidence']:.0%} confidence, {comp['num_clauses']} clauses\\n\"\n",
    "    \n",
    "    risk_synthesis = analyze_with_ollama(f\"Analyze this cross-agent risk comparison:\\n{model_context}\", [])\n",
    "    \n",
    "    if risk_synthesis:\n",
    "        print(risk_synthesis)\n",
    "        print()\n",
    "    \n",
    "    print(\"Agent Risk Assessment Table:\")\n",
    "    print(\"┌─────────────┬────────────┬────────────┬────────────┬──────────────┬──────────────┐\")\n",
    "    print(\"│ Agent       │ Risk Level │ Confidence │ Clauses    │ Namespace    │ Model        │\")\n",
    "    print(\"├─────────────┼────────────┼────────────┼────────────┼──────────────┼──────────────┤\")\n",
    "    \n",
    "    risk_weights = {\"high\": 3, \"medium\": 2, \"low\": 1, \"unknown\": 0}\n",
    "    total_risk_score = 0\n",
    "    \n",
    "    for comp in risk_comparison:\n",
    "        agent_name = comp['agent'].capitalize()\n",
    "        risk = comp['risk_level'].capitalize()\n",
    "        conf = comp['confidence']\n",
    "        clauses = comp['num_clauses']\n",
    "        namespace = comp['namespace'][:12]\n",
    "        model = comp['model_used'][:12]\n",
    "        \n",
    "        risk_weight = risk_weights.get(comp['risk_level'].lower(), 0)\n",
    "        weighted_score = risk_weight * conf\n",
    "        total_risk_score += weighted_score\n",
    "        \n",
    "        print(f\"│ {agent_name:11} │ {risk:10} │ {conf:10.2f} │ {clauses:10} │ {namespace:12} │ {model:12} │\")\n",
    "    \n",
    "    print(\"└─────────────┴────────────┴────────────┴────────────┴──────────────┴──────────────┘\")\n",
    "    \n",
    "    avg_risk_score = total_risk_score / len(risk_comparison)\n",
    "    \n",
    "    print(f\"\\nAggregate Risk Analysis:\")\n",
    "    print(f\"   Total Risk Score: {total_risk_score:.2f}\")\n",
    "    print(f\"   Average Risk Score: {avg_risk_score:.2f}\")\n",
    "    \n",
    "    overall_risk = \"HIGH\" if avg_risk_score >= 2.5 else \"MEDIUM\" if avg_risk_score >= 1.5 else \"LOW\"\n",
    "    print(f\"   Overall Contract Risk: {overall_risk}\")\n",
    "    \n",
    "    comparison_output = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"agents_compared\": len(risk_comparison),\n",
    "        \"risk_comparison\": risk_comparison,\n",
    "        \"aggregate_metrics\": {\n",
    "            \"total_risk_score\": round(total_risk_score, 2),\n",
    "            \"average_risk_score\": round(avg_risk_score, 2),\n",
    "            \"overall_risk_level\": overall_risk,\n",
    "            \"average_confidence\": round(sum(c['confidence'] for c in risk_comparison) / len(risk_comparison), 2)\n",
    "        },\n",
    "        \"model_synthesis\": risk_synthesis if risk_synthesis else \"Not generated\"\n",
    "    }\n",
    "    \n",
    "    comparison_file = os.path.join(MILESTONE3_OUTPUT, \"risk_comparison_analysis_new.json\")\n",
    "    with open(comparison_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(comparison_output, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nEnhanced risk comparison saved: {comparison_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc8bc8",
   "metadata": {},
   "source": [
    "# Cross-Agent Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "85121bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Initializing Components\n",
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False, 'architecture': 'BertModel'})\n",
      "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
      "  (2): Normalize()\n",
      ") loaded\n",
      "Connected to Pinecone index: <pinecone.db_data.index.Index object at 0x0000024F8166F920>\n",
      "Loaded original agent outputs from 4 agents\n",
      "Agents: ['legal', 'compliance', 'finance', 'operations']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone\n",
    "\n",
    "MILESTONE3_OUTPUT = \"../Data/Results/Milestone3\"\n",
    "PINECONE_API_KEY = 'pcsk_3ftgmC_GzUZkRCnxa2jmDu7TTjnGWjC3QaN8c2PcQ5KN5PUSyQaEmmcdGUGu2BLd4Y7TRn'\n",
    "\n",
    "print(\"\\n Initializing Components\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  \n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(\"clauseai-agents\")\n",
    "print(f\"{embedding_model} loaded\") \n",
    "print(f\"Connected to Pinecone index: {index}\")\n",
    "\n",
    "parallel_file = os.path.join(MILESTONE3_OUTPUT, \"parallel_agent_outputs.json\")\n",
    "if os.path.exists(parallel_file):\n",
    "    with open(parallel_file, 'r', encoding='utf-8') as f:\n",
    "        parallel_data = json.load(f)\n",
    "    agent_outputs = parallel_data.get('agent_outputs', {})\n",
    "    print(f\"Loaded original agent outputs from {len(agent_outputs)} agents\")\n",
    "    print(\"Agents:\", list(agent_outputs.keys()))\n",
    "else:\n",
    "    print(f\"Warning: {parallel_file} not found. Ensure parallel execution completed.\")\n",
    "    agent_outputs = {}\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b03d9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pinecone Index Statistics:\n",
      "  Total Vectors: 5\n",
      "  Dimension: 384\n",
      "  Index Fullness: 0.0\n",
      "\n",
      "  Namespaces:\n",
      "    - legal_intermediate: 1 vectors\n",
      "    - routing_decisions: 1 vectors\n",
      "    - finance_intermediate: 1 vectors\n",
      "    - compliance_intermediate: 1 vectors\n",
      "    - operations_intermediate: 1 vectors\n"
     ]
    }
   ],
   "source": [
    "stats = index.describe_index_stats()\n",
    "print(f\"\\nPinecone Index Statistics:\")\n",
    "print(f\"  Total Vectors: {stats.total_vector_count}\")\n",
    "print(f\"  Dimension: {stats.dimension}\")\n",
    "print(f\"  Index Fullness: {stats.index_fullness}\")\n",
    "\n",
    "if hasattr(stats, 'namespaces') and stats.namespaces:\n",
    "    print(f\"\\n  Namespaces:\")\n",
    "    for ns, ns_stats in stats.namespaces.items():\n",
    "        print(f\"    - {ns}: {ns_stats.vector_count} vectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d7f23",
   "metadata": {},
   "source": [
    "#### 1. Retrieving All Agent Memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "132c51d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving All Agent Memories\n",
      "\n",
      "FIXED: Retrieved 4 memories across 4 namespaces\n",
      "Sample metadata keys: ['agent_name', 'clauses_analyzed', 'confidence', 'contract_id', 'execution_time', 'has_recommendations', 'model', 'namespace', 'num_clauses', 'processing_stage', 'risk_level', 'session_id', 'timestamp']\n",
      "Sample agent: operations risk: medium\n"
     ]
    }
   ],
   "source": [
    "print(\"Retrieving All Agent Memories\\n\")\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "try:\n",
    "    memory_query_embedding = embedding_model.encode(\n",
    "        \"contract analysis multi-agent outputs\"\n",
    "    ).tolist()\n",
    "\n",
    "    M3_NAMESPACES = [\n",
    "        \"legal_intermediate\",\n",
    "        \"compliance_intermediate\",\n",
    "        \"finance_intermediate\",\n",
    "        \"operations_intermediate\",\n",
    "    ]\n",
    "\n",
    "    class UnifiedQueryResult:\n",
    "        def __init__(self):\n",
    "            self.matches = []\n",
    "\n",
    "    all_agent_memory = UnifiedQueryResult()\n",
    "\n",
    "    def query_namespace(ns: str):\n",
    "        return index.query(\n",
    "            vector=memory_query_embedding,\n",
    "            top_k=50,\n",
    "            include_metadata=True,\n",
    "            namespace=ns,\n",
    "        )\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=len(M3_NAMESPACES)) as executor:\n",
    "        futures = {\n",
    "            executor.submit(query_namespace, ns): ns\n",
    "            for ns in M3_NAMESPACES\n",
    "        }\n",
    "\n",
    "        for future in as_completed(futures):\n",
    "            ns = futures[future]\n",
    "            result = future.result()\n",
    "\n",
    "            if result and getattr(result, \"matches\", None):\n",
    "                all_agent_memory.matches.extend(result.matches)\n",
    "\n",
    "    if not all_agent_memory.matches:\n",
    "        raise Exception(\"No matches returned from any M3 namespace\")\n",
    "\n",
    "    print(\n",
    "        f\"FIXED: Retrieved {len(all_agent_memory.matches)} memories \"\n",
    "        f\"across {len(M3_NAMESPACES)} namespaces\"\n",
    "    )\n",
    "\n",
    "    sample_meta = all_agent_memory.matches[0].metadata\n",
    "    print(\"Sample metadata keys:\", list(sample_meta.keys()))\n",
    "    print(\n",
    "        \"Sample agent:\",\n",
    "        sample_meta.get(\"agent_name\"),\n",
    "        \"risk:\",\n",
    "        sample_meta.get(\"risk_level\"),\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Pinecone issue: {e}\")\n",
    "    print(\"Using DIRECT schema-based fallback...\\n\")\n",
    "\n",
    "    class PineconeSchemaMatch:\n",
    "        def __init__(self, metadata_dict):\n",
    "            self.metadata = metadata_dict\n",
    "\n",
    "    class FixedQueryResult:\n",
    "        def __init__(self):\n",
    "            self.matches = []\n",
    "\n",
    "    all_agent_memory = FixedQueryResult()\n",
    "\n",
    "    agent_memory_examples = [\n",
    "        {\n",
    "            \"ID\": \"m3_4ddffbdafb3e_20260116_142038_compliance\",\n",
    "            \"agent_name\": \"compliance\",\n",
    "            \"clauses_analyzed\": 1,\n",
    "            \"confidence\": 1,\n",
    "            \"contract_id\": \"4ddffbdafb3e\",\n",
    "            \"execution_time\": 163.776,\n",
    "            \"has_recommendations\": True,\n",
    "            \"model\": \"gemma2:9b\",\n",
    "            \"namespace\": \"compliance_intermediate\",\n",
    "            \"num_clauses\": 1,\n",
    "            \"processing_stage\": \"ollama_enhanced\",\n",
    "            \"risk_level\": \"high\",\n",
    "            \"session_id\": \"m3_4ddffbdafb3e_20260116_142038\",\n",
    "            \"timestamp\": \"2026-01-16T14:36:23.100878\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for data in agent_memory_examples:\n",
    "        all_agent_memory.matches.append(PineconeSchemaMatch(data))\n",
    "\n",
    "    print(\n",
    "        f\"Schema fallback: Loaded \"\n",
    "        f\"{len(all_agent_memory.matches)} structured memories\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "948fd421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[OPERATIONS] risk=medium | confidence=0.8 | clauses=2 | stage=ollama_enhanced | model=gemma2:9b\\n[FINANCE] risk=medium | confidence=0.7 | clauses=3 | stage=ollama_enhanced | model=gemma2:9b\\n[COMPLIANCE] risk=high | confidence=1 | clauses=1 | stage=ollama_enhanced | model=gemma2:9b\\n[LEGAL] risk=low | confidence=0.85 | clauses=2 | stage=ollama_enhanced | model=gemma2:9b'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_context = \"\\n\".join(\n",
    "    [\n",
    "        (\n",
    "            f\"[{m.metadata.get('agent_name', 'unknown').upper()}] \"\n",
    "            f\"risk={m.metadata.get('risk_level', 'unknown')} | \"\n",
    "            f\"confidence={m.metadata.get('confidence', 'n/a')} | \"\n",
    "            f\"clauses={m.metadata.get('clauses_analyzed', m.metadata.get('num_clauses', 'n/a'))} | \"\n",
    "            f\"stage={m.metadata.get('processing_stage', 'unknown')} | \"\n",
    "            f\"model={m.metadata.get('model', 'unknown')}\"\n",
    "        )\n",
    "        for m in all_agent_memory.matches\n",
    "        if hasattr(m, \"metadata\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "shared_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "63e7072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_context = {}\n",
    "\n",
    "for m in all_agent_memory.matches:\n",
    "    if not hasattr(m, \"metadata\"):\n",
    "        continue\n",
    "\n",
    "    meta = m.metadata\n",
    "    agent_name = meta.get(\"agent_name\")\n",
    "\n",
    "    if not agent_name:\n",
    "        continue\n",
    "\n",
    "    detailed_context[agent_name] = {\n",
    "        \"risk_level\": meta.get(\"risk_level\", \"unknown\"),\n",
    "        \"confidence\": meta.get(\"confidence\", 0),\n",
    "        \"num_clauses\": meta.get(\n",
    "            \"num_clauses\",\n",
    "            meta.get(\"clauses_analyzed\", 0),\n",
    "        ),\n",
    "        \"execution_time\": meta.get(\"execution_time\"),\n",
    "        \"has_recommendations\": meta.get(\"has_recommendations\"),\n",
    "        \"processing_stage\": meta.get(\"processing_stage\"),\n",
    "        \"model\": meta.get(\"model\"),\n",
    "        \"session_id\": meta.get(\"session_id\"),\n",
    "        \"extracted_clauses\": meta.get(\"extracted_clauses\", []),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e8f7ca",
   "metadata": {},
   "source": [
    "#### 2. Passing Context to Legal Agent for Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "49ecb8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Refining Legal Agent Assessment\n",
      "\n",
      "Legal Agent - Initial Assessment:\n",
      "   Risk Level: LOW\n",
      "   Confidence: 85%\n",
      "   Clauses: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRefining Legal Agent Assessment\")\n",
    "\n",
    "print(\"\\nLegal Agent - Initial Assessment:\")\n",
    "legal_initial = detailed_context.get('legal', {})\n",
    "print(f\"   Risk Level: {legal_initial.get('risk_level', 'N/A').upper()}\")\n",
    "print(f\"   Confidence: {legal_initial.get('confidence', 0):.0%}\")\n",
    "print(f\"   Clauses: {legal_initial.get('num_clauses', 0)}\")\n",
    "\n",
    "def refine_legal_agent(initial_assessment, other_agents_context):\n",
    "    initial_risk = initial_assessment.get('risk_level', 'low')\n",
    "    initial_confidence = initial_assessment.get('confidence', 0)\n",
    "    \n",
    "    compliance_risk = other_agents_context.get('compliance', {}).get('risk_level', 'low')\n",
    "    finance_risk = other_agents_context.get('finance', {}).get('risk_level', 'low')\n",
    "    \n",
    "    escalation_reasons = []\n",
    "    refined_risk = initial_risk\n",
    "    refined_confidence = initial_confidence\n",
    "    \n",
    "    if compliance_risk == 'high':\n",
    "        if initial_risk == 'low':\n",
    "            refined_risk = 'medium'\n",
    "            refined_confidence = min(0.90, initial_confidence + 0.10)\n",
    "        escalation_reasons.append(\n",
    "            \"Compliance identified high-risk confidentiality violations that have legal implications\"\n",
    "        )\n",
    "    \n",
    "    if finance_risk in ['medium', 'high'] and 'termination' in str(\n",
    "        initial_assessment.get('extracted_clauses', [])\n",
    "    ).lower():\n",
    "        refined_risk = 'high' if refined_risk == 'medium' else 'medium'\n",
    "        refined_confidence = min(0.95, refined_confidence + 0.05)\n",
    "        escalation_reasons.append(\n",
    "            \"Termination clauses combined with financial penalties create compound risk\"\n",
    "        )\n",
    "    \n",
    "    medium_risk_count = sum(\n",
    "        1 for agent_data in other_agents_context.values()\n",
    "        if agent_data.get('risk_level') == 'medium'\n",
    "    )\n",
    "    \n",
    "    if medium_risk_count >= 2 and initial_risk == 'low':\n",
    "        refined_risk = 'medium'\n",
    "        refined_confidence = min(0.88, initial_confidence + 0.03)\n",
    "        escalation_reasons.append(\n",
    "            f\"Multiple domains ({medium_risk_count}) showing medium risk increases overall legal exposure\"\n",
    "        )\n",
    "    \n",
    "    return {\n",
    "        'original_risk': initial_risk,\n",
    "        'refined_risk': refined_risk,\n",
    "        'original_confidence': initial_confidence,\n",
    "        'refined_confidence': refined_confidence,\n",
    "        'escalation_reasons': escalation_reasons,\n",
    "        'cross_agent_influences': {\n",
    "            'compliance': compliance_risk,\n",
    "            'finance': finance_risk,\n",
    "            'operations': other_agents_context.get('operations', {}).get(\n",
    "                'risk_level', 'unknown'\n",
    "            ),\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "refined_legal = refine_legal_agent(legal_initial, detailed_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e26127c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  → Analyzing with Ollama gemma2:9b...\n"
     ]
    }
   ],
   "source": [
    "model_validation = analyze_with_ollama(\n",
    "    {\n",
    "        \"task\": \"legal_cross_agent_refinement\",\n",
    "        \"input\": {\n",
    "            \"initial_legal_assessment\": legal_initial,\n",
    "            \"heuristic_refinement\": refined_legal,\n",
    "            \"cross_agent_context\": detailed_context,\n",
    "        },\n",
    "        \"instructions\": (\n",
    "            \"Validate the refined legal risk using compliance, finance, and operations context. \"\n",
    "            \"Confirm or adjust the refined risk and confidence. \"\n",
    "            \"Return STRICT JSON with keys: refined_risk, refined_confidence, justification.\"\n",
    "        ),\n",
    "    },\n",
    "    all_agent_memory.matches \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211928b3",
   "metadata": {},
   "source": [
    "#### 3. Updating Legal Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "99600c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updating Legal Memory\n",
      "\n",
      "Legal Agent - Final Refined Analysis:\n",
      "   Risk Level: MEDIUM\n",
      "   Confidence: 88%\n",
      "   Escalation Reasons:\n",
      "      1. Compliance identified high-risk confidentiality violations that have legal implications\n",
      "      2. Multiple domains (2) showing medium risk increases overall legal exposure\n",
      "   Cross-Agent Influences:\n",
      "      • Compliance: high\n",
      "      • Finance: medium\n",
      "      • Operations: medium\n",
      "Refined legal assessment stored in Pinecone\n",
      "Refined legal assessment saved: ../Data/Results/Milestone3\\legal_agent_refined.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUpdating Legal Memory\")\n",
    "\n",
    "print(\"\\nLegal Agent - Final Refined Analysis:\")\n",
    "print(f\"   Risk Level: {refined_legal['final_risk'].upper()}\")\n",
    "print(f\"   Confidence: {refined_legal['final_confidence']:.0%}\")\n",
    "\n",
    "if refined_legal['escalation_reasons']:\n",
    "    print(\"   Escalation Reasons:\")\n",
    "    for i, r in enumerate(refined_legal['escalation_reasons'], 1):\n",
    "        print(f\"      {i}. {r}\")\n",
    "else:\n",
    "    print(\"   Escalation Reasons: None\")\n",
    "\n",
    "print(\"   Cross-Agent Influences:\")\n",
    "for k, v in refined_legal['cross_agent_influences'].items():\n",
    "    print(f\"      • {k.capitalize()}: {v}\")\n",
    "\n",
    "\n",
    "legal_refined_output = {\n",
    "    \"agent_name\": \"legal_refined\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"refinement_iteration\": 1,\n",
    "    \"original_assessment\": legal_initial,\n",
    "    \"refined_assessment\": {\n",
    "        \"risk_level\": refined_legal[\"final_risk\"],\n",
    "        \"confidence\": refined_legal[\"final_confidence\"],\n",
    "        \"clause_type\": \"Legal Analysis (Cross-Agent Refined)\",\n",
    "        \"extracted_clauses\": legal_initial.get(\"extracted_clauses\", []),\n",
    "        \"evidence\": legal_initial.get(\"evidence\", []),\n",
    "        \"escalation_reasons\": refined_legal[\"escalation_reasons\"],\n",
    "        \"model_justification\": refined_legal.get(\"model_justification\", \"\"),\n",
    "    },\n",
    "    # \n",
    "    \"cross_agent_context\": detailed_context,\n",
    "}\n",
    "\n",
    "\n",
    "refined_legal_text = f\"\"\"\n",
    "Agent: Legal (Refined)\n",
    "Final Risk Level: {refined_legal['final_risk']}\n",
    "Final Confidence: {refined_legal['final_confidence']}\n",
    "Escalation Reasons: {' | '.join(refined_legal['escalation_reasons']) if refined_legal['escalation_reasons'] else 'None'}\n",
    "Cross-Agent Context: {json.dumps(detailed_context, indent=2)}\n",
    "\"\"\"\n",
    "\n",
    "refined_legal_embedding = embedding_model.encode(\n",
    "    refined_legal_text\n",
    ").tolist()\n",
    "\n",
    "\n",
    "contract_id = hashlib.md5(\n",
    "    json.dumps(agent_outputs, sort_keys=True).encode()\n",
    ").hexdigest()[:12]\n",
    "\n",
    "refined_legal_id = f\"{contract_id}_legal_refined_v1\"\n",
    "\n",
    "try:\n",
    "    index.upsert(\n",
    "        vectors=[{\n",
    "            \"id\": refined_legal_id,\n",
    "            \"values\": refined_legal_embedding,\n",
    "            \"metadata\": {\n",
    "                \"agent_name\": \"legal_refined\",\n",
    "                \"risk_level\": refined_legal[\"final_risk\"],\n",
    "                \"confidence\": refined_legal[\"final_confidence\"],\n",
    "                \"clause_type\": \"Legal Analysis (Refined)\",\n",
    "                \"num_clauses\": legal_initial.get(\"num_clauses\", 0),\n",
    "                \"contract_id\": contract_id,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"refinement_iteration\": 1,\n",
    "                \"escalated\": len(refined_legal[\"escalation_reasons\"]) > 0,\n",
    "                \"processing_stage\": \"cross_agent_refinement\",\n",
    "                \"model_used\": \"gemma2:9b\",\n",
    "            },\n",
    "        }],\n",
    "        namespace=\"legal_intermediate\",  \n",
    "    )\n",
    "\n",
    "    print(\"Refined legal assessment stored in Pinecone\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Pinecone storage failed: {e}\")\n",
    "    print(\"Refined assessment saved locally only\")\n",
    "\n",
    "\n",
    "refined_legal_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"legal_agent_refined.json\",\n",
    ")\n",
    "\n",
    "with open(refined_legal_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(legal_refined_output, f, indent=2)\n",
    "\n",
    "print(f\"Refined legal assessment saved: {refined_legal_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1836f",
   "metadata": {},
   "source": [
    "#### 4. Refinement of Finance Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f1cbafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_model_json(raw_output: str):\n",
    "   \n",
    "    if not raw_output or not raw_output.strip():\n",
    "        return None, \"Empty model response\"\n",
    "\n",
    "    try:\n",
    "        return json.loads(raw_output), None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        start = raw_output.index(\"{\")\n",
    "        end = raw_output.rindex(\"}\") + 1\n",
    "        return json.loads(raw_output[start:end]), None\n",
    "    except Exception as e:\n",
    "        return None, f\"Unparseable model output: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "964c2833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Refining Finance Agent Assessment\n",
      "\n",
      "Finance Agent - Initial Assessment:\n",
      "   Risk Level: MEDIUM\n",
      "   Confidence: 70%\n",
      "   Clauses: 3\n",
      "  → Analyzing with Ollama gemma2:9b...\n",
      "\n",
      "Finance Agent - Refined Assessment:\n",
      "   Original Risk: MEDIUM\n",
      "   Heuristic Risk: HIGH\n",
      "   Final Risk (Model): HIGH\n",
      "   Confidence Change: 70% → 85%\n",
      "\n",
      "   Risk Escalation Detected:\n",
      "      1. Legal risk escalated to medium, increasing financial liability exposure\n",
      "      2. High compliance risk may result in regulatory fines and penalties\n",
      "      3. Operations risk combined with payment obligations creates cash flow uncertainty\n",
      "\n",
      "   Cross-Agent Influences:\n",
      "      • Legal: medium\n",
      "      • Compliance: high\n",
      "      • Operations: medium\n",
      "\n",
      "   Model Justification:\n",
      "      The initial finance risk assessment was 'medium' with a confidence of 0.7. However, cross-agent influences from compliance ('high') and operations ('medium') significantly elevate the overall financial risk. The compliance agent identified a high risk due to potential regulatory fines and penalties, while the operations agent highlighted cash flow uncertainty stemming from operational risks combined with payment obligations. Considering these factors, the refined risk level is 'high' with a confidence of 0.85.\n",
      "\n",
      "Refined finance assessment saved: ../Data/Results/Milestone3\\finance_agent_refined.json\n",
      "Refined finance assessment stored in Pinecone\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRefining Finance Agent Assessment\")\n",
    "\n",
    "print(\"\\nFinance Agent - Initial Assessment:\")\n",
    "finance_initial = detailed_context.get(\"finance\", {})\n",
    "print(f\"   Risk Level: {finance_initial.get('risk_level', 'N/A').upper()}\")\n",
    "print(f\"   Confidence: {finance_initial.get('confidence', 0):.0%}\")\n",
    "print(f\"   Clauses: {finance_initial.get('num_clauses', 0)}\")\n",
    "\n",
    "\n",
    "def refine_finance_agent(initial_assessment, other_agents_context, refined_legal):\n",
    "    initial_risk = initial_assessment.get(\"risk_level\", \"medium\")\n",
    "    initial_confidence = initial_assessment.get(\"confidence\", 0)\n",
    "\n",
    "    escalation_reasons = []\n",
    "    refined_risk = initial_risk\n",
    "    refined_confidence = initial_confidence\n",
    "\n",
    "    if (\n",
    "        refined_legal[\"refined_risk\"] in [\"medium\", \"high\"]\n",
    "        and refined_legal[\"original_risk\"] != refined_legal[\"refined_risk\"]\n",
    "    ):\n",
    "        refined_risk = \"high\" if initial_risk == \"medium\" else \"medium\"\n",
    "        refined_confidence = min(0.85, initial_confidence + 0.10)\n",
    "        escalation_reasons.append(\n",
    "            f\"Legal risk escalated to {refined_legal['refined_risk']}, increasing financial liability exposure\"\n",
    "        )\n",
    "\n",
    "    compliance_risk = other_agents_context.get(\"compliance\", {}).get(\"risk_level\", \"low\")\n",
    "    if compliance_risk == \"high\":\n",
    "        refined_risk = \"high\"\n",
    "        refined_confidence = min(0.90, initial_confidence + 0.15)\n",
    "        escalation_reasons.append(\n",
    "            \"High compliance risk may result in regulatory fines and penalties\"\n",
    "        )\n",
    "\n",
    "    operations_risk = other_agents_context.get(\"operations\", {}).get(\"risk_level\", \"low\")\n",
    "    if operations_risk == \"medium\" and initial_risk == \"medium\":\n",
    "        refined_confidence = min(0.85, initial_confidence + 0.10)\n",
    "        escalation_reasons.append(\n",
    "            \"Operations risk combined with payment obligations creates cash flow uncertainty\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"original_risk\": initial_risk,\n",
    "        \"refined_risk\": refined_risk,\n",
    "        \"original_confidence\": initial_confidence,\n",
    "        \"refined_confidence\": refined_confidence,\n",
    "        \"escalation_reasons\": escalation_reasons,\n",
    "        \"cross_agent_influences\": {\n",
    "            \"legal\": refined_legal[\"final_risk\"],\n",
    "            \"compliance\": compliance_risk,\n",
    "            \"operations\": operations_risk,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "refined_finance = refine_finance_agent(\n",
    "    finance_initial,\n",
    "    detailed_context,\n",
    "    refined_legal,\n",
    ")\n",
    "\n",
    "def parse_model_json(raw_output: str):\n",
    "    if not raw_output or not raw_output.strip():\n",
    "        return None, \"Empty model response\"\n",
    "\n",
    "    try:\n",
    "        return json.loads(raw_output), None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        start = raw_output.index(\"{\")\n",
    "        end = raw_output.rindex(\"}\") + 1\n",
    "        return json.loads(raw_output[start:end]), None\n",
    "    except Exception as e:\n",
    "        return None, f\"Unparseable model output: {e}\"\n",
    "\n",
    "\n",
    "try:\n",
    "    raw_model_output = analyze_with_ollama(\n",
    "        {\n",
    "            \"task\": \"finance_cross_agent_refinement\",\n",
    "            \"input\": {\n",
    "                \"initial_finance_assessment\": finance_initial,\n",
    "                \"heuristic_refinement\": refined_finance,\n",
    "                \"cross_agent_context\": detailed_context,\n",
    "            },\n",
    "            \"instructions\": (\n",
    "                \"Validate the refined finance risk using legal, compliance, and operations context. \"\n",
    "                \"Confirm or adjust the risk level and confidence. \"\n",
    "                \"Return STRICT JSON with keys: refined_risk, refined_confidence, justification.\"\n",
    "            ),\n",
    "        },\n",
    "        all_agent_memory.matches,\n",
    "    )\n",
    "\n",
    "    parsed, parse_error = parse_model_json(raw_model_output)\n",
    "\n",
    "    if parsed:\n",
    "        refined_finance[\"final_risk\"] = parsed.get(\n",
    "            \"refined_risk\", refined_finance[\"refined_risk\"]\n",
    "        )\n",
    "        refined_finance[\"final_confidence\"] = parsed.get(\n",
    "            \"refined_confidence\", refined_finance[\"refined_confidence\"]\n",
    "        )\n",
    "        refined_finance[\"model_justification\"] = parsed.get(\n",
    "            \"justification\", \"Model confirmed heuristic assessment\"\n",
    "        )\n",
    "    else:\n",
    "        refined_finance[\"final_risk\"] = refined_finance[\"refined_risk\"]\n",
    "        refined_finance[\"final_confidence\"] = refined_finance[\"refined_confidence\"]\n",
    "        refined_finance[\"model_justification\"] = (\n",
    "            f\"Model output unusable, heuristic retained. Reason: {parse_error}\"\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    refined_finance[\"final_risk\"] = refined_finance[\"refined_risk\"]\n",
    "    refined_finance[\"final_confidence\"] = refined_finance[\"refined_confidence\"]\n",
    "    refined_finance[\"model_justification\"] = f\"Model validation fallback: {e}\"\n",
    "\n",
    "\n",
    "print(\"\\nFinance Agent - Refined Assessment:\")\n",
    "print(f\"   Original Risk: {refined_finance['original_risk'].upper()}\")\n",
    "print(f\"   Heuristic Risk: {refined_finance['refined_risk'].upper()}\")\n",
    "print(f\"   Final Risk (Model): {refined_finance['final_risk'].upper()}\")\n",
    "print(\n",
    "    f\"   Confidence Change: \"\n",
    "    f\"{refined_finance['original_confidence']:.0%} → \"\n",
    "    f\"{refined_finance['final_confidence']:.0%}\"\n",
    ")\n",
    "\n",
    "if refined_finance[\"escalation_reasons\"]:\n",
    "    print(\"\\n   Risk Escalation Detected:\")\n",
    "    for i, r in enumerate(refined_finance[\"escalation_reasons\"], 1):\n",
    "        print(f\"      {i}. {r}\")\n",
    "else:\n",
    "    print(\"\\n   No risk escalation detected\")\n",
    "\n",
    "print(\"\\n   Cross-Agent Influences:\")\n",
    "for agent, risk in refined_finance[\"cross_agent_influences\"].items():\n",
    "    print(f\"      • {agent.capitalize()}: {risk}\")\n",
    "\n",
    "print(\"\\n   Model Justification:\")\n",
    "print(f\"      {refined_finance['model_justification']}\")\n",
    "\n",
    "\n",
    "finance_refined_output = {\n",
    "    \"agent_name\": \"finance_refined\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"refinement_iteration\": 1,\n",
    "    \"original_assessment\": finance_initial,\n",
    "    \"refined_assessment\": {\n",
    "        \"risk_level\": refined_finance[\"final_risk\"],\n",
    "        \"confidence\": refined_finance[\"final_confidence\"],\n",
    "        \"clause_type\": \"Finance Analysis (Cross-Agent Refined)\",\n",
    "        \"extracted_clauses\": finance_initial.get(\"extracted_clauses\", []),\n",
    "        \"evidence\": finance_initial.get(\"evidence\", []),\n",
    "        \"escalation_reasons\": refined_finance[\"escalation_reasons\"],\n",
    "        \"model_justification\": refined_finance[\"model_justification\"],\n",
    "    },\n",
    "    \"cross_agent_context\": detailed_context,\n",
    "}\n",
    "\n",
    "refined_finance_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"finance_agent_refined.json\",\n",
    ")\n",
    "\n",
    "with open(refined_finance_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(finance_refined_output, f, indent=2)\n",
    "\n",
    "print(f\"\\nRefined finance assessment saved: {refined_finance_file}\")\n",
    "\n",
    "\n",
    "refined_finance_text = f\"\"\"\n",
    "Agent: Finance (Refined)\n",
    "Final Risk Level: {refined_finance['final_risk']}\n",
    "Final Confidence: {refined_finance['final_confidence']}\n",
    "Escalation Reasons: {' | '.join(refined_finance['escalation_reasons']) if refined_finance['escalation_reasons'] else 'None'}\n",
    "\"\"\"\n",
    "\n",
    "refined_finance_embedding = embedding_model.encode(\n",
    "    refined_finance_text\n",
    ").tolist()\n",
    "\n",
    "refined_finance_id = f\"{contract_id}_finance_refined_v1\"\n",
    "\n",
    "try:\n",
    "    index.upsert(\n",
    "        vectors=[{\n",
    "            \"id\": refined_finance_id,\n",
    "            \"values\": refined_finance_embedding,\n",
    "            \"metadata\": {\n",
    "                \"agent_name\": \"finance_refined\",\n",
    "                \"risk_level\": refined_finance[\"final_risk\"],\n",
    "                \"confidence\": refined_finance[\"final_confidence\"],\n",
    "                \"clause_type\": \"Finance Analysis (Refined)\",\n",
    "                \"num_clauses\": finance_initial.get(\"num_clauses\", 0),\n",
    "                \"contract_id\": contract_id,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"refinement_iteration\": 1,\n",
    "                \"escalated\": len(refined_finance[\"escalation_reasons\"]) > 0,\n",
    "                \"processing_stage\": \"cross_agent_refinement\",\n",
    "                \"model_used\": \"gemma2:9b\",\n",
    "            },\n",
    "        }],\n",
    "        namespace=\"finance_intermediate\",\n",
    "    )\n",
    "    print(\"Refined finance assessment stored in Pinecone\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Pinecone storage failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b8bc2",
   "metadata": {},
   "source": [
    "#### 5. Compliance Agent Reading from Finance Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd97dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Compliance Agent - Initial Assessment:\n",
      "   Risk Level: HIGH\n",
      "   Confidence: 100%\n",
      "   Clauses: 1\n",
      "\n",
      "Compliance Reads Refined Finance Output\n",
      "   → Finance escalated to: HIGH\n",
      "   → Finance confidence: 85%\n",
      "  → Analyzing with Ollama gemma2:9b...\n",
      "\n",
      "Compliance Agent - Refined Assessment:\n",
      "   Original Risk: HIGH\n",
      "   Heuristic Risk: CRITICAL\n",
      "   Final Risk (Model): HIGH\n",
      "   Confidence: 90%\n",
      "\n",
      "   RISK ESCALATION DETECTED:\n",
      "      1. Combined high financial and compliance risks create critical contractual exposure\n",
      "      2. Confidentiality breaches may trigger both regulatory fines and financial penalties\n",
      "      3. Financial penalty clauses amplify the cost of compliance violations\n",
      "      4. Pattern detected: 3 domains show elevated risk, suggesting systemic contract issues\n",
      "\n",
      "   Finance Influence:\n",
      "      • Finance Risk Level: HIGH\n",
      "      • Finance Confidence: 85%\n",
      "      • Finance Escalations: 3\n",
      "\n",
      "   Model Justification:\n",
      "      While the initial compliance risk assessment was 'high' with 100% confidence, cross-agent influences from finance ('medium') and operations ('medium') significantly elevate the overall risk. The finance agent highlights potential regulatory fines and penalties, while the operations agent points to cash flow uncertainty stemming from operational risks combined with payment obligations. Considering these factors, the refined risk level is 'high' with a confidence of 0.9.\n",
      "\n",
      "Refined compliance assessment saved: ../Data/Results/Milestone3\\compliance_agent_refined.json\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCompliance Agent - Initial Assessment:\")\n",
    "\n",
    "compliance_initial = detailed_context.get(\"compliance\", {})\n",
    "print(f\"   Risk Level: {compliance_initial.get('risk_level', 'N/A').upper()}\")\n",
    "print(f\"   Confidence: {compliance_initial.get('confidence', 0):.0%}\")\n",
    "print(f\"   Clauses: {compliance_initial.get('num_clauses', 0)}\")\n",
    "\n",
    "print(\"\\nCompliance Reads Refined Finance Output\")\n",
    "print(f\"   → Finance escalated to: {refined_finance['final_risk'].upper()}\")\n",
    "print(f\"   → Finance confidence: {refined_finance['final_confidence']:.0%}\")\n",
    "\n",
    "\n",
    "def refine_compliance_agent(initial_assessment, refined_finance, other_agents):\n",
    "    initial_risk = initial_assessment.get(\"risk_level\", \"high\")\n",
    "    initial_confidence = initial_assessment.get(\"confidence\", 1.0)\n",
    "\n",
    "    escalation_reasons = []\n",
    "    refined_risk = initial_risk\n",
    "    refined_confidence = initial_confidence\n",
    "\n",
    "    if refined_finance[\"final_risk\"] == \"high\" and initial_risk == \"high\":\n",
    "        refined_risk = \"critical\"\n",
    "        refined_confidence = 1.0\n",
    "        escalation_reasons.append(\n",
    "            \"Combined high financial and compliance risks create critical contractual exposure\"\n",
    "        )\n",
    "        escalation_reasons.append(\n",
    "            \"Confidentiality breaches may trigger both regulatory fines and financial penalties\"\n",
    "        )\n",
    "\n",
    "    if \"penalties\" in str(refined_finance.get(\"escalation_reasons\", [])).lower():\n",
    "        if refined_risk != \"critical\":\n",
    "            refined_risk = \"high\"\n",
    "        refined_confidence = 1.0\n",
    "        escalation_reasons.append(\n",
    "            \"Financial penalty clauses amplify the cost of compliance violations\"\n",
    "        )\n",
    "\n",
    "    elevated_count = sum(\n",
    "        1 for agent in other_agents.values()\n",
    "        if agent.get(\"risk_level\") in [\"medium\", \"high\"]\n",
    "    )\n",
    "\n",
    "    if elevated_count >= 3:\n",
    "        escalation_reasons.append(\n",
    "            f\"Pattern detected: {elevated_count} domains show elevated risk, \"\n",
    "            f\"suggesting systemic contract issues\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"original_risk\": initial_risk,\n",
    "        \"refined_risk\": refined_risk,\n",
    "        \"original_confidence\": initial_confidence,\n",
    "        \"refined_confidence\": refined_confidence,\n",
    "        \"escalation_reasons\": escalation_reasons,\n",
    "        \"finance_influence\": {\n",
    "            \"finance_risk\": refined_finance[\"final_risk\"],\n",
    "            \"finance_confidence\": refined_finance[\"final_confidence\"],\n",
    "            \"finance_escalation_count\": len(\n",
    "                refined_finance.get(\"escalation_reasons\", [])\n",
    "            ),\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "refined_compliance = refine_compliance_agent(\n",
    "    compliance_initial,\n",
    "    refined_finance,\n",
    "    detailed_context,\n",
    ")\n",
    "\n",
    "def parse_model_json(raw_output: str):\n",
    "    if not raw_output or not raw_output.strip():\n",
    "        return None, \"Empty model response\"\n",
    "\n",
    "    try:\n",
    "        return json.loads(raw_output), None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        start = raw_output.index(\"{\")\n",
    "        end = raw_output.rindex(\"}\") + 1\n",
    "        return json.loads(raw_output[start:end]), None\n",
    "    except Exception as e:\n",
    "        return None, f\"Unparseable model output: {e}\"\n",
    "\n",
    "\n",
    "try:\n",
    "    raw_model_output = analyze_with_ollama(\n",
    "        {\n",
    "            \"task\": \"compliance_cross_agent_refinement\",\n",
    "            \"input\": {\n",
    "                \"initial_compliance_assessment\": compliance_initial,\n",
    "                \"heuristic_refinement\": refined_compliance,\n",
    "                \"finance_refined\": refined_finance,\n",
    "                \"cross_agent_context\": detailed_context,\n",
    "            },\n",
    "            \"instructions\": (\n",
    "                \"Validate the refined compliance risk using finance, legal, and operations context. \"\n",
    "                \"Confirm or adjust the risk level and confidence. \"\n",
    "                \"Return STRICT JSON with keys: refined_risk, refined_confidence, justification.\"\n",
    "            ),\n",
    "        },\n",
    "        all_agent_memory.matches,\n",
    "    )\n",
    "\n",
    "    parsed, parse_error = parse_model_json(raw_model_output)\n",
    "\n",
    "    if parsed:\n",
    "        refined_compliance[\"final_risk\"] = parsed.get(\n",
    "            \"refined_risk\", refined_compliance[\"refined_risk\"]\n",
    "        )\n",
    "        refined_compliance[\"final_confidence\"] = parsed.get(\n",
    "            \"refined_confidence\", refined_compliance[\"refined_confidence\"]\n",
    "        )\n",
    "        refined_compliance[\"model_justification\"] = parsed.get(\n",
    "            \"justification\", \"Model confirmed heuristic assessment\"\n",
    "        )\n",
    "    else:\n",
    "        refined_compliance[\"final_risk\"] = refined_compliance[\"refined_risk\"]\n",
    "        refined_compliance[\"final_confidence\"] = refined_compliance[\"refined_confidence\"]\n",
    "        refined_compliance[\"model_justification\"] = (\n",
    "            f\"Model output unusable, heuristic retained. Reason: {parse_error}\"\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    refined_compliance[\"final_risk\"] = refined_compliance[\"refined_risk\"]\n",
    "    refined_compliance[\"final_confidence\"] = refined_compliance[\"refined_confidence\"]\n",
    "    refined_compliance[\"model_justification\"] = f\"Model validation fallback: {e}\"\n",
    "\n",
    "\n",
    "print(\"\\nCompliance Agent - Refined Assessment:\")\n",
    "print(f\"   Original Risk: {refined_compliance['original_risk'].upper()}\")\n",
    "print(f\"   Heuristic Risk: {refined_compliance['refined_risk'].upper()}\")\n",
    "print(f\"   Final Risk (Model): {refined_compliance['final_risk'].upper()}\")\n",
    "print(f\"   Confidence: {refined_compliance['final_confidence']:.0%}\")\n",
    "\n",
    "if refined_compliance[\"escalation_reasons\"]:\n",
    "    print(\"\\n   RISK ESCALATION DETECTED:\")\n",
    "    for i, reason in enumerate(refined_compliance[\"escalation_reasons\"], 1):\n",
    "        print(f\"      {i}. {reason}\")\n",
    "\n",
    "print(\"\\n   Finance Influence:\")\n",
    "print(\n",
    "    f\"      • Finance Risk Level: \"\n",
    "    f\"{refined_compliance['finance_influence']['finance_risk'].upper()}\"\n",
    ")\n",
    "print(\n",
    "    f\"      • Finance Confidence: \"\n",
    "    f\"{refined_compliance['finance_influence']['finance_confidence']:.0%}\"\n",
    ")\n",
    "print(\n",
    "    f\"      • Finance Escalations: \"\n",
    "    f\"{refined_compliance['finance_influence']['finance_escalation_count']}\"\n",
    ")\n",
    "\n",
    "print(\"\\n   Model Justification:\")\n",
    "print(f\"      {refined_compliance['model_justification']}\")\n",
    "\n",
    "\n",
    "compliance_refined_output = {\n",
    "    \"agent_name\": \"compliance_refined\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"refinement_iteration\": 1,\n",
    "    \"original_assessment\": compliance_initial,\n",
    "    \"refined_assessment\": {\n",
    "        \"risk_level\": refined_compliance[\"final_risk\"],\n",
    "        \"confidence\": refined_compliance[\"final_confidence\"],\n",
    "        \"clause_type\": \"Compliance Analysis (Cross-Agent Refined)\",\n",
    "        \"extracted_clauses\": compliance_initial.get(\"extracted_clauses\", []),\n",
    "        \"evidence\": compliance_initial.get(\"evidence\", []),\n",
    "        \"escalation_reasons\": refined_compliance[\"escalation_reasons\"],\n",
    "        \"model_justification\": refined_compliance[\"model_justification\"],\n",
    "    },\n",
    "    \"finance_influence\": refined_compliance[\"finance_influence\"],\n",
    "    \"cross_agent_context\": detailed_context,\n",
    "}\n",
    "\n",
    "refined_compliance_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"compliance_agent_refined.json\",\n",
    ")\n",
    "\n",
    "with open(refined_compliance_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(compliance_refined_output, f, indent=2)\n",
    "\n",
    "print(f\"\\nRefined compliance assessment saved: {refined_compliance_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e1c36b",
   "metadata": {},
   "source": [
    "#### 6. Refinement of Operations Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054373c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Operations Agent - Initial Assessment:\n",
      "   Risk Level: MEDIUM\n",
      "   Confidence: 80%\n",
      "   Clauses: 2\n",
      "\n",
      "Operations Reads Refined Outputs from All Agents...\n",
      "   → Legal escalated to: MEDIUM\n",
      "   → Finance escalated to: HIGH\n",
      "   → Compliance escalated to: HIGH\n",
      "  → Analyzing with Ollama gemma2:9b...\n",
      "\n",
      "Operations Agent - Refined Assessment:\n",
      "   Original Risk: MEDIUM\n",
      "   Heuristic Risk: HIGH\n",
      "   Final Risk (Model): HIGH\n",
      "   Confidence Change: 80% → 92%\n",
      "\n",
      "   RISK ESCALATION DETECTED:\n",
      "      1. Legal risk escalation to medium introduces operational uncertainty\n",
      "      2. Termination and IP clauses may restrict operational flexibility\n",
      "      3. 2 domains at high/critical risk indicate systemic operational challenges\n",
      "      4. Cross-domain risks may cascade into service delivery failures\n",
      "      5. Financial penalties reduce operational budget for licensing and fulfillment\n",
      "      6. Confidentiality requirements may restrict information sharing with affiliates and subcontractors\n",
      "\n",
      "   Cross-Agent Influences:\n",
      "      • Legal: MEDIUM\n",
      "      • Finance: HIGH\n",
      "      • Compliance: HIGH\n",
      "\n",
      "   Escalation Triggers:\n",
      "      Yes Legal Escalated\n",
      "      Yes Finance Escalated\n",
      "      No Compliance Escalated\n",
      "\n",
      "   Model Justification:\n",
      "      While the initial operations risk assessment was 'medium', cross-agent influences from finance ('high'), compliance ('high'), and legal ('medium') significantly elevate the overall risk. The finance agent highlights potential regulatory fines and penalties, while the compliance agent points to confidentiality breaches and operational risks combined with payment obligations. Legal concerns regarding contract interpretation and enforcement further contribute to the heightened risk.\n",
      "\n",
      "   Specific Operational Risks:\n",
      "      Licensing Risk: HIGH\n",
      "      Fulfillment Risk: HIGH\n",
      "      Vendor Management Risk: HIGH\n",
      "      Delivery Timeline Risk: HIGH\n",
      "\n",
      "Refined operations assessment saved: ../Data/Results/Milestone3\\operations_agent_refined.json\n",
      "Refined operations assessment stored in Pinecone\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOperations Agent - Initial Assessment:\")\n",
    "\n",
    "operations_initial = detailed_context.get(\"operations\", {})\n",
    "print(f\"   Risk Level: {operations_initial.get('risk_level', 'N/A').upper()}\")\n",
    "print(f\"   Confidence: {operations_initial.get('confidence', 0):.0%}\")\n",
    "print(f\"   Clauses: {operations_initial.get('num_clauses', 0)}\")\n",
    "\n",
    "print(\"\\nOperations Reads Refined Outputs from All Agents...\")\n",
    "print(f\"   → Legal escalated to: {refined_legal['final_risk'].upper()}\")\n",
    "print(f\"   → Finance escalated to: {refined_finance['final_risk'].upper()}\")\n",
    "print(f\"   → Compliance escalated to: {refined_compliance['final_risk'].upper()}\")\n",
    "\n",
    "\n",
    "def refine_operations_agent(\n",
    "    initial_assessment,\n",
    "    refined_legal,\n",
    "    refined_finance,\n",
    "    refined_compliance,\n",
    "    other_agents,\n",
    "):\n",
    "    initial_risk = initial_assessment.get(\"risk_level\", \"medium\")\n",
    "    initial_confidence = initial_assessment.get(\"confidence\", 0.8)\n",
    "\n",
    "    escalation_reasons = []\n",
    "    refined_risk = initial_risk\n",
    "    refined_confidence = initial_confidence\n",
    "\n",
    "    if (\n",
    "        refined_compliance[\"final_risk\"] == \"critical\"\n",
    "        and refined_finance[\"final_risk\"] == \"high\"\n",
    "    ):\n",
    "        refined_risk = \"high\"\n",
    "        refined_confidence = min(0.95, initial_confidence + 0.15)\n",
    "        escalation_reasons.append(\n",
    "            \"Critical compliance and high finance risks create operational delivery challenges\"\n",
    "        )\n",
    "        escalation_reasons.append(\n",
    "            \"Licensing and fulfillment services may be impacted by regulatory scrutiny and financial constraints\"\n",
    "        )\n",
    "\n",
    "    if (\n",
    "        refined_legal[\"final_risk\"] in [\"medium\", \"high\"]\n",
    "        and refined_legal[\"original_risk\"] == \"low\"\n",
    "    ):\n",
    "        refined_risk = \"high\"\n",
    "        refined_confidence = min(0.90, initial_confidence + 0.10)\n",
    "        escalation_reasons.append(\n",
    "            f\"Legal risk escalation to {refined_legal['final_risk']} introduces operational uncertainty\"\n",
    "        )\n",
    "        escalation_reasons.append(\n",
    "            \"Termination and IP clauses may restrict operational flexibility\"\n",
    "        )\n",
    "\n",
    "    high_risk_agents = sum(\n",
    "        1\n",
    "        for agent in [refined_legal, refined_finance, refined_compliance]\n",
    "        if agent.get(\"final_risk\") in [\"high\", \"critical\"]\n",
    "    )\n",
    "\n",
    "    if high_risk_agents >= 2:\n",
    "        refined_risk = \"high\"\n",
    "        refined_confidence = min(0.92, initial_confidence + 0.12)\n",
    "        escalation_reasons.append(\n",
    "            f\"{high_risk_agents} domains at high/critical risk indicate systemic operational challenges\"\n",
    "        )\n",
    "        escalation_reasons.append(\n",
    "            \"Cross-domain risks may cascade into service delivery failures\"\n",
    "        )\n",
    "\n",
    "    if \"penalties\" in str(refined_finance.get(\"escalation_reasons\", [])).lower():\n",
    "        escalation_reasons.append(\n",
    "            \"Financial penalties reduce operational budget for licensing and fulfillment\"\n",
    "        )\n",
    "\n",
    "    if refined_compliance[\"final_risk\"] in [\"high\", \"critical\"]:\n",
    "        escalation_reasons.append(\n",
    "            \"Confidentiality requirements may restrict information sharing with affiliates and subcontractors\"\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"original_risk\": initial_risk,\n",
    "        \"refined_risk\": refined_risk,\n",
    "        \"original_confidence\": initial_confidence,\n",
    "        \"refined_confidence\": refined_confidence,\n",
    "        \"escalation_reasons\": escalation_reasons,\n",
    "        \"cross_agent_influences\": {\n",
    "            \"legal\": refined_legal[\"final_risk\"],\n",
    "            \"finance\": refined_finance[\"final_risk\"],\n",
    "            \"compliance\": refined_compliance[\"final_risk\"],\n",
    "        },\n",
    "        \"escalation_triggers\": {\n",
    "            \"legal_escalated\": refined_legal[\"original_risk\"] != refined_legal[\"final_risk\"],\n",
    "            \"finance_escalated\": refined_finance[\"original_risk\"] != refined_finance[\"final_risk\"],\n",
    "            \"compliance_escalated\": refined_compliance[\"original_risk\"] != refined_compliance[\"final_risk\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "refined_operations = refine_operations_agent(\n",
    "    operations_initial,\n",
    "    refined_legal,\n",
    "    refined_finance,\n",
    "    refined_compliance,\n",
    "    detailed_context,\n",
    ")\n",
    "\n",
    "def parse_model_json(raw_output: str):\n",
    "    if not raw_output or not raw_output.strip():\n",
    "        return None, \"Empty model response\"\n",
    "\n",
    "    try:\n",
    "        return json.loads(raw_output), None\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        start = raw_output.index(\"{\")\n",
    "        end = raw_output.rindex(\"}\") + 1\n",
    "        return json.loads(raw_output[start:end]), None\n",
    "    except Exception as e:\n",
    "        return None, f\"Unparseable model output: {e}\"\n",
    "\n",
    "\n",
    "try:\n",
    "    raw_model_output = analyze_with_ollama(\n",
    "        {\n",
    "            \"task\": \"operations_cross_agent_refinement\",\n",
    "            \"input\": {\n",
    "                \"initial_operations_assessment\": operations_initial,\n",
    "                \"heuristic_refinement\": refined_operations,\n",
    "                \"legal_refined\": refined_legal,\n",
    "                \"finance_refined\": refined_finance,\n",
    "                \"compliance_refined\": refined_compliance,\n",
    "                \"cross_agent_context\": detailed_context,\n",
    "            },\n",
    "            \"instructions\": (\n",
    "                \"Validate the refined operations risk using legal, finance, and compliance context. \"\n",
    "                \"Confirm or adjust the risk level and confidence. \"\n",
    "                \"Return STRICT JSON with keys: refined_risk, refined_confidence, justification.\"\n",
    "            ),\n",
    "        },\n",
    "        all_agent_memory.matches,\n",
    "    )\n",
    "\n",
    "    parsed, parse_error = parse_model_json(raw_model_output)\n",
    "\n",
    "    if parsed:\n",
    "        refined_operations[\"final_risk\"] = parsed.get(\n",
    "            \"refined_risk\", refined_operations[\"refined_risk\"]\n",
    "        )\n",
    "        refined_operations[\"final_confidence\"] = parsed.get(\n",
    "            \"refined_confidence\", refined_operations[\"refined_confidence\"]\n",
    "        )\n",
    "        refined_operations[\"model_justification\"] = parsed.get(\n",
    "            \"justification\", \"Model confirmed heuristic assessment\"\n",
    "        )\n",
    "    else:\n",
    "        refined_operations[\"final_risk\"] = refined_operations[\"refined_risk\"]\n",
    "        refined_operations[\"final_confidence\"] = refined_operations[\"refined_confidence\"]\n",
    "        refined_operations[\"model_justification\"] = (\n",
    "            f\"Model output unusable, heuristic retained. Reason: {parse_error}\"\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    refined_operations[\"final_risk\"] = refined_operations[\"refined_risk\"]\n",
    "    refined_operations[\"final_confidence\"] = refined_operations[\"refined_confidence\"]\n",
    "    refined_operations[\"model_justification\"] = f\"Model validation fallback: {e}\"\n",
    "\n",
    "\n",
    "print(\"\\nOperations Agent - Refined Assessment:\")\n",
    "print(f\"   Original Risk: {refined_operations['original_risk'].upper()}\")\n",
    "print(f\"   Heuristic Risk: {refined_operations['refined_risk'].upper()}\")\n",
    "print(f\"   Final Risk (Model): {refined_operations['final_risk'].upper()}\")\n",
    "print(\n",
    "    f\"   Confidence Change: \"\n",
    "    f\"{refined_operations['original_confidence']:.0%} → \"\n",
    "    f\"{refined_operations['final_confidence']:.0%}\"\n",
    ")\n",
    "\n",
    "if refined_operations[\"escalation_reasons\"]:\n",
    "    print(\"\\n   RISK ESCALATION DETECTED:\")\n",
    "    for i, reason in enumerate(refined_operations[\"escalation_reasons\"], 1):\n",
    "        print(f\"      {i}. {reason}\")\n",
    "\n",
    "print(\"\\n   Cross-Agent Influences:\")\n",
    "for agent, risk in refined_operations[\"cross_agent_influences\"].items():\n",
    "    print(f\"      • {agent.capitalize()}: {risk.upper()}\")\n",
    "\n",
    "print(\"\\n   Escalation Triggers:\")\n",
    "for trigger, status in refined_operations[\"escalation_triggers\"].items():\n",
    "    print(\n",
    "        f\"      {'Yes' if status else 'No'} \"\n",
    "        f\"{trigger.replace('_', ' ').title()}\"\n",
    "    )\n",
    "\n",
    "print(\"\\n   Model Justification:\")\n",
    "print(f\"      {refined_operations['model_justification']}\")\n",
    "\n",
    "\n",
    "operational_risks = {\n",
    "    \"licensing_risk\": \"high\"\n",
    "    if refined_compliance[\"final_risk\"] in [\"high\", \"critical\"]\n",
    "    else \"medium\",\n",
    "    \"fulfillment_risk\": \"high\"\n",
    "    if refined_finance[\"final_risk\"] == \"high\"\n",
    "    else \"medium\",\n",
    "    \"vendor_management_risk\": \"high\"\n",
    "    if refined_operations[\"final_risk\"] == \"high\"\n",
    "    else \"medium\",\n",
    "    \"delivery_timeline_risk\": \"high\"\n",
    "    if len(refined_operations[\"escalation_reasons\"]) >= 3\n",
    "    else \"medium\",\n",
    "}\n",
    "\n",
    "print(\"\\n   Specific Operational Risks:\")\n",
    "for risk_type, risk_level in operational_risks.items():\n",
    "    print(f\"      {risk_type.replace('_', ' ').title()}: {risk_level.upper()}\")\n",
    "\n",
    "\n",
    "operations_refined_output = {\n",
    "    \"agent_name\": \"operations_refined\",\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"refinement_iteration\": 1,\n",
    "    \"original_assessment\": operations_initial,\n",
    "    \"refined_assessment\": {\n",
    "        \"risk_level\": refined_operations[\"final_risk\"],\n",
    "        \"confidence\": refined_operations[\"final_confidence\"],\n",
    "        \"clause_type\": \"Operations Analysis (Cross-Agent Refined)\",\n",
    "        \"extracted_clauses\": operations_initial.get(\"extracted_clauses\", []),\n",
    "        \"evidence\": operations_initial.get(\"evidence\", []),\n",
    "        \"escalation_reasons\": refined_operations[\"escalation_reasons\"],\n",
    "        \"model_justification\": refined_operations[\"model_justification\"],\n",
    "    },\n",
    "    \"cross_agent_context\": detailed_context,\n",
    "    \"cross_agent_influences\": refined_operations[\"cross_agent_influences\"],\n",
    "    \"escalation_triggers\": refined_operations[\"escalation_triggers\"],\n",
    "    \"operational_risks\": operational_risks,\n",
    "}\n",
    "\n",
    "refined_operations_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"operations_agent_refined.json\",\n",
    ")\n",
    "\n",
    "with open(refined_operations_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(operations_refined_output, f, indent=2)\n",
    "\n",
    "print(f\"\\nRefined operations assessment saved: {refined_operations_file}\")\n",
    "\n",
    "\n",
    "refined_operations_text = f\"\"\"\n",
    "Agent: Operations (Refined)\n",
    "Final Risk Level: {refined_operations['final_risk']}\n",
    "Final Confidence: {refined_operations['final_confidence']}\n",
    "Escalation Reasons: {' | '.join(refined_operations['escalation_reasons']) if refined_operations['escalation_reasons'] else 'None'}\n",
    "Operational Risks: {', '.join([f'{k}: {v}' for k, v in operational_risks.items()])}\n",
    "Cross-Agent Influences: Legal {refined_legal['final_risk']}, Finance {refined_finance['final_risk']}, Compliance {refined_compliance['final_risk']}\n",
    "\"\"\"\n",
    "\n",
    "refined_operations_embedding = embedding_model.encode(\n",
    "    refined_operations_text\n",
    ").tolist()\n",
    "\n",
    "refined_operations_id = f\"{contract_id}_operations_refined_v1\"\n",
    "\n",
    "try:\n",
    "    index.upsert(\n",
    "        vectors=[{\n",
    "            \"id\": refined_operations_id,\n",
    "            \"values\": refined_operations_embedding,\n",
    "            \"metadata\": {\n",
    "                \"agent_name\": \"operations_refined\",\n",
    "                \"risk_level\": refined_operations[\"final_risk\"],\n",
    "                \"confidence\": refined_operations[\"final_confidence\"],\n",
    "                \"clause_type\": \"Operations Analysis (Refined)\",\n",
    "                \"num_clauses\": operations_initial.get(\"num_clauses\", 0),\n",
    "                \"contract_id\": contract_id,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"refinement_iteration\": 1,\n",
    "                \"escalated\": len(refined_operations[\"escalation_reasons\"]) > 0,\n",
    "                \"processing_stage\": \"cross_agent_refinement\",\n",
    "                \"model_used\": \"gemma2:9b\",\n",
    "            },\n",
    "        }],\n",
    "        namespace=\"operations_intermediate\",\n",
    "    )\n",
    "    print(\"Refined operations assessment stored in Pinecone\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Pinecone storage failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd06328a",
   "metadata": {},
   "source": [
    "#### 6. Upserting to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "096b0906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All refined agent results successfully upserted to Pinecone\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "PINECONE_INDEX_NAME = \"contract-agents\"\n",
    "MODEL_USED = \"gemma2:9b\"\n",
    "\n",
    "REFINEMENT_ITERATION = int(time.time())\n",
    "\n",
    "\n",
    "def resolve_final_risk(agent: dict) -> str:\n",
    "   \n",
    "    return (\n",
    "        agent.get(\"final_risk\")\n",
    "        or agent.get(\"refined_risk\")\n",
    "        or agent.get(\"original_risk\", \"unknown\")\n",
    "    )\n",
    "\n",
    "\n",
    "def resolve_final_confidence(agent: dict) -> float:\n",
    "   \n",
    "    return (\n",
    "        agent.get(\"final_confidence\")\n",
    "        or agent.get(\"refined_confidence\")\n",
    "        or agent.get(\"original_confidence\", 0.0)\n",
    "    )\n",
    "\n",
    "\n",
    "def upsert_refined_agent(\n",
    "    *,\n",
    "    index,\n",
    "    namespace: str,\n",
    "    contract_id: str,\n",
    "    agent_key: str,\n",
    "    refined_agent: dict,\n",
    "    embedding_text: str,\n",
    "):\n",
    "   \n",
    "\n",
    "    vector_id = f\"{contract_id}_{agent_key}_refined_v{REFINEMENT_ITERATION}\"\n",
    "\n",
    "    embedding = embedding_model.encode(embedding_text).tolist()\n",
    "\n",
    "    metadata = {\n",
    "        \"agent_name\": agent_key,\n",
    "        \"risk_level\": resolve_final_risk(refined_agent),\n",
    "        \"confidence\": resolve_final_confidence(refined_agent),\n",
    "        \"contract_id\": contract_id,\n",
    "        \"processing_stage\": \"cross_agent_refinement\",\n",
    "        \"refinement_iteration\": REFINEMENT_ITERATION,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"model_used\": MODEL_USED,\n",
    "        \"escalated\": len(refined_agent.get(\"escalation_reasons\", [])) > 0,\n",
    "        \"has_model_justification\": bool(\n",
    "            refined_agent.get(\"model_justification\")\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    index.upsert(\n",
    "        vectors=[{\n",
    "            \"id\": vector_id,\n",
    "            \"values\": embedding,\n",
    "            \"metadata\": metadata,\n",
    "        }],\n",
    "        namespace=namespace,\n",
    "    )\n",
    "\n",
    "    return vector_id\n",
    "\n",
    "\n",
    "legal_text = f\"\"\"\n",
    "Agent: Legal (Refined)\n",
    "Final Risk Level: {resolve_final_risk(refined_legal)}\n",
    "Final Confidence: {resolve_final_confidence(refined_legal)}\n",
    "Escalation Reasons: {' | '.join(refined_legal.get('escalation_reasons', [])) or 'None'}\n",
    "\"\"\"\n",
    "\n",
    "upsert_refined_agent(\n",
    "    index=index,\n",
    "    namespace=\"legal_intermediate\",\n",
    "    contract_id=contract_id,\n",
    "    agent_key=\"legal\",\n",
    "    refined_agent=refined_legal,\n",
    "    embedding_text=legal_text,\n",
    ")\n",
    "\n",
    "finance_text = f\"\"\"\n",
    "Agent: Finance (Refined)\n",
    "Final Risk Level: {resolve_final_risk(refined_finance)}\n",
    "Final Confidence: {resolve_final_confidence(refined_finance)}\n",
    "Escalation Reasons: {' | '.join(refined_finance.get('escalation_reasons', [])) or 'None'}\n",
    "\"\"\"\n",
    "\n",
    "upsert_refined_agent(\n",
    "    index=index,\n",
    "    namespace=\"finance_intermediate\",\n",
    "    contract_id=contract_id,\n",
    "    agent_key=\"finance\",\n",
    "    refined_agent=refined_finance,\n",
    "    embedding_text=finance_text,\n",
    ")\n",
    "\n",
    "compliance_text = f\"\"\"\n",
    "Agent: Compliance (Refined)\n",
    "Final Risk Level: {resolve_final_risk(refined_compliance)}\n",
    "Final Confidence: {resolve_final_confidence(refined_compliance)}\n",
    "Escalation Reasons: {' | '.join(refined_compliance.get('escalation_reasons', [])) or 'None'}\n",
    "\"\"\"\n",
    "\n",
    "upsert_refined_agent(\n",
    "    index=index,\n",
    "    namespace=\"compliance_intermediate\",\n",
    "    contract_id=contract_id,\n",
    "    agent_key=\"compliance\",\n",
    "    refined_agent=refined_compliance,\n",
    "    embedding_text=compliance_text,\n",
    ")\n",
    "\n",
    "operations_text = f\"\"\"\n",
    "Agent: Operations (Refined)\n",
    "Final Risk Level: {resolve_final_risk(refined_operations)}\n",
    "Final Confidence: {resolve_final_confidence(refined_operations)}\n",
    "Escalation Reasons: {' | '.join(refined_operations.get('escalation_reasons', [])) or 'None'}\n",
    "\"\"\"\n",
    "\n",
    "upsert_refined_agent(\n",
    "    index=index,\n",
    "    namespace=\"operations_intermediate\",\n",
    "    contract_id=contract_id,\n",
    "    agent_key=\"operations\",\n",
    "    refined_agent=refined_operations,\n",
    "    embedding_text=operations_text,\n",
    ")\n",
    "\n",
    "print(\"All refined agent results successfully upserted to Pinecone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "49d19552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final merged coordinator output successfully upserted to Pinecone\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "MODEL_USED = \"gemma2:9b\"\n",
    "REFINEMENT_ITERATION = int(time.time())  \n",
    "\n",
    "\n",
    "def resolve_final_risk(agent: dict) -> str:\n",
    "    return (\n",
    "        agent.get(\"final_risk\")\n",
    "        or agent.get(\"refined_risk\")\n",
    "        or agent.get(\"original_risk\", \"unknown\")\n",
    "    )\n",
    "\n",
    "\n",
    "def resolve_final_confidence(agent: dict) -> float:\n",
    "    return (\n",
    "        agent.get(\"final_confidence\")\n",
    "        or agent.get(\"refined_confidence\")\n",
    "        or agent.get(\"original_confidence\", 0.0)\n",
    "    )\n",
    "\n",
    "\n",
    "final_merged_output = {\n",
    "    \"contract_id\": contract_id,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"processing_stage\": \"final_merged\",\n",
    "    \"refinement_iteration\": REFINEMENT_ITERATION,\n",
    "    \"agents\": {\n",
    "        \"legal\": {\n",
    "            \"risk\": resolve_final_risk(refined_legal),\n",
    "            \"confidence\": resolve_final_confidence(refined_legal),\n",
    "            \"justification\": refined_legal.get(\"model_justification\", \"\"),\n",
    "        },\n",
    "        \"finance\": {\n",
    "            \"risk\": resolve_final_risk(refined_finance),\n",
    "            \"confidence\": resolve_final_confidence(refined_finance),\n",
    "            \"justification\": refined_finance.get(\"model_justification\", \"\"),\n",
    "        },\n",
    "        \"compliance\": {\n",
    "            \"risk\": resolve_final_risk(refined_compliance),\n",
    "            \"confidence\": resolve_final_confidence(refined_compliance),\n",
    "            \"justification\": refined_compliance.get(\"model_justification\", \"\"),\n",
    "        },\n",
    "        \"operations\": {\n",
    "            \"risk\": resolve_final_risk(refined_operations),\n",
    "            \"confidence\": resolve_final_confidence(refined_operations),\n",
    "            \"justification\": refined_operations.get(\"model_justification\", \"\"),\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "final_merged_text = f\"\"\"\n",
    "Final Contract Risk Summary\n",
    "\n",
    "Legal Risk: {final_merged_output['agents']['legal']['risk']}\n",
    "Finance Risk: {final_merged_output['agents']['finance']['risk']}\n",
    "Compliance Risk: {final_merged_output['agents']['compliance']['risk']}\n",
    "Operations Risk: {final_merged_output['agents']['operations']['risk']}\n",
    "\"\"\"\n",
    "\n",
    "final_embedding = embedding_model.encode(final_merged_text).tolist()\n",
    "\n",
    "final_vector_id = f\"{contract_id}_final_merged_v{REFINEMENT_ITERATION}\"\n",
    "\n",
    "\n",
    "index.upsert(\n",
    "    vectors=[{\n",
    "        \"id\": final_vector_id,\n",
    "        \"values\": final_embedding,\n",
    "        \"metadata\": {\n",
    "            \"contract_id\": contract_id,\n",
    "            \"processing_stage\": \"final_merged\",\n",
    "            \"refinement_iteration\": REFINEMENT_ITERATION,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"model_used\": MODEL_USED,\n",
    "\n",
    "            \"legal_risk\": final_merged_output[\"agents\"][\"legal\"][\"risk\"],\n",
    "            \"finance_risk\": final_merged_output[\"agents\"][\"finance\"][\"risk\"],\n",
    "            \"compliance_risk\": final_merged_output[\"agents\"][\"compliance\"][\"risk\"],\n",
    "            \"operations_risk\": final_merged_output[\"agents\"][\"operations\"][\"risk\"],\n",
    "        },\n",
    "    }],\n",
    "    namespace=\"final_merged\",\n",
    ")\n",
    "\n",
    "print(\"Final merged coordinator output successfully upserted to Pinecone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1a77e",
   "metadata": {},
   "source": [
    "#### 6. Refinement Summary & Saving Refined Memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ad592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL AGENTS REFINED\n",
      "\n",
      "┌─────────────┬──────────────┬──────────────┬───────────────────┬────────────┬─────────────┐\n",
      "│ Agent       │ Original     │ Final        │ Confidence Change │ Escalated? │ Escalations │\n",
      "├─────────────┼──────────────┼──────────────┼───────────────────┼────────────┼─────────────┤\n",
      "│ Legal       │ Low          │ Medium       │ 85% → 88%         │ Yes        │           2 │\n",
      "│ Finance     │ Medium       │ High         │ 70% → 85%         │ Yes        │           3 │\n",
      "│ Compliance  │ High         │ High         │ 100% → 90%        │ No         │           4 │\n",
      "│ Operations  │ Medium       │ High         │ 80% → 92%         │ Yes        │           6 │\n",
      "└─────────────┴──────────────┴──────────────┴───────────────────┴────────────┴─────────────┘\n",
      "\n",
      "Complete Refinement Impact:\n",
      "   • Total Agents Refined: 4\n",
      "   • Agents with Risk Escalations: 3\n",
      "   • Total Escalation Reasons Identified: 15\n",
      "   • Escalation Rate: 75%\n",
      "\n",
      "Risk Level Progression:\n",
      "   Finance    : medium   ↑   high     (3 reasons)\n",
      "   Compliance : high     →   high     (4 reasons)\n",
      "   Operations : medium   ↑   high     (6 reasons)\n",
      "   Legal      : low      ↑   medium   (2 reasons)\n",
      "\n",
      "Key Findings:\n",
      "   WARNING: 3/4 agents escalated risk levels\n",
      "      → Multi-domain risk interactions detected\n",
      "\n",
      "Risk Cascade Pattern Detected:\n",
      "   1. Compliance: high → high\n",
      "      ↓ Influenced Legal\n",
      "   2. Legal: low → medium\n",
      "      ↓ Influenced Finance\n",
      "   3. Finance: medium → high\n",
      "      ↓ Influenced Operations\n",
      "   4. Operations: medium → high\n",
      "\n",
      "Highest Impact Agent:\n",
      "   • Agent: OPERATIONS\n",
      "   • Escalation Reasons: 6\n",
      "   • Risk Change: medium → high\n",
      "\n",
      "Complete refinement summary saved: ../Data/Results/Milestone3\\cross_agent_refinement_complete.json\n"
     ]
    }
   ],
   "source": [
    "print(\"ALL AGENTS REFINED\")\n",
    "\n",
    "def resolve_final_risk(agent):\n",
    "    return (\n",
    "        agent.get(\"final_risk\")\n",
    "        or agent.get(\"refined_risk\")\n",
    "        or agent.get(\"original_risk\", \"unknown\")\n",
    "    )\n",
    "\n",
    "def resolve_final_confidence(agent):\n",
    "    return (\n",
    "        agent.get(\"final_confidence\")\n",
    "        or agent.get(\"refined_confidence\")\n",
    "        or agent.get(\"original_confidence\", 0.0)\n",
    "    )\n",
    "\n",
    "\n",
    "refinement_summary_complete = {\n",
    "    \"legal\": {\n",
    "        \"original\": refined_legal[\"original_risk\"],\n",
    "        \"final\": resolve_final_risk(refined_legal),\n",
    "        \"confidence_change\": (\n",
    "            f\"{refined_legal['original_confidence']:.0%} → \"\n",
    "            f\"{resolve_final_confidence(refined_legal):.0%}\"\n",
    "        ),\n",
    "        \"escalated\": refined_legal[\"original_risk\"] != resolve_final_risk(refined_legal),\n",
    "        \"escalation_count\": len(refined_legal.get(\"escalation_reasons\", [])),\n",
    "    },\n",
    "    \"finance\": {\n",
    "        \"original\": refined_finance[\"original_risk\"],\n",
    "        \"final\": resolve_final_risk(refined_finance),\n",
    "        \"confidence_change\": (\n",
    "            f\"{refined_finance['original_confidence']:.0%} → \"\n",
    "            f\"{resolve_final_confidence(refined_finance):.0%}\"\n",
    "        ),\n",
    "        \"escalated\": refined_finance[\"original_risk\"] != resolve_final_risk(refined_finance),\n",
    "        \"escalation_count\": len(refined_finance.get(\"escalation_reasons\", [])),\n",
    "    },\n",
    "    \"compliance\": {\n",
    "        \"original\": refined_compliance[\"original_risk\"],\n",
    "        \"final\": resolve_final_risk(refined_compliance),\n",
    "        \"confidence_change\": (\n",
    "            f\"{refined_compliance['original_confidence']:.0%} → \"\n",
    "            f\"{resolve_final_confidence(refined_compliance):.0%}\"\n",
    "        ),\n",
    "        \"escalated\": refined_compliance[\"original_risk\"] != resolve_final_risk(refined_compliance),\n",
    "        \"escalation_count\": len(refined_compliance.get(\"escalation_reasons\", [])),\n",
    "    },\n",
    "    \"operations\": {\n",
    "        \"original\": refined_operations[\"original_risk\"],\n",
    "        \"final\": resolve_final_risk(refined_operations),\n",
    "        \"confidence_change\": (\n",
    "            f\"{refined_operations['original_confidence']:.0%} → \"\n",
    "            f\"{resolve_final_confidence(refined_operations):.0%}\"\n",
    "        ),\n",
    "        \"escalated\": refined_operations[\"original_risk\"] != resolve_final_risk(refined_operations),\n",
    "        \"escalation_count\": len(refined_operations.get(\"escalation_reasons\", [])),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\n┌─────────────┬──────────────┬──────────────┬───────────────────┬────────────┬─────────────┐\")\n",
    "print(\"│ Agent       │ Original     │ Final        │ Confidence Change │ Escalated? │ Escalations │\")\n",
    "print(\"├─────────────┼──────────────┼──────────────┼───────────────────┼────────────┼─────────────┤\")\n",
    "\n",
    "for agent, data in refinement_summary_complete.items():\n",
    "    print(\n",
    "        f\"│ {agent.capitalize():11} \"\n",
    "        f\"│ {data['original'].capitalize():12} \"\n",
    "        f\"│ {data['final'].capitalize():12} \"\n",
    "        f\"│ {data['confidence_change']:17} \"\n",
    "        f\"│ {'Yes' if data['escalated'] else 'No':10} \"\n",
    "        f\"│ {data['escalation_count']:11} │\"\n",
    "    )\n",
    "\n",
    "print(\"└─────────────┴──────────────┴──────────────┴───────────────────┴────────────┴─────────────┘\")\n",
    "\n",
    "\n",
    "total_agents = len(refinement_summary_complete)\n",
    "total_escalations = sum(1 for d in refinement_summary_complete.values() if d[\"escalated\"])\n",
    "total_escalation_reasons = sum(d[\"escalation_count\"] for d in refinement_summary_complete.values())\n",
    "\n",
    "print(\"\\nComplete Refinement Impact:\")\n",
    "print(f\"   • Total Agents Refined: {total_agents}\")\n",
    "print(f\"   • Agents with Risk Escalations: {total_escalations}\")\n",
    "print(f\"   • Total Escalation Reasons Identified: {total_escalation_reasons}\")\n",
    "print(f\"   • Escalation Rate: {(total_escalations / total_agents) * 100:.0f}%\")\n",
    "\n",
    "\n",
    "print(\"\\nRisk Level Progression:\")\n",
    "risk_order = {\"critical\": 4, \"high\": 3, \"medium\": 2, \"low\": 1}\n",
    "\n",
    "for agent, data in sorted(\n",
    "    refinement_summary_complete.items(),\n",
    "    key=lambda x: risk_order.get(x[1][\"final\"], 0),\n",
    "    reverse=True,\n",
    "):\n",
    "    original_val = risk_order.get(data[\"original\"], 0)\n",
    "    final_val = risk_order.get(data[\"final\"], 0)\n",
    "    delta = final_val - original_val\n",
    "\n",
    "    arrow = \"↑\" * delta if delta > 0 else \"↓\" * abs(delta) if delta < 0 else \"→\"\n",
    "\n",
    "    print(\n",
    "        f\"   {agent.capitalize():11}: \"\n",
    "        f\"{data['original']:8} {arrow:3} {data['final']:8} \"\n",
    "        f\"({data['escalation_count']} reasons)\"\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "\n",
    "if total_escalations == total_agents:\n",
    "    print(\"   CRITICAL: All agents escalated risk levels\")\n",
    "    print(\"      → Cross-agent reasoning revealed systemic contract issues\")\n",
    "elif total_escalations >= 2:\n",
    "    print(f\"   WARNING: {total_escalations}/{total_agents} agents escalated risk levels\")\n",
    "    print(\"      → Multi-domain risk interactions detected\")\n",
    "else:\n",
    "    print(\"   Limited escalation detected\")\n",
    "    print(\"      → Original assessments largely confirmed\")\n",
    "\n",
    "\n",
    "print(\"\\nRisk Cascade Pattern Detected:\")\n",
    "print(f\"   1. Compliance: {refined_compliance['original_risk']} → {resolve_final_risk(refined_compliance)}\")\n",
    "print(f\"      ↓ Influenced Legal\")\n",
    "print(f\"   2. Legal: {refined_legal['original_risk']} → {resolve_final_risk(refined_legal)}\")\n",
    "print(f\"      ↓ Influenced Finance\")\n",
    "print(f\"   3. Finance: {refined_finance['original_risk']} → {resolve_final_risk(refined_finance)}\")\n",
    "print(f\"      ↓ Influenced Operations\")\n",
    "print(f\"   4. Operations: {refined_operations['original_risk']} → {resolve_final_risk(refined_operations)}\")\n",
    "\n",
    "\n",
    "highest_impact_agent = max(\n",
    "    refinement_summary_complete.items(),\n",
    "    key=lambda x: x[1][\"escalation_count\"],\n",
    ")\n",
    "\n",
    "print(\"\\nHighest Impact Agent:\")\n",
    "print(f\"   • Agent: {highest_impact_agent[0].upper()}\")\n",
    "print(f\"   • Escalation Reasons: {highest_impact_agent[1]['escalation_count']}\")\n",
    "print(\n",
    "    f\"   • Risk Change: \"\n",
    "    f\"{highest_impact_agent[1]['original']} → {highest_impact_agent[1]['final']}\"\n",
    ")\n",
    "\n",
    "\n",
    "complete_summary_final = {\n",
    "    \"refinement_timestamp\": datetime.now().isoformat(),\n",
    "    \"refinement_approach\": \"cross-agent multi-turn reasoning (complete)\",\n",
    "    \"agents_refined\": list(refinement_summary_complete.keys()),\n",
    "    \"refinement_results\": refinement_summary_complete,\n",
    "    \"aggregate_metrics\": {\n",
    "        \"total_agents\": total_agents,\n",
    "        \"total_escalations\": total_escalations,\n",
    "        \"total_escalation_reasons\": total_escalation_reasons,\n",
    "        \"escalation_rate\": round((total_escalations / total_agents) * 100, 1),\n",
    "        \"highest_impact_agent\": highest_impact_agent[0],\n",
    "    },\n",
    "}\n",
    "\n",
    "summary_file_final = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"cross_agent_refinement_complete.json\",\n",
    ")\n",
    "\n",
    "with open(summary_file_final, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(complete_summary_final, f, indent=2)\n",
    "\n",
    "print(f\"\\nComplete refinement summary saved: {summary_file_final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "30b993a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Human-Readable Risk Summary\n",
      "\n",
      "HUMAN-READABLE RISK SUMMARY\n",
      "\n",
      "CONTRACT RISK ASSESSMENT – EXECUTIVE SUMMARY\n",
      "\n",
      "Assessment Timestamp: 2026-01-16T19:45:45.289836\n",
      "\n",
      "This assessment reflects cross-agent, multi-turn reasoning across Legal, Finance, Compliance, and Operations domains.\n",
      "\n",
      "\n",
      "LEGAL RISK ANALYSIS\n",
      "-------------------\n",
      "   Initial Risk Level   : LOW\n",
      "   Final Risk Level     : MEDIUM\n",
      "   Confidence Change    : 85% → 88%\n",
      "   Risk Escalation      : YES\n",
      "   Escalation Rationale:\n",
      "      - Compliance identified high-risk confidentiality violations that have legal implications\n",
      "      - Multiple domains (2) showing medium risk increases overall legal exposure\n",
      "   Model Validation:\n",
      "      Model validation fallback: analyze_with_ollama() missing 1 required positional argument: 'retrieved_matches'\n",
      "\n",
      "FINANCE RISK ANALYSIS\n",
      "---------------------\n",
      "   Initial Risk Level   : MEDIUM\n",
      "   Final Risk Level     : HIGH\n",
      "   Confidence Change    : 70% → 85%\n",
      "   Risk Escalation      : YES\n",
      "   Escalation Rationale:\n",
      "      - Legal risk escalated to medium, increasing financial liability exposure\n",
      "      - High compliance risk may result in regulatory fines and penalties\n",
      "      - Operations risk combined with payment obligations creates cash flow uncertainty\n",
      "   Model Validation:\n",
      "      The initial finance risk assessment was 'medium' with a confidence of 0.7. However, cross-agent influences from compliance ('high') and operations ('medium') significantly elevate the overall financial risk. The compliance agent identified a high risk due to potential regulatory fines and penalties, while the operations agent highlighted cash flow uncertainty stemming from operational risks combined with payment obligations. Considering these factors, the refined risk level is 'high' with a confidence of 0.85.\n",
      "\n",
      "COMPLIANCE RISK ANALYSIS\n",
      "------------------------\n",
      "   Initial Risk Level   : HIGH\n",
      "   Final Risk Level     : HIGH\n",
      "   Confidence Change    : 100% → 90%\n",
      "   Risk Escalation      : NO\n",
      "   Rationale            : Original assessment confirmed after cross-agent review.\n",
      "   Model Validation:\n",
      "      While the initial compliance risk assessment was 'high' with 100% confidence, cross-agent influences from finance ('medium') and operations ('medium') significantly elevate the overall risk. The finance agent highlights potential regulatory fines and penalties, while the operations agent points to cash flow uncertainty stemming from operational risks combined with payment obligations. Considering these factors, the refined risk level is 'high' with a confidence of 0.9.\n",
      "\n",
      "OPERATIONS RISK ANALYSIS\n",
      "------------------------\n",
      "   Initial Risk Level   : MEDIUM\n",
      "   Final Risk Level     : HIGH\n",
      "   Confidence Change    : 80% → 92%\n",
      "   Risk Escalation      : YES\n",
      "   Escalation Rationale:\n",
      "      - Legal risk escalation to medium introduces operational uncertainty\n",
      "      - Termination and IP clauses may restrict operational flexibility\n",
      "      - 2 domains at high/critical risk indicate systemic operational challenges\n",
      "      - Cross-domain risks may cascade into service delivery failures\n",
      "      - Financial penalties reduce operational budget for licensing and fulfillment\n",
      "      - Confidentiality requirements may restrict information sharing with affiliates and subcontractors\n",
      "   Model Validation:\n",
      "      While the initial operations risk assessment was 'medium', cross-agent influences from finance ('high'), compliance ('high'), and legal ('medium') significantly elevate the overall risk. The finance agent highlights potential regulatory fines and penalties, while the compliance agent points to confidentiality breaches and operational risks combined with payment obligations. Legal concerns regarding contract interpretation and enforcement further contribute to the heightened risk.\n",
      "\n",
      "CROSS-AGENT RISK DYNAMICS\n",
      "-------------------------\n",
      "Cross-agent analysis identified cascading risk propagation across domains:\n",
      "   Compliance risk influenced Legal exposure (Final: HIGH → MEDIUM)\n",
      "   Legal escalation increased Financial liability risk (Final: MEDIUM → HIGH)\n",
      "   Financial and Compliance risks combined to affect Operational feasibility (Final: HIGH)\n",
      "\n",
      "OVERALL RISK CONCLUSION\n",
      "-----------------------\n",
      "The highest risk concentration was identified in the Finance domain.\n",
      "Cross-domain dependencies indicate that independent, siloed analysis would underestimate compound contractual exposure.\n",
      "Mitigation actions should prioritize domains with both high intrinsic risk and strong cross-agent influence.\n",
      "\n",
      "Human-readable risk summary saved: ../Data/Results/Milestone3\\risk_summary_new.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating Human-Readable Risk Summary\")\n",
    "\n",
    "def resolve_final_risk(agent):\n",
    "    return (\n",
    "        agent.get(\"final_risk\")\n",
    "        or agent.get(\"refined_risk\")\n",
    "        or agent.get(\"original_risk\", \"unknown\")\n",
    "    )\n",
    "\n",
    "\n",
    "def resolve_final_confidence(agent):\n",
    "    return (\n",
    "        agent.get(\"final_confidence\")\n",
    "        or agent.get(\"refined_confidence\")\n",
    "        or agent.get(\"original_confidence\", 0.0)\n",
    "    )\n",
    "\n",
    "\n",
    "def format_reasons(reasons):\n",
    "    if not reasons:\n",
    "        return \"No material escalation reasons identified.\"\n",
    "    return \"\\n\".join([f\"      - {r}\" for r in reasons])\n",
    "\n",
    "\n",
    "human_risk_summary = []\n",
    "\n",
    "human_risk_summary.append(\"CONTRACT RISK ASSESSMENT – EXECUTIVE SUMMARY\\n\")\n",
    "human_risk_summary.append(f\"Assessment Timestamp: {datetime.now().isoformat()}\\n\")\n",
    "human_risk_summary.append(\n",
    "    \"This assessment reflects cross-agent, multi-turn reasoning across \"\n",
    "    \"Legal, Finance, Compliance, and Operations domains.\\n\"\n",
    ")\n",
    "\n",
    "agents_data = {\n",
    "    \"Legal\": refined_legal,\n",
    "    \"Finance\": refined_finance,\n",
    "    \"Compliance\": refined_compliance,\n",
    "    \"Operations\": refined_operations,\n",
    "}\n",
    "\n",
    "for agent_name, agent_data in agents_data.items():\n",
    "    original_risk = agent_data.get(\"original_risk\", \"unknown\")\n",
    "    final_risk = resolve_final_risk(agent_data)\n",
    "    original_conf = agent_data.get(\"original_confidence\", 0.0)\n",
    "    final_conf = resolve_final_confidence(agent_data)\n",
    "\n",
    "    human_risk_summary.append(f\"\\n{agent_name.upper()} RISK ANALYSIS\")\n",
    "    human_risk_summary.append(\"-\" * (len(agent_name) + 14))\n",
    "\n",
    "    human_risk_summary.append(\n",
    "        f\"   Initial Risk Level   : {original_risk.upper()}\"\n",
    "    )\n",
    "    human_risk_summary.append(\n",
    "        f\"   Final Risk Level     : {final_risk.upper()}\"\n",
    "    )\n",
    "    human_risk_summary.append(\n",
    "        f\"   Confidence Change    : {original_conf:.0%} → {final_conf:.0%}\"\n",
    "    )\n",
    "\n",
    "    if original_risk != final_risk:\n",
    "        human_risk_summary.append(\"   Risk Escalation      : YES\")\n",
    "        human_risk_summary.append(\"   Escalation Rationale:\")\n",
    "        human_risk_summary.append(\n",
    "            format_reasons(agent_data.get(\"escalation_reasons\", []))\n",
    "        )\n",
    "    else:\n",
    "        human_risk_summary.append(\"   Risk Escalation      : NO\")\n",
    "        human_risk_summary.append(\n",
    "            \"   Rationale            : Original assessment confirmed after cross-agent review.\"\n",
    "        )\n",
    "\n",
    "    if agent_data.get(\"model_justification\"):\n",
    "        human_risk_summary.append(\"   Model Validation:\")\n",
    "        human_risk_summary.append(\n",
    "            f\"      {agent_data['model_justification']}\"\n",
    "        )\n",
    "\n",
    "\n",
    "human_risk_summary.append(\"\\nCROSS-AGENT RISK DYNAMICS\")\n",
    "human_risk_summary.append(\"-------------------------\")\n",
    "\n",
    "human_risk_summary.append(\n",
    "    \"Cross-agent analysis identified cascading risk propagation across domains:\"\n",
    ")\n",
    "\n",
    "human_risk_summary.append(\n",
    "    f\"   Compliance risk influenced Legal exposure \"\n",
    "    f\"(Final: {resolve_final_risk(refined_compliance).upper()} → \"\n",
    "    f\"{resolve_final_risk(refined_legal).upper()})\"\n",
    ")\n",
    "\n",
    "human_risk_summary.append(\n",
    "    f\"   Legal escalation increased Financial liability risk \"\n",
    "    f\"(Final: {resolve_final_risk(refined_legal).upper()} → \"\n",
    "    f\"{resolve_final_risk(refined_finance).upper()})\"\n",
    ")\n",
    "\n",
    "human_risk_summary.append(\n",
    "    f\"   Financial and Compliance risks combined to affect Operational feasibility \"\n",
    "    f\"(Final: {resolve_final_risk(refined_operations).upper()})\"\n",
    ")\n",
    "\n",
    "\n",
    "risk_priority = {\"critical\": 4, \"high\": 3, \"medium\": 2, \"low\": 1}\n",
    "\n",
    "highest_risk_agent = max(\n",
    "    agents_data.items(),\n",
    "    key=lambda x: risk_priority.get(resolve_final_risk(x[1]), 0),\n",
    ")\n",
    "\n",
    "human_risk_summary.append(\"\\nOVERALL RISK CONCLUSION\")\n",
    "human_risk_summary.append(\"-----------------------\")\n",
    "\n",
    "human_risk_summary.append(\n",
    "    f\"The highest risk concentration was identified in the \"\n",
    "    f\"{highest_risk_agent[0]} domain.\"\n",
    ")\n",
    "\n",
    "human_risk_summary.append(\n",
    "    \"Cross-domain dependencies indicate that independent, siloed analysis \"\n",
    "    \"would underestimate compound contractual exposure.\"\n",
    ")\n",
    "\n",
    "human_risk_summary.append(\n",
    "    \"Mitigation actions should prioritize domains with both high intrinsic \"\n",
    "    \"risk and strong cross-agent influence.\"\n",
    ")\n",
    "\n",
    "\n",
    "human_risk_summary_text = \"\\n\".join(human_risk_summary)\n",
    "\n",
    "print(\"\\nHUMAN-READABLE RISK SUMMARY\\n\")\n",
    "print(human_risk_summary_text)\n",
    "\n",
    "human_summary_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"risk_summary_new.txt\",\n",
    ")\n",
    "\n",
    "with open(human_summary_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(human_risk_summary_text)\n",
    "\n",
    "print(f\"\\nHuman-readable risk summary saved: {human_summary_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eb7b068d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining Refined Agent Outputs into Single JSON\n",
      "Combined refined agent output saved:\n",
      "   ../Data/Results/Milestone3\\refined_agent_outputs_combined.json\n",
      "\n",
      "Aggregation Summary:\n",
      "   Total Agents Included       : 4\n",
      "   Agents with Escalations     : 4\n",
      "   Total Escalation Reasons    : 15\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCombining Refined Agent Outputs into Single JSON\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "REFINED_AGENTS = [\"legal\", \"finance\", \"compliance\", \"operations\"]\n",
    "\n",
    "combined_refined_output = {\n",
    "    \"aggregation_type\": \"post-refinement-agent-outputs\",\n",
    "    \"generated_at\": datetime.now().isoformat(),\n",
    "    \"agents\": {},\n",
    "    \"summary\": {\n",
    "        \"total_agents\": 0,\n",
    "        \"agents_with_escalations\": 0,\n",
    "        \"total_escalation_reasons\": 0,\n",
    "    }\n",
    "}\n",
    "\n",
    "agents_with_escalations = 0\n",
    "total_escalation_reasons = 0\n",
    "\n",
    "for agent in REFINED_AGENTS:\n",
    "    refined_file = os.path.join(\n",
    "        MILESTONE3_OUTPUT,\n",
    "        f\"{agent}_agent_refined.json\"\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(refined_file):\n",
    "        print(f\"   WARNING: Missing refined file for {agent}\")\n",
    "        continue\n",
    "\n",
    "    with open(refined_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        refined_data = json.load(f)\n",
    "\n",
    "    refined_assessment = refined_data.get(\"refined_assessment\", {})\n",
    "    escalation_reasons = refined_assessment.get(\"escalation_reasons\", [])\n",
    "\n",
    "    has_escalation = len(escalation_reasons) > 0\n",
    "\n",
    "    combined_refined_output[\"agents\"][agent] = {\n",
    "        \"agent_name\": agent,\n",
    "        \"risk_level\": refined_assessment.get(\"risk_level\"),\n",
    "        \"confidence\": refined_assessment.get(\"confidence\"),\n",
    "        \"clause_type\": refined_assessment.get(\"clause_type\"),\n",
    "        \"num_escalation_reasons\": len(escalation_reasons),\n",
    "        \"escalation_reasons\": escalation_reasons,\n",
    "        \"timestamp\": refined_data.get(\"timestamp\"),\n",
    "        \"refinement_iteration\": refined_data.get(\"refinement_iteration\", 1),\n",
    "        \"has_escalation\": has_escalation,\n",
    "    }\n",
    "\n",
    "    if has_escalation:\n",
    "        agents_with_escalations += 1\n",
    "        total_escalation_reasons += len(escalation_reasons)\n",
    "\n",
    "combined_refined_output[\"summary\"].update({\n",
    "    \"total_agents\": len(combined_refined_output[\"agents\"]),\n",
    "    \"agents_with_escalations\": agents_with_escalations,\n",
    "    \"total_escalation_reasons\": total_escalation_reasons,\n",
    "})\n",
    "\n",
    "combined_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"refined_agent_outputs_combined.json\"\n",
    ")\n",
    "\n",
    "with open(combined_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(combined_refined_output, f, indent=2)\n",
    "\n",
    "print(\"Combined refined agent output saved:\")\n",
    "print(f\"   {combined_file}\")\n",
    "\n",
    "print(\"\\nAggregation Summary:\")\n",
    "print(f\"   Total Agents Included       : {combined_refined_output['summary']['total_agents']}\")\n",
    "print(f\"   Agents with Escalations     : {agents_with_escalations}\")\n",
    "print(f\"   Total Escalation Reasons    : {total_escalation_reasons}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f683ecd",
   "metadata": {},
   "source": [
    "# Final Contract-Level JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "671b5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1d505eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing Final Contract-Level Output...\n",
      "Using Pinecone Index: clauseai-agents\n",
      "Embedding model: all-MiniLM-L6-v2 (reused)\n",
      "Components ready for final output\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MILESTONE3_OUTPUT = \"../Data/Results/Milestone3\"\n",
    "PINECONE_INDEX_NAME = \"clauseai-agents\"\n",
    "\n",
    "print(\"\\nPreparing Final Contract-Level Output...\")\n",
    "\n",
    "assert embedding_model is not None, \"Embedding model not initialized\"\n",
    "assert index is not None, \"Pinecone index not initialized\"\n",
    "\n",
    "print(f\"Using Pinecone Index: {PINECONE_INDEX_NAME}\")\n",
    "print(\"Embedding model: all-MiniLM-L6-v2 (reused)\")\n",
    "print(\"Components ready for final output\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb52c31",
   "metadata": {},
   "source": [
    "#### 1. Defining Final Output Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5e911989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining Final Contract-Level Output Schema\n",
      "Final contract-level schema defined\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining Final Contract-Level Output Schema\")\n",
    "\n",
    "FINAL_CONTRACT_SCHEMA = {\n",
    "    \"contract_id\": \"\",\n",
    "\n",
    "    \"contract_metadata\": {\n",
    "        \"analysis_timestamp\": \"\",\n",
    "        \"analysis_type\": \"multi-agent-rag-cross-refinement\",\n",
    "        \"model_used\": \"gemma2:9b\",\n",
    "        \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "        \"agents_deployed\": [\"legal\", \"finance\", \"compliance\", \"operations\"],\n",
    "        \"refinement_iterations\": 0\n",
    "    },\n",
    "\n",
    "    \"agent_assessments\": {\n",
    "        \"legal\": {\n",
    "            \"original_risk\": \"\",\n",
    "            \"final_risk\": \"\",\n",
    "            \"original_confidence\": 0.0,\n",
    "            \"final_confidence\": 0.0,\n",
    "            \"num_clauses\": 0,\n",
    "            \"escalated\": False,\n",
    "            \"escalation_reasons\": [],\n",
    "            \"model_justification\": \"\"\n",
    "        },\n",
    "        \"finance\": {\n",
    "            \"original_risk\": \"\",\n",
    "            \"final_risk\": \"\",\n",
    "            \"original_confidence\": 0.0,\n",
    "            \"final_confidence\": 0.0,\n",
    "            \"num_clauses\": 0,\n",
    "            \"escalated\": False,\n",
    "            \"escalation_reasons\": [],\n",
    "            \"model_justification\": \"\"\n",
    "        },\n",
    "        \"compliance\": {\n",
    "            \"original_risk\": \"\",\n",
    "            \"final_risk\": \"\",\n",
    "            \"original_confidence\": 0.0,\n",
    "            \"final_confidence\": 0.0,\n",
    "            \"num_clauses\": 0,\n",
    "            \"escalated\": False,\n",
    "            \"escalation_reasons\": [],\n",
    "            \"model_justification\": \"\"\n",
    "        },\n",
    "        \"operations\": {\n",
    "            \"original_risk\": \"\",\n",
    "            \"final_risk\": \"\",\n",
    "            \"original_confidence\": 0.0,\n",
    "            \"final_confidence\": 0.0,\n",
    "            \"num_clauses\": 0,\n",
    "            \"escalated\": False,\n",
    "            \"escalation_reasons\": [],\n",
    "            \"model_justification\": \"\"\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"overall_assessment\": {\n",
    "        \"overall_risk\": \"\",\n",
    "        \"overall_confidence\": 0.0,\n",
    "        \"risk_distribution\": {\n",
    "            \"critical\": 0,\n",
    "            \"high\": 0,\n",
    "            \"medium\": 0,\n",
    "            \"low\": 0\n",
    "        },\n",
    "        \"highest_risk_domain\": \"\",\n",
    "        \"total_clauses_analyzed\": 0\n",
    "    },\n",
    "\n",
    "    \"high_risk_clauses\": [\n",
    "        {\n",
    "            \"clause_text\": \"\",\n",
    "            \"identified_by\": \"\",\n",
    "            \"risk_level\": \"\",\n",
    "            \"rationale\": \"\"\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    \"confidence_metrics\": {\n",
    "        \"average_confidence\": 0.0,\n",
    "        \"confidence_range\": {\n",
    "            \"min\": 0.0,\n",
    "            \"max\": 0.0\n",
    "        },\n",
    "        \"most_confident_agent\": \"\",\n",
    "        \"least_confident_agent\": \"\"\n",
    "    },\n",
    "\n",
    "    \"risk_escalations\": {\n",
    "        \"total_escalations\": 0,\n",
    "        \"escalated_agents\": [],\n",
    "        \"escalation_reasons\": [],\n",
    "        \"cascade_pattern\": []\n",
    "    },\n",
    "\n",
    "    \"audit_trail\": {\n",
    "        \"pinecone_index\": \"contract-agents\",\n",
    "        \"final_merged_vector_id\": \"\",\n",
    "        \"refinement_iteration\": 0,\n",
    "        \"source_namespaces\": [\n",
    "            \"legal_intermediate\",\n",
    "            \"finance_intermediate\",\n",
    "            \"compliance_intermediate\",\n",
    "            \"operations_intermediate\",\n",
    "            \"final_merged\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"generated_at\": \"\"\n",
    "}\n",
    "\n",
    "print(\"Final contract-level schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad6d163",
   "metadata": {},
   "source": [
    "#### 2. Retrieving Latest Agent Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "07f65be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieving Latest Refined Agent Outputs\n",
      "   Legal: Retrieving latest refined assessment\n",
      "      Retrieved from Pinecone\n",
      "   Compliance: Retrieving latest refined assessment\n",
      "      Retrieved from Pinecone\n",
      "   Finance: Retrieving latest refined assessment\n",
      "      Retrieved from Pinecone\n",
      "   Operations: Retrieving latest refined assessment\n",
      "      Retrieved from Pinecone\n",
      "\n",
      "Retrieved latest refined outputs for 4 agents\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRetrieving Latest Refined Agent Outputs\")\n",
    "\n",
    "def get_latest_agent_from_pinecone(agent_name: str):\n",
    "    namespace = f\"{agent_name}_intermediate\"\n",
    "\n",
    "    try:\n",
    "        res = index.query(\n",
    "            vector=[0.0] * 384,  \n",
    "            top_k=10,\n",
    "            include_metadata=True,\n",
    "            namespace=namespace,\n",
    "            filter={\"contract_id\": contract_id},\n",
    "        )\n",
    "\n",
    "        if not res.matches:\n",
    "            return None\n",
    "\n",
    "        latest = max(\n",
    "            res.matches,\n",
    "            key=lambda m: m.metadata.get(\"refinement_iteration\", 0)\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"source\": \"pinecone\",\n",
    "            \"vector_id\": latest.id,\n",
    "            \"metadata\": latest.metadata,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   {agent_name.capitalize()}: Pinecone query failed - {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_latest_agent_from_file(agent_name: str):\n",
    "    refined_file = os.path.join(\n",
    "        MILESTONE3_OUTPUT,\n",
    "        f\"{agent_name}_agent_refined.json\"\n",
    "    )\n",
    "\n",
    "    if os.path.exists(refined_file):\n",
    "        with open(refined_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            return {\n",
    "                \"source\": \"file\",\n",
    "                \"data\": json.load(f)\n",
    "            }\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_latest_agent_output(agent_name: str):\n",
    "    print(f\"   {agent_name.capitalize()}: Retrieving latest refined assessment\")\n",
    "\n",
    "    pinecone_result = get_latest_agent_from_pinecone(agent_name)\n",
    "    if pinecone_result:\n",
    "        print(f\"      Retrieved from Pinecone\")\n",
    "        return pinecone_result\n",
    "\n",
    "    file_result = get_latest_agent_from_file(agent_name)\n",
    "    if file_result:\n",
    "        print(f\"      Loaded from local refined file\")\n",
    "        return file_result\n",
    "\n",
    "    print(f\"      No refined assessment found\")\n",
    "    return None\n",
    "\n",
    "agents = [\"legal\", \"compliance\", \"finance\", \"operations\"]\n",
    "agent_outputs = {}\n",
    "\n",
    "for agent in agents:\n",
    "    agent_outputs[agent] = get_latest_agent_output(agent)\n",
    "\n",
    "retrieved_count = len([v for v in agent_outputs.values() if v])\n",
    "\n",
    "print(f\"\\nRetrieved latest refined outputs for {retrieved_count} agents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5cd672",
   "metadata": {},
   "source": [
    "#### 3. Collecting All Agent Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ed940d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting All Agent Outputs (Pinecone-first)\n",
      "\n",
      "   Loading original agent outputs\n",
      "      Legal: Loaded from ../Data/Results/Legal_Agent\n",
      "      Compliance: Loaded from ../Data/Results/Compliance_Agent\n",
      "      Finance: Loaded from ../Data/Results/Finance_Agent\n",
      "      Operations: Loaded from ../Data/Results/Operations_Agent\n",
      "\n",
      "   Loaded original data for 4 agents\n",
      "\n",
      "   Processing Legal Agent...\n",
      "      Original Assessment:\n",
      "         Risk: low\n",
      "         Clauses: 2\n",
      "         Evidence: 1\n",
      "      Refined Assessment (Pinecone):\n",
      "         Risk: low → medium\n",
      "         Confidence: 85% → 88%\n",
      "         Refinement Iteration: 1768572143\n",
      "\n",
      "   Processing Compliance Agent...\n",
      "      Original Assessment:\n",
      "         Risk: high\n",
      "         Clauses: 1\n",
      "         Evidence: 1\n",
      "      Refined Assessment (Pinecone):\n",
      "         Risk: high → high\n",
      "         Confidence: 100% → 90%\n",
      "         Refinement Iteration: 1768572143\n",
      "\n",
      "   Processing Finance Agent...\n",
      "      Original Assessment:\n",
      "         Risk: medium\n",
      "         Clauses: 3\n",
      "         Evidence: 1\n",
      "      Refined Assessment (Pinecone):\n",
      "         Risk: medium → high\n",
      "         Confidence: 70% → 85%\n",
      "         Refinement Iteration: 1768572143\n",
      "\n",
      "   Processing Operations Agent...\n",
      "      Original Assessment:\n",
      "         Risk: medium\n",
      "         Clauses: 2\n",
      "         Evidence: 2\n",
      "      Refined Assessment (Pinecone):\n",
      "         Risk: medium → high\n",
      "         Confidence: 80% → 92%\n",
      "         Refinement Iteration: 1768572143\n",
      "\n",
      "Collected complete data from 4 agents\n",
      "\n",
      "Data Collection Summary:\n",
      "   Total Clauses Collected: 8\n",
      "   Total Evidence Entries: 5\n",
      "   Refined Agents: 4\n",
      "   Agents with Escalations: 3\n",
      "\n",
      "   Clause Breakdown by Agent:\n",
      "      • Legal      : 2 clauses, 1 evidence\n",
      "      • Compliance : 1 clauses, 1 evidence\n",
      "      • Finance    : 3 clauses, 1 evidence\n",
      "      • Operations : 2 clauses, 2 evidence\n",
      "\n",
      "Data collection successful: 8 clauses retrieved\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCollecting All Agent Outputs (Pinecone-first)\")\n",
    "\n",
    "def resolve_final_risk(agent):\n",
    "    return (\n",
    "        agent.get(\"final_risk\")\n",
    "        or agent.get(\"refined_risk\")\n",
    "        or agent.get(\"original_risk\", \"unknown\")\n",
    "    )\n",
    "\n",
    "def resolve_final_confidence(agent):\n",
    "    return (\n",
    "        agent.get(\"final_confidence\")\n",
    "        or agent.get(\"refined_confidence\")\n",
    "        or agent.get(\"original_confidence\", 0.0)\n",
    "    )\n",
    "\n",
    "def get_latest_refined_from_pinecone(agent_name: str):\n",
    "    namespace = f\"{agent_name}_intermediate\"\n",
    "    try:\n",
    "        res = index.query(\n",
    "            vector=[0.0] * 384,\n",
    "            top_k=10,\n",
    "            include_metadata=True,\n",
    "            namespace=namespace,\n",
    "            filter={\"contract_id\": contract_id},\n",
    "        )\n",
    "        if not res.matches:\n",
    "            return None\n",
    "\n",
    "        return max(\n",
    "            res.matches,\n",
    "            key=lambda m: m.metadata.get(\"refinement_iteration\", 0)\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"      Pinecone error for {agent_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"\\n   Loading original agent outputs\")\n",
    "original_outputs = {}\n",
    "\n",
    "agent_file_mapping = {\n",
    "    \"legal\": LEGAL_AGENT_OUTPUT,\n",
    "    \"compliance\": COMPLIANCE_AGENT_OUTPUT,\n",
    "    \"finance\": FINANCE_AGENT_OUTPUT,\n",
    "    \"operations\": OPERATIONS_AGENT_OUTPUT\n",
    "}\n",
    "\n",
    "for agent_name, agent_dir in agent_file_mapping.items():\n",
    "    original_data = load_latest_agent_output(agent_dir)\n",
    "    if original_data:\n",
    "        original_outputs[agent_name] = original_data\n",
    "        print(f\"      {agent_name.capitalize()}: Loaded from {agent_dir}\")\n",
    "\n",
    "parallel_file = os.path.join(MILESTONE3_OUTPUT, \"parallel_agent_outputs.json\")\n",
    "if os.path.exists(parallel_file):\n",
    "    with open(parallel_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        parallel_data = json.load(f)\n",
    "        for agent_name, agent_data in parallel_data.get(\"agent_outputs\", {}).items():\n",
    "            if agent_name not in original_outputs and agent_data:\n",
    "                original_outputs[agent_name] = agent_data\n",
    "                print(f\"      {agent_name.capitalize()}: Loaded from parallel outputs\")\n",
    "\n",
    "print(f\"\\n   Loaded original data for {len(original_outputs)} agents\\n\")\n",
    "\n",
    "\n",
    "agents = [\"legal\", \"compliance\", \"finance\", \"operations\"]\n",
    "collected_data = {}\n",
    "\n",
    "for agent_name in agents:\n",
    "    print(f\"   Processing {agent_name.capitalize()} Agent...\")\n",
    "\n",
    "    original_agent_data = original_outputs.get(agent_name, {})\n",
    "    original_output = original_agent_data.get(\"output\", {})\n",
    "\n",
    "    original_clauses = original_output.get(\"extracted_clauses\", [])\n",
    "    original_evidence = original_output.get(\"evidence\", [])\n",
    "    original_risk = original_output.get(\"risk_level\", \"unknown\")\n",
    "    original_confidence = original_output.get(\"confidence\", 0.0)\n",
    "\n",
    "    print(f\"      Original Assessment:\")\n",
    "    print(f\"         Risk: {original_risk}\")\n",
    "    print(f\"         Clauses: {len(original_clauses)}\")\n",
    "    print(f\"         Evidence: {len(original_evidence)}\")\n",
    "\n",
    "    refined_match = get_latest_refined_from_pinecone(agent_name)\n",
    "\n",
    "    if refined_match:\n",
    "        meta = refined_match.metadata\n",
    "\n",
    "        final_risk = meta.get(\"risk_level\", original_risk)\n",
    "        final_confidence = meta.get(\"confidence\", original_confidence)\n",
    "        refinement_iteration = meta.get(\"refinement_iteration\", 0)\n",
    "        escalated = final_risk != original_risk\n",
    "\n",
    "        collected_data[agent_name] = {\n",
    "            \"agent_name\": agent_name,\n",
    "            \"risk_level\": final_risk,\n",
    "            \"confidence\": final_confidence,\n",
    "            \"num_clauses\": len(original_clauses),\n",
    "            \"extracted_clauses\": original_clauses,\n",
    "            \"evidence\": original_evidence,\n",
    "            \"is_refined\": True,\n",
    "            \"original_risk\": original_risk,\n",
    "            \"original_confidence\": original_confidence,\n",
    "            \"refinement_iteration\": refinement_iteration,\n",
    "            \"escalated\": escalated,\n",
    "        }\n",
    "\n",
    "        print(f\"      Refined Assessment (Pinecone):\")\n",
    "        print(f\"         Risk: {original_risk} → {final_risk}\")\n",
    "        print(f\"         Confidence: {original_confidence:.0%} → {final_confidence:.0%}\")\n",
    "        print(f\"         Refinement Iteration: {refinement_iteration}\")\n",
    "\n",
    "    else:\n",
    "        collected_data[agent_name] = {\n",
    "            \"agent_name\": agent_name,\n",
    "            \"risk_level\": original_risk,\n",
    "            \"confidence\": original_confidence,\n",
    "            \"num_clauses\": len(original_clauses),\n",
    "            \"extracted_clauses\": original_clauses,\n",
    "            \"evidence\": original_evidence,\n",
    "            \"is_refined\": False,\n",
    "            \"original_risk\": original_risk,\n",
    "            \"original_confidence\": original_confidence,\n",
    "            \"refinement_iteration\": 0,\n",
    "            \"escalated\": False,\n",
    "        }\n",
    "\n",
    "        print(f\"      No refined assessment found; using original only\")\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "print(f\"Collected complete data from {len(collected_data)} agents\\n\")\n",
    "\n",
    "total_clauses = sum(d[\"num_clauses\"] for d in collected_data.values())\n",
    "total_evidence = sum(len(d.get(\"evidence\", [])) for d in collected_data.values())\n",
    "refined_agents = sum(1 for d in collected_data.values() if d[\"is_refined\"])\n",
    "total_escalations = sum(1 for d in collected_data.values() if d[\"escalated\"])\n",
    "\n",
    "print(\"Data Collection Summary:\")\n",
    "print(f\"   Total Clauses Collected: {total_clauses}\")\n",
    "print(f\"   Total Evidence Entries: {total_evidence}\")\n",
    "print(f\"   Refined Agents: {refined_agents}\")\n",
    "print(f\"   Agents with Escalations: {total_escalations}\")\n",
    "\n",
    "print(\"\\n   Clause Breakdown by Agent:\")\n",
    "for agent_name, data in collected_data.items():\n",
    "    print(\n",
    "        f\"      • {agent_name.capitalize():11}: \"\n",
    "        f\"{data['num_clauses']} clauses, \"\n",
    "        f\"{len(data.get('evidence', []))} evidence\"\n",
    "    )\n",
    "\n",
    "if total_clauses == 0:\n",
    "    print(\"\\nWARNING: No clauses collected from any agent\")\n",
    "else:\n",
    "    print(f\"\\nData collection successful: {total_clauses} clauses retrieved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa071a",
   "metadata": {},
   "source": [
    "#### 4. Computing Overall Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5a7fb7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing Overall Contract Risk\n",
      "   Legal      : medium   (weight: 2, confidence: 0.88, score: 1.76)\n",
      "   Compliance : high     (weight: 3, confidence: 0.90, score: 2.70)\n",
      "   Finance    : high     (weight: 3, confidence: 0.85, score: 2.55)\n",
      "   Operations : high     (weight: 3, confidence: 0.92, score: 2.76)\n",
      "\n",
      "Risk Calculation Summary:\n",
      "   Total Weighted Score   : 9.77\n",
      "   Average Weighted Score : 2.44\n",
      "   Overall Contract Risk  : MEDIUM\n",
      "   Highest Risk Domain    : OPERATIONS (HIGH)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing Overall Contract Risk\")\n",
    "\n",
    "risk_weights = {\n",
    "    \"critical\": 4,\n",
    "    \"high\": 3,\n",
    "    \"medium\": 2,\n",
    "    \"low\": 1,\n",
    "    \"unknown\": 0\n",
    "}\n",
    "\n",
    "weighted_scores = []\n",
    "risk_distribution = {\n",
    "    \"critical\": 0,\n",
    "    \"high\": 0,\n",
    "    \"medium\": 0,\n",
    "    \"low\": 0,\n",
    "    \"unknown\": 0\n",
    "}\n",
    "\n",
    "for agent_name, data in collected_data.items():\n",
    "    risk_level = data.get(\"risk_level\", \"unknown\").lower()\n",
    "    confidence = data.get(\"confidence\", 0.0)\n",
    "\n",
    "    weight = risk_weights.get(risk_level, 0)\n",
    "    weighted_score = weight * confidence\n",
    "\n",
    "    weighted_scores.append(weighted_score)\n",
    "    risk_distribution[risk_level] += 1\n",
    "\n",
    "    print(\n",
    "        f\"   {agent_name.capitalize():11}: \"\n",
    "        f\"{risk_level:8} \"\n",
    "        f\"(weight: {weight}, confidence: {confidence:.2f}, score: {weighted_score:.2f})\"\n",
    "    )\n",
    "\n",
    "total_weighted_score = sum(weighted_scores)\n",
    "avg_weighted_score = (\n",
    "    total_weighted_score / len(weighted_scores)\n",
    "    if weighted_scores else 0.0\n",
    ")\n",
    "\n",
    "print(\"\\nRisk Calculation Summary:\")\n",
    "print(f\"   Total Weighted Score   : {total_weighted_score:.2f}\")\n",
    "print(f\"   Average Weighted Score : {avg_weighted_score:.2f}\")\n",
    "\n",
    "if avg_weighted_score >= 3.5:\n",
    "    overall_risk = \"CRITICAL\"\n",
    "elif avg_weighted_score >= 2.5:\n",
    "    overall_risk = \"HIGH\"\n",
    "elif avg_weighted_score >= 1.5:\n",
    "    overall_risk = \"MEDIUM\"\n",
    "else:\n",
    "    overall_risk = \"LOW\"\n",
    "\n",
    "print(f\"   Overall Contract Risk  : {overall_risk}\")\n",
    "\n",
    "highest_risk_agent = max(\n",
    "    collected_data.items(),\n",
    "    key=lambda x: (\n",
    "        risk_weights.get(x[1].get(\"risk_level\", \"unknown\").lower(), 0),\n",
    "        x[1].get(\"confidence\", 0.0)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"   Highest Risk Domain    : \"\n",
    "    f\"{highest_risk_agent[0].upper()} \"\n",
    "    f\"({highest_risk_agent[1]['risk_level'].upper()})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e376bf",
   "metadata": {},
   "source": [
    "#### 5. Adding Timestamp and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "692879a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adding Timestamp and Metadata\n",
      "   Contract ID reused (stable)\n",
      "   Contract ID            : 4ddffbdafb3e\n",
      "   Generated At           : 2026-01-16T20:07:47.588572\n",
      "   Agents Deployed        : legal, compliance, finance, operations\n",
      "   Refined Agents         : 4/4\n",
      "   Latest Refinement Iter : 1768572143\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAdding Timestamp and Metadata\")\n",
    "\n",
    "if \"contract_id\" not in globals() or not contract_id:\n",
    "    contract_content = json.dumps(collected_data, sort_keys=True)\n",
    "    contract_id = hashlib.md5(contract_content.encode()).hexdigest()[:16]\n",
    "    print(\"   Contract ID generated (fallback)\")\n",
    "else:\n",
    "    print(\"   Contract ID reused (stable)\")\n",
    "\n",
    "generated_timestamp = datetime.now().isoformat()\n",
    "\n",
    "agents = list(collected_data.keys())\n",
    "\n",
    "refined_agents = [\n",
    "    agent for agent, data in collected_data.items()\n",
    "    if data.get(\"is_refined\", False)\n",
    "]\n",
    "\n",
    "latest_refinement_iteration = max(\n",
    "    (data.get(\"refinement_iteration\", 0) for data in collected_data.values()),\n",
    "    default=0\n",
    ")\n",
    "\n",
    "print(f\"   Contract ID            : {contract_id}\")\n",
    "print(f\"   Generated At           : {generated_timestamp}\")\n",
    "print(f\"   Agents Deployed        : {', '.join(agents)}\")\n",
    "print(f\"   Refined Agents         : {len(refined_agents)}/{len(agents)}\")\n",
    "print(f\"   Latest Refinement Iter : {latest_refinement_iteration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5135577e",
   "metadata": {},
   "source": [
    "#### 6. Generating Final JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "32d1ed4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tracking Risk Escalations\n",
      "   Refinement Escalations (Risk Changed): 3/4\n",
      "      - Legal: low -> medium\n",
      "      - Finance: medium -> high\n",
      "      - Operations: medium -> high\n",
      "\n",
      "   Escalation Reasons:\n",
      "\n",
      "      Agent: Legal (Clause-Level)\n",
      "         Clause LEGAL-1:\n",
      "            The other party asserts any rights in or to the terminating party's intellectual property in violation of this Agreement...\n",
      "            - Clause contributes to medium risk classification\n",
      "         Clause LEGAL-2:\n",
      "            The other party shall give notice of termination in writing to the other party, which notice shall specify in reasonable...\n",
      "            - Clause contributes to medium risk classification\n",
      "\n",
      "      Agent: Compliance (Clause-Level)\n",
      "         Clause COMPLIANCE-1:\n",
      "            The receiving party will not disclose the other party's confidential information to any third parties without the other ...\n",
      "            - Clause contributes to high risk classification\n",
      "\n",
      "      Agent: Finance (Clause-Level)\n",
      "         Clause FINANCE-1:\n",
      "            In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, incl...\n",
      "            - Clause contributes to high risk classification\n",
      "         Clause FINANCE-2:\n",
      "            ), Recipient shall reimburse Provider for all such Out-of-Pocket Costs.\n",
      "            - Clause contributes to high risk classification\n",
      "         Clause FINANCE-3:\n",
      "            Provider shall provide Recipient with monthly invo\n",
      "            - Clause contributes to high risk classification\n",
      "\n",
      "      Agent: Operations (Clause-Level)\n",
      "         Clause OPERATIONS-1:\n",
      "            Collectible Concepts Group will obtain any licenses deemed by the Joint Venturers to add value in the marketing of the P...\n",
      "            - Clause contributes to high risk classification\n",
      "         Clause OPERATIONS-2:\n",
      "            Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distribution of the Produ...\n",
      "            - Clause contributes to high risk classification\n",
      "\n",
      "   Total Escalation Reasons Tracked: 8\n",
      "\n",
      "Building Final Contract-Level Report\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTracking Risk Escalations\")\n",
    "\n",
    "confidences = [\n",
    "    data[\"confidence\"]\n",
    "    for data in collected_data.values()\n",
    "    if isinstance(data.get(\"confidence\"), (int, float))\n",
    "]\n",
    "\n",
    "confidence_metrics = {\n",
    "    \"average_confidence\": statistics.mean(confidences) if confidences else 0.0,\n",
    "    \"median_confidence\": statistics.median(confidences) if confidences else 0.0,\n",
    "    \"std_deviation\": statistics.stdev(confidences) if len(confidences) > 1 else 0.0,\n",
    "    \"confidence_range\": {\n",
    "        \"min\": min(confidences) if confidences else 0.0,\n",
    "        \"max\": max(confidences) if confidences else 0.0,\n",
    "    }\n",
    "}\n",
    "\n",
    "refinement_escalated_agents = []\n",
    "\n",
    "for agent_name, data in collected_data.items():\n",
    "    if (\n",
    "        data.get(\"original_risk\")\n",
    "        and data[\"original_risk\"] != data[\"risk_level\"]\n",
    "    ):\n",
    "        refinement_escalated_agents.append(agent_name)\n",
    "\n",
    "print(\n",
    "    f\"   Refinement Escalations (Risk Changed): \"\n",
    "    f\"{len(refinement_escalated_agents)}/{len(collected_data)}\"\n",
    ")\n",
    "\n",
    "if refinement_escalated_agents:\n",
    "    for agent in refinement_escalated_agents:\n",
    "        original = collected_data[agent][\"original_risk\"]\n",
    "        refined = collected_data[agent][\"risk_level\"]\n",
    "        print(f\"      - {agent.capitalize()}: {original} -> {refined}\")\n",
    "else:\n",
    "    print(\"      No agents escalated during refinement\")\n",
    "\n",
    "\n",
    "print(\"\\n   Escalation Reasons:\")\n",
    "\n",
    "all_escalation_reasons = []\n",
    "escalation_clauses = []\n",
    "agent_level_escalations = []\n",
    "\n",
    "for agent_name, data in collected_data.items():\n",
    "    clauses = data.get(\"extracted_clauses\", [])\n",
    "    reasons = data.get(\"escalation_reasons\", [])\n",
    "    risk_level = data.get(\"risk_level\", \"\").lower()\n",
    "\n",
    "    if clauses and (risk_level in [\"high\", \"critical\", \"medium\"]):\n",
    "        print(f\"\\n      Agent: {agent_name.capitalize()} (Clause-Level)\")\n",
    "\n",
    "        for idx, clause in enumerate(clauses, 1):\n",
    "            clause_id = f\"{agent_name.upper()}-{idx}\"\n",
    "\n",
    "            clause_reason = f\"Clause contributes to {data['risk_level']} risk classification\"\n",
    "\n",
    "            escalation_clauses.append({\n",
    "                \"agent\": agent_name,\n",
    "                \"clause_id\": clause_id,\n",
    "                \"risk_level\": data[\"risk_level\"],\n",
    "                \"clause_text\": clause,\n",
    "                \"escalation_reason\": clause_reason,\n",
    "            })\n",
    "\n",
    "            print(f\"         Clause {clause_id}:\")\n",
    "            print(f\"            {clause[:120]}{'...' if len(clause) > 120 else ''}\")\n",
    "            print(f\"            - {clause_reason}\")\n",
    "\n",
    "            all_escalation_reasons.append({\n",
    "                \"agent\": agent_name,\n",
    "                \"clause_id\": clause_id,\n",
    "                \"reason\": clause_reason,\n",
    "            })\n",
    "\n",
    "    elif reasons:\n",
    "        print(f\"\\n      Agent: {agent_name.capitalize()} (Agent-Level)\")\n",
    "\n",
    "        for r in reasons:\n",
    "            print(f\"         - {r}\")\n",
    "\n",
    "            agent_level_escalations.append({\n",
    "                \"agent\": agent_name,\n",
    "                \"reason\": r,\n",
    "                \"trigger\": \"cross-agent refinement\",\n",
    "            })\n",
    "\n",
    "            all_escalation_reasons.append({\n",
    "                \"agent\": agent_name,\n",
    "                \"clause_id\": None,\n",
    "                \"reason\": r,\n",
    "            })\n",
    "\n",
    "total_escalation_reasons = len(all_escalation_reasons)\n",
    "\n",
    "print(f\"\\n   Total Escalation Reasons Tracked: {total_escalation_reasons}\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nBuilding Final Contract-Level Report\")\n",
    "\n",
    "final_output = {\n",
    "    \"contract_id\": contract_id,\n",
    "\n",
    "    \"contract_metadata\": {\n",
    "        \"analysis_timestamp\": generated_timestamp,\n",
    "        \"analysis_type\": \"multi-agent-rag-cross-refinement\",\n",
    "        \"model_used\": \"gemma2:9b\",\n",
    "        \"embedding_model\": \"all-MiniLM-L6-v2\",\n",
    "        \"agents_deployed\": agents,\n",
    "        \"refinement_iterations\": latest_refinement_iteration,\n",
    "        \"total_agents\": len(collected_data),\n",
    "        \"refined_agents\": len(refined_agents),\n",
    "        \"version\": \"1.0\",\n",
    "    },\n",
    "\n",
    "    \"agent_assessments\": {\n",
    "        agent: {\n",
    "            \"original_risk\": data[\"original_risk\"],\n",
    "            \"final_risk\": data[\"risk_level\"],\n",
    "            \"original_confidence\": data[\"original_confidence\"],\n",
    "            \"final_confidence\": round(data[\"confidence\"], 3),\n",
    "            \"num_clauses\": data[\"num_clauses\"],\n",
    "            \"refinement_escalated\": (\n",
    "                data.get(\"original_risk\") != data[\"risk_level\"]\n",
    "            ),\n",
    "            \"agent_level_escalation_reasons\": data.get(\"escalation_reasons\", []),\n",
    "        }\n",
    "        for agent, data in collected_data.items()\n",
    "    },\n",
    "\n",
    "    \"overall_assessment\": {\n",
    "        \"overall_risk\": overall_risk,\n",
    "        \"overall_confidence\": round(confidence_metrics[\"average_confidence\"], 3),\n",
    "        \"weighted_risk_score\": round(avg_weighted_score, 3),\n",
    "        \"risk_distribution\": risk_distribution,\n",
    "        \"highest_risk_domain\": highest_risk_agent[0],\n",
    "        \"total_clauses_analyzed\": sum(\n",
    "            data[\"num_clauses\"] for data in collected_data.values()\n",
    "        ),\n",
    "    },\n",
    "\n",
    "    \"risk_escalations\": {\n",
    "        \"refinement_escalations\": {\n",
    "            \"count\": len(refinement_escalated_agents),\n",
    "            \"agents\": refinement_escalated_agents\n",
    "        },\n",
    "        \"clause_level_escalations\": {\n",
    "            \"count\": total_escalation_reasons,\n",
    "            \"clauses\": escalation_clauses,\n",
    "            \"reasons\": all_escalation_reasons\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"generated_at\": generated_timestamp,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "014bd6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Final Escalation Outputs\n",
      "Final escalation JSON saved: ../Data/Results/Milestone3\\final_escalation_analysis_new.json\n",
      "\n",
      "FINAL CONTRACT ESCALATION SUMMARY\n",
      "========================================\n",
      "Contract ID        : 4ddffbdafb3e\n",
      "Generated At       : 2026-01-16T20:07:47.588572\n",
      "Overall Risk       : MEDIUM\n",
      "Average Confidence : 89%\n",
      "Weighted Risk Score: 2.44 / 4.00\n",
      "\n",
      "REFINEMENT ESCALATIONS (RISK CHANGED)\n",
      "----------------------------------------\n",
      "- Legal: low -> medium\n",
      "- Finance: medium -> high\n",
      "- Operations: medium -> high\n",
      "\n",
      "CLAUSE-LEVEL ESCALATIONS\n",
      "----------------------------------------\n",
      "[LEGAL] LEGAL-1\n",
      "  Risk Level : medium\n",
      "  Clause     : The other party asserts any rights in or to the terminating party's intellectual property in violation of this Agreement.\n",
      "  Reason     : Clause contributes to medium risk classification\n",
      "\n",
      "[LEGAL] LEGAL-2\n",
      "  Risk Level : medium\n",
      "  Clause     : The other party shall give notice of termination in writing to the other party, which notice shall specify in reasonable detail the event(s) of default that giv...\n",
      "  Reason     : Clause contributes to medium risk classification\n",
      "\n",
      "[COMPLIANCE] COMPLIANCE-1\n",
      "  Risk Level : high\n",
      "  Clause     : The receiving party will not disclose the other party's confidential information to any third parties without the other party's prior written consent.\n",
      "  Reason     : Clause contributes to high risk classification\n",
      "\n",
      "[FINANCE] FINANCE-1\n",
      "  Risk Level : high\n",
      "  Clause     : In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, including, without limitation, license fees ...\n",
      "  Reason     : Clause contributes to high risk classification\n",
      "\n",
      "[FINANCE] FINANCE-2\n",
      "  Risk Level : high\n",
      "  Clause     : ), Recipient shall reimburse Provider for all such Out-of-Pocket Costs.\n",
      "  Reason     : Clause contributes to high risk classification\n",
      "\n",
      "[FINANCE] FINANCE-3\n",
      "  Risk Level : high\n",
      "  Clause     : Provider shall provide Recipient with monthly invo\n",
      "  Reason     : Clause contributes to high risk classification\n",
      "\n",
      "[OPERATIONS] OPERATIONS-1\n",
      "  Risk Level : high\n",
      "  Clause     : Collectible Concepts Group will obtain any licenses deemed by the Joint Venturers to add value in the marketing of the Products\n",
      "  Reason     : Clause contributes to high risk classification\n",
      "\n",
      "[OPERATIONS] OPERATIONS-2\n",
      "  Risk Level : high\n",
      "  Clause     : Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distribution of the Products\n",
      "  Reason     : Clause contributes to high risk classification\n",
      "\n",
      "\n",
      "AGENT-LEVEL ESCALATIONS (NO DIRECT CLAUSE)\n",
      "----------------------------------------\n",
      "No agent-level escalation reasons\n",
      "\n",
      "ESCALATION SUMMARY\n",
      "----------------------------------------\n",
      "Total Refinement Escalations : 3\n",
      "Clause-Level Escalations     : 8\n",
      "Agent-Level Escalations      : 0\n",
      "Total Escalation Reasons     : 8\n",
      "\n",
      "Human-readable escalation summary saved: ../Data/Results/Milestone3\\final_escalation_summary_new.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating Final Escalation Outputs\")\n",
    "\n",
    "final_escalation_output = {\n",
    "    \"contract_id\": contract_id,\n",
    "    \"generated_at\": generated_timestamp,\n",
    "\n",
    "    \"overall_assessment\": {\n",
    "        \"overall_risk\": overall_risk,\n",
    "        \"average_confidence\": round(confidence_metrics[\"average_confidence\"], 3),\n",
    "        \"weighted_risk_score\": round(avg_weighted_score, 3),\n",
    "        \"highest_risk_domain\": highest_risk_agent[0],\n",
    "        \"risk_distribution\": risk_distribution,\n",
    "    },\n",
    "\n",
    "    \"refinement_escalations\": {\n",
    "        \"count\": len(refinement_escalated_agents),\n",
    "        \"agents\": refinement_escalated_agents,\n",
    "    },\n",
    "\n",
    "    \"clause_level_escalations\": {\n",
    "        \"count\": len(escalation_clauses),\n",
    "        \"clauses\": escalation_clauses,\n",
    "    },\n",
    "\n",
    "    \"agent_level_escalations\": {\n",
    "        \"count\": len(agent_level_escalations),\n",
    "        \"agents\": agent_level_escalations,\n",
    "    },\n",
    "\n",
    "    \"all_escalation_reasons\": {\n",
    "        \"total_reasons\": len(all_escalation_reasons),\n",
    "        \"reasons\": all_escalation_reasons,\n",
    "    },\n",
    "\n",
    "    \"agents_summary\": {\n",
    "        agent: {\n",
    "            \"original_risk\": data[\"original_risk\"],\n",
    "            \"final_risk\": data[\"risk_level\"],\n",
    "            \"confidence\": round(data[\"confidence\"], 3),\n",
    "            \"num_clauses\": data[\"num_clauses\"],\n",
    "            \"refinement_escalated\": (\n",
    "                data.get(\"original_risk\") != data[\"risk_level\"]\n",
    "            ),\n",
    "        }\n",
    "        for agent, data in collected_data.items()\n",
    "    },\n",
    "}\n",
    "\n",
    "final_json_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"final_escalation_analysis_new.json\"\n",
    ")\n",
    "\n",
    "with open(final_json_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_escalation_output, f, indent=2)\n",
    "\n",
    "print(f\"Final escalation JSON saved: {final_json_file}\")\n",
    "\n",
    "\n",
    "\n",
    "human_summary_lines = []\n",
    "\n",
    "human_summary_lines.append(\"FINAL CONTRACT ESCALATION SUMMARY\")\n",
    "human_summary_lines.append(\"=\" * 40)\n",
    "human_summary_lines.append(f\"Contract ID        : {contract_id}\")\n",
    "human_summary_lines.append(f\"Generated At       : {generated_timestamp}\")\n",
    "human_summary_lines.append(f\"Overall Risk       : {overall_risk}\")\n",
    "human_summary_lines.append(\n",
    "    f\"Average Confidence : {confidence_metrics['average_confidence']:.0%}\"\n",
    ")\n",
    "human_summary_lines.append(\n",
    "    f\"Weighted Risk Score: {avg_weighted_score:.2f} / 4.00\"\n",
    ")\n",
    "\n",
    "human_summary_lines.append(\"\\nREFINEMENT ESCALATIONS (RISK CHANGED)\")\n",
    "human_summary_lines.append(\"-\" * 40)\n",
    "\n",
    "if refinement_escalated_agents:\n",
    "    for agent in refinement_escalated_agents:\n",
    "        o = collected_data[agent][\"original_risk\"]\n",
    "        r = collected_data[agent][\"risk_level\"]\n",
    "        human_summary_lines.append(\n",
    "            f\"- {agent.capitalize()}: {o} -> {r}\"\n",
    "        )\n",
    "else:\n",
    "    human_summary_lines.append(\"No agents escalated during refinement\")\n",
    "\n",
    "human_summary_lines.append(\"\\nCLAUSE-LEVEL ESCALATIONS\")\n",
    "human_summary_lines.append(\"-\" * 40)\n",
    "\n",
    "if escalation_clauses:\n",
    "    for clause in escalation_clauses:\n",
    "        human_summary_lines.append(\n",
    "            f\"[{clause['agent'].upper()}] {clause['clause_id']}\"\n",
    "        )\n",
    "        human_summary_lines.append(\n",
    "            f\"  Risk Level : {clause['risk_level']}\"\n",
    "        )\n",
    "        human_summary_lines.append(\n",
    "            f\"  Clause     : {clause['clause_text'][:160]}\"\n",
    "            + (\"...\" if len(clause[\"clause_text\"]) > 160 else \"\")\n",
    "        )\n",
    "        human_summary_lines.append(\n",
    "            f\"  Reason     : {clause['escalation_reason']}\"\n",
    "        )\n",
    "        human_summary_lines.append(\"\")\n",
    "else:\n",
    "    human_summary_lines.append(\"No clause-level escalation clauses identified\")\n",
    "\n",
    "human_summary_lines.append(\"\\nAGENT-LEVEL ESCALATIONS (NO DIRECT CLAUSE)\")\n",
    "human_summary_lines.append(\"-\" * 40)\n",
    "\n",
    "if agent_level_escalations:\n",
    "    for entry in agent_level_escalations:\n",
    "        human_summary_lines.append(\n",
    "            f\"- {entry['agent'].capitalize()}: {entry['reason']}\"\n",
    "        )\n",
    "else:\n",
    "    human_summary_lines.append(\"No agent-level escalation reasons\")\n",
    "\n",
    "human_summary_lines.append(\"\\nESCALATION SUMMARY\")\n",
    "human_summary_lines.append(\"-\" * 40)\n",
    "human_summary_lines.append(\n",
    "    f\"Total Refinement Escalations : {len(refinement_escalated_agents)}\"\n",
    ")\n",
    "human_summary_lines.append(\n",
    "    f\"Clause-Level Escalations     : {len(escalation_clauses)}\"\n",
    ")\n",
    "human_summary_lines.append(\n",
    "    f\"Agent-Level Escalations      : {len(agent_level_escalations)}\"\n",
    ")\n",
    "human_summary_lines.append(\n",
    "    f\"Total Escalation Reasons     : {len(all_escalation_reasons)}\"\n",
    ")\n",
    "\n",
    "human_summary_text = \"\\n\".join(human_summary_lines)\n",
    "\n",
    "print(\"\\n\" + human_summary_text)\n",
    "\n",
    "human_summary_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"final_escalation_summary_new.txt\"\n",
    ")\n",
    "\n",
    "with open(human_summary_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(human_summary_text)\n",
    "\n",
    "print(f\"\\nHuman-readable escalation summary saved: {human_summary_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43225a2d",
   "metadata": {},
   "source": [
    "# Report Template Design - Human-Readable Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b3a722d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MILESTONE3_OUTPUT = \"../Data/Results/Milestone3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b55d1",
   "metadata": {},
   "source": [
    "#### 1. Defining Report Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c2eaac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining Report Structure\n",
      "Report structure defined with sections:\n",
      "   1. Executive Summary\n",
      "   2. Overall Risk Assessment\n",
      "   3. Legal Analysis\n",
      "   4. Compliance Analysis\n",
      "   5. Financial Analysis\n",
      "   6. Operational Analysis\n",
      "   7. High-Risk Clauses\n",
      "   8. Risk Escalations\n",
      "   9. Conclusion & Recommendations\n",
      "\n",
      "Generating Human-Readable Contract Report\n",
      "\n",
      "Human-readable contract report saved: ../Data/Results/Milestone3\\contract_report_new.txt\n",
      "\n",
      "Report generation complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Defining Report Structure\")\n",
    "\n",
    "REPORT_STRUCTURE = [\n",
    "    \"Executive Summary\",\n",
    "    \"Overall Risk Assessment\",\n",
    "    \"Legal Analysis\",\n",
    "    \"Compliance Analysis\",\n",
    "    \"Financial Analysis\",\n",
    "    \"Operational Analysis\",\n",
    "    \"High-Risk Clauses\",\n",
    "    \"Risk Escalations\",\n",
    "    \"Conclusion & Recommendations\",\n",
    "]\n",
    "\n",
    "print(\"Report structure defined with sections:\")\n",
    "for i, section in enumerate(REPORT_STRUCTURE, 1):\n",
    "    print(f\"   {i}. {section}\")\n",
    "\n",
    "\n",
    "print(\"\\nGenerating Human-Readable Contract Report\")\n",
    "\n",
    "report_lines = []\n",
    "\n",
    "report_lines.append(\"EXECUTIVE SUMMARY\")\n",
    "report_lines.append(\"=\" * 70)\n",
    "report_lines.append(f\"Contract ID        : {contract_id}\")\n",
    "report_lines.append(f\"Analysis Timestamp : {generated_timestamp}\")\n",
    "report_lines.append(f\"Overall Risk       : {overall_risk}\")\n",
    "report_lines.append(\n",
    "    f\"Average Confidence : {confidence_metrics['average_confidence']:.0%}\"\n",
    ")\n",
    "report_lines.append(\n",
    "    f\"Weighted Risk Score: {avg_weighted_score:.2f} / 4.00\"\n",
    ")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"OVERALL RISK ASSESSMENT\")\n",
    "report_lines.append(\"=\" * 70)\n",
    "for risk_level, count in sorted(\n",
    "    risk_distribution.items(),\n",
    "    key=lambda x: {\"critical\": 4, \"high\": 3, \"medium\": 2, \"low\": 1}.get(x[0], 0),\n",
    "    reverse=True,\n",
    "):\n",
    "    report_lines.append(\n",
    "        f\"- {risk_level.capitalize():8}: {count} agent(s)\"\n",
    "    )\n",
    "report_lines.append(\n",
    "    f\"Highest Risk Domain: {highest_risk_agent[0].capitalize()}\"\n",
    ")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "def add_agent_section(agent_name, title):\n",
    "    data = collected_data.get(agent_name, {})\n",
    "    report_lines.append(title.upper())\n",
    "    report_lines.append(\"-\" * 70)\n",
    "    report_lines.append(f\"Final Risk Level   : {data.get('risk_level', 'N/A').upper()}\")\n",
    "    report_lines.append(\n",
    "        f\"Confidence         : {data.get('confidence', 0):.0%}\"\n",
    "    )\n",
    "    report_lines.append(\n",
    "        f\"Original Risk      : {data.get('original_risk', 'N/A')}\"\n",
    "    )\n",
    "    report_lines.append(\n",
    "        f\"Clauses Analyzed   : {data.get('num_clauses', 0)}\"\n",
    "    )\n",
    "\n",
    "    if data.get(\"escalation_reasons\"):\n",
    "        report_lines.append(\"Escalation Reasons:\")\n",
    "        for r in data[\"escalation_reasons\"]:\n",
    "            report_lines.append(f\"  - {r}\")\n",
    "    else:\n",
    "        report_lines.append(\"Escalation Reasons: None\")\n",
    "\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "add_agent_section(\"legal\", \"Legal Analysis\")\n",
    "add_agent_section(\"compliance\", \"Compliance Analysis\")\n",
    "add_agent_section(\"finance\", \"Financial Analysis\")\n",
    "add_agent_section(\"operations\", \"Operational Analysis\")\n",
    "\n",
    "report_lines.append(\"HIGH-RISK CLAUSES\")\n",
    "report_lines.append(\"=\" * 70)\n",
    "\n",
    "if escalation_clauses:\n",
    "    for clause in escalation_clauses:\n",
    "        report_lines.append(\n",
    "            f\"[{clause['agent'].upper()}] {clause['clause_id']} \"\n",
    "            f\"(Risk: {clause['risk_level'].upper()})\"\n",
    "        )\n",
    "        report_lines.append(\n",
    "            f\"Clause Text: {clause['clause_text'][:200]}\"\n",
    "            + (\"...\" if len(clause[\"clause_text\"]) > 200 else \"\")\n",
    "        )\n",
    "        report_lines.append(\n",
    "            f\"Reason     : {clause['escalation_reason']}\"\n",
    "        )\n",
    "        report_lines.append(\"\")\n",
    "else:\n",
    "    report_lines.append(\"No high-risk clauses identified.\")\n",
    "    report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"RISK ESCALATIONS\")\n",
    "report_lines.append(\"=\" * 70)\n",
    "\n",
    "report_lines.append(\n",
    "    f\"Refinement Escalations (Risk Changed): \"\n",
    "    f\"{len(refinement_escalated_agents)}\"\n",
    ")\n",
    "if refinement_escalated_agents:\n",
    "    for agent in refinement_escalated_agents:\n",
    "        o = collected_data[agent][\"original_risk\"]\n",
    "        r = collected_data[agent][\"risk_level\"]\n",
    "        report_lines.append(f\"- {agent.capitalize()}: {o} -> {r}\")\n",
    "else:\n",
    "    report_lines.append(\"- None\")\n",
    "\n",
    "report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"Agent-Level Escalations:\")\n",
    "if agent_level_escalations:\n",
    "    for entry in agent_level_escalations:\n",
    "        report_lines.append(\n",
    "            f\"- {entry['agent'].capitalize()}: {entry['reason']}\"\n",
    "        )\n",
    "else:\n",
    "    report_lines.append(\"- None\")\n",
    "\n",
    "report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\n",
    "    f\"Total Escalation Reasons Identified: {len(all_escalation_reasons)}\"\n",
    ")\n",
    "report_lines.append(\"\")\n",
    "\n",
    "report_lines.append(\"CONCLUSION & RECOMMENDATIONS\")\n",
    "report_lines.append(\"=\" * 70)\n",
    "\n",
    "if overall_risk in [\"CRITICAL\", \"HIGH\"]:\n",
    "    report_lines.append(\n",
    "        \"This contract presents elevated risk and requires immediate review.\"\n",
    "    )\n",
    "    report_lines.append(\n",
    "        \"Key high-risk clauses and cross-domain escalation patterns were identified.\"\n",
    "    )\n",
    "    report_lines.append(\n",
    "        \"It is recommended to renegotiate high-risk clauses and obtain senior approval.\"\n",
    "    )\n",
    "elif overall_risk == \"MEDIUM\":\n",
    "    report_lines.append(\n",
    "        \"This contract presents moderate risk. Review and mitigation are advised.\"\n",
    "    )\n",
    "else:\n",
    "    report_lines.append(\n",
    "        \"This contract presents low risk and may proceed under standard approval.\"\n",
    "    )\n",
    "\n",
    "report_lines.append(\"\")\n",
    "\n",
    "human_report_text = \"\\n\".join(report_lines)\n",
    "\n",
    "report_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"contract_report_new.txt\"\n",
    ")\n",
    "\n",
    "with open(report_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(human_report_text)\n",
    "\n",
    "print(f\"\\nHuman-readable contract report saved: {report_file}\")\n",
    "\n",
    "print(\"\\nReport generation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd8f3e",
   "metadata": {},
   "source": [
    "#### 2. Mapping JSON Data to Report Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "74ffdda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mapping Combined Refined Agent JSON to Report Sections\n",
      "Loaded combined refined agent output\n",
      "Mapped data to report sections:\n",
      "   • Executive Summary\n",
      "   • Legal Analysis\n",
      "   • Finance Analysis\n",
      "   • Compliance Analysis\n",
      "   • Operations Analysis\n",
      "   • Risk Escalations\n",
      "   • Conclusion\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMapping Combined Refined Agent JSON to Report Sections\")\n",
    "\n",
    "combined_json_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"refined_agent_outputs_combined.json\"\n",
    ")\n",
    "\n",
    "if not os.path.exists(combined_json_file):\n",
    "    raise FileNotFoundError(\"Combined refined agent JSON not found\")\n",
    "\n",
    "with open(combined_json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    combined_data = json.load(f)\n",
    "\n",
    "print(\"Loaded combined refined agent output\")\n",
    "\n",
    "\n",
    "def map_combined_json_to_sections(data: dict) -> dict:\n",
    "    sections = {}\n",
    "\n",
    "    agents = data.get(\"agents\", {})\n",
    "\n",
    "    highest_risk_agent = max(\n",
    "        agents.items(),\n",
    "        key=lambda x: {\"critical\": 4, \"high\": 3, \"medium\": 2, \"low\": 1}.get(\n",
    "            x[1][\"risk_level\"], 0\n",
    "        ),\n",
    "    )[0]\n",
    "\n",
    "    sections[\"executive_summary\"] = {\n",
    "        \"analysis_timestamp\": data.get(\"generated_at\"),\n",
    "        \"total_agents\": len(agents),\n",
    "        \"agents_with_escalations\": data[\"summary\"][\"agents_with_escalations\"],\n",
    "        \"total_escalation_reasons\": data[\"summary\"][\"total_escalation_reasons\"],\n",
    "        \"highest_risk_domain\": highest_risk_agent,\n",
    "        \"requires_attention\": any(\n",
    "            a[\"risk_level\"] in [\"high\", \"critical\"]\n",
    "            for a in agents.values()\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for agent_name, agent_data in agents.items():\n",
    "        sections[f\"{agent_name}_analysis\"] = {\n",
    "            \"agent_name\": agent_name,\n",
    "            \"final_risk\": agent_data.get(\"risk_level\"),\n",
    "            \"final_confidence\": agent_data.get(\"confidence\"),\n",
    "            \"num_escalation_reasons\": agent_data.get(\n",
    "                \"num_escalation_reasons\", 0\n",
    "            ),\n",
    "            \"escalation_reasons\": agent_data.get(\n",
    "                \"escalation_reasons\", []\n",
    "            ),\n",
    "            \"has_escalation\": agent_data.get(\"has_escalation\", False),\n",
    "        }\n",
    "\n",
    "    escalation_details = []\n",
    "\n",
    "    for agent_name, agent_data in agents.items():\n",
    "        if agent_data.get(\"escalation_reasons\"):\n",
    "            escalation_details.append({\n",
    "                \"agent\": agent_name,\n",
    "                \"risk_level\": agent_data[\"risk_level\"],\n",
    "                \"escalation_reasons\": agent_data[\"escalation_reasons\"],\n",
    "                \"count\": len(agent_data[\"escalation_reasons\"]),\n",
    "            })\n",
    "\n",
    "    sections[\"risk_escalations\"] = {\n",
    "        \"total_agents_escalated\": data[\"summary\"][\"agents_with_escalations\"],\n",
    "        \"total_escalation_reasons\": data[\"summary\"][\"total_escalation_reasons\"],\n",
    "        \"details\": escalation_details,\n",
    "    }\n",
    "\n",
    "    sections[\"conclusion\"] = {\n",
    "        \"requires_attention\": sections[\"executive_summary\"][\"requires_attention\"],\n",
    "        \"recommended_actions\": (\n",
    "            [\n",
    "                \"Immediate legal review required\",\n",
    "                \"Renegotiate escalated clauses\",\n",
    "                \"Obtain senior management approval\",\n",
    "            ]\n",
    "            if sections[\"executive_summary\"][\"requires_attention\"]\n",
    "            else [\n",
    "                \"Proceed with standard approval process\",\n",
    "            ]\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return sections\n",
    "\n",
    "\n",
    "report_sections = map_combined_json_to_sections(combined_data)\n",
    "\n",
    "print(\"Mapped data to report sections:\")\n",
    "for section_name in report_sections:\n",
    "    print(f\"   • {section_name.replace('_', ' ').title()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73210e0",
   "metadata": {},
   "source": [
    "#### 3. Generating Report Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1a73b752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Report Content\n",
      "Content generation function updated for combined refined-agent mapping\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating Report Content\")\n",
    "\n",
    "from typing import Dict\n",
    "\n",
    "def generate_section_content(section_name: str, section_data: Dict) -> str:\n",
    "    content = []\n",
    "\n",
    "    if section_name == \"executive_summary\":\n",
    "        content.append(\"EXECUTIVE SUMMARY\")\n",
    "        content.append(\"=\" * 80)\n",
    "        content.append(f\"\\nAnalysis Timestamp: {section_data['analysis_timestamp']}\")\n",
    "        content.append(f\"Total Agents Analyzed: {section_data['total_agents']}\")\n",
    "        content.append(\n",
    "            f\"Agents with Escalations: {section_data['agents_with_escalations']}\"\n",
    "        )\n",
    "        content.append(\n",
    "            f\"Total Escalation Reasons: {section_data['total_escalation_reasons']}\"\n",
    "        )\n",
    "        content.append(\n",
    "            f\"Highest Risk Domain: {section_data['highest_risk_domain'].capitalize()}\"\n",
    "        )\n",
    "\n",
    "        if section_data[\"requires_attention\"]:\n",
    "            content.append(\"\\nSTATUS: REQUIRES IMMEDIATE ATTENTION\")\n",
    "        else:\n",
    "            content.append(\"\\nSTATUS: No immediate escalation required\")\n",
    "\n",
    "    elif section_name.endswith(\"_analysis\"):\n",
    "        agent_name = section_data[\"agent_name\"].upper()\n",
    "\n",
    "        content.append(f\"\\n{agent_name} ANALYSIS\")\n",
    "        content.append(\"=\" * 80)\n",
    "\n",
    "        content.append(\n",
    "            f\"\\nFinal Risk Level: {section_data['final_risk'].upper()}\"\n",
    "        )\n",
    "        content.append(\n",
    "            f\"Final Confidence: {section_data['final_confidence']:.0%}\"\n",
    "        )\n",
    "        content.append(\n",
    "            f\"Escalation Detected: {'YES' if section_data['has_escalation'] else 'NO'}\"\n",
    "        )\n",
    "\n",
    "        if section_data[\"has_escalation\"]:\n",
    "            content.append(\n",
    "                f\"\\nEscalation Reasons ({section_data['num_escalation_reasons']}):\"\n",
    "            )\n",
    "            for i, reason in enumerate(\n",
    "                section_data[\"escalation_reasons\"], 1\n",
    "            ):\n",
    "                content.append(f\"  {i}. {reason}\")\n",
    "        else:\n",
    "            content.append(\"\\nNo escalation reasons recorded.\")\n",
    "\n",
    "    elif section_name == \"risk_escalations\":\n",
    "        content.append(\"\\nRISK ESCALATIONS\")\n",
    "        content.append(\"=\" * 80)\n",
    "\n",
    "        content.append(\n",
    "            f\"\\nTotal Agents Escalated: {section_data['total_agents_escalated']}\"\n",
    "        )\n",
    "        content.append(\n",
    "            f\"Total Escalation Reasons: {section_data['total_escalation_reasons']}\"\n",
    "        )\n",
    "\n",
    "        if section_data[\"details\"]:\n",
    "            content.append(\"\\nEscalation Details:\")\n",
    "            for detail in section_data[\"details\"]:\n",
    "                content.append(\n",
    "                    f\"\\nAgent: {detail['agent'].upper()} \"\n",
    "                    f\"(Risk: {detail['risk_level'].upper()})\"\n",
    "                )\n",
    "                content.append(\n",
    "                    f\"Reasons ({detail['count']}):\"\n",
    "                )\n",
    "                for reason in detail[\"escalation_reasons\"]:\n",
    "                    content.append(f\"  - {reason}\")\n",
    "        else:\n",
    "            content.append(\"\\nNo escalations recorded across agents.\")\n",
    "\n",
    "    elif section_name == \"conclusion\":\n",
    "        content.append(\"\\nCONCLUSION & RECOMMENDATIONS\")\n",
    "        content.append(\"=\" * 80)\n",
    "\n",
    "        if section_data[\"requires_attention\"]:\n",
    "            content.append(\n",
    "                \"\\nThis contract requires remediation before approval.\"\n",
    "            )\n",
    "        else:\n",
    "            content.append(\n",
    "                \"\\nThis contract may proceed under standard approval.\"\n",
    "            )\n",
    "\n",
    "        content.append(\"\\nRecommended Actions:\")\n",
    "        for i, action in enumerate(\n",
    "            section_data[\"recommended_actions\"], 1\n",
    "        ):\n",
    "            content.append(f\"  {i}. {action}\")\n",
    "\n",
    "    return \"\\n\".join(content)\n",
    "\n",
    "print(\"Content generation function updated for combined refined-agent mapping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275cf364",
   "metadata": {},
   "source": [
    "#### 4. Previewing Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2ab30a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Previewing Executive Summary\n",
      "EXECUTIVE SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Analysis Timestamp: 2026-01-16T21:18:20.937559\n",
      "Total Agents Analyzed: 4\n",
      "Agents with Escalations: 4\n",
      "Total Escalation Reasons: 15\n",
      "Highest Risk Domain: Finance\n",
      "\n",
      "STATUS: REQUIRES IMMEDIATE ATTENTION\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPreviewing Executive Summary\")\n",
    "\n",
    "if \"executive_summary\" not in report_sections:\n",
    "    raise KeyError(\"Executive summary section not found in mapped report sections\")\n",
    "\n",
    "exec_summary_text = generate_section_content(\n",
    "    section_name=\"executive_summary\",\n",
    "    section_data=report_sections[\"executive_summary\"]\n",
    ")\n",
    "\n",
    "print(exec_summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "159fc379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating complete report\n",
      "Full report saved: ../Data/Results/Milestone3\\contract_analysis_report_new.txt\n",
      "Report length: 4155 characters\n",
      "Sections generated: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating complete report\")\n",
    "\n",
    "full_report = []\n",
    "\n",
    "SECTION_ORDER = [\n",
    "    \"executive_summary\",\n",
    "    \"legal_analysis\",\n",
    "    \"compliance_analysis\",\n",
    "    \"finance_analysis\",\n",
    "    \"operations_analysis\",\n",
    "    \"risk_escalations\",\n",
    "    \"conclusion\",\n",
    "]\n",
    "\n",
    "for section_name in SECTION_ORDER:\n",
    "    if section_name not in report_sections:\n",
    "        print(f\"   Skipping missing section: {section_name}\")\n",
    "        continue\n",
    "\n",
    "    section_text = generate_section_content(\n",
    "        section_name,\n",
    "        report_sections[section_name]\n",
    "    )\n",
    "\n",
    "    full_report.append(section_text)\n",
    "    full_report.append(\"\\n\\n\")\n",
    "\n",
    "report_text = \"\\n\".join(full_report)\n",
    "\n",
    "report_file = os.path.join(\n",
    "    MILESTONE3_OUTPUT,\n",
    "    \"contract_analysis_report_new.txt\"\n",
    ")\n",
    "\n",
    "with open(report_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "print(f\"Full report saved: {report_file}\")\n",
    "print(f\"Report length: {len(report_text)} characters\")\n",
    "print(f\"Sections generated: {len(full_report) // 2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
