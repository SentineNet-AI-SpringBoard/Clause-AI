{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9242eb7",
   "metadata": {},
   "source": [
    "# Milestone 3 — Parallel Agents + Persistent Agent Memory (Pinecone)\n",
    "\n",
    "\n",
    "\n",
    "This notebook implements Milestone 3:\n",
    "\n",
    "- Run **sequential vs parallel** (async) agent pipelines and compare runtime.\n",
    "\n",
    "- **Persist agent outputs** into Pinecone as “agent memory” vectors with metadata (`contract_id`, `agent_type`, `timestamp`).\n",
    "\n",
    "- **Recall stored memory** later (filter by `contract_id` and optionally `agent_type`) to answer follow-ups **without rerunning** the agents.\n",
    "\n",
    "\n",
    "\n",
    "Prereqs:\n",
    "\n",
    "- Pinecone index already populated with contract chunk vectors (Milestone 2).\n",
    "\n",
    "- Environment variable `PINECONE_API_KEY` set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33782173",
   "metadata": {},
   "source": [
    "## 1) Project / Environment Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c984620",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:54:46,092 | INFO | ROOT=C:\\Users\\LENOVO\\OneDrive\\Dokumen\\legal contracts eda\\milestone3\n",
      "2026-01-20 07:54:46,092 | INFO | ARTIFACTS_DIR=C:\\Users\\LENOVO\\OneDrive\\Dokumen\\legal contracts eda\\milestone3\\artifacts (exists=False)\n",
      "2026-01-20 07:54:46,105 | INFO | Loaded .env keys: []\n",
      "2026-01-20 07:54:46,106 | INFO | Env guards: TRANSFORMERS_NO_TF=1 USE_TF=0 TRANSFORMERS_NO_FLAX=1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "ROOT = Path.cwd().resolve()\n",
    "ARTIFACTS_DIR = ROOT / \"artifacts\"\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "\n",
    "# Avoid optional TensorFlow/JAX imports (common Windows DLL issues, and not needed here)\n",
    "os.environ.setdefault(\"TRANSFORMERS_NO_TF\", \"1\")\n",
    "os.environ.setdefault(\"USE_TF\", \"0\")\n",
    "os.environ.setdefault(\"TRANSFORMERS_NO_FLAX\", \"1\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(\"milestone3\")\n",
    "\n",
    "def utc_now_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "def load_env_file(path: Path) -> Dict[str, str]:\n",
    "    \"\"\"Minimal .env loader (no extra deps).\n",
    "\n",
    "    - Skips blanks and comments\n",
    "    - Supports KEY=VALUE\n",
    "    - Strips surrounding quotes\n",
    "    - Does NOT override already-set env vars\n",
    "    \"\"\"\n",
    "    loaded: Dict[str, str] = {}\n",
    "    if not path.exists():\n",
    "        return loaded\n",
    "\n",
    "    for raw_line in path.read_text(encoding=\"utf-8\").splitlines():\n",
    "        line = raw_line.strip()\n",
    "        if not line or line.startswith(\"#\"):\n",
    "            continue\n",
    "        if \"=\" not in line:\n",
    "            continue\n",
    "        key, value = line.split(\"=\", 1)\n",
    "        key = key.strip()\n",
    "        value = value.strip().strip('\"').strip(\"'\")\n",
    "        if not key:\n",
    "            continue\n",
    "        if os.getenv(key) is None:\n",
    "            os.environ[key] = value\n",
    "            loaded[key] = value\n",
    "    return loaded\n",
    "\n",
    "# Auto-load root .env if present\n",
    "env_loaded = load_env_file(ROOT / \".env\")\n",
    "\n",
    "logger.info(f\"ROOT={ROOT}\")\n",
    "logger.info(f\"ARTIFACTS_DIR={ARTIFACTS_DIR} (exists={ARTIFACTS_DIR.exists()})\")\n",
    "logger.info(f\"Loaded .env keys: {sorted(env_loaded.keys())}\")\n",
    "logger.info(\"Env guards: TRANSFORMERS_NO_TF=%s USE_TF=%s TRANSFORMERS_NO_FLAX=%s\", os.getenv(\"TRANSFORMERS_NO_TF\"), os.getenv(\"USE_TF\"), os.getenv(\"TRANSFORMERS_NO_FLAX\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edbca265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared agent list used across the notebook\n",
    "AGENT_TYPES = [\"legal_agent\", \"compliance_agent\", \"finance_agent\", \"operations_agent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a976547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\LENOVO\\anaconda3\\python.exe\n",
      "Before:\n",
      "- huggingface-hub: 0.36.0\n",
      "- transformers:    4.57.4\n",
      "- sentence-transformers: 5.2.0\n",
      "- tensorflow:      2.19.0\n",
      "- tensorflow-intel: 2.18.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.36.0)\n",
      "Requirement already satisfied: transformers>=4.40.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (4.57.4)\n",
      "Collecting transformers>=4.40.0\n",
      "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: sentence-transformers>=2.7.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (5.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers>=4.40.0) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers>=4.40.0) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers>=4.40.0) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from transformers>=4.40.0) (0.5.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.7.0) (2.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.7.0) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.7.0) (1.13.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.7.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.7.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.7.0) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.7.0) (69.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.7.0) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.24.0) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.7.0) (2.1.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.24.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.24.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.24.0) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.24.0) (2025.11.12)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.7.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.7.0) (2.2.0)\n",
      "Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 3.7/12.0 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.6/12.0 MB 22.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 22.1 MB/s eta 0:00:00\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.57.4\n",
      "    Uninstalling transformers-4.57.4:\n",
      "      Successfully uninstalled transformers-4.57.4\n",
      "Successfully installed transformers-4.57.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "After:\n",
      "- huggingface-hub: 0.36.0\n",
      "- transformers:    4.57.6\n",
      "- sentence-transformers: 5.2.0\n",
      "- tensorflow:      2.19.0\n",
      "- tensorflow-intel: 2.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Dependency repair for this notebook kernel (run once if imports fail)\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import importlib.metadata as _md  # py3.8+\n",
    "except Exception:  # pragma: no cover\n",
    "    _md = None\n",
    "\n",
    "def _v(pkg: str) -> str:\n",
    "    if _md is None:\n",
    "        return \"(unknown)\"\n",
    "    try:\n",
    "        return _md.version(pkg)\n",
    "    except Exception:\n",
    "        return \"(not installed)\"\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Before:\")\n",
    "print(\"- huggingface-hub:\", _v(\"huggingface-hub\"))\n",
    "print(\"- transformers:   \", _v(\"transformers\"))\n",
    "print(\"- sentence-transformers:\", _v(\"sentence-transformers\"))\n",
    "print(\"- tensorflow:     \", _v(\"tensorflow\"))\n",
    "print(\"- tensorflow-intel:\", _v(\"tensorflow-intel\"))\n",
    "\n",
    "# IMPORTANT: %pip installs into the currently-running Jupyter kernel environment.\n",
    "# If you still see the same import error after this, restart the kernel and rerun from Cell 3.\n",
    "%pip install -U \"huggingface-hub>=0.24.0,<1.0\" \"transformers>=4.40.0\" \"sentence-transformers>=2.7.0\"\n",
    "\n",
    "# If you see: \"Failed to load the native TensorFlow runtime\" on Windows, TensorFlow is installed but broken.\n",
    "# Sentence-transformers does not require TensorFlow for embeddings, so removing it is safe for this notebook:\n",
    "# %pip uninstall -y tensorflow tensorflow-intel\n",
    "\n",
    "print(\"\\nAfter:\")\n",
    "print(\"- huggingface-hub:\", _v(\"huggingface-hub\"))\n",
    "print(\"- transformers:   \", _v(\"transformers\"))\n",
    "print(\"- sentence-transformers:\", _v(\"sentence-transformers\"))\n",
    "print(\"- tensorflow:     \", _v(\"tensorflow\"))\n",
    "print(\"- tensorflow-intel:\", _v(\"tensorflow-intel\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae23b0b",
   "metadata": {},
   "source": [
    "## 2) Connect to Pinecone + Load Embeddings Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11a75061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:55:08,162 | INFO | Connected to Pinecone index 'cuad-index' via pinecone.Pinecone\n",
      "2026-01-20 07:55:19,023 | INFO | Loading embedding model: all-MiniLM-L6-v2\n",
      "2026-01-20 07:55:19,026 | INFO | Use pytorch device_name: cpu\n",
      "2026-01-20 07:55:19,026 | INFO | Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# Pinecone connection (supports both newer and older SDK styles)\n",
    "\n",
    "from getpass import getpass\n",
    "\n",
    "# Ensure optional TensorFlow/JAX stacks are not used (avoids Windows DLL issues)\n",
    "os.environ.setdefault(\"TRANSFORMERS_NO_TF\", \"1\")\n",
    "os.environ.setdefault(\"USE_TF\", \"0\")\n",
    "os.environ.setdefault(\"TRANSFORMERS_NO_FLAX\", \"1\")\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = os.getenv(\"PINECONE_INDEX\", \"cuad-index\")\n",
    "PINECONE_ENV = os.getenv(\"PINECONE_ENV\")\n",
    "\n",
    "# If the env var isn't set, allow interactive entry (common in notebooks)\n",
    "if not PINECONE_API_KEY:\n",
    "    PINECONE_API_KEY = getpass(\"Enter PINECONE_API_KEY (input hidden): \")\n",
    "    PINECONE_API_KEY = (PINECONE_API_KEY or \"\").strip()\n",
    "    if not PINECONE_API_KEY:\n",
    "        raise RuntimeError(\n",
    "            \"Missing PINECONE_API_KEY. Set it as an environment variable, or re-run and enter it when prompted.\"\n",
    "        )\n",
    "    os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "\n",
    "index = None\n",
    "try:\n",
    "    # Newer SDK\n",
    "    from pinecone import Pinecone\n",
    "\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    index = pc.Index(INDEX_NAME)\n",
    "    logger.info(f\"Connected to Pinecone index '{INDEX_NAME}' via pinecone.Pinecone\")\n",
    "except Exception as e_new:\n",
    "    try:\n",
    "        # Older SDK\n",
    "        import pinecone\n",
    "\n",
    "        if not PINECONE_ENV:\n",
    "            raise RuntimeError(\n",
    "                \"Using legacy pinecone SDK requires PINECONE_ENV. \"\n",
    "                \"Set env var PINECONE_ENV (e.g., 'us-east1-gcp'), then re-run.\"\n",
    "            )\n",
    "        pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "        index = pinecone.Index(INDEX_NAME)\n",
    "        logger.info(f\"Connected to Pinecone index '{INDEX_NAME}' via pinecone.init\")\n",
    "    except Exception as e_old:\n",
    "        raise RuntimeError(f\"Failed to connect to Pinecone: new={e_new} old={e_old}\")\n",
    "\n",
    "# Embedding model\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except Exception as e:\n",
    "    msg = str(e)\n",
    "    if \"Failed to load the native TensorFlow runtime\" in msg or \"_pywrap_tensorflow_internal\" in msg:\n",
    "        raise RuntimeError(\n",
    "            \"TensorFlow is installed but failing to load native DLLs on this machine.\\n\\n\"\n",
    "            \"Sentence-transformers does not require TensorFlow for embeddings. Fix by removing TensorFlow from this env:\\n\"\n",
    "            \"  pip uninstall -y tensorflow tensorflow-intel\\n\\n\"\n",
    "            \"Then restart the kernel and rerun from Section 1.\"\n",
    "        ) from e\n",
    "    if \"huggingface-hub\" in msg and \"Try:\" in msg:\n",
    "        raise RuntimeError(\n",
    "            \"Dependency mismatch while importing sentence-transformers.\\n\\n\"\n",
    "            \"Your environment has an older huggingface-hub that is incompatible with transformers.\\n\\n\"\n",
    "            \"Fix (pip):\\n\"\n",
    "            \"  pip install -U huggingface-hub transformers sentence-transformers\\n\\n\"\n",
    "            \"Fix (conda-forge):\\n\"\n",
    "            \"  conda install -c conda-forge huggingface-hub transformers sentence-transformers\\n\\n\"\n",
    "            \"Then restart the kernel and rerun from Section 1.\"\n",
    "        ) from e\n",
    "    raise RuntimeError(\n",
    "        \"Failed to import sentence-transformers.\\n\\n\"\n",
    "        \"Try:\\n\"\n",
    "        \"  pip install -U sentence-transformers transformers huggingface-hub\\n\\n\"\n",
    "        \"Then restart the kernel and rerun from Section 1.\\n\\n\"\n",
    "        f\"Original error: {type(e).__name__}: {e}\"\n",
    "    ) from e\n",
    "\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\", \"all-MiniLM-L6-v2\")\n",
    "CACHE_DIR = ROOT / \"models_cache\" / \"hub\"\n",
    "logger.info(f\"Loading embedding model: {EMBEDDING_MODEL}\")\n",
    "model = SentenceTransformer(EMBEDDING_MODEL, cache_folder=str(CACHE_DIR))\n",
    "\n",
    "def embed_query(text: str) -> List[float]:\n",
    "    vec = model.encode([text], convert_to_numpy=True)[0]\n",
    "    return vec.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47aa598",
   "metadata": {},
   "source": [
    "## 3) Agent Pipelines (Retrieval-First) + Timing (Sequential vs Parallel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a19e879",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_TYPES = [\"legal_agent\", \"compliance_agent\", \"finance_agent\", \"operations_agent\"]\n",
    "\n",
    "\n",
    "\n",
    "AGENT_QUERIES: Dict[str, List[str]] = {\n",
    "\n",
    "    \"legal_agent\": [\n",
    "\n",
    "        \"What are the termination clauses and conditions?\",\n",
    "\n",
    "        \"What happens in case of breach of contract?\",\n",
    "\n",
    "        \"What are the confidentiality and non-disclosure obligations?\",\n",
    "\n",
    "        \"What are the indemnification and hold harmless obligations?\",\n",
    "\n",
    "    ],\n",
    "\n",
    "    \"compliance_agent\": [\n",
    "\n",
    "        \"What are the data protection and privacy obligations?\",\n",
    "\n",
    "        \"What regulatory requirements must be followed?\",\n",
    "\n",
    "        \"What are the audit and reporting requirements?\",\n",
    "\n",
    "        \"What are the data retention and deletion obligations?\",\n",
    "\n",
    "        \"What are the breach notification and incident reporting requirements?\",\n",
    "\n",
    "        \"What security audit or certification requirements exist (SOC2/ISO/HIPAA)?\",\n",
    "\n",
    "    ],\n",
    "\n",
    "    \"finance_agent\": [\n",
    "\n",
    "        \"What are the payment terms and conditions?\",\n",
    "\n",
    "        \"What are the fees, invoices, and billing requirements?\",\n",
    "\n",
    "        \"What are the penalties and late fees for non-payment?\",\n",
    "\n",
    "        \"What are the interest charges or interest rate for late payment?\",\n",
    "\n",
    "        \"What is the financial liability and indemnification?\",\n",
    "\n",
    "    ],\n",
    "\n",
    "    \"operations_agent\": [\n",
    "\n",
    "        \"What are the deliverables and project outputs?\",\n",
    "\n",
    "        \"What are the timelines and milestones for delivery?\",\n",
    "\n",
    "        \"What are the service level agreements (SLAs)?\",\n",
    "\n",
    "        \"What are the performance standards and obligations?\",\n",
    "\n",
    "        \"What are the operational requirements and responsibilities?\",\n",
    "\n",
    "        \"What are the uptime commitments, uptime guarantees, and service credits?\",\n",
    "\n",
    "    ],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pinecone_query(\n",
    "\n",
    "    *,\n",
    "\n",
    "    query: str,\n",
    "\n",
    "    top_k: int = 5,\n",
    "\n",
    "    namespace: Optional[str] = None,\n",
    "\n",
    "    metadata_filter: Optional[Dict[str, Any]] = None,\n",
    "\n",
    ") -> Any:\n",
    "\n",
    "    qvec = embed_query(query)\n",
    "\n",
    "    kwargs: Dict[str, Any] = {\n",
    "\n",
    "        \"vector\": qvec,\n",
    "\n",
    "        \"top_k\": top_k,\n",
    "\n",
    "        \"include_metadata\": True,\n",
    "\n",
    "    }\n",
    "\n",
    "    if namespace is not None:\n",
    "\n",
    "        kwargs[\"namespace\"] = namespace\n",
    "\n",
    "    if metadata_filter is not None:\n",
    "\n",
    "        kwargs[\"filter\"] = metadata_filter\n",
    "\n",
    "    return index.query(**kwargs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _extract_matches(resp: Any) -> List[Dict[str, Any]]:\n",
    "\n",
    "    matches = getattr(resp, \"matches\", None)\n",
    "\n",
    "    if matches is None and isinstance(resp, dict):\n",
    "\n",
    "        matches = resp.get(\"matches\")\n",
    "\n",
    "    if not matches:\n",
    "\n",
    "        return []\n",
    "\n",
    "\n",
    "\n",
    "    out: List[Dict[str, Any]] = []\n",
    "\n",
    "    for m in matches:\n",
    "\n",
    "        md = getattr(m, \"metadata\", None)\n",
    "\n",
    "        score = getattr(m, \"score\", None)\n",
    "\n",
    "        if md is None and isinstance(m, dict):\n",
    "\n",
    "            md = m.get(\"metadata\")\n",
    "\n",
    "            score = m.get(\"score\")\n",
    "\n",
    "        out.append({\n",
    "\n",
    "            \"score\": float(score) if score is not None else None,\n",
    "\n",
    "            \"metadata\": md or {},\n",
    "\n",
    "        })\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _confidence_from_matches(matches: List[Dict[str, Any]]) -> Optional[float]:\n",
    "\n",
    "    scores = [m.get(\"score\") for m in matches if isinstance(m.get(\"score\"), (int, float))]\n",
    "\n",
    "    if not scores:\n",
    "\n",
    "        return None\n",
    "\n",
    "    return float(sum(scores) / len(scores))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_agent_pipeline(\n",
    "\n",
    "    *,\n",
    "\n",
    "    agent_type: str,\n",
    "\n",
    "    question: str,\n",
    "\n",
    "    contract_id: str,\n",
    "\n",
    "    top_k_per_query: int = 5,\n",
    "\n",
    "    chunks_namespace: Optional[str] = None,\n",
    "\n",
    "    filter_chunks_by_contract_id: bool = False,\n",
    "\n",
    ") -> Dict[str, Any]:\n",
    "\n",
    "    if agent_type not in AGENT_QUERIES:\n",
    "\n",
    "        raise ValueError(f\"Unknown agent_type: {agent_type}\")\n",
    "\n",
    "\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "\n",
    "\n",
    "    # Only enable this if your chunk vectors' metadata includes: {\"contract_id\": \"...\"}\n",
    "\n",
    "    md_filter = (\n",
    "\n",
    "        {\"contract_id\": {\"$eq\": contract_id}}\n",
    "\n",
    "        if filter_chunks_by_contract_id\n",
    "\n",
    "        else None\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    all_matches: List[Dict[str, Any]] = []\n",
    "\n",
    "    per_query: List[Dict[str, Any]] = []\n",
    "\n",
    "    for q in AGENT_QUERIES[agent_type]:\n",
    "\n",
    "        resp = pinecone_query(query=q, top_k=top_k_per_query, namespace=chunks_namespace, metadata_filter=md_filter)\n",
    "\n",
    "        matches = _extract_matches(resp)\n",
    "\n",
    "        per_query.append({\"query\": q, \"matches\": matches})\n",
    "\n",
    "        all_matches.extend(matches)\n",
    "\n",
    "\n",
    "\n",
    "    confidence = _confidence_from_matches(all_matches)\n",
    "\n",
    "    elapsed = time.perf_counter() - t0\n",
    "\n",
    "\n",
    "\n",
    "    return {\n",
    "\n",
    "        \"agent_type\": agent_type,\n",
    "\n",
    "        \"contract_id\": contract_id,\n",
    "\n",
    "        \"question\": question,\n",
    "\n",
    "        \"timestamp\": utc_now_iso(),\n",
    "\n",
    "        \"elapsed_seconds\": elapsed,\n",
    "\n",
    "        \"confidence\": confidence,\n",
    "\n",
    "        \"retrieval\": {\n",
    "\n",
    "            \"top_k_per_query\": top_k_per_query,\n",
    "\n",
    "            \"filter_chunks_by_contract_id\": filter_chunks_by_contract_id,\n",
    "\n",
    "            \"per_query\": per_query,\n",
    "\n",
    "        },\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_sequential(\n",
    "\n",
    "    *,\n",
    "\n",
    "    question: str,\n",
    "\n",
    "    contract_id: str,\n",
    "\n",
    "    agents: List[str] = AGENT_TYPES,\n",
    "\n",
    "    filter_chunks_by_contract_id: bool = False,\n",
    "\n",
    ") -> Tuple[Dict[str, Any], float]:\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    out: Dict[str, Any] = {}\n",
    "\n",
    "    for a in agents:\n",
    "\n",
    "        out[a] = run_agent_pipeline(\n",
    "\n",
    "            agent_type=a,\n",
    "\n",
    "            question=question,\n",
    "\n",
    "            contract_id=contract_id,\n",
    "\n",
    "            filter_chunks_by_contract_id=filter_chunks_by_contract_id,\n",
    "\n",
    "        )\n",
    "\n",
    "    return out, time.perf_counter() - t0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "async def run_parallel(\n",
    "\n",
    "    *,\n",
    "\n",
    "    question: str,\n",
    "\n",
    "    contract_id: str,\n",
    "\n",
    "    agents: List[str] = AGENT_TYPES,\n",
    "\n",
    "    filter_chunks_by_contract_id: bool = False,\n",
    "\n",
    ") -> Tuple[Dict[str, Any], float]:\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "\n",
    "    tasks = [\n",
    "\n",
    "        asyncio.to_thread(\n",
    "\n",
    "            run_agent_pipeline,\n",
    "\n",
    "            agent_type=a,\n",
    "\n",
    "            question=question,\n",
    "\n",
    "            contract_id=contract_id,\n",
    "\n",
    "            filter_chunks_by_contract_id=filter_chunks_by_contract_id,\n",
    "\n",
    "        )\n",
    "\n",
    "        for a in agents\n",
    "\n",
    "    ]\n",
    "\n",
    "    results = await asyncio.gather(*tasks)\n",
    "\n",
    "    out = {r[\"agent_type\"]: r for r in results}\n",
    "\n",
    "    return out, time.perf_counter() - t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c827a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc717a78ed42497db1f3c9394813ad68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58358c6ffb1644f4b4f728c819495fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6d081d669c4190b88deba5162840c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dedc69450c477ba345a51a32f2df26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4bfb504e97473c8ab19663c459b291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ff0813ec8a46f996a2f29dd3e04e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f00467aece94e36afa7adddbe7b7ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ff91191c33439da273ff72b4010274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6653fa43b37040bc872f93274fcb24ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cdc4a6f1cf942b389e9c9ce591ccac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4a00ca5e7541fb85d468b5a4d0d8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8c8f95ca584dda806fc02761125af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f952484cbee3456abef164b9a8046d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5546bc103a8403c8feac582ece7d467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67c5690e0db4fb09b1a5d467fe860cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee785740c09542fdafac9c83e29a90a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3277a4c582ae4892acf8f5e56ba735ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be80f78d3eb4790a44cc476dbb7c6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a878b693304127980f24638f3bcfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe895a07dae846eaab54b7206f9ec167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030d993987ca40beaff5bc35866dd6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971242b0821a41e0a717f0511bc7bd52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d6cfcaf4de4f508b36a0778dd0db62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d97faed4f8448690d085aabd0c91f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e6b7883988473883e92ad007624b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33fa6cab8344530812dbab977f9e8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5282308234fe438da16e19cffcd57e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f9d4a6fe58547a89a4b7832c3816d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b29ee9c5f1654d82a972843ca4de6721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659d37254cb74d10ad805805c977cfcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e765c53843446fa9b321c03cd60a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8684985afbf14241af93b08ac3e66515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a56cc6f5614a8287edd96b2d7b74d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a6d404b61d4c9bb5502ef703a3d026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558d8bb5f9be4826af8d593db5e8b9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b737011fdffc4dd49c37f146f27514b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf53e279310460cb3b3955315b0f291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd7cec0ffe34e419dd4e60bbea561da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ef32c7643b41d49007e987c74b267e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7192b05b9e964e1da37b6a289e6abb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f1cd442e2e4d6e9a6e8ae0152cbe5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e8e6552c614b4f96b1801354edfcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential seconds: 8.922\n",
      "Parallel seconds:   3.098\n",
      "\n",
      "Per-agent confidence (parallel):\n",
      "- legal_agent: 0.6607\n",
      "- compliance_agent: 0.5007\n",
      "- finance_agent: 0.5432\n",
      "- operations_agent: 0.4704\n"
     ]
    }
   ],
   "source": [
    "# Configure your run\n",
    "\n",
    "# - CONTRACT_ID can be any stable identifier you choose (used for memory persistence/recall).\n",
    "\n",
    "# - If your chunk vectors include contract_id in metadata, set FILTER_CHUNKS_BY_CONTRACT_ID=True.\n",
    "\n",
    "CONTRACT_ID = os.getenv(\"CONTRACT_ID\", \"demo_contract\")\n",
    "\n",
    "QUESTION = \"What are the payment terms, audit requirements, and uptime commitments?\"\n",
    "\n",
    "FILTER_CHUNKS_BY_CONTRACT_ID = False\n",
    "\n",
    "\n",
    "\n",
    "seq_out, seq_s = run_sequential(\n",
    "\n",
    "    question=QUESTION,\n",
    "\n",
    "    contract_id=CONTRACT_ID,\n",
    "\n",
    "    filter_chunks_by_contract_id=FILTER_CHUNKS_BY_CONTRACT_ID,\n",
    "\n",
    ")\n",
    "\n",
    "par_out, par_s = await run_parallel(\n",
    "\n",
    "    question=QUESTION,\n",
    "\n",
    "    contract_id=CONTRACT_ID,\n",
    "\n",
    "    filter_chunks_by_contract_id=FILTER_CHUNKS_BY_CONTRACT_ID,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Sequential seconds:\", round(seq_s, 3))\n",
    "\n",
    "print(\"Parallel seconds:  \", round(par_s, 3))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nPer-agent confidence (parallel):\")\n",
    "\n",
    "for a in AGENT_TYPES:\n",
    "\n",
    "    conf = par_out[a].get(\"confidence\")\n",
    "\n",
    "    print(f\"- {a}: {None if conf is None else round(conf, 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb88b18",
   "metadata": {},
   "source": [
    "## 4) Persist Agent Outputs as Vector Memory (Pinecone)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6434a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_MEMORY_NAMESPACE = \"agent_memory\"\n",
    "\n",
    "AGENT_MEMORY_RECORD_TYPE = \"agent_memory\"\n",
    "\n",
    "\n",
    "\n",
    "def safe_json_dumps(obj: Any, max_chars: int = 6000) -> str:\n",
    "    \"\"\"Serialize to JSON for storage in metadata.\n",
    "\n",
    "    Important: If we truncate, we keep the returned string as VALID JSON so it can be json.loads()'d later.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s = json.dumps(obj, ensure_ascii=False)\n",
    "    except Exception:\n",
    "        s = str(obj)\n",
    "    if len(s) <= max_chars:\n",
    "        return s\n",
    "    # Wrap a preview in a valid JSON object to avoid broken/partial JSON strings\n",
    "    preview = s[: max_chars - 200]\n",
    "    wrapper = {\"_truncated\": True, \"preview\": preview, \"chars\": len(s)}\n",
    "    return json.dumps(wrapper, ensure_ascii=False)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentMemoryRecord:\n",
    "    contract_id: str\n",
    "    agent_type: str\n",
    "    timestamp: str\n",
    "    question: str\n",
    "    output: Any\n",
    "\n",
    "    def to_text(self) -> str:\n",
    "        return (\n",
    "            f\"contract_id: {self.contract_id}\\n\"\n",
    "            f\"agent_type: {self.agent_type}\\n\"\n",
    "            f\"timestamp: {self.timestamp}\\n\"\n",
    "            f\"question: {self.question}\\n\\n\"\n",
    "            f\"output_json: {safe_json_dumps(self.output)}\\n\"\n",
    "        )\n",
    "\n",
    "    def to_metadata(self) -> Dict[str, Any]:\n",
    "        md: Dict[str, Any] = {\n",
    "            \"record_type\": AGENT_MEMORY_RECORD_TYPE,\n",
    "            \"contract_id\": self.contract_id,\n",
    "            \"agent_type\": self.agent_type,\n",
    "            # Alias to match common examples\n",
    "            \"agent\": self.agent_type,\n",
    "            \"timestamp\": self.timestamp,\n",
    "            \"question\": self.question[:1000],\n",
    "            \"output_json\": safe_json_dumps(self.output, 6000),\n",
    "        }\n",
    "\n",
    "        # If output contains a risk_level or confidence, store explicitly for filtering / reporting.\n",
    "        if isinstance(self.output, dict):\n",
    "            rl = self.output.get(\"risk_level\")\n",
    "            if isinstance(rl, str) and rl.strip():\n",
    "                md[\"risk_level\"] = rl.strip().lower()\n",
    "            conf = self.output.get(\"confidence\")\n",
    "            if isinstance(conf, (int, float)):\n",
    "                md[\"confidence\"] = float(conf)\n",
    "\n",
    "        return md\n",
    "\n",
    "\n",
    "def persist_agent_memory(*, records: List[AgentMemoryRecord], namespace: str = AGENT_MEMORY_NAMESPACE) -> List[str]:\n",
    "    vectors = []\n",
    "    ids: List[str] = []\n",
    "    for r in records:\n",
    "        text = r.to_text()\n",
    "        vec = embed_query(text)\n",
    "        vid = f\"{r.contract_id}:{r.agent_type}:{r.timestamp}:{uuid.uuid4().hex}\"\n",
    "        ids.append(vid)\n",
    "        vectors.append({\"id\": vid, \"values\": vec, \"metadata\": r.to_metadata()})\n",
    "\n",
    "    index.upsert(vectors=vectors, namespace=namespace)\n",
    "    return ids\n",
    "\n",
    "\n",
    "def query_agent_memory(*, query: str, contract_id: str, agent_type: Optional[str] = None, top_k: int = 5, namespace: str = AGENT_MEMORY_NAMESPACE) -> Any:\n",
    "    filt: Dict[str, Any] = {\n",
    "        \"record_type\": {\"$eq\": AGENT_MEMORY_RECORD_TYPE},\n",
    "        \"contract_id\": {\"$eq\": contract_id},\n",
    "    }\n",
    "    if agent_type:\n",
    "        filt[\"agent_type\"] = {\"$eq\": agent_type}\n",
    "\n",
    "    return index.query(\n",
    "        vector=embed_query(query),\n",
    "        top_k=top_k,\n",
    "        include_metadata=True,\n",
    "        namespace=namespace,\n",
    "        filter=filt,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4b725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3711b9949aca4bb29eef16104cddec2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8437bca6a9c4cc3b5eef9a0f83fac57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9f0a4dc71749a48f0e4a78f079be5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dfceaf77e47417680c8e55e5554bc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted 4 agent-memory vectors into namespace 'agent_memory'.\n",
      "Example IDs: ['demo_contract:legal_agent:2026-01-20T02:25:38.086838+00:00:eff88a22803a48e8ac6708d724229eab', 'demo_contract:compliance_agent:2026-01-20T02:25:38.086838+00:00:a60e4967ec98472ea250772dd626d24f']\n"
     ]
    }
   ],
   "source": [
    "# Persist the PARALLEL outputs from Section 3\n",
    "\n",
    "records = [\n",
    "\n",
    "    AgentMemoryRecord(\n",
    "\n",
    "        contract_id=CONTRACT_ID,\n",
    "\n",
    "        agent_type=a,\n",
    "\n",
    "        timestamp=utc_now_iso(),\n",
    "\n",
    "        question=QUESTION,\n",
    "\n",
    "        output=par_out[a],\n",
    "\n",
    "    )\n",
    "\n",
    "    for a in AGENT_TYPES\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "ids = persist_agent_memory(records=records)\n",
    "\n",
    "print(f\"Upserted {len(ids)} agent-memory vectors into namespace '{AGENT_MEMORY_NAMESPACE}'.\")\n",
    "\n",
    "print(\"Example IDs:\", ids[:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4d04b0",
   "metadata": {},
   "source": [
    "## 5) Recall Stored Agent Memory (No Rerun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb5c5fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349fcd88ef224f94a1088c139e86ece8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9e35087cfb40d98a00dac476b1828d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations memory matches:\n",
      "- score: 0.300049812\n",
      "  ts: 2026-01-08T13:29:46.417164+00:00\n",
      "  question: What are the payment terms, audit requirements, and uptime commitments?\n",
      "- score: 0.287986785\n",
      "  ts: 2026-01-09T13:31:38.825623+00:00\n",
      "  question: What are the payment terms, audit requirements, and uptime commitments?\n",
      "- score: 0.25385\n",
      "  ts: 2026-01-13T12:48:08.557038+00:00\n",
      "  question: What are the payment terms, audit requirements, and uptime commitments?\n",
      "\n",
      "Finance memory matches:\n",
      "- score: 0.208692566\n",
      "  ts: 2026-01-08T13:29:46.417164+00:00\n",
      "  question: What are the payment terms, audit requirements, and uptime commitments?\n",
      "- score: 0.205164433\n",
      "  ts: 2026-01-09T13:31:38.825623+00:00\n",
      "  question: What are the payment terms, audit requirements, and uptime commitments?\n",
      "- score: 0.163004875\n",
      "  ts: 2026-01-13T12:48:08.557038+00:00\n",
      "  question: What are the payment terms, audit requirements, and uptime commitments?\n"
     ]
    }
   ],
   "source": [
    "# Recall examples (filtered by contract_id and optionally agent_type)\n",
    "\n",
    "recall_ops = query_agent_memory(\n",
    "\n",
    "    query=\"uptime commitments service credits\",\n",
    "\n",
    "    contract_id=CONTRACT_ID,\n",
    "\n",
    "    agent_type=\"operations_agent\",\n",
    "\n",
    "    top_k=3,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "recall_fin = query_agent_memory(\n",
    "\n",
    "    query=\"interest charges late payment\",\n",
    "\n",
    "    contract_id=CONTRACT_ID,\n",
    "\n",
    "    agent_type=\"finance_agent\",\n",
    "\n",
    "    top_k=3,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Operations memory matches:\")\n",
    "\n",
    "for m in getattr(recall_ops, \"matches\", [])[:3]:\n",
    "\n",
    "    print(\"- score:\", getattr(m, \"score\", None))\n",
    "\n",
    "    print(\"  ts:\", (getattr(m, \"metadata\", {}) or {}).get(\"timestamp\"))\n",
    "\n",
    "    print(\"  question:\", (getattr(m, \"metadata\", {}) or {}).get(\"question\"))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nFinance memory matches:\")\n",
    "\n",
    "for m in getattr(recall_fin, \"matches\", [])[:3]:\n",
    "\n",
    "    print(\"- score:\", getattr(m, \"score\", None))\n",
    "\n",
    "    print(\"  ts:\", (getattr(m, \"metadata\", {}) or {}).get(\"timestamp\"))\n",
    "\n",
    "    print(\"  question:\", (getattr(m, \"metadata\", {}) or {}).get(\"question\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bb6686",
   "metadata": {},
   "source": [
    "## 6) Cross-Agent Refinement (Memory → Shared Context → Refine → Persist)\n",
    "\n",
    "> Goal: enable one agent to use another agent’s stored output as context, refine risk assessment, and write back the refined result into Pinecone memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b39c613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1816a7013f743e9912bb052926c951c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e042476b49174692bc12cd2177f370d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "066827c588744af99cebbab61f582aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e47be0859c49598fc686fff2bd134c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "legal_agent risk: high\n",
      "compliance_agent risk: high\n",
      "finance_agent risk: high\n",
      "operations_agent risk: medium\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "# Fallback if earlier cells were not executed yet\n",
    "AGENTS_FOR_REFINEMENT = globals().get(\"AGENT_TYPES\") or [\n",
    "    \"legal_agent\",\n",
    "    \"compliance_agent\",\n",
    "    \"finance_agent\",\n",
    "    \"operations_agent\",\n",
    "]\n",
    "\n",
    "def _as_utc_aware(dt: datetime) -> datetime:\n",
    "    \"\"\"Normalize datetimes to timezone-aware UTC for safe comparisons.\"\"\"\n",
    "    if dt.tzinfo is None:\n",
    "        return dt.replace(tzinfo=timezone.utc)\n",
    "    return dt.astimezone(timezone.utc)\n",
    "\n",
    "def _parse_ts(ts: Optional[str]) -> datetime:\n",
    "    # Always return a timezone-aware UTC datetime to avoid naive/aware comparison errors.\n",
    "    if not ts:\n",
    "        return datetime.min.replace(tzinfo=timezone.utc)\n",
    "    try:\n",
    "        # Handles ISO 8601 like: 2026-01-08T12:34:56.789+00:00 or ...Z\n",
    "        dt = datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\"))\n",
    "        return _as_utc_aware(dt)\n",
    "    except Exception:\n",
    "        return datetime.min.replace(tzinfo=timezone.utc)\n",
    "\n",
    "def _matches(resp: Any) -> List[Any]:\n",
    "    if isinstance(resp, dict):\n",
    "        return resp.get(\"matches\") or []\n",
    "    return getattr(resp, \"matches\", []) or []\n",
    "\n",
    "def _md(match: Any) -> Dict[str, Any]:\n",
    "    if isinstance(match, dict):\n",
    "        return match.get(\"metadata\") or {}\n",
    "    return getattr(match, \"metadata\", {}) or {}\n",
    "\n",
    "def _infer_risk_from_text(text: str) -> Tuple[str, str]:\n",
    "    t = (text or \"\").lower()\n",
    "    # Very simple heuristic just for milestone demonstration\n",
    "    high_terms = [\"penalt\", \"late fee\", \"interest\", \"termination\", \"breach\", \"indemn\", \"liability\", \"service credit\"]\n",
    "    medium_terms = [\"audit\", \"confidential\", \"privacy\", \"retention\", \"notification\", \"sla\"]\n",
    "\n",
    "    if any(k in t for k in high_terms):\n",
    "        return \"high\", \"Contains high-impact financial/legal terms (heuristic).\"\n",
    "    if any(k in t for k in medium_terms):\n",
    "        return \"medium\", \"Contains standard compliance/operations terms (heuristic).\"\n",
    "    return \"medium\", \"Defaulted to medium (insufficient signal in stored output).\"\n",
    "\n",
    "def fetch_latest_agent_memory(*, contract_id: str, agent_type: str, top_k: int = 10) -> Optional[Dict[str, Any]]:\n",
    "    resp = query_agent_memory(query=f\"{agent_type} risk assessment\", contract_id=contract_id, agent_type=agent_type, top_k=top_k)\n",
    "    best = None\n",
    "    best_ts = datetime.min.replace(tzinfo=timezone.utc)\n",
    "    for m in _matches(resp):\n",
    "        md = _md(m)\n",
    "        ts = _parse_ts(md.get(\"timestamp\"))\n",
    "        if ts > best_ts:\n",
    "            best = md\n",
    "            best_ts = ts\n",
    "    return best\n",
    "\n",
    "# 1) Retrieve latest memory per agent and build shared_context\n",
    "latest_by_agent: Dict[str, Dict[str, Any]] = {}\n",
    "for agent_type in AGENTS_FOR_REFINEMENT:\n",
    "    md = fetch_latest_agent_memory(contract_id=CONTRACT_ID, agent_type=agent_type)\n",
    "    if md is None:\n",
    "        latest_by_agent[agent_type] = {\n",
    "            \"agent\": agent_type,\n",
    "            \"risk_level\": \"unknown\",\n",
    "            \"confidence\": None,\n",
    "            \"timestamp\": None,\n",
    "            \"output_json\": \"\",\n",
    "        }\n",
    "        continue\n",
    "\n",
    "    # Prefer explicit risk_level metadata, else infer from stored output_json text\n",
    "    output_json = md.get(\"output_json\") or \"\"\n",
    "    risk_level = md.get(\"risk_level\")\n",
    "    if not isinstance(risk_level, str) or not risk_level.strip():\n",
    "        risk_level, _ = _infer_risk_from_text(output_json)\n",
    "\n",
    "    # Best-effort confidence from memory metadata\n",
    "    conf = md.get(\"confidence\")\n",
    "    if not isinstance(conf, (int, float)):\n",
    "        conf = None\n",
    "\n",
    "    latest_by_agent[agent_type] = {\n",
    "        \"agent\": md.get(\"agent\") or md.get(\"agent_type\") or agent_type,\n",
    "        \"risk_level\": risk_level,\n",
    "        \"confidence\": float(conf) if isinstance(conf, (int, float)) else None,\n",
    "        \"timestamp\": md.get(\"timestamp\"),\n",
    "        \"output_json\": output_json,\n",
    "    }\n",
    "\n",
    "shared_context = \"\\n\".join([f\"{v['agent']} risk: {v['risk_level']}\" for v in latest_by_agent.values()])\n",
    "print(shared_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5f2a6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"agent_type\": \"compliance_agent\",\n",
      "  \"risk_level\": \"high\",\n",
      "  \"confidence\": 0.5006666596666667,\n",
      "  \"reason\": \"No escalation: finance risk not high (heuristic).\",\n",
      "  \"based_on\": {\n",
      "    \"shared_context\": \"legal_agent risk: high\\ncompliance_agent risk: high\\nfinance_agent risk: high\\noperations_agent risk: medium\",\n",
      "    \"finance_risk\": \"high\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 2) Let compliance agent read finance output and refine (risk escalation demo)\n",
    "finance = latest_by_agent.get(\"finance_agent\", {})\n",
    "compliance = latest_by_agent.get(\"compliance_agent\", {})\n",
    "\n",
    "finance_risk = (finance.get(\"risk_level\") or \"unknown\").lower()\n",
    "compliance_risk = (compliance.get(\"risk_level\") or \"unknown\").lower()\n",
    "\n",
    "# Best-effort confidence: inherit from latest compliance if available, else finance, else None\n",
    "def _as_float(x: Any) -> Optional[float]:\n",
    "    return float(x) if isinstance(x, (int, float)) else None\n",
    "\n",
    "inherited_confidence = (\n",
    "    _as_float(compliance.get(\"confidence\"))\n",
    "    or _as_float((compliance.get(\"output\") or {}).get(\"confidence\") if isinstance(compliance.get(\"output\"), dict) else None)\n",
    "    or _as_float(finance.get(\"confidence\"))\n",
    "    or _as_float((finance.get(\"output\") or {}).get(\"confidence\") if isinstance(finance.get(\"output\"), dict) else None)\n",
    "    or None\n",
    " )\n",
    "\n",
    "refined_risk = compliance_risk\n",
    "reason = \"No escalation: finance risk not high (heuristic).\"\n",
    "\n",
    "if finance_risk == \"high\" and compliance_risk in {\"low\", \"medium\", \"unknown\"}:\n",
    "    refined_risk = \"high\"\n",
    "    reason = \"Escalated to high because finance risk is high; combined exposure increases compliance risk.\"\n",
    "\n",
    "refined_compliance = {\n",
    "    \"agent_type\": \"compliance_agent\",\n",
    "    \"risk_level\": refined_risk,\n",
    "    \"confidence\": inherited_confidence,\n",
    "    \"reason\": reason,\n",
    "    \"based_on\": {\n",
    "        \"shared_context\": shared_context,\n",
    "        \"finance_risk\": finance_risk,\n",
    "    },\n",
    "}\n",
    "\n",
    "print(json.dumps(refined_compliance, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38406d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28006c60a74c4a10ae2c16f07f12b873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted refined compliance memory: demo_contract:compliance_agent:2026-01-20T02:25:40.936936+00:00:b19ae6dbbb064158b4f24ee21fbbf243\n"
     ]
    }
   ],
   "source": [
    "# 3) Update Compliance memory (persist refined assessment)\n",
    "refined_record = AgentMemoryRecord(\n",
    "    contract_id=CONTRACT_ID,\n",
    "    agent_type=\"compliance_agent\",\n",
    "    timestamp=utc_now_iso(),\n",
    "    question=\"Cross-agent refinement: compliance reads finance output and re-evaluates risk\",\n",
    "    output=refined_compliance,\n",
    ")\n",
    "\n",
    "refined_ids = persist_agent_memory(records=[refined_record])\n",
    "print(\"Upserted refined compliance memory:\", refined_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f0312",
   "metadata": {},
   "source": [
    "## 6B) Live Signal-Driven Agent Orchestration (Event → Triggers → Routing → Run → Persist)\n",
    "\n",
    "This section upgrades Milestone 3 from **static batch execution** to a **live, signal-driven orchestration** model.\n",
    "\n",
    "Key ideas:\n",
    "- A `LiveTriggerEvent` represents an incoming signal (new query, new chunk, memory upsert, confidence drop).\n",
    "- `evaluate_triggers(event)` decides *which agents should run* and *why* (explainable decisions).\n",
    "- `route_agents_live(event)` applies **memory-aware guardrails** (skip if a similar recent memory already exists), then re-runs only relevant agents and **persists new memory** (append-only, no overwrites).\n",
    "\n",
    "Backward-compatible: existing pipelines and memory persistence are reused; this layer only adds routing + trigger logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bda7156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "# ----------------------------\n",
    "# Live trigger schema\n",
    "# ----------------------------\n",
    "\n",
    "SUPPORTED_EVENT_TYPES = {\n",
    "    \"new_user_query\",\n",
    "    \"new_contract_chunk\",\n",
    "    \"memory_upserted\",\n",
    "    \"confidence_drop\",\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class LiveTriggerEvent:\n",
    "    event_type: str\n",
    "    contract_id: str\n",
    "    payload: Dict[str, Any]\n",
    "    timestamp: str = \"\"\n",
    "    source: str = \"notebook\"\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.event_type = (self.event_type or \"\").strip()\n",
    "        if self.event_type not in SUPPORTED_EVENT_TYPES:\n",
    "            raise ValueError(f\"Unsupported event_type: {self.event_type}. Supported: {sorted(SUPPORTED_EVENT_TYPES)}\")\n",
    "        if not self.timestamp:\n",
    "            # Reuse earlier helper if present; fallback to UTC now.\n",
    "            ts_fn = globals().get(\"utc_now_iso\")\n",
    "            self.timestamp = ts_fn() if callable(ts_fn) else datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "@dataclass\n",
    "class TriggerReason:\n",
    "    agent_type: str\n",
    "    trigger_type: str\n",
    "    triggering_signal: str\n",
    "    threshold: Optional[float]\n",
    "    value: Optional[float]\n",
    "    decision: str  # \"run\" | \"skip\"\n",
    "    notes: str = \"\"\n",
    "\n",
    "@dataclass\n",
    "class ControllerDecision:\n",
    "    agents_to_run: List[str]\n",
    "    reasons: List[TriggerReason]\n",
    "    no_evidence: bool = False\n",
    "    evidence_score: Optional[float] = None\n",
    "    user_message: str = \"\"\n",
    "\n",
    "# ----------------------------\n",
    "# Helper functions\n",
    "# ----------------------------\n",
    "\n",
    "def _now_utc() -> datetime:\n",
    "    return datetime.now(timezone.utc)\n",
    "\n",
    "def _as_utc_aware(dt: datetime) -> datetime:\n",
    "    if dt.tzinfo is None:\n",
    "        return dt.replace(tzinfo=timezone.utc)\n",
    "    return dt.astimezone(timezone.utc)\n",
    "\n",
    "def _parse_ts(ts: Optional[str]) -> datetime:\n",
    "    if not ts:\n",
    "        return datetime.min.replace(tzinfo=timezone.utc)\n",
    "    try:\n",
    "        return _as_utc_aware(datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\")))\n",
    "    except Exception:\n",
    "        return datetime.min.replace(tzinfo=timezone.utc)\n",
    "\n",
    "def _matches(resp: Any) -> List[Any]:\n",
    "    if isinstance(resp, dict):\n",
    "        return resp.get(\"matches\") or []\n",
    "    return getattr(resp, \"matches\", []) or []\n",
    "\n",
    "def _md(match: Any) -> Dict[str, Any]:\n",
    "    if isinstance(match, dict):\n",
    "        return match.get(\"metadata\") or {}\n",
    "    return getattr(match, \"metadata\", {}) or {}\n",
    "\n",
    "def _score(match: Any) -> Optional[float]:\n",
    "    if isinstance(match, dict):\n",
    "        s = match.get(\"score\")\n",
    "        return float(s) if isinstance(s, (int, float)) else None\n",
    "    s = getattr(match, \"score\", None)\n",
    "    return float(s) if isinstance(s, (int, float)) else None\n",
    "\n",
    "def _event_text(event: LiveTriggerEvent) -> str:\n",
    "    \"\"\"Extract the primary text signal from an event.\"\"\"\n",
    "    p = event.payload or {}\n",
    "    if event.event_type == \"new_user_query\":\n",
    "        return str(p.get(\"query\") or \"\").strip()\n",
    "    if event.event_type == \"new_contract_chunk\":\n",
    "        return str(p.get(\"chunk_text\") or p.get(\"text\") or \"\").strip()\n",
    "    if event.event_type == \"memory_upserted\":\n",
    "        # Usually a summary string or output_json preview; keep it short.\n",
    "        return str(p.get(\"summary\") or p.get(\"output_text\") or p.get(\"text\") or \"\").strip()\n",
    "    if event.event_type == \"confidence_drop\":\n",
    "        return str(p.get(\"details\") or p.get(\"text\") or \"\").strip()\n",
    "    return \"\"\n",
    "\n",
    "def infer_risk_from_text(text: str) -> str:\n",
    "    \"\"\"Lightweight risk inference for trigger decisions (heuristic).\"\"\"\n",
    "    t = (text or \"\").lower()\n",
    "    terms = globals().get(\"HIGH_RISK_TERMS\")\n",
    "    if not isinstance(terms, list) or not terms:\n",
    "        terms = [\"penalt\", \"late fee\", \"interest\", \"termination\", \"breach\", \"indemn\", \"liability\", \"service credit\", \"data breach\", \"uncapped\"]\n",
    "    if any(k in t for k in terms):\n",
    "        return \"high\"\n",
    "    return \"medium\"\n",
    "\n",
    "def _top_memory_similarity(*, query: str, contract_id: str, agent_type: str, top_k: int = 1) -> Tuple[Optional[float], Optional[Dict[str, Any]]]:\n",
    "    \"\"\"Return (top_score, top_metadata) for memory matches of a given agent.\"\"\"\n",
    "    if not query.strip():\n",
    "        return None, None\n",
    "    resp = query_agent_memory(query=query, contract_id=contract_id, agent_type=agent_type, top_k=top_k)\n",
    "    ms = _matches(resp)\n",
    "    if not ms:\n",
    "        return None, None\n",
    "    m0 = ms[0]\n",
    "    return _score(m0), _md(m0)\n",
    "\n",
    "def _latest_memory_meta(*, contract_id: str, agent_type: str, top_k: int = 10) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"Fetch newest memory record metadata for an agent (by timestamp).\"\"\"\n",
    "    resp = query_agent_memory(query=\"risk\", contract_id=contract_id, agent_type=agent_type, top_k=top_k)\n",
    "    best_md = None\n",
    "    best_ts = datetime.min.replace(tzinfo=timezone.utc)\n",
    "    for m in _matches(resp):\n",
    "        md = _md(m)\n",
    "        ts = _parse_ts(md.get(\"timestamp\"))\n",
    "        if ts > best_ts:\n",
    "            best_ts = ts\n",
    "            best_md = md\n",
    "    return best_md\n",
    "\n",
    "def _probe_chunk_evidence(*, text: str, contract_id: str, top_k: int = 3, chunks_namespace: Optional[str] = None, filter_chunks_by_contract_id: bool = False) -> Optional[float]:\n",
    "    \"\"\"Lightweight 'is this question answerable from this document?' probe.\n",
    "\n",
    "    We query the *chunk* index (not the memory index). If scores are very low (or no matches),\n",
    "    we treat it as 'not found in the provided document'.\n",
    "    \"\"\"\n",
    "    q = (text or \"\").strip()\n",
    "    if not q:\n",
    "        return None\n",
    "    md_filter = ({\"contract_id\": {\"$eq\": contract_id}} if filter_chunks_by_contract_id else None)\n",
    "    try:\n",
    "        resp = pinecone_query(query=q, top_k=top_k, namespace=chunks_namespace, metadata_filter=md_filter)\n",
    "        matches = _extract_matches(resp)\n",
    "    except Exception:\n",
    "        return None\n",
    "    scores = [m.get(\"score\") for m in matches if isinstance(m, dict) and isinstance(m.get(\"score\"), (int, float))]\n",
    "    return float(max(scores)) if scores else None\n",
    "\n",
    "# ----------------------------\n",
    "# Controller (Orchestrator)\n",
    "# ----------------------------\n",
    "\n",
    "class ControllerAgent:\n",
    "    \"\"\"Controller that decides which agents run based on live signals + memory state.\n",
    "\n",
    "    This replaces 'keyword routing' with an explainable decision layer that can:\n",
    "    - route agents based on semantic similarity to prior memory\n",
    "    - escalate on detected risk signals\n",
    "    - refresh low-confidence agents\n",
    "    - avoid unnecessary runs using memory-aware guardrails (done in route_agents_live)\n",
    "    - detect 'no evidence in document' queries early\n",
    "    \"\"\"\n",
    "\n",
    "    def decide(\n",
    "        self,\n",
    "        event: LiveTriggerEvent,\n",
    "        *,\n",
    "        similarity_route_threshold: float = 0.45,\n",
    "        risk_trigger_threshold: str = \"high\",\n",
    "        confidence_trigger_threshold: float = 0.60,\n",
    "        no_evidence_threshold: float = 0.25,\n",
    "        filter_chunks_by_contract_id: bool = False,\n",
    "        chunks_namespace: Optional[str] = None,\n",
    "    ) -> ControllerDecision:\n",
    "        text = _event_text(event)\n",
    "        reasons: List[TriggerReason] = []\n",
    "        selected = set()\n",
    "\n",
    "        # 0) Early 'not found in document' handling (only for user questions)\n",
    "        if event.event_type == \"new_user_query\" and text.strip():\n",
    "            ev = _probe_chunk_evidence(\n",
    "                text=text,\n",
    "                contract_id=event.contract_id,\n",
    "                top_k=3,\n",
    "                chunks_namespace=chunks_namespace,\n",
    "                filter_chunks_by_contract_id=filter_chunks_by_contract_id,\n",
    "            )\n",
    "            if ev is None or ev < no_evidence_threshold:\n",
    "                msg = (\n",
    "                    \"I couldn’t find relevant evidence in the provided contract/document for this question. \"\n",
    "                    \"Please upload/ingest the correct contract (or additional pages/annexes), or rephrase the question. \"\n",
    "                    \"If you still want, I can provide general guidance, but it won’t be grounded in your document.\"\n",
    "                )\n",
    "                return ControllerDecision(\n",
    "                    agents_to_run=[],\n",
    "                    reasons=[],\n",
    "                    no_evidence=True,\n",
    "                    evidence_score=ev,\n",
    "                    user_message=msg,\n",
    "                )\n",
    "\n",
    "        # 1) Semantic routing: query agent memory per agent_type and route the ones that match strongly\n",
    "        had_any_memory = False\n",
    "        for a in AGENT_TYPES:\n",
    "            score, _ = _top_memory_similarity(query=text, contract_id=event.contract_id, agent_type=a, top_k=1)\n",
    "            if score is not None:\n",
    "                had_any_memory = True\n",
    "            if score is not None and score >= similarity_route_threshold:\n",
    "                selected.add(a)\n",
    "                reasons.append(TriggerReason(\n",
    "                    agent_type=a,\n",
    "                    trigger_type=event.event_type,\n",
    "                    triggering_signal=f\"semantic_similarity(query→{a}_memory)\",\n",
    "                    threshold=similarity_route_threshold,\n",
    "                    value=score,\n",
    "                    decision=\"run\",\n",
    "                    notes=f\"Similarity >= {similarity_route_threshold}\",\n",
    "                ))\n",
    "\n",
    "        # Cold-start fallback: if there is no memory yet for this contract, run all agents once\n",
    "        if (not selected) and (not had_any_memory) and event.event_type in {\"new_user_query\", \"new_contract_chunk\"} and text.strip():\n",
    "            for a in AGENT_TYPES:\n",
    "                selected.add(a)\n",
    "                reasons.append(TriggerReason(\n",
    "                    agent_type=a,\n",
    "                    trigger_type=\"cold_start\",\n",
    "                    triggering_signal=\"no_existing_memory_for_contract\",\n",
    "                    threshold=None,\n",
    "                    value=None,\n",
    "                    decision=\"run\",\n",
    "                    notes=\"No agent memory found yet; running all agents for initial baseline.\",\n",
    "                ))\n",
    "\n",
    "        # 2) Risk-driven escalation on the incoming signal itself\n",
    "        inferred_risk = infer_risk_from_text(text)\n",
    "        if inferred_risk == risk_trigger_threshold:\n",
    "            # When risk looks high, re-run legal/compliance/finance at minimum (ops optional)\n",
    "            for a in [\"legal_agent\", \"compliance_agent\", \"finance_agent\"]:\n",
    "                if a in AGENT_TYPES:\n",
    "                    if a not in selected:\n",
    "                        selected.add(a)\n",
    "                    reasons.append(TriggerReason(\n",
    "                        agent_type=a,\n",
    "                        trigger_type=event.event_type,\n",
    "                        triggering_signal=\"inferred_risk(event_text)\",\n",
    "                        threshold=None,\n",
    "                        value=None,\n",
    "                        decision=\"run\",\n",
    "                        notes=f\"Inferred risk '{inferred_risk}'\",\n",
    "                    ))\n",
    "\n",
    "        # 3) Confidence-driven refresh: if latest memory confidence is low, re-run that agent\n",
    "        for a in AGENT_TYPES:\n",
    "            md = _latest_memory_meta(contract_id=event.contract_id, agent_type=a, top_k=10)\n",
    "            conf = None if md is None else md.get(\"confidence\")\n",
    "            if isinstance(conf, (int, float)) and float(conf) < confidence_trigger_threshold:\n",
    "                selected.add(a)\n",
    "                reasons.append(TriggerReason(\n",
    "                    agent_type=a,\n",
    "                    trigger_type=\"confidence_threshold\",\n",
    "                    triggering_signal=\"latest_memory.confidence\",\n",
    "                    threshold=confidence_trigger_threshold,\n",
    "                    value=float(conf),\n",
    "                    decision=\"run\",\n",
    "                    notes=\"Confidence below threshold\",\n",
    "                ))\n",
    "\n",
    "        # 4) Event-specific cascades (memory_upserted / confidence_drop)\n",
    "        if event.event_type == \"memory_upserted\":\n",
    "            up_agent = str((event.payload or {}).get(\"agent_type\") or \"\").strip()\n",
    "            up_risk = str((event.payload or {}).get(\"risk_level\") or \"\").strip().lower()\n",
    "            if up_agent == \"finance_agent\" and up_risk == \"high\" and \"compliance_agent\" in AGENT_TYPES:\n",
    "                selected.add(\"compliance_agent\")\n",
    "                reasons.append(TriggerReason(\n",
    "                    agent_type=\"compliance_agent\",\n",
    "                    trigger_type=\"memory_upserted\",\n",
    "                    triggering_signal=\"finance_high_risk_memory_upserted\",\n",
    "                    threshold=None,\n",
    "                    value=None,\n",
    "                    decision=\"run\",\n",
    "                    notes=\"Cross-agent cascade: finance high risk → refresh compliance\",\n",
    "                ))\n",
    "\n",
    "        if event.event_type == \"confidence_drop\":\n",
    "            agent = str((event.payload or {}).get(\"agent_type\") or \"\").strip()\n",
    "            dropped = (event.payload or {}).get(\"confidence\")\n",
    "            if agent in AGENT_TYPES and isinstance(dropped, (int, float)) and float(dropped) < confidence_trigger_threshold:\n",
    "                selected.add(agent)\n",
    "                reasons.append(TriggerReason(\n",
    "                    agent_type=agent,\n",
    "                    trigger_type=\"confidence_drop\",\n",
    "                    triggering_signal=\"event.confidence\",\n",
    "                    threshold=confidence_trigger_threshold,\n",
    "                    value=float(dropped),\n",
    "                    decision=\"run\",\n",
    "                    notes=\"Confidence drop event below threshold\",\n",
    "                ))\n",
    "\n",
    "        return ControllerDecision(agents_to_run=sorted(selected), reasons=reasons)\n",
    "\n",
    "# Backward-compatible helper (older code may still call evaluate_triggers directly).\n",
    "def evaluate_triggers(\n",
    "    event: LiveTriggerEvent,\n",
    "    *,\n",
    "    similarity_route_threshold: float = 0.45,\n",
    "    risk_trigger_threshold: str = \"high\",\n",
    "    confidence_trigger_threshold: float = 0.60,\n",
    "    no_evidence_threshold: float = 0.25,\n",
    "    filter_chunks_by_contract_id: bool = False,\n",
    "    chunks_namespace: Optional[str] = None,\n",
    ") -> Tuple[List[str], List[TriggerReason]]:\n",
    "    decision = ControllerAgent().decide(\n",
    "        event,\n",
    "        similarity_route_threshold=similarity_route_threshold,\n",
    "        risk_trigger_threshold=risk_trigger_threshold,\n",
    "        confidence_trigger_threshold=confidence_trigger_threshold,\n",
    "        no_evidence_threshold=no_evidence_threshold,\n",
    "        filter_chunks_by_contract_id=filter_chunks_by_contract_id,\n",
    "        chunks_namespace=chunks_namespace,\n",
    "    )\n",
    "    # If no_evidence is True, we intentionally return an empty run list; caller can inspect separately if needed.\n",
    "    return decision.agents_to_run, decision.reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6027397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Dynamic agent execution (minimal changes to existing pipeline)\n",
    "# ----------------------------\n",
    "\n",
    "def build_dynamic_queries(*, agent_type: str, user_text: str, max_queries: int = 4) -> List[str]:\n",
    "    \"\"\"Generate agent queries from the live input instead of relying on a static AGENT_QUERIES table.\n",
    "\n",
    "    This keeps backward compatibility: the underlying retrieval is unchanged (Pinecone query → matches).\n",
    "    \"\"\"\n",
    "    base = (user_text or \"\").strip()\n",
    "    if not base:\n",
    "        return []\n",
    "    a = (agent_type or \"\").strip()\n",
    "    # Small, agent-specific expansions (derived from the input)\n",
    "    expansions: List[str] = [base]\n",
    "    if a == \"finance_agent\":\n",
    "        expansions += [f\"payment terms {base}\", f\"fees invoices billing {base}\", f\"late fees interest {base}\"]\n",
    "    elif a == \"compliance_agent\":\n",
    "        expansions += [f\"privacy data protection {base}\", f\"audit reporting {base}\", f\"security incident breach notification {base}\"]\n",
    "    elif a == \"legal_agent\":\n",
    "        expansions += [f\"termination breach {base}\", f\"indemnification liability {base}\", f\"confidentiality NDA {base}\"]\n",
    "    elif a == \"operations_agent\":\n",
    "        expansions += [f\"SLA uptime service credits {base}\", f\"deliverables milestones {base}\", f\"performance standards {base}\"]\n",
    "    # Deduplicate while preserving order\n",
    "    out: List[str] = []\n",
    "    seen = set()\n",
    "    for q in expansions:\n",
    "        qn = \" \".join(str(q).split())\n",
    "        if not qn or qn in seen:\n",
    "            continue\n",
    "        seen.add(qn)\n",
    "        out.append(qn)\n",
    "        if len(out) >= max_queries:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def run_agent_pipeline_dynamic(\n",
    "    *,\n",
    "    agent_type: str,\n",
    "    user_text: str,\n",
    "    contract_id: str,\n",
    "    top_k_per_query: int = 5,\n",
    "    chunks_namespace: Optional[str] = None,\n",
    "    filter_chunks_by_contract_id: bool = False,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Live variant of the pipeline: uses dynamic queries derived from user_text.\n",
    "\n",
    "    Keeps the returned schema similar to run_agent_pipeline(), so downstream persistence/aggregation still works.\n",
    "    \"\"\"\n",
    "    queries = build_dynamic_queries(agent_type=agent_type, user_text=user_text, max_queries=4)\n",
    "    if not queries:\n",
    "        return {\n",
    "            \"agent_type\": agent_type,\n",
    "            \"contract_id\": contract_id,\n",
    "            \"question\": user_text,\n",
    "            \"timestamp\": utc_now_iso(),\n",
    "            \"elapsed_seconds\": 0.0,\n",
    "            \"confidence\": None,\n",
    "            \"retrieval\": {\"top_k_per_query\": top_k_per_query, \"filter_chunks_by_contract_id\": filter_chunks_by_contract_id, \"per_query\": []},\n",
    "            \"note\": \"No query text provided to dynamic pipeline.\",\n",
    "        }\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    md_filter = ({\"contract_id\": {\"$eq\": contract_id}} if filter_chunks_by_contract_id else None)\n",
    "    all_matches: List[Dict[str, Any]] = []\n",
    "    per_query: List[Dict[str, Any]] = []\n",
    "    for q in queries:\n",
    "        resp = pinecone_query(query=q, top_k=top_k_per_query, namespace=chunks_namespace, metadata_filter=md_filter)\n",
    "        matches = _extract_matches(resp)\n",
    "        per_query.append({\"query\": q, \"matches\": matches})\n",
    "        all_matches.extend(matches)\n",
    "    confidence = _confidence_from_matches(all_matches)\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    return {\n",
    "        \"agent_type\": agent_type,\n",
    "        \"contract_id\": contract_id,\n",
    "        \"question\": user_text,\n",
    "        \"timestamp\": utc_now_iso(),\n",
    "        \"elapsed_seconds\": elapsed,\n",
    "        \"confidence\": confidence,\n",
    "        \"retrieval\": {\n",
    "            \"top_k_per_query\": top_k_per_query,\n",
    "            \"filter_chunks_by_contract_id\": filter_chunks_by_contract_id,\n",
    "            \"per_query\": per_query,\n",
    "        },\n",
    "        \"_live\": True,\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# Memory-aware guardrails + live routing\n",
    "# ----------------------------\n",
    "\n",
    "def should_skip_due_to_recent_similar_memory(\n",
    "    *,\n",
    "    event_text: str,\n",
    "    contract_id: str,\n",
    "    agent_type: str,\n",
    "    similarity_skip_threshold: float = 0.85,\n",
    "    recent_window: timedelta = timedelta(hours=24),\n",
    ") -> Tuple[bool, Optional[float], Optional[str]]:\n",
    "    \"\"\"Return (skip, score, matched_timestamp).\"\"\"\n",
    "    score, md = _top_memory_similarity(query=event_text, contract_id=contract_id, agent_type=agent_type, top_k=1)\n",
    "    if score is None or md is None:\n",
    "        return False, score, None\n",
    "    if score < similarity_skip_threshold:\n",
    "        return False, score, md.get(\"timestamp\")\n",
    "    ts = _parse_ts(md.get(\"timestamp\"))\n",
    "    is_recent = (_now_utc() - ts) <= recent_window\n",
    "    return bool(is_recent), score, md.get(\"timestamp\")\n",
    "\n",
    "def route_agents_live(\n",
    "    event: LiveTriggerEvent,\n",
    "    *,\n",
    "    similarity_route_threshold: float = 0.45,\n",
    "    confidence_trigger_threshold: float = 0.60,\n",
    "    similarity_skip_threshold: float = 0.85,\n",
    "    recent_hours: int = 24,\n",
    "    top_k_per_query: int = 5,\n",
    "    filter_chunks_by_contract_id: bool = False,\n",
    "    chunks_namespace: Optional[str] = None,\n",
    "    no_evidence_threshold: float = 0.25,\n",
    "    controller: Optional[ControllerAgent] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Live orchestration entrypoint: controller decides → guardrails → run agents → persist new memory.\n",
    "\n",
    "    Key behavior change vs rule-based routing:\n",
    "    - A ControllerAgent decides which agents should run, based on live signals + memory state.\n",
    "    - If the user asks something that has no supporting evidence in the document (chunk index),\n",
    "      the system returns a safe 'not found' response and DOES NOT hallucinate.\n",
    "    \"\"\"\n",
    "    text = _event_text(event)\n",
    "    controller = controller or ControllerAgent()\n",
    "\n",
    "    decision = controller.decide(\n",
    "        event,\n",
    "        similarity_route_threshold=similarity_route_threshold,\n",
    "        confidence_trigger_threshold=confidence_trigger_threshold,\n",
    "        no_evidence_threshold=no_evidence_threshold,\n",
    "        filter_chunks_by_contract_id=filter_chunks_by_contract_id,\n",
    "        chunks_namespace=chunks_namespace,\n",
    "    )\n",
    "\n",
    "    # Early stop: question not found in the document / no strong evidence\n",
    "    if decision.no_evidence:\n",
    "        logger.info(\n",
    "            \"live_route no_evidence: contract_id=%s evidence_score=%s threshold=%s\",\n",
    "            event.contract_id, decision.evidence_score, no_evidence_threshold,\n",
    "        )\n",
    "        return {\n",
    "            \"event\": {\"event_type\": event.event_type, \"contract_id\": event.contract_id, \"timestamp\": event.timestamp, \"payload\": event.payload},\n",
    "            \"no_evidence\": True,\n",
    "            \"evidence_score\": decision.evidence_score,\n",
    "            \"threshold\": no_evidence_threshold,\n",
    "            \"user_message\": decision.user_message,\n",
    "            \"agents_selected\": [],\n",
    "            \"reasons\": [],\n",
    "            \"executed\": [],\n",
    "            \"skipped\": {},\n",
    "            \"persisted_ids\": [],\n",
    "            \"outputs\": {},\n",
    "        }\n",
    "\n",
    "    agents_to_run = decision.agents_to_run\n",
    "    reasons = decision.reasons\n",
    "\n",
    "    # Log explainability\n",
    "    for r in reasons:\n",
    "        logger.info(\n",
    "            \"live_route decision: agent=%s decision=%s trigger_type=%s signal=%s threshold=%s value=%s notes=%s\",\n",
    "            r.agent_type, r.decision, r.trigger_type, r.triggering_signal, r.threshold, r.value, r.notes,\n",
    "        )\n",
    "\n",
    "    recent_window = timedelta(hours=int(recent_hours))\n",
    "    executed: Dict[str, Any] = {}\n",
    "    skipped: Dict[str, Any] = {}\n",
    "    persist_ids: List[str] = []\n",
    "\n",
    "    for a in agents_to_run:\n",
    "        # Guardrail: do we already have a highly similar recent memory? If yes, skip execution.\n",
    "        skip, sim, sim_ts = should_skip_due_to_recent_similar_memory(\n",
    "            event_text=text,\n",
    "            contract_id=event.contract_id,\n",
    "            agent_type=a,\n",
    "            similarity_skip_threshold=similarity_skip_threshold,\n",
    "            recent_window=recent_window,\n",
    "        )\n",
    "        if skip:\n",
    "            skipped[a] = {\n",
    "                \"reason\": \"recent_similar_memory\",\n",
    "                \"similarity\": sim,\n",
    "                \"matched_timestamp\": sim_ts,\n",
    "                \"threshold\": similarity_skip_threshold,\n",
    "                \"recent_hours\": recent_hours,\n",
    "            }\n",
    "            logger.info(\"live_route skip: agent=%s similarity=%s ts=%s\", a, sim, sim_ts)\n",
    "            continue\n",
    "\n",
    "        # Run only the relevant agent using the dynamic pipeline (chunk retrieval)\n",
    "        out = run_agent_pipeline_dynamic(\n",
    "            agent_type=a,\n",
    "            user_text=text,\n",
    "            contract_id=event.contract_id,\n",
    "            top_k_per_query=top_k_per_query,\n",
    "            chunks_namespace=chunks_namespace,\n",
    "            filter_chunks_by_contract_id=filter_chunks_by_contract_id,\n",
    "        )\n",
    "        executed[a] = out\n",
    "\n",
    "        # Persist append-only memory (do not overwrite old ones)\n",
    "        rec = AgentMemoryRecord(\n",
    "            contract_id=event.contract_id,\n",
    "            agent_type=a,\n",
    "            timestamp=utc_now_iso(),\n",
    "            question=f\"LIVE:{event.event_type}: {text}\"[:1000],\n",
    "            output=out,\n",
    "        )\n",
    "        new_ids = persist_agent_memory(records=[rec])\n",
    "        persist_ids.extend(new_ids)\n",
    "        logger.info(\"live_route persisted: agent=%s id=%s\", a, new_ids[0] if new_ids else None)\n",
    "\n",
    "    return {\n",
    "        \"event\": {\"event_type\": event.event_type, \"contract_id\": event.contract_id, \"timestamp\": event.timestamp, \"payload\": event.payload},\n",
    "        \"no_evidence\": False,\n",
    "        \"agents_selected\": agents_to_run,\n",
    "        \"reasons\": [r.__dict__ for r in reasons],\n",
    "        \"executed\": list(executed.keys()),\n",
    "        \"skipped\": skipped,\n",
    "        \"persisted_ids\": persist_ids,\n",
    "        \"outputs\": executed,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3ef260f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa36d449b25f4cce9b7d33656b389422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1042674571c4251a1d45211d94c5e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ec5203daa7453a8f6ff6fbaf4436e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d0801805ab40418c10fa650aa629ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78faeca166c64c8fa5a1c27ae57f18e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1eacd483174de195d83263ad3b8c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e13c1eab9d417ab008dc0e8804d07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861c8d1ed8714fc48df2d3bf617bf7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1d0967f8e942eca4ea3e3d96156b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:55:44,199 | INFO | live_route decision: agent=legal_agent decision=run trigger_type=new_user_query signal=inferred_risk(event_text) threshold=None value=None notes=Inferred risk 'high'\n",
      "2026-01-20 07:55:44,199 | INFO | live_route decision: agent=compliance_agent decision=run trigger_type=new_user_query signal=inferred_risk(event_text) threshold=None value=None notes=Inferred risk 'high'\n",
      "2026-01-20 07:55:44,199 | INFO | live_route decision: agent=finance_agent decision=run trigger_type=new_user_query signal=inferred_risk(event_text) threshold=None value=None notes=Inferred risk 'high'\n",
      "2026-01-20 07:55:44,199 | INFO | live_route decision: agent=compliance_agent decision=run trigger_type=confidence_threshold signal=latest_memory.confidence threshold=0.6 value=0.5006666596666667 notes=Confidence below threshold\n",
      "2026-01-20 07:55:44,199 | INFO | live_route decision: agent=finance_agent decision=run trigger_type=confidence_threshold signal=latest_memory.confidence threshold=0.6 value=0.54319379216 notes=Confidence below threshold\n",
      "2026-01-20 07:55:44,199 | INFO | live_route decision: agent=operations_agent decision=run trigger_type=confidence_threshold signal=latest_memory.confidence threshold=0.6 value=0.47038306226666665 notes=Confidence below threshold\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37206c7b73e40f3b4f50d49b446c1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1069dca95394b50b762914eebdcec01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d40c275fa547f18405b1b9cbf96a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bfd02838014e7b9fdcb90236fe2166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af484a719525446181151e82b9ca36b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b72ad35d0ff4a3c9c4165ca3e749e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:55:46,095 | INFO | live_route persisted: agent=compliance_agent id=demo_contract:compliance_agent:2026-01-20T02:25:45.667943+00:00:34acdac730454d4b957897ebac652729\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53b933a45754032a7f57c66ea876b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be07963db614b5ca74eed8f833867db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbee607f0bc45acb338fae0e8aa457c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31b474e0dda49fdb4e484ba45527957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9a49674e3ae473bb34daa682c9e4202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3caba7c42f14869b951048b2bae47af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:55:48,065 | INFO | live_route persisted: agent=finance_agent id=demo_contract:finance_agent:2026-01-20T02:25:47.595730+00:00:cd2c44aef4744dcead12c345b4ae5be6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5fca4325d9417da8f8868ed0f79eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9a6c7363f24290953801e8e5758f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ba3537ee884342958922d04b951d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8760301f0041ae9e7a4b4d62a8d753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7ee10cabbe4ef3b73f8da8a925e749",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9060728cd64be0b40724b04668df1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:55:50,069 | INFO | live_route persisted: agent=legal_agent id=demo_contract:legal_agent:2026-01-20T02:25:49.578397+00:00:b6030339bdac4484819564772b6c682a\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad64576f5ace45d5b2a1bde053a0a453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caf639b850da45588c6c571a0bad0487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb394f36548d43589ea82aee53faa6c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8947eda63f403d877d4b7b919d3b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a63b8905c44cd594c1ef3fe0b192a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c9afb9c8264d78baf6b96a15949c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:55:51,999 | INFO | live_route persisted: agent=operations_agent id=demo_contract:operations_agent:2026-01-20T02:25:51.555922+00:00:6d2f671bce304c09859c9a1ae77a745a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live routing executed agents: ['compliance_agent', 'finance_agent', 'legal_agent', 'operations_agent']\n",
      "Live routing skipped agents: []\n",
      "Persisted memory ids (count): 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f6d0822ee54071ac45e5804e55b033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b95eb047d65423788b0db9fc03ca7d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2412f2d525b749e8bbb6cb0ba616b353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782cf385520043228164f1c850ebdd83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fa177593044108ab742ad071ba8b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79cf331ed63d49a5b4ea52ecb9cc7322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368145a2f17544f5930f0adcc310be76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6ae44f777341869b88eead8b6395e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:55:54,368 | INFO | live_route decision: agent=legal_agent decision=run trigger_type=new_contract_chunk signal=inferred_risk(event_text) threshold=None value=None notes=Inferred risk 'high'\n",
      "2026-01-20 07:55:54,368 | INFO | live_route decision: agent=compliance_agent decision=run trigger_type=new_contract_chunk signal=inferred_risk(event_text) threshold=None value=None notes=Inferred risk 'high'\n",
      "2026-01-20 07:55:54,368 | INFO | live_route decision: agent=finance_agent decision=run trigger_type=new_contract_chunk signal=inferred_risk(event_text) threshold=None value=None notes=Inferred risk 'high'\n",
      "2026-01-20 07:55:54,368 | INFO | live_route decision: agent=legal_agent decision=run trigger_type=confidence_threshold signal=latest_memory.confidence threshold=0.6 value=0.59799429235 notes=Confidence below threshold\n",
      "2026-01-20 07:55:54,368 | INFO | live_route decision: agent=compliance_agent decision=run trigger_type=confidence_threshold signal=latest_memory.confidence threshold=0.6 value=0.5407544333 notes=Confidence below threshold\n",
      "2026-01-20 07:55:54,368 | INFO | live_route decision: agent=finance_agent decision=run trigger_type=confidence_threshold signal=latest_memory.confidence threshold=0.6 value=0.5371839389499999 notes=Confidence below threshold\n",
      "2026-01-20 07:55:54,368 | INFO | live_route decision: agent=operations_agent decision=run trigger_type=confidence_threshold signal=latest_memory.confidence threshold=0.6 value=0.49731041640000007 notes=Confidence below threshold\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f41a9a9592438c80bf4576f88fc071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2927bc8a56054497968208ebdd4f5463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588b1cf9582c4f7f9ffc12194508dcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab539284c5b4cceb3966c6371f5336f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314426c4fc19494384d493d1ad8291ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21441511b3ca4361ae1625933e6c2c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:55:56,249 | INFO | live_route persisted: agent=compliance_agent id=demo_contract:compliance_agent:2026-01-20T02:25:55.795588+00:00:7635d6c9b96f417e9212a0c4190a1c17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efa7a76c077467597d31db4efbe00d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95887354e0994baaa278277d69fcd5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e2a72ea35848eea4d7253fef44b76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b317e2df5f134cc88c8d03f4763213d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec9c908df8249cca1060e25b539009d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5b79aa9f9a420d91cc48d9a64ff963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:55:58,362 | INFO | live_route persisted: agent=finance_agent id=demo_contract:finance_agent:2026-01-20T02:25:57.860308+00:00:385d69bf27ad4926949c2e17d7f2231d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b576ee22decd495991985cb934086614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b7aa0a629d41cfabbe8a1554b1b8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c966bfac02b46e2bd020103a32df082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40c9704427e487cbb2d571b0d21b1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8875ab6e03694dcaa3c742a02b4fd76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93737ee1c2cc4f258f6f39c996334c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:56:00,283 | INFO | live_route persisted: agent=legal_agent id=demo_contract:legal_agent:2026-01-20T02:25:59.844415+00:00:f2e51a538d75466381c5e74ee10b3ba3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb786b879b84da9aab842a050c00edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38665f23f13741fd81fe7ff0fd050325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ed9c2c7ace49cabc5fd89b287e6485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8cdb4f7905d45779a0a5b32d2b060a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b2d3439a214be19c08e334e90b97f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ece005ff254345b9b17be313d693a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:56:02,322 | INFO | live_route persisted: agent=operations_agent id=demo_contract:operations_agent:2026-01-20T02:26:01.827393+00:00:0cb973c1ac6e47e09545100dd7a0e07d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunk event executed agents: ['compliance_agent', 'finance_agent', 'legal_agent', 'operations_agent']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5b565bea474b70888d2e27e9499901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe161a679c2495d9970b2fe55804ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d71637c5e4742238621f78bd946c90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c660696d56347ac901e2e235be62ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "603fd7be72e948d0afb5a2efb12152be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a119f613af4145ef8dc630c3ee1a5e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3649f6cb49a24ef49fae2d84808d1486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34516663b49c46f0919090e3b603ff32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d91cd83d8b4add894a133fd4c05d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:56:05,192 | INFO | live_route decision: agent=compliance_agent decision=run trigger_type=confidence_threshold signal=latest_memory.confidence threshold=0.6 value=0.45270323614999997 notes=Confidence below threshold\n",
      "2026-01-20 07:56:05,192 | INFO | live_route decision: agent=finance_agent decision=run trigger_type=confidence_threshold signal=latest_memory.confidence threshold=0.6 value=0.49326843470000004 notes=Confidence below threshold\n",
      "2026-01-20 07:56:05,192 | INFO | live_route decision: agent=operations_agent decision=run trigger_type=confidence_threshold signal=latest_memory.confidence threshold=0.6 value=0.44699437745 notes=Confidence below threshold\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb86c98dd8f541c6b4c6776ae69912e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c812077af2454324bf6384fc3d849c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532770fb61374379ba474809ff0ffc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de7e4163e2f45bab7e9eb0f148e3750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e40b9c71c9494ee2ab3dddfc4a14c069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072e6031c4854ecc9dc80b6cc06bfd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:56:07,158 | INFO | live_route persisted: agent=compliance_agent id=demo_contract:compliance_agent:2026-01-20T02:26:06.725131+00:00:693868f48b8342cd80d84e0b772bca73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b929418b7be4e55b5d047c7df68b9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df224adf09d349bd9c33bf50476e3c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6092359d26c54d9a843336dbc52e925d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35af8c6126f84dafaae1d285f5b1ae4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c329e0a20e842f6816033aded060a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e687eeb8fe47c48d375865afe7647c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:56:09,093 | INFO | live_route persisted: agent=finance_agent id=demo_contract:finance_agent:2026-01-20T02:26:08.647262+00:00:7325dfc7b1b9436d88216e5df392e27f\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b29c5034f474dcb8ba86d4828d4f544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba72119ac93d42ecbc9c2e300c243c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a367048b37c45548da5f6f61a0c2bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75e3a07579846788762cee20fe2c2d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3923007074448b49c48644a9e147e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3946bfbcdc0e48618c636e0a3f38aa5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-20 07:56:11,138 | INFO | live_route persisted: agent=operations_agent id=demo_contract:operations_agent:2026-01-20T02:26:10.654965+00:00:58941d107656464fa4fa392ed0cf890e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No-evidence flag: False\n",
      "User message: None\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Live routing demo (replaces static batch execution)\n",
    "# ----------------------------\n",
    "\n",
    "# Example 1: New user query arrives (should route relevant agents)\n",
    "event1 = LiveTriggerEvent(\n",
    "    event_type=\"new_user_query\",\n",
    "    contract_id=CONTRACT_ID,\n",
    "    payload={\"query\": \"Please summarize payment terms, audit rights, and uptime credits; highlight any penalties or uncapped liability.\"},\n",
    ")\n",
    "\n",
    "result1 = route_agents_live(\n",
    "    event1,\n",
    "    similarity_route_threshold=0.45,\n",
    "    confidence_trigger_threshold=0.60,\n",
    "    similarity_skip_threshold=0.85,\n",
    "    recent_hours=24,\n",
    "    top_k_per_query=5,\n",
    "    filter_chunks_by_contract_id=FILTER_CHUNKS_BY_CONTRACT_ID,\n",
    "    # chunks_namespace=CHUNKS_NAMESPACE,  # uncomment if you have an explicit chunks namespace variable\n",
    "    no_evidence_threshold=0.25,\n",
    ")\n",
    "\n",
    "print(\"Live routing executed agents:\", result1[\"executed\"])\n",
    "print(\"Live routing skipped agents:\", list(result1[\"skipped\"].keys()))\n",
    "print(\"Persisted memory ids (count):\", len(result1[\"persisted_ids\"]))\n",
    "\n",
    "# Example 2: New contract chunk arrives (e.g., ingestion pipeline appended a chunk)\n",
    "event2 = LiveTriggerEvent(\n",
    "    event_type=\"new_contract_chunk\",\n",
    "    contract_id=CONTRACT_ID,\n",
    "    payload={\"chunk_text\": \"Service credits apply if uptime falls below 99.9%. Provider may limit liability; penalties may apply for repeated outages.\"},\n",
    ")\n",
    "\n",
    "result2 = route_agents_live(\n",
    "    event2,\n",
    "    filter_chunks_by_contract_id=FILTER_CHUNKS_BY_CONTRACT_ID,\n",
    "    no_evidence_threshold=0.25,\n",
    ")\n",
    "print(\"\\nChunk event executed agents:\", result2[\"executed\"])\n",
    "\n",
    "# Example 3: User asks a question NOT covered by the document (should return no_evidence=True)\n",
    "event3 = LiveTriggerEvent(\n",
    "    event_type=\"new_user_query\",\n",
    "    contract_id=CONTRACT_ID,\n",
    "    payload={\"query\": \"What is the warranty period for the physical hardware included in this contract?\"},\n",
    ")\n",
    "\n",
    "result3 = route_agents_live(\n",
    "    event3,\n",
    "    filter_chunks_by_contract_id=FILTER_CHUNKS_BY_CONTRACT_ID,\n",
    "    no_evidence_threshold=0.25,\n",
    ")\n",
    "print(\"\\nNo-evidence flag:\", result3.get(\"no_evidence\"))\n",
    "print(\"User message:\", result3.get(\"user_message\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b540456",
   "metadata": {},
   "source": [
    "## 7) Final Contract-Level JSON Output (Latest Memories → Standard JSON)\n",
    "\n",
    "This section produces a **single standardized JSON** for a contract by:\n",
    "- Pulling the **latest** stored memory per agent from Pinecone\n",
    "- Aggregating **confidence** across agents\n",
    "- Extracting a list of **high-risk clauses** (evidence snippets)\n",
    "- Computing an **overall risk level**\n",
    "- Saving the final JSON to disk (so it can be used outside the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aad44c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ba0065dc414cec9c0e16c5ee222e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0814e3b05645fc9b58b26904def414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36040296c2d342b7ac3e7e9fb3ef8152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf138e30eb1f4ae4b1aaabb6c3b439be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\LENOVO\\OneDrive\\Dokumen\\legal contracts eda\\milestone3\\outputs\\final_contract_demo_contract.json\n",
      "overall_risk: high\n",
      "confidence overall_avg: 0.49904849398749995\n",
      "high_risk_clauses: 3\n"
     ]
    }
   ],
   "source": [
    "# Define the final schema + generate the final contract-level JSON from latest Pinecone memories\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "# Where to save outputs (prefer milestone3/outputs if present; otherwise milestone3/artifacts)\n",
    "OUTPUTS_DIR = (ROOT / \"outputs\") if (ROOT / \"outputs\").exists() else (ROOT / \"artifacts\")\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RISK_ORDER = {\"low\": 0, \"medium\": 1, \"high\": 2, \"unknown\": 1}\n",
    "HIGH_RISK_TERMS = [\n",
    "    \"penalt\", \"late fee\", \"interest\", \"termination\", \"breach\", \"indemn\", \"liability\", \"service credit\",\n",
    "    \"audit right\", \"uncapped\", \"limitation of liability\", \"data breach\", \"incident\", \"non-compliance\",\n",
    "    \"security\", \"subprocessor\", \"cross-border\", \"governing law\", \"injunction\",\n",
    "]\n",
    "\n",
    "# Defensive: if this list ever becomes nested (e.g., due to a trailing comma edit), flatten it\n",
    "if HIGH_RISK_TERMS and isinstance(HIGH_RISK_TERMS[0], (list, tuple, set)):\n",
    "    HIGH_RISK_TERMS = [t for group in HIGH_RISK_TERMS for t in group]\n",
    "\n",
    "FINAL_CONTRACT_SCHEMA: Dict[str, Any] = {\n",
    "    \"contract_id\": \"\",\n",
    "    \"legal\": {},\n",
    "    \"compliance\": {},\n",
    "    \"finance\": {},\n",
    "    \"operations\": {},\n",
    "    \"overall_risk\": \"\",\n",
    "    \"confidence\": {\n",
    "        \"per_agent\": {},\n",
    "        \"overall_avg\": None,\n",
    "    },\n",
    "    \"high_risk_clauses\": [],\n",
    "    \"generated_at\": \"\",\n",
    "}\n",
    "\n",
    "def _utc_now_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "def _as_utc_aware(dt: datetime) -> datetime:\n",
    "    if dt.tzinfo is None:\n",
    "        return dt.replace(tzinfo=timezone.utc)\n",
    "    return dt.astimezone(timezone.utc)\n",
    "\n",
    "def _parse_ts(ts: Optional[str]) -> datetime:\n",
    "    if not ts:\n",
    "        return datetime.min.replace(tzinfo=timezone.utc)\n",
    "    try:\n",
    "        dt = datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\"))\n",
    "        return _as_utc_aware(dt)\n",
    "    except Exception:\n",
    "        return datetime.min.replace(tzinfo=timezone.utc)\n",
    "\n",
    "def _matches(resp: Any) -> List[Any]:\n",
    "    if isinstance(resp, dict):\n",
    "        return resp.get(\"matches\") or []\n",
    "    return getattr(resp, \"matches\", []) or []\n",
    "\n",
    "def _md(match: Any) -> Dict[str, Any]:\n",
    "    if isinstance(match, dict):\n",
    "        return match.get(\"metadata\") or {}\n",
    "    return getattr(match, \"metadata\", {}) or {}\n",
    "\n",
    "def _safe_json_loads(s: str) -> Optional[Any]:\n",
    "    if not isinstance(s, str) or not s.strip():\n",
    "        return None\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _extract_text_from_match_metadata(md: Dict[str, Any]) -> str:\n",
    "    # Try common metadata keys used by chunking pipelines\n",
    "    for key in (\"text\", \"chunk_text\", \"content\", \"clause_text\", \"snippet\", \"page_content\"):\n",
    "        v = md.get(key)\n",
    "        if isinstance(v, str) and v.strip():\n",
    "            return v.strip()\n",
    "    # Fallback: show a compact representation\n",
    "    try:\n",
    "        return json.dumps(md, ensure_ascii=False)[:800]\n",
    "    except Exception:\n",
    "        return str(md)[:800]\n",
    "\n",
    "def _infer_risk_level(output: Any) -> str:\n",
    "    if isinstance(output, dict):\n",
    "        rl = output.get(\"risk_level\")\n",
    "        if isinstance(rl, str) and rl.strip():\n",
    "            return rl.strip().lower()\n",
    "    # fallback heuristic on serialized output\n",
    "    text = json.dumps(output, ensure_ascii=False).lower() if output is not None else \"\"\n",
    "    if any(t in text for t in HIGH_RISK_TERMS):\n",
    "        return \"high\"\n",
    "    return \"medium\"\n",
    "\n",
    "def _extract_term_hits(*, text: str, agent_type: str, max_items: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Fallback evidence extraction when we don't have structured retrieval matches available.\"\"\"\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return []\n",
    "    lower = text.lower()\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    seen_terms = set()\n",
    "    for term in HIGH_RISK_TERMS:\n",
    "        if term in seen_terms:\n",
    "            continue\n",
    "        idx = lower.find(term)\n",
    "        if idx < 0:\n",
    "            continue\n",
    "        seen_terms.add(term)\n",
    "        start = max(0, idx - 120)\n",
    "        end = min(len(text), idx + 160)\n",
    "        snippet = text[start:end].replace(\"\\n\", \" \")\n",
    "        out.append({\n",
    "            \"agent\": agent_type,\n",
    "            \"query\": \"(memory-text-scan)\",\n",
    "            \"score\": None,\n",
    "            \"snippet\": snippet[:800],\n",
    "            \"is_high_risk\": True,\n",
    "            \"matched_term\": term,\n",
    "        })\n",
    "        if len(out) >= max_items:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def get_latest_agent_output(*, contract_id: str, agent_type: str, top_k: int = 10) -> Dict[str, Any]:\n",
    "    \"\"\"Return the latest stored agent output for this contract+agent.\n",
    "\n",
    "    Best-effort confidence behavior: if the latest record has no numeric confidence (common for refinement-only\n",
    "    records), fall back to the newest record in the result set that *does* have confidence.\n",
    "    \"\"\"\n",
    "    resp = query_agent_memory(\n",
    "        query=\"risk\",\n",
    "        contract_id=contract_id,\n",
    "        agent_type=agent_type,\n",
    "        top_k=top_k,\n",
    "    )\n",
    "    matches = _matches(resp)\n",
    "    if not matches:\n",
    "        return {\n",
    "            \"agent_type\": agent_type,\n",
    "            \"timestamp\": None,\n",
    "            \"risk_level\": \"unknown\",\n",
    "            \"confidence\": None,\n",
    "            \"output\": {\"risk_level\": \"unknown\", \"note\": \"No memory found\"},\n",
    "            \"_memory_metadata\": {},\n",
    "        }\n",
    "\n",
    "    # Sort all candidates by timestamp (desc)\n",
    "    ranked: List[Tuple[datetime, Dict[str, Any]]] = []\n",
    "    for m in matches:\n",
    "        md = _md(m)\n",
    "        ranked.append((_parse_ts(md.get(\"timestamp\")), md))\n",
    "    ranked.sort(key=lambda t: t[0], reverse=True)\n",
    "\n",
    "    best_md = ranked[0][1]\n",
    "    # output_json is expected to be JSON; if it was truncated, it should still be valid JSON wrapper\n",
    "    output_raw = best_md.get(\"output_json\") or \"\"\n",
    "    output_obj = _safe_json_loads(output_raw)\n",
    "    if output_obj is None:\n",
    "        output_obj = {\"raw_output_json\": output_raw}\n",
    "\n",
    "    # Prefer explicit risk_level metadata, else infer\n",
    "    risk_level = best_md.get(\"risk_level\")\n",
    "    if not isinstance(risk_level, str) or not risk_level.strip():\n",
    "        risk_level = _infer_risk_level(output_obj)\n",
    "\n",
    "    # 1) First try: explicit confidence from the latest record's metadata\n",
    "    conf: Optional[float] = None\n",
    "    c_latest = best_md.get(\"confidence\")\n",
    "    if isinstance(c_latest, (int, float)):\n",
    "        conf = float(c_latest)\n",
    "    # 2) Second try: confidence embedded in the latest record's output JSON\n",
    "    if conf is None and isinstance(output_obj, dict):\n",
    "        c2 = output_obj.get(\"confidence\")\n",
    "        if isinstance(c2, (int, float)):\n",
    "            conf = float(c2)\n",
    "    # 3) Fallback: newest record (by timestamp) that has numeric confidence in metadata or output\n",
    "    if conf is None:\n",
    "        for _, md in ranked[1:]:\n",
    "            c_md = md.get(\"confidence\")\n",
    "            if isinstance(c_md, (int, float)):\n",
    "                conf = float(c_md)\n",
    "                break\n",
    "            o = _safe_json_loads(md.get(\"output_json\") or \"\")\n",
    "            if isinstance(o, dict):\n",
    "                c_o = o.get(\"confidence\")\n",
    "                if isinstance(c_o, (int, float)):\n",
    "                    conf = float(c_o)\n",
    "                    break\n",
    "\n",
    "    return {\n",
    "        \"agent_type\": agent_type,\n",
    "        \"timestamp\": best_md.get(\"timestamp\"),\n",
    "        \"risk_level\": str(risk_level).lower(),\n",
    "        \"confidence\": conf,\n",
    "        \"output\": output_obj,\n",
    "        \"_memory_metadata\": best_md,\n",
    "    }\n",
    "\n",
    "def _extract_high_risk_clauses(*, agent_output: Any, agent_type: str, max_items: int = 5) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Extract evidence snippets from retrieval matches and label them as high-risk if terms match.\"\"\"\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    if not isinstance(agent_output, dict):\n",
    "        return out\n",
    "    retrieval = agent_output.get(\"retrieval\")\n",
    "    if not isinstance(retrieval, dict):\n",
    "        return out\n",
    "    per_query = retrieval.get(\"per_query\")\n",
    "    if not isinstance(per_query, list):\n",
    "        return out\n",
    "\n",
    "    candidates: List[Tuple[float, Dict[str, Any]]] = []\n",
    "    for item in per_query:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "        q = item.get(\"query\")\n",
    "        matches = item.get(\"matches\")\n",
    "        if not isinstance(matches, list):\n",
    "            continue\n",
    "        for m in matches:\n",
    "            if not isinstance(m, dict):\n",
    "                continue\n",
    "            score = m.get(\"score\")\n",
    "            md = m.get(\"metadata\") if isinstance(m.get(\"metadata\"), dict) else {}\n",
    "            snippet = _extract_text_from_match_metadata(md)\n",
    "            snippet_l = snippet.lower()\n",
    "            is_high = any(t in snippet_l for t in HIGH_RISK_TERMS)\n",
    "            score_f = float(score) if isinstance(score, (int, float)) else 0.0\n",
    "            rank_score = score_f + (0.25 if is_high else 0.0)\n",
    "            candidates.append((rank_score, {\n",
    "                \"agent\": agent_type,\n",
    "                \"query\": q,\n",
    "                \"score\": score_f if isinstance(score, (int, float)) else None,\n",
    "                \"snippet\": snippet[:800],\n",
    "                \"is_high_risk\": bool(is_high),\n",
    "            }))\n",
    "\n",
    "    candidates.sort(key=lambda t: t[0], reverse=True)\n",
    "    seen = set()\n",
    "    for _, c in candidates:\n",
    "        key = (c.get(\"agent\"), c.get(\"snippet\"))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        if c.get(\"is_high_risk\"):\n",
    "            out.append(c)\n",
    "        if len(out) >= max_items:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def _overall_risk(agent_risks: Dict[str, str]) -> str:\n",
    "    best = \"low\"\n",
    "    for r in agent_risks.values():\n",
    "        r = (r or \"unknown\").lower()\n",
    "        if RISK_ORDER.get(r, 1) > RISK_ORDER.get(best, 0):\n",
    "            best = r\n",
    "    if best not in {\"low\", \"medium\", \"high\"}:\n",
    "        best = \"medium\"\n",
    "    return best\n",
    "\n",
    "# 1) Retrieve latest outputs\n",
    "latest = {a: get_latest_agent_output(contract_id=CONTRACT_ID, agent_type=a) for a in AGENT_TYPES}\n",
    "\n",
    "# 2) Collect into final JSON\n",
    "final = dict(FINAL_CONTRACT_SCHEMA)\n",
    "final[\"contract_id\"] = CONTRACT_ID\n",
    "final[\"generated_at\"] = _utc_now_iso()\n",
    "\n",
    "agent_risks: Dict[str, str] = {}\n",
    "conf_per_agent: Dict[str, Optional[float]] = {}\n",
    "high_risk_clauses: List[Dict[str, Any]] = []\n",
    "\n",
    "for a in AGENT_TYPES:\n",
    "    payload = latest[a]\n",
    "    output_obj = payload.get(\"output\")\n",
    "    agent_risks[a] = payload.get(\"risk_level\") or _infer_risk_level(output_obj)\n",
    "    conf_per_agent[a] = payload.get(\"confidence\")\n",
    "    # Evidence from structured retrieval (if present)\n",
    "    high_risk_clauses.extend(_extract_high_risk_clauses(agent_output=output_obj, agent_type=a, max_items=5))\n",
    "    # Fallback evidence: scan stored memory text for high-risk terms\n",
    "    if not high_risk_clauses:\n",
    "        mem_text = (payload.get(\"_memory_metadata\") or {}).get(\"output_json\") or \"\"\n",
    "        high_risk_clauses.extend(_extract_term_hits(text=mem_text, agent_type=a, max_items=3))\n",
    "\n",
    "final[\"legal\"] = latest[\"legal_agent\"][\"output\"]\n",
    "final[\"compliance\"] = latest[\"compliance_agent\"][\"output\"]\n",
    "final[\"finance\"] = latest[\"finance_agent\"][\"output\"]\n",
    "final[\"operations\"] = latest[\"operations_agent\"][\"output\"]\n",
    "\n",
    "final[\"overall_risk\"] = _overall_risk(agent_risks)\n",
    "final[\"confidence\"][\"per_agent\"] = conf_per_agent\n",
    "vals = [v for v in conf_per_agent.values() if isinstance(v, (int, float))]\n",
    "final[\"confidence\"][\"overall_avg\"] = (sum(vals) / len(vals)) if vals else None\n",
    "\n",
    "# Keep only high-risk items and cap length\n",
    "final[\"high_risk_clauses\"] = high_risk_clauses[:20]\n",
    "\n",
    "out_path = OUTPUTS_DIR / f\"final_contract_{CONTRACT_ID}.json\"\n",
    "out_path.write_text(json.dumps(final, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved:\", out_path)\n",
    "print(\"overall_risk:\", final[\"overall_risk\"])\n",
    "print(\"confidence overall_avg:\", final[\"confidence\"][\"overall_avg\"])\n",
    "print(\"high_risk_clauses:\", len(final[\"high_risk_clauses\"]))\n",
    "if final[\"confidence\"][\"overall_avg\"] is None:\n",
    "    print(\"NOTE: Confidence is None because older memories may not include a stored confidence score.\")\n",
    "    print(\"      Re-run Section 3 + Section 4 to persist fresh memories; new upserts store confidence in metadata.\")\n",
    "if len(final[\"high_risk_clauses\"]) == 0:\n",
    "    print(\"NOTE: No high-risk evidence snippets were extracted.\")\n",
    "    print(\"      To improve this, ensure your chunk vectors store clause text in metadata (e.g., key 'text' or 'page_content').\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e148de70",
   "metadata": {},
   "source": [
    "## 8) Human-Readable Report Template (Executive Summary + Section Bullets)\n",
    "\n",
    "Same data → multiple views: executives don’t read JSON, lawyers want evidence, managers want summaries.\n",
    "\n",
    "This section converts the final JSON into a simple report structure with:\n",
    "- Plain-language **Executive Summary**\n",
    "- Bullet points per section (legal / compliance / finance / operations)\n",
    "- A short list of high-risk clause snippets (evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "017ab57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REPORT PREVIEW (tone=executive)\n",
      "================================================================================\n",
      "\n",
      "## Executive Summary\n",
      "- Overall risk: high (HIGH RISK).\n",
      "- Confidence (avg): 0.499.\n",
      "- High-risk evidence snippets: 3.\n",
      "- Route to approval if risk is high.\n",
      "- Prioritize review of the highlighted items.\n",
      "- Negotiate risk-heavy terms where possible.\n",
      "\n",
      "## Overall Risk Assessment [HIGH RISK]\n",
      "- Overall risk level: high (HIGH RISK).\n",
      "- Confidence (avg): 0.49904849398749995\n",
      "- Legal confidence: 0.51838344655\n",
      "- Compliance confidence: 0.45270323614999997\n",
      "- Finance confidence: 0.5230778456999999\n",
      "- Operations confidence: 0.50202944755\n",
      "\n",
      "## Legal Analysis [HIGH RISK]\n",
      "- Key legal obligations summarized from retrieval outputs.\n",
      "- Review termination, breach, and indemnity language if present.\n",
      "- Section risk: high\n",
      "\n",
      "## Compliance Analysis [HIGH RISK]\n",
      "- Key privacy/security/compliance obligations summarized from retrieval outputs.\n",
      "- Review audit rights, incident notification, and data handling language if present.\n",
      "- Section risk: high\n",
      "\n",
      "## Financial Analysis [HIGH RISK]\n",
      "- Key payment, invoicing, and late-fee obligations summarized from retrieval outputs.\n",
      "- Review liability and penalty exposure if present.\n",
      "- Section risk: high\n",
      "\n",
      "## Operational Analysis [HIGH RISK]\n",
      "- Key deliverables, timelines, and SLA obligations summarized from retrieval outputs.\n",
      "- Review uptime commitments and service credits if present.\n",
      "- Section risk: high\n",
      "\n",
      "## Conclusion & Recommendations\n",
      "- Prioritize review of the highlighted items.\n",
      "- Route to approval if risk is high.\n",
      "- Negotiate risk-heavy terms where possible.\n",
      "- Key evidence:\n",
      "- [HIGH RISK] [legal_agent] (term: penalt) \": \"demo_contract\", \"question\": \"Service credits apply if uptime falls below 99.9%. Provider may limit liability; penalties may apply for repeated outages.\", \"timestamp\": \"2026-01-20T02:25:59.844415+\n",
      "- [HIGH RISK] [legal_agent] (term: breach) 830.0, \"chunk_index\": 14.0, \"contract_id\": \"ABILITYINC_06_15_2020-EX-4.25-SERVICES AGREEMENT\", \"text\": \". 3.3 Breach. Any Party (the \\\\\"Non-Breaching Party\\\\\") may terminate this Agreement with respe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "REPORT_STRUCTURE = [\n",
    "    \"Executive Summary\",\n",
    "    \"Overall Risk Assessment\",\n",
    "    \"Legal Analysis\",\n",
    "    \"Compliance Analysis\",\n",
    "    \"Financial Analysis\",\n",
    "    \"Operational Analysis\",\n",
    "    \"Conclusion & Recommendations\",\n",
    "]\n",
    "\n",
    "def _bulletize(lines: List[str]) -> str:\n",
    "    return \"\\n\".join([f\"- {ln}\" for ln in lines if isinstance(ln, str) and ln.strip()])\n",
    "\n",
    "def _clean_snippet(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    # Normalize common escaped forms from JSON previews\n",
    "    s = s.replace(\"\\\\n\", \" \").replace(\"\\n\", \" \")\n",
    "    s = s.replace(\"\\\\\\\"\", '\"').replace(\"\\\\/\", \"/\")\n",
    "    # Collapse whitespace\n",
    "    s = \" \".join(s.split())\n",
    "    return s.strip()\n",
    "\n",
    "def _looks_like_json_fragment(s: str) -> bool:\n",
    "    \"\"\"Detect snippets that are likely cut-through JSON rather than readable clause text.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return True\n",
    "    t = s.strip()\n",
    "    if not t:\n",
    "        return True\n",
    "    tl = t.lower()\n",
    "\n",
    "    # Hard-block: retrieval/memory JSON keys (these are NOT clause text)\n",
    "    hard_markers = [\n",
    "        \"top_k_per_query\",\n",
    "        \"filter_chunks_by_contract_id\",\n",
    "        \"per_query\",\n",
    "        \"matches\",\n",
    "        \"retrieval\\\":\",\n",
    "        \"metadata\\\":\",\n",
    "        \"output_json\",\n",
    "        \"raw_output_json\",\n",
    "    ]\n",
    "    if any(m in tl for m in hard_markers):\n",
    "        return True\n",
    "\n",
    "    # Soft heuristics: many JSON-ish tokens and low natural-language signal\n",
    "    jsonish = sum(t.count(ch) for ch in [\"{\", \"}\", \"[\", \"]\", \":\"])\n",
    "    backslashes = t.count(\"\\\\\")\n",
    "    quotes = t.count('\"')\n",
    "    letters = sum(ch.isalpha() for ch in t)\n",
    "    spaces = t.count(\" \")\n",
    "\n",
    "    if (jsonish + backslashes + quotes) >= 8 and (letters < 60 or spaces < 8):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# ----------------------------\n",
    "# Tone + formatting utilities\n",
    "# ----------------------------\n",
    "\n",
    "TONE_TEMPLATES: Dict[str, Dict[str, str]] = {\n",
    "    # Default: concise, neutral, business-friendly\n",
    "    \"neutral\": {\n",
    "        \"risk_prefix_high\": \"HIGH RISK\",\n",
    "        \"risk_prefix_medium\": \"MEDIUM RISK\",\n",
    "        \"risk_prefix_low\": \"LOW RISK\",\n",
    "        \"summary_label\": \"Summary\",\n",
    "        \"evidence_label\": \"High-risk evidence\",\n",
    "        \"recommendation_label\": \"Recommendations\",\n",
    "        \"phrase_review\": \"Review the highlighted clauses before signing.\",\n",
    "        \"phrase_escalate\": \"Escalate for legal/compliance approval.\",\n",
    "        \"phrase_negotiate\": \"Consider negotiation on the highlighted terms.\",\n",
    "    },\n",
    "    # Executive: shorter, decision-oriented\n",
    "    \"executive\": {\n",
    "        \"risk_prefix_high\": \"HIGH RISK\",\n",
    "        \"risk_prefix_medium\": \"ELEVATED RISK\",\n",
    "        \"risk_prefix_low\": \"LOW RISK\",\n",
    "        \"summary_label\": \"Executive Summary\",\n",
    "        \"evidence_label\": \"Key evidence\",\n",
    "        \"recommendation_label\": \"Action\",\n",
    "        \"phrase_review\": \"Prioritize review of the highlighted items.\",\n",
    "        \"phrase_escalate\": \"Route to approval if risk is high.\",\n",
    "        \"phrase_negotiate\": \"Negotiate risk-heavy terms where possible.\",\n",
    "    },\n",
    "    # Legal: more formal phrasing\n",
    "    \"legal\": {\n",
    "        \"risk_prefix_high\": \"HIGH RISK\",\n",
    "        \"risk_prefix_medium\": \"MODERATE RISK\",\n",
    "        \"risk_prefix_low\": \"LOW RISK\",\n",
    "        \"summary_label\": \"Overview\",\n",
    "        \"evidence_label\": \"Supporting excerpts\",\n",
    "        \"recommendation_label\": \"Next steps\",\n",
    "        \"phrase_review\": \"Conduct clause-by-clause review of referenced provisions.\",\n",
    "        \"phrase_escalate\": \"Seek counsel review and required internal approvals.\",\n",
    "        \"phrase_negotiate\": \"Evaluate mitigation language and negotiation positions.\",\n",
    "    },\n",
    "}\n",
    "\n",
    "def _tone(name: str) -> Dict[str, str]:\n",
    "    t = (name or \"neutral\").strip().lower()\n",
    "    return TONE_TEMPLATES.get(t, TONE_TEMPLATES[\"neutral\"])\n",
    "\n",
    "def _risk_tag(risk_level: str, tone_name: str) -> str:\n",
    "    t = _tone(tone_name)\n",
    "    rl = (risk_level or \"medium\").strip().lower()\n",
    "    if rl == \"high\":\n",
    "        return t[\"risk_prefix_high\"]\n",
    "    if rl == \"low\":\n",
    "        return t[\"risk_prefix_low\"]\n",
    "    return t[\"risk_prefix_medium\"]\n",
    "\n",
    "def _safe_risk_from_section(obj: Any) -> str:\n",
    "    \"\"\"Best-effort extraction of risk from agent output section.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        rl = obj.get(\"risk_level\")\n",
    "        if isinstance(rl, str) and rl.strip():\n",
    "            return rl.strip().lower()\n",
    "    return \"unknown\"\n",
    "\n",
    "def _infer_section_risk(obj: Any) -> str:\n",
    "    \"\"\"Fallback risk inference when sections don't have explicit risk_level.\"\"\"\n",
    "    rl = _safe_risk_from_section(obj)\n",
    "    if rl in {\"low\", \"medium\", \"high\"}:\n",
    "        return rl\n",
    "    # Prefer the notebook-wide HIGH_RISK_TERMS if it exists (defined in Section 7).\n",
    "    terms = globals().get(\"HIGH_RISK_TERMS\")\n",
    "    if not isinstance(terms, list) or not terms:\n",
    "        terms = [\n",
    "            \"penalt\", \"late fee\", \"interest\", \"termination\", \"breach\", \"indemn\", \"liability\", \"service credit\",\n",
    "            \"audit\", \"privacy\", \"security\", \"incident\", \"retention\", \"subprocessor\", \"governing law\",\n",
    "        ]\n",
    "    try:\n",
    "        text = json.dumps(obj, ensure_ascii=False).lower() if obj is not None else \"\"\n",
    "    except Exception:\n",
    "        text = str(obj).lower() if obj is not None else \"\"\n",
    "    if any(t in text for t in terms):\n",
    "        return \"high\"\n",
    "    return \"medium\"\n",
    "\n",
    "def _format_section_title(title: str, *, risk_level: Optional[str], tone_name: str) -> str:\n",
    "    if risk_level and (risk_level or \"\").lower() == \"high\":\n",
    "        return f\"{title} [{_risk_tag('high', tone_name)}]\"\n",
    "    if title == \"Overall Risk Assessment\" and risk_level:\n",
    "        return f\"{title} [{_risk_tag(risk_level, tone_name)}]\"\n",
    "    return title\n",
    "\n",
    "def build_executive_summary_bullets(final_json: Dict[str, Any], *, tone_name: str = \"neutral\") -> List[str]:\n",
    "    t = _tone(tone_name)\n",
    "    risk = (final_json.get(\"overall_risk\") or \"medium\").lower()\n",
    "    conf = (final_json.get(\"confidence\") or {}).get(\"overall_avg\")\n",
    "    conf_s = \"unknown\" if conf is None else f\"{conf:.3f}\"\n",
    "    n_hi = len(final_json.get(\"high_risk_clauses\") or [])\n",
    "\n",
    "    bullets: List[str] = [\n",
    "        f\"Overall risk: {risk} ({_risk_tag(risk, tone_name)}).\",\n",
    "        f\"Confidence (avg): {conf_s}.\",\n",
    "        f\"High-risk evidence snippets: {n_hi}.\",\n",
    "    ]\n",
    "    # Decision-oriented nudges\n",
    "    if risk == \"high\":\n",
    "        bullets.append(t[\"phrase_escalate\"])\n",
    "    bullets.append(t[\"phrase_review\"])\n",
    "    if n_hi > 0:\n",
    "        bullets.append(t[\"phrase_negotiate\"])\n",
    "    return bullets\n",
    "\n",
    "def build_report(\n",
    "    final_json: Dict[str, Any],\n",
    "    *,\n",
    "    tone_name: str = \"neutral\",\n",
    "    max_evidence_items: int = 8,\n",
    ") -> Dict[str, str]:\n",
    "    per_agent_conf = (final_json.get(\"confidence\") or {}).get(\"per_agent\") or {}\n",
    "    hi = final_json.get(\"high_risk_clauses\") or []\n",
    "    t = _tone(tone_name)\n",
    "\n",
    "    # Determine per-section risk so we can highlight high-risk sections\n",
    "    section_risk = {\n",
    "        \"legal\": _infer_section_risk(final_json.get(\"legal\")),\n",
    "        \"compliance\": _infer_section_risk(final_json.get(\"compliance\")),\n",
    "        \"finance\": _infer_section_risk(final_json.get(\"finance\")),\n",
    "        \"operations\": _infer_section_risk(final_json.get(\"operations\")),\n",
    "    }\n",
    "    overall_risk = (final_json.get(\"overall_risk\") or \"medium\").lower()\n",
    "\n",
    "    report: Dict[str, str] = {}\n",
    "    report[\"Executive Summary\"] = _bulletize(build_executive_summary_bullets(final_json, tone_name=tone_name))\n",
    "\n",
    "    report[\"Overall Risk Assessment\"] = _bulletize([\n",
    "        f\"Overall risk level: {overall_risk} ({_risk_tag(overall_risk, tone_name)}).\",\n",
    "        f\"Confidence (avg): {(final_json.get('confidence') or {}).get('overall_avg')}\",\n",
    "        f\"Legal confidence: {per_agent_conf.get('legal_agent')}\",\n",
    "        f\"Compliance confidence: {per_agent_conf.get('compliance_agent')}\",\n",
    "        f\"Finance confidence: {per_agent_conf.get('finance_agent')}\",\n",
    "        f\"Operations confidence: {per_agent_conf.get('operations_agent')}\",\n",
    "    ])\n",
    "\n",
    "    # Per-section bullets (keep it generic; the evidence list carries the detail)\n",
    "    report[\"Legal Analysis\"] = _bulletize([\n",
    "        \"Key legal obligations summarized from retrieval outputs.\",\n",
    "        \"Review termination, breach, and indemnity language if present.\",\n",
    "        f\"Section risk: {section_risk['legal']}\",\n",
    "    ])\n",
    "    report[\"Compliance Analysis\"] = _bulletize([\n",
    "        \"Key privacy/security/compliance obligations summarized from retrieval outputs.\",\n",
    "        \"Review audit rights, incident notification, and data handling language if present.\",\n",
    "        f\"Section risk: {section_risk['compliance']}\",\n",
    "    ])\n",
    "    report[\"Financial Analysis\"] = _bulletize([\n",
    "        \"Key payment, invoicing, and late-fee obligations summarized from retrieval outputs.\",\n",
    "        \"Review liability and penalty exposure if present.\",\n",
    "        f\"Section risk: {section_risk['finance']}\",\n",
    "    ])\n",
    "    report[\"Operational Analysis\"] = _bulletize([\n",
    "        \"Key deliverables, timelines, and SLA obligations summarized from retrieval outputs.\",\n",
    "        \"Review uptime commitments and service credits if present.\",\n",
    "        f\"Section risk: {section_risk['operations']}\",\n",
    "    ])\n",
    "\n",
    "    # Evidence: prefer readable snippets (skip JSON fragments from truncated memory previews)\n",
    "    top_evidence: List[str] = []\n",
    "    for item in hi:\n",
    "        if not isinstance(item, dict):\n",
    "            continue\n",
    "        raw = item.get(\"snippet\") or \"\"\n",
    "        snippet = _clean_snippet(raw)\n",
    "        if not snippet:\n",
    "            continue\n",
    "        if _looks_like_json_fragment(snippet):\n",
    "            continue\n",
    "        agent = item.get(\"agent\") or \"unknown_agent\"\n",
    "        term = item.get(\"matched_term\")\n",
    "        term_s = f\"(term: {term}) \" if isinstance(term, str) and term else \"\"\n",
    "        # Highlight evidence lines if the overall risk is high\n",
    "        prefix = f\"[{agent}] {term_s}\"\n",
    "        if overall_risk == \"high\":\n",
    "            prefix = f\"[{_risk_tag('high', tone_name)}] \" + prefix\n",
    "        top_evidence.append((prefix + snippet)[:240])\n",
    "        if len(top_evidence) >= max_evidence_items:\n",
    "            break\n",
    "\n",
    "    report[\"Conclusion & Recommendations\"] = _bulletize([\n",
    "        t[\"phrase_review\"],\n",
    "        *( [t[\"phrase_escalate\"]] if overall_risk == \"high\" else [] ),\n",
    "        t[\"phrase_negotiate\"],\n",
    "        f\"{t['evidence_label']}:\" if top_evidence else \"No clean high-risk evidence snippets were extracted from memory.\",\n",
    "        *top_evidence,\n",
    "    ])\n",
    "\n",
    "    # Attach a display title map so we can highlight whole sections while rendering\n",
    "    report[\"__meta__\"] = json.dumps({\n",
    "        \"tone\": tone_name,\n",
    "        \"overall_risk\": overall_risk,\n",
    "        \"section_risk\": section_risk,\n",
    "    })\n",
    "    return report\n",
    "\n",
    "def render_report_text(report: Dict[str, str], *, tone_name: str = \"neutral\") -> str:\n",
    "    \"\"\"Render the report dict into a single clean text block with section highlighting.\"\"\"\n",
    "    meta = {}\n",
    "    try:\n",
    "        meta = json.loads(report.get(\"__meta__\") or \"{}\")\n",
    "    except Exception:\n",
    "        meta = {}\n",
    "\n",
    "    overall_risk = (meta.get(\"overall_risk\") or \"medium\").lower()\n",
    "    section_risk = meta.get(\"section_risk\") or {}\n",
    "\n",
    "    lines: List[str] = []\n",
    "    lines.append(\"=\" * 80)\n",
    "    lines.append(f\"REPORT PREVIEW (tone={tone_name})\")\n",
    "    lines.append(\"=\" * 80)\n",
    "\n",
    "    for section in REPORT_STRUCTURE:\n",
    "        rl: Optional[str] = None\n",
    "        if section == \"Overall Risk Assessment\":\n",
    "            rl = overall_risk\n",
    "        elif section == \"Legal Analysis\":\n",
    "            rl = section_risk.get(\"legal\")\n",
    "        elif section == \"Compliance Analysis\":\n",
    "            rl = section_risk.get(\"compliance\")\n",
    "        elif section == \"Financial Analysis\":\n",
    "            rl = section_risk.get(\"finance\")\n",
    "        elif section == \"Operational Analysis\":\n",
    "            rl = section_risk.get(\"operations\")\n",
    "\n",
    "        title = _format_section_title(section, risk_level=rl, tone_name=tone_name)\n",
    "        lines.append(\"\")\n",
    "        lines.append(f\"## {title}\")\n",
    "        lines.append(report.get(section, \"\"))\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ---------\n",
    "# Usage\n",
    "# ---------\n",
    "TONE = os.getenv(\"REPORT_TONE\", \"executive\")  # neutral | executive | legal\n",
    "report = build_report(final, tone_name=TONE)\n",
    "print(render_report_text(report, tone_name=TONE))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
