ClauseAI: AI-PoweredContract Analysis

1. Project Overview
   
    ClauseAI is an AI-powered system designed to automate the process of contract analysis, improving efficiency and precision while generating customized, actionable reports. It leverages a multi-agent framework where each AI agent specializes in a distinct domain—such as compliance, finance, and operations—to deliver comprehensive and professional insights.

2. System Architecture & Methodology
   
    The system employs a LangGraph architecture, where each node represents a specialized contract analysis function.
    1. Core Workflow
      1. Input Phase: Users upload contract documents or connect to external legal data APIs.
      2. AI Planning Phase: A Coordinator agent assigns tasks to specialized domain agents.
      3. Analysis Phase: Domain agents perform multi-turn discussions with expert AI submodules and execute parallelized data extraction.
      4. Reporting Phase: The system synthesizes multi-agent outputs into concise, professional summaries.

3. Technology Stack
    1. Programming Language: Python 3.x 
    2. Orchestration: LangChain & LangGraph 
    3. Vector Database: Pinecone 
    4. Models: OpenAI API (Architecture) and Gemma-2b-it (Milestone 1 Implementation) 
    5. Parsing: PyPDF2, python-docx 
    6. Frontend: Streamlit

4. Milestone 1 Implementation: Progress Report
   
    The first milestone focused on environment setup and the establishment of the RAG (Retrieval-Augmented Generation) pipeline.
    1. Data Pipeline Details
        1. Source Data: 510 text files from the full_contract_txt folder.
        2. Processing: Documents were transformed using LangChain, converted into chunks, and stored as embeddings in Pinecone.
        3. Retrieval: The system generated 20 RAG search files to serve as the context for specialized agents.
   3. Issues Faced:
      1. Instead using API Key for embedding sentence transformer model - all-minilm-l6-v2
      2. Before using gemma-2b-it as teh base model several other models like Qwen2.5, Mistral-7B where tried - but due the large size teh models failed to load in VSCode witha CPU memory of 16gb RAM
     
5. Milestone 2 Implementation: Progress Report
   
   This milestone focused on implemention coordination between the agents, routing of the agents and the creation of LanGraph - nodes and agent to agent communication
   1. Data Pipeline Details
       1. Source Date - 4 output files - JSON format - from Legal, Compliance, Finance and Operations Agents - generated by the model - "gemma-2b-it"
       2. Processing - Agent output JSON files are loaded as pre-computed data - routing rules and coordinator functions are defined using specific keywords - Langraph is loaded all the agents are added as nodes with Legal Agent as entry point
       3. Collaborative Node Execution - Compliance Agent to analyse the data and write the risk in shared memory - Finance Agent reads from check for related risks - Legal Agent perfomrs the final Validation
    2. Issues Faced:
        1. Initially the agent output gave empty string - the pre-computed data was not store properly
        2. No other majors issues where ffaced during the compilation of the entire notebook
           
6. Milestone 3 Implementation: Progress Report

   This milestone focus on parallel execution of each agent, shared memory for all the agents, cross-agent refinement to enhance the risk level of each agent analysis, JSON output and final Human-readable risk report template generation.
   1. Data Pipeline Details
         1. Milestone3.ipynb Notebook:
               1. Source Data - agent output retreived from pinecone index "clauseai-agents"
               2. Model - gemma2:9B
               3. Processing - Parallel execution of the agents is performed - created a shared memory for all the agents - cross-agent refinement of each agent conducted for risk enhancement - updated the refined risk pinecone - generated template for both JSON output and  Human-Readable Risk Analysis Report
               4. Risk Enhancement - legal agent risk changed from "low" to "medium" - finance and operations agent risk changed from "medium" to "high" - compliance risk remained the same "high"
         3. app.py:
               1. Source Data - Milestone 3 output directory
               2. APIs - FastAPI, Pydantic, Uvicorn
               3. Functions - load the combined agent outputs, pinecone agent output retreival, model analysis
               4. Method - POST "analyze" - GET "health" "root end" - 200 
               5. Error - for invalid or short contract - 400
   3. Issues Faced
         1. Minor issues with requirements_api.txt - resolved by uninstalling and reinstalling
         2. Model timeout=60 - failed to call the model - increased to 600
