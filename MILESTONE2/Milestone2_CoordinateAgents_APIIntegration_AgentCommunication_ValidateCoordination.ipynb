{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dDCxQvR0uzD"
      },
      "source": [
        "# Coordinate Agents, API Integration, Agent Communication and Validate Coordination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dDpd0UH0vGS"
      },
      "source": [
        "#### Milestone 2: Week 3-4\n",
        "1. Develop the Planning Module to generate and coordinate specialized agents\n",
        "2. Implement API integration for contract upload and domain classification.\n",
        "3. Design basic prompt templates for agent communication.\n",
        "4. Validate inter-agent coordination using LangGraph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iru3Y_td3ISc"
      },
      "source": [
        "#### 1. Load Agent Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 1642,
          "status": "ok",
          "timestamp": 1767343504743,
          "user": {
            "displayName": "Krishnaveni K S",
            "userId": "14365777729970297747"
          },
          "user_tz": -330
        },
        "id": "zRKA8cJp4Lmi"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import re\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import requests\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2522,
          "status": "ok",
          "timestamp": 1767343711632,
          "user": {
            "displayName": "Krishnaveni K S",
            "userId": "14365777729970297747"
          },
          "user_tz": -330
        },
        "id": "YllxkwXlyUTP",
        "outputId": "d8fef18f-56e1-4627-ca5c-92ec8fbc3e59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOADING AGENT OUTPUTS\n",
            "\n",
            "Loading Agent Outputs\n",
            "\n",
            "1. Legal Agent\n",
            "  Loaded PRE-COMPUTED results: legal_agent_output.json\n",
            "     Contracts: 1\n",
            "     Total Clauses: 2\n",
            "     Source: From Legal Agent\n",
            "\n",
            "2. Compliance Agent\n",
            "  Loaded PRE-COMPUTED results: compliance_agent_output.json\n",
            "     Contracts: 1\n",
            "     Total Clauses: 1\n",
            "     Source: From Compliance Agent\n",
            "\n",
            "3. Finance Agent\n",
            "  Loaded PRE-COMPUTED results: finance_agent_output.json\n",
            "     Contracts: 1\n",
            "     Total Clauses: 3\n",
            "     Source: From Finance Agent\n",
            "\n",
            "4. Operations Agent\n",
            "  Loaded PRE-COMPUTED results: operations_agent_output.json\n",
            "     Contracts: 1\n",
            "     Total Clauses: 2\n",
            "     Source: From Operations Agent\n",
            "\n",
            "Total Agents Loaded: 4\n",
            "Total Pre-Computed Contracts: 4\n",
            "Total Pre-Computed Clauses: 8\n"
          ]
        }
      ],
      "source": [
        "print(\"LOADING AGENT OUTPUTS\")\n",
        "\n",
        "LEGAL_AGENT_OUTPUT = \"../Data/Results/Legal_Agent\"\n",
        "COMPLIANCE_AGENT_OUTPUT = \"../Data/Results/Compliance_Agent\"\n",
        "FINANCE_AGENT_OUTPUT = \"../Data/Results/Finance_Agent\"\n",
        "OPERATIONS_AGENT_OUTPUT = \"../Data/Results/Operations_Agent\"\n",
        "COORDINATOR_OUTPUT = \"../Data/Results/Coordinator\"\n",
        "\n",
        "os.makedirs(COORDINATOR_OUTPUT, exist_ok=True)\n",
        "\n",
        "def load_latest_agent_output(output_dir, agent_name):\n",
        "    \n",
        "    if not os.path.exists(output_dir):\n",
        "        print(f\"  Directory not found: {output_dir}\")\n",
        "        return None, None\n",
        "    \n",
        "    json_files = [f for f in os.listdir(output_dir) if f.endswith('.json')]\n",
        "    if not json_files:\n",
        "        print(f\"  No JSON files found in {output_dir}\")\n",
        "        return None, None\n",
        "    \n",
        "    base_files = [f for f in json_files \n",
        "                  if \"ENHANCED\" not in f.upper() \n",
        "                  and \"student\" not in f.lower()\n",
        "                  and \"consolidated\" in f.lower()] \n",
        "    \n",
        "    if not base_files:\n",
        "        base_files = [f for f in json_files \n",
        "                      if \"ENHANCED\" not in f.upper() \n",
        "                      and \"student\" not in f.lower()]\n",
        "    \n",
        "    if not base_files:\n",
        "        base_files = json_files  \n",
        "    \n",
        "    latest_file = max(base_files, key=lambda f: os.path.getctime(os.path.join(output_dir, f)))\n",
        "    filepath = os.path.join(output_dir, latest_file)\n",
        "    \n",
        "    try:\n",
        "        with open(filepath, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "        print(f\"  Loaded PRE-COMPUTED results: {latest_file}\")\n",
        "        return data, latest_file\n",
        "    except Exception as e:\n",
        "        print(f\"  Error loading {latest_file}: {str(e)[:50]}\")\n",
        "        return None, None\n",
        "\n",
        "print(\"\\nLoading Agent Outputs\")\n",
        "\n",
        "agent_outputs = {}\n",
        "\n",
        "print(\"\\n1. Legal Agent\")\n",
        "legal_output, legal_file = load_latest_agent_output(LEGAL_AGENT_OUTPUT, \"Legal\")\n",
        "if legal_output:\n",
        "    contracts_count = len(legal_output.get(\"contracts\", [legal_output])) if legal_output.get(\"contracts\") else 1\n",
        "    total_clauses = legal_output.get(\"metadata\", {}).get(\"total_clauses_extracted\", \n",
        "                     len(legal_output.get(\"output\", {}).get(\"extracted_clauses\", [])))\n",
        "    \n",
        "    agent_outputs[\"legal\"] = {\n",
        "        \"data\": legal_output,\n",
        "        \"file\": legal_file,\n",
        "        \"contracts_count\": contracts_count,\n",
        "        \"total_clauses\": total_clauses,\n",
        "        \"source\": \"From Legal Agent\"\n",
        "    }\n",
        "    print(f\"     Contracts: {agent_outputs['legal']['contracts_count']}\")\n",
        "    print(f\"     Total Clauses: {agent_outputs['legal']['total_clauses']}\")\n",
        "    print(f\"     Source: {agent_outputs['legal']['source']}\")\n",
        "\n",
        "print(\"\\n2. Compliance Agent\")\n",
        "compliance_output, compliance_file = load_latest_agent_output(COMPLIANCE_AGENT_OUTPUT, \"Compliance\")\n",
        "if compliance_output:\n",
        "    contracts_count = len(compliance_output.get(\"contracts\", [compliance_output])) if compliance_output.get(\"contracts\") else 1\n",
        "    total_clauses = compliance_output.get(\"metadata\", {}).get(\"total_clauses_extracted\",\n",
        "                     len(compliance_output.get(\"output\", {}).get(\"extracted_clauses\", [])))\n",
        "    \n",
        "    agent_outputs[\"compliance\"] = {\n",
        "        \"data\": compliance_output,\n",
        "        \"file\": compliance_file,\n",
        "        \"contracts_count\": contracts_count,\n",
        "        \"total_clauses\": total_clauses,\n",
        "        \"source\": \"From Compliance Agent\"\n",
        "    }\n",
        "    print(f\"     Contracts: {agent_outputs['compliance']['contracts_count']}\")\n",
        "    print(f\"     Total Clauses: {agent_outputs['compliance']['total_clauses']}\")\n",
        "    print(f\"     Source: {agent_outputs['compliance']['source']}\")\n",
        "\n",
        "print(\"\\n3. Finance Agent\")\n",
        "finance_output, finance_file = load_latest_agent_output(FINANCE_AGENT_OUTPUT, \"Finance\")\n",
        "if finance_output:\n",
        "    contracts_count = len(finance_output.get(\"contracts\", [finance_output])) if finance_output.get(\"contracts\") else 1\n",
        "    total_clauses = finance_output.get(\"metadata\", {}).get(\"total_clauses_extracted\",\n",
        "                     len(finance_output.get(\"output\", {}).get(\"extracted_clauses\", [])))\n",
        "    \n",
        "    agent_outputs[\"finance\"] = {\n",
        "        \"data\": finance_output,\n",
        "        \"file\": finance_file,\n",
        "        \"contracts_count\": contracts_count,\n",
        "        \"total_clauses\": total_clauses,\n",
        "        \"source\": \"From Finance Agent\"\n",
        "    }\n",
        "    print(f\"     Contracts: {agent_outputs['finance']['contracts_count']}\")\n",
        "    print(f\"     Total Clauses: {agent_outputs['finance']['total_clauses']}\")\n",
        "    print(f\"     Source: {agent_outputs['finance']['source']}\")\n",
        "\n",
        "print(\"\\n4. Operations Agent\")\n",
        "operations_output, operations_file = load_latest_agent_output(OPERATIONS_AGENT_OUTPUT, \"Operations\")\n",
        "if operations_output:\n",
        "    contracts_count = len(operations_output.get(\"contracts\", [operations_output])) if operations_output.get(\"contracts\") else 1\n",
        "    total_clauses = operations_output.get(\"metadata\", {}).get(\"total_clauses_extracted\",\n",
        "                     len(operations_output.get(\"output\", {}).get(\"extracted_clauses\", [])))\n",
        "    \n",
        "    agent_outputs[\"operations\"] = {\n",
        "        \"data\": operations_output,\n",
        "        \"file\": operations_file,\n",
        "        \"contracts_count\": contracts_count,\n",
        "        \"total_clauses\": total_clauses,\n",
        "        \"source\": \"From Operations Agent\"\n",
        "    }\n",
        "    print(f\"     Contracts: {agent_outputs['operations']['contracts_count']}\")\n",
        "    print(f\"     Total Clauses: {agent_outputs['operations']['total_clauses']}\")\n",
        "    print(f\"     Source: {agent_outputs['operations']['source']}\")\n",
        "\n",
        "print(f\"\\nTotal Agents Loaded: {len(agent_outputs)}\")\n",
        "print(f\"Total Pre-Computed Contracts: {sum(a['contracts_count'] for a in agent_outputs.values())}\")\n",
        "print(f\"Total Pre-Computed Clauses: {sum(a['total_clauses'] for a in agent_outputs.values())}\")\n",
        "\n",
        "if len(agent_outputs) < 4:\n",
        "    print(\"\\nWARNING: Not all agents loaded. Some routing may fail.\")\n",
        "    print(\"   Run agents first to generate outputs, then run coordinator.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Pinecone Setup and Agent Output Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PINECONE SETUP AND DATA UPLOAD\n",
            "Creating Pinecone index: contract-agents\n",
            "Index 'contract-agents' created successfully\n",
            "Connected to index: contract-agents\n"
          ]
        }
      ],
      "source": [
        "print(\"PINECONE SETUP AND DATA UPLOAD\")\n",
        "\n",
        "PINECONE_API_KEY = 'pcsk_3ftgmC_GzUZkRCnxa2jmDu7TTjnGWjC3QaN8c2PcQ5KN5PUSyQaEmmcdGUGu2BLd4Y7TRn'\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "INDEX_NAME = 'contract-agents'\n",
        "DIMENSION = 384\n",
        "\n",
        "existing_indexes = [idx.name for idx in pc.list_indexes()]\n",
        "if INDEX_NAME not in existing_indexes:\n",
        "    print(f\"Creating Pinecone index: {INDEX_NAME}\")\n",
        "    pc.create_index(\n",
        "        name=INDEX_NAME,\n",
        "        dimension=DIMENSION,\n",
        "        metric='cosine',\n",
        "        spec=ServerlessSpec(cloud='aws', region='us-east-1')\n",
        "    )\n",
        "    print(f\"Index '{INDEX_NAME}' created successfully\")\n",
        "else:\n",
        "    print(f\"Index '{INDEX_NAME}' already exists\")\n",
        "\n",
        "index = pc.Index(INDEX_NAME)\n",
        "print(f\"Connected to index: {INDEX_NAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INSTALLING SENTENCE TRANSFORMERS FOR PROPER EMBEDDINGS\n",
            "sentence-transformers already installed\n",
            "\n",
            "Loading embedding model...\n",
            "Embedding model loaded: all-MiniLM-L6-v2 (384 dimensions)\n",
            "Embedding function ready\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"INSTALLING SENTENCE TRANSFORMERS FOR PROPER EMBEDDINGS\")\n",
        "\n",
        "try:\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    print(\"sentence-transformers already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing sentence-transformers...\")\n",
        "    import subprocess\n",
        "    subprocess.check_call(['pip', 'install', 'sentence-transformers', '-q'])\n",
        "    from sentence_transformers import SentenceTransformer\n",
        "    print(\"sentence-transformers installed successfully\")\n",
        "\n",
        "print(\"\\nLoading embedding model...\")\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Embedding model loaded: all-MiniLM-L6-v2 (384 dimensions)\")\n",
        "\n",
        "def create_embedding(text):\n",
        "    embedding = embedding_model.encode(text, convert_to_numpy=True)\n",
        "    return embedding.tolist()\n",
        "\n",
        "print(\"Embedding function ready\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LOADING AGENT OUTPUT JSON FILES\n"
          ]
        }
      ],
      "source": [
        "print(\"LOADING AGENT OUTPUT JSON FILES\")\n",
        "\n",
        "agent_file_paths = {\n",
        "    'legal': '../Data/Results/Legal_Agent',\n",
        "    'compliance': '../Data/Results/Compliance_Agent',\n",
        "    'finance': '../Data/Results/Finance_Agent',\n",
        "    'operations': '../Data/Results/Operations_Agent'\n",
        "}\n",
        "\n",
        "if not os.path.exists('../Data/Results/Legal_Agent'):\n",
        "    print(\"Using files from current directory...\")\n",
        "    agent_file_paths = {\n",
        "        'legal': '.',\n",
        "        'compliance': '.',\n",
        "        'finance': '.',\n",
        "        'operations': '.'\n",
        "    }\n",
        "\n",
        "def find_agent_file(directory, agent_name):\n",
        "    if not os.path.exists(directory):\n",
        "        return None\n",
        "    \n",
        "    json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
        "    \n",
        "    for filename in json_files:\n",
        "        if agent_name in filename.lower() and 'output' in filename.lower():\n",
        "            return os.path.join(directory, filename)\n",
        "    \n",
        "    if json_files:\n",
        "        return os.path.join(directory, json_files[0])\n",
        "    \n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CREATING VECTORS WITH SEMANTIC EMBEDDINGS\n",
            "  LEGAL: 2 clauses from legal_agent_output.json\n",
            "  COMPLIANCE: 1 clauses from compliance_agent_output.json\n",
            "  FINANCE: 3 clauses from finance_agent_output.json\n",
            "  OPERATIONS: 2 clauses from operations_agent_output.json\n"
          ]
        }
      ],
      "source": [
        "print(\"CREATING VECTORS WITH SEMANTIC EMBEDDINGS\")\n",
        "\n",
        "vectors_to_upsert = []\n",
        "agent_summary = {}\n",
        "\n",
        "for agent_name, directory in agent_file_paths.items():\n",
        "    agent_file = find_agent_file(directory, agent_name)\n",
        "    \n",
        "    if not agent_file:\n",
        "        direct_file = f\"{agent_name}_agent_output.json\"\n",
        "        if os.path.exists(direct_file):\n",
        "            agent_file = direct_file\n",
        "    \n",
        "    if agent_file and os.path.exists(agent_file):\n",
        "        try:\n",
        "            with open(agent_file, 'r', encoding='utf-8') as f:\n",
        "                agent_data = json.load(f)\n",
        "            \n",
        "            output_data = agent_data.get('output', {})\n",
        "            clauses = output_data.get('extracted_clauses', [])\n",
        "            risk_level = output_data.get('risk_level', 'unknown')\n",
        "            confidence = output_data.get('confidence', 0.0)\n",
        "            timestamp = agent_data.get('timestamp', '')\n",
        "            \n",
        "            for idx, clause in enumerate(clauses):\n",
        "                if clause and len(clause.strip()) > 0:\n",
        "                    vector_id = f\"{agent_name}_{idx}\"\n",
        "                    \n",
        "                    embedding = create_embedding(clause)\n",
        "                    \n",
        "                    metadata = {\n",
        "                        'agent': agent_name,\n",
        "                        'clause': clause[:1000],\n",
        "                        'clause_full': clause,\n",
        "                        'risk_level': risk_level,\n",
        "                        'confidence': float(confidence),\n",
        "                        'timestamp': timestamp,\n",
        "                        'clause_index': idx\n",
        "                    }\n",
        "                    vectors_to_upsert.append((vector_id, embedding, metadata))\n",
        "            \n",
        "            agent_summary[agent_name] = {\n",
        "                'file': os.path.basename(agent_file),\n",
        "                'clauses': len(clauses),\n",
        "                'risk_level': risk_level,\n",
        "                'confidence': confidence\n",
        "            }\n",
        "            \n",
        "            print(f\"  {agent_name.upper()}: {len(clauses)} clauses from {os.path.basename(agent_file)}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  {agent_name.upper()}: Error loading file - {str(e)}\")\n",
        "    else:\n",
        "        print(f\"  {agent_name.upper()}: File not found in {directory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "UPLOADING 8 VECTORS TO PINECONE\n",
            "  Uploaded batch 1/1\n",
            "Successfully uploaded 8 vectors to Pinecone\n",
            "PINECONE INDEX STATS\n",
            "  Total vectors: 8\n",
            "  Dimension: 384\n",
            "  Index fullness: 0.0\n",
            "AGENT DATA SUMMARY\n",
            "\n",
            "LEGAL:\n",
            "  File: legal_agent_output.json\n",
            "  Clauses: 2\n",
            "  Risk Level: low\n",
            "  Confidence: 0.85\n",
            "\n",
            "COMPLIANCE:\n",
            "  File: compliance_agent_output.json\n",
            "  Clauses: 1\n",
            "  Risk Level: high\n",
            "  Confidence: 1.0\n",
            "\n",
            "FINANCE:\n",
            "  File: finance_agent_output.json\n",
            "  Clauses: 3\n",
            "  Risk Level: medium\n",
            "  Confidence: 0.7\n",
            "\n",
            "OPERATIONS:\n",
            "  File: operations_agent_output.json\n",
            "  Clauses: 2\n",
            "  Risk Level: medium\n",
            "  Confidence: 0.8\n",
            "PINECONE SETUP AND DATA UPLOAD COMPLETE!\n"
          ]
        }
      ],
      "source": [
        "if vectors_to_upsert:\n",
        "    print(f\"UPLOADING {len(vectors_to_upsert)} VECTORS TO PINECONE\")\n",
        "\n",
        "    batch_size = 100\n",
        "    for i in range(0, len(vectors_to_upsert), batch_size):\n",
        "        batch = vectors_to_upsert[i:i+batch_size]\n",
        "        index.upsert(vectors=batch)\n",
        "        print(f\"  Uploaded batch {i//batch_size + 1}/{(len(vectors_to_upsert)-1)//batch_size + 1}\")\n",
        "    \n",
        "    print(f\"Successfully uploaded {len(vectors_to_upsert)} vectors to Pinecone\")\n",
        "    \n",
        "    import time\n",
        "    time.sleep(2)  \n",
        "    stats = index.describe_index_stats()\n",
        "    \n",
        "    print(f\"PINECONE INDEX STATS\")\n",
        "    print(f\"  Total vectors: {stats.total_vector_count}\")\n",
        "    print(f\"  Dimension: {stats.dimension}\")\n",
        "    print(f\"  Index fullness: {stats.index_fullness}\")\n",
        "    \n",
        "    print(f\"AGENT DATA SUMMARY\")\n",
        "    for agent, info in agent_summary.items():\n",
        "        print(f\"\\n{agent.upper()}:\")\n",
        "        print(f\"  File: {info['file']}\")\n",
        "        print(f\"  Clauses: {info['clauses']}\")\n",
        "        print(f\"  Risk Level: {info['risk_level']}\")\n",
        "        print(f\"  Confidence: {info['confidence']}\")\n",
        "else:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"ERROR: No vectors to upload!\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(\"Please ensure agent output JSON files are available.\")\n",
        "    print(f\"\\nSearched in:\")\n",
        "    for agent, path in agent_file_paths.items():\n",
        "        print(f\"  {agent}: {path}\")\n",
        "\n",
        "print(\"PINECONE SETUP AND DATA UPLOAD COMPLETE!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### All the Agents are loaded - along with the outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Defining Coordinator Routing Rules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DYNAMIC COORDINATOR WITH GEMMA-2-9B-IT\n",
            "\n",
            "Dynamic Coordinator initialized\n",
            "Model: gemma-2-9b-it\n",
            "Ollama URL: http://localhost:11434/api/generate\n",
            "\n",
            "Coordinator will use LLM reasoning to route queries\n"
          ]
        }
      ],
      "source": [
        "print(\"DYNAMIC COORDINATOR WITH GEMMA-2-9B-IT\")\n",
        "\n",
        "OLLAMA_MODEL = \"gemma-2-9b-it\"\n",
        "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "\n",
        "def query_ollama(prompt, model=OLLAMA_MODEL):\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            OLLAMA_URL,\n",
        "            json={\n",
        "                \"model\": model,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": False\n",
        "            },\n",
        "            timeout=30\n",
        "        )\n",
        "        if response.status_code == 200:\n",
        "            return response.json().get('response', '')\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Ollama error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def dynamic_route_query(query):\n",
        "    \n",
        "    coordinator_prompt = f\"\"\"You are a contract analysis coordinator. Given a user query about a contract, \n",
        "determine which specialized agents should analyze it.\n",
        "\n",
        "Available agents:\n",
        "- Legal: termination, liability, jurisdiction, governing law, indemnity\n",
        "- Compliance: data protection, GDPR, privacy, audit, regulatory requirements\n",
        "- Finance: payment terms, fees, penalties, costs, invoicing\n",
        "- Operations: deliverables, timelines, SLAs, performance, milestones\n",
        "\n",
        "User Query: \"{query}\"\n",
        "\n",
        "Respond ONLY with a JSON object in this exact format:\n",
        "{{\n",
        "  \"agents\": [\"agent1\", \"agent2\"],\n",
        "  \"reasoning\": \"brief explanation\"\n",
        "}}\n",
        "\n",
        "JSON Response:\"\"\"\n",
        "    \n",
        "    response = query_ollama(coordinator_prompt)\n",
        "    \n",
        "    if response:\n",
        "        try:\n",
        "            import re\n",
        "            json_match = re.search(r'\\{[^}]+\\}', response, re.DOTALL)\n",
        "            if json_match:\n",
        "                result = json.loads(json_match.group())\n",
        "                return {\n",
        "                    'agents': result.get('agents', []),\n",
        "                    'reasoning': result.get('reasoning', ''),\n",
        "                    'approach': 'dynamic_llm_coordinator'\n",
        "                }\n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    return {\n",
        "        'agents': ['legal', 'compliance', 'finance', 'operations'],\n",
        "        'reasoning': 'Fallback: routing to all agents',\n",
        "        'approach': 'fallback'\n",
        "    }\n",
        "\n",
        "print(\"\\nDynamic Coordinator initialized\")\n",
        "print(f\"Model: {OLLAMA_MODEL}\")\n",
        "print(f\"Ollama URL: {OLLAMA_URL}\")\n",
        "print(\"\\nCoordinator will use LLM reasoning to route queries\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Keywords for Each Agent\n",
        "1. Legal - termination, terminate, cancel, cancellation, governing law, jurisdiction, venue, applicable law, liability, liable, damages, limitation of liability \n",
        "2. Compliance - gdpr, data protection, privacy, personal data, audit, auditing, inspection, review, regulatory, regulation, compliance, legal requirement\n",
        "3. Finance - payment, pay, paid, payable, remittance, fee, fees, charge, charges, cost, penalty, penalties, late fee, late payment\n",
        "4. Operations - deliverable, deliver, delivery, output, timeline, deadline, schedule, due date, sla, service level, performance, kpi, metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Defining Routing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DYNAMIC COORDINATOR WITH GEMMA-2-9B-IT\n",
            "\n",
            "Checking Ollama setup...\n",
            "URL: http://localhost:11434/api/generate\n",
            "Ollama is running\n",
            "  Available models: gemma2:9b\n",
            "  Using model: gemma2:9b\n",
            "\n",
            "Testing model connection...\n",
            "Model gemma2:9b is responding\n",
            "  Test response: Hello! ðŸ‘‹\n",
            "\n",
            "How can I help you today? ðŸ˜Š...\n",
            "Dynamic coordinator initialized!\n"
          ]
        }
      ],
      "source": [
        "print(\"DYNAMIC COORDINATOR WITH GEMMA-2-9B-IT\")\n",
        "\n",
        "OLLAMA_MODEL = \"gemma2:9b\" \n",
        "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "\n",
        "def check_ollama_models():\n",
        "    \"\"\"Check available Ollama models\"\"\"\n",
        "    try:\n",
        "        response = requests.get(\"http://localhost:11434/api/tags\", timeout=5)\n",
        "        if response.status_code == 200:\n",
        "            models = response.json().get('models', [])\n",
        "            return [m['name'] for m in models]\n",
        "        return []\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "def query_ollama(prompt, model=OLLAMA_MODEL):\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            OLLAMA_URL,\n",
        "            json={\n",
        "                \"model\": model,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": False,\n",
        "                \"options\": {\n",
        "                    \"temperature\": 0.3,\n",
        "                    \"top_p\": 0.9,\n",
        "                    \"num_predict\": 150\n",
        "                }\n",
        "            },\n",
        "            timeout=60\n",
        "        )\n",
        "        if response.status_code == 200:\n",
        "            return response.json().get('response', '')\n",
        "        else:\n",
        "            print(f\"Ollama HTTP error: {response.status_code}\")\n",
        "            print(f\"Response: {response.text[:200]}\")\n",
        "            return None\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        print(\"ERROR: Cannot connect to Ollama. Make sure Ollama is running (ollama serve)\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Ollama error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def dynamic_route_query(query):\n",
        "    \n",
        "    coordinator_prompt = f\"\"\"You are an intelligent contract analysis coordinator. Analyze the user's query and determine which specialized agents should handle it.\n",
        "\n",
        "Available Agents:\n",
        "1. LEGAL - Handles: termination clauses, liability, indemnification, jurisdiction, governing law, dispute resolution, breach of contract, legal rights\n",
        "2. COMPLIANCE - Handles: data protection, GDPR, privacy regulations, audit requirements, regulatory compliance, confidentiality, certification standards\n",
        "3. FINANCE - Handles: payment terms, fees, invoicing, costs, penalties, late payments, reimbursement, financial obligations\n",
        "4. OPERATIONS - Handles: deliverables, timelines, milestones, SLAs, service levels, performance metrics, KPIs, project schedules\n",
        "\n",
        "User Query: \"{query}\"\n",
        "\n",
        "Based on the query, select the most relevant agent(s). You can select multiple agents if the query covers multiple domains.\n",
        "\n",
        "Respond with ONLY a valid JSON object (no other text):\n",
        "{{\n",
        "  \"agents\": [\"agent1\", \"agent2\"],\n",
        "  \"reasoning\": \"brief explanation of why these agents were selected\"\n",
        "}}\n",
        "\n",
        "Valid agent names: legal, compliance, finance, operations\n",
        "\n",
        "JSON Response:\"\"\"\n",
        "    \n",
        "    print(f\"\\nQuerying {OLLAMA_MODEL} coordinator...\")\n",
        "    response = query_ollama(coordinator_prompt)\n",
        "    \n",
        "    if response:\n",
        "        try:\n",
        "            import re\n",
        "            \n",
        "            json_match = re.search(r'\\{[^{}]*\"agents\"[^{}]*\\}', response, re.DOTALL)\n",
        "            if json_match:\n",
        "                json_str = json_match.group()\n",
        "                result = json.loads(json_str)\n",
        "                \n",
        "                valid_agents = ['legal', 'compliance', 'finance', 'operations']\n",
        "                selected_agents = [a.lower() for a in result.get('agents', []) if a.lower() in valid_agents]\n",
        "                \n",
        "                if selected_agents:\n",
        "                    return {\n",
        "                        'agents': selected_agents,\n",
        "                        'reasoning': result.get('reasoning', 'LLM-based routing'),\n",
        "                        'approach': 'dynamic_llm_coordinator',\n",
        "                        'model': OLLAMA_MODEL,\n",
        "                        'scores': {agent: 1 for agent in selected_agents}\n",
        "                    }\n",
        "            \n",
        "            agents_found = []\n",
        "            for agent in ['legal', 'compliance', 'finance', 'operations']:\n",
        "                if agent in response.lower():\n",
        "                    agents_found.append(agent)\n",
        "            \n",
        "            if agents_found:\n",
        "                return {\n",
        "                    'agents': agents_found,\n",
        "                    'reasoning': 'Extracted from LLM response',\n",
        "                    'approach': 'dynamic_llm_coordinator_parsed',\n",
        "                    'model': OLLAMA_MODEL,\n",
        "                    'scores': {agent: 1 for agent in agents_found}\n",
        "                }\n",
        "                \n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"JSON parsing error: {str(e)}\")\n",
        "            print(f\"Response was: {response[:200]}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing LLM response: {str(e)}\")\n",
        "    \n",
        "    print(\"Falling back to keyword-based routing...\")\n",
        "    return fallback_keyword_routing(query)\n",
        "\n",
        "\n",
        "def fallback_keyword_routing(query):\n",
        "    query_lower = query.lower()\n",
        "    \n",
        "    keyword_rules = {\n",
        "        'legal': ['termination', 'terminate', 'cancel', 'liability', 'liable', \n",
        "                  'jurisdiction', 'governing law', 'indemnif', 'breach', 'dispute'],\n",
        "        'compliance': ['gdpr', 'data protection', 'privacy', 'audit', 'compliance', \n",
        "                       'regulation', 'confidential', 'security', 'certification'],\n",
        "        'finance': ['payment', 'fee', 'cost', 'invoice', 'penalty', 'charge', \n",
        "                    'financial', 'reimburs', 'budget', 'expense'],\n",
        "        'operations': ['deliverable', 'timeline', 'milestone', 'sla', 'performance', \n",
        "                       'schedule', 'deadline', 'kpi', 'service level']\n",
        "    }\n",
        "    \n",
        "    agent_scores = defaultdict(int)\n",
        "    for agent, keywords in keyword_rules.items():\n",
        "        for keyword in keywords:\n",
        "            if keyword in query_lower:\n",
        "                agent_scores[agent] += 1\n",
        "    \n",
        "    if agent_scores:\n",
        "        routed_agents = sorted(agent_scores.keys(), key=lambda a: agent_scores[a], reverse=True)\n",
        "        return {\n",
        "            'agents': routed_agents,\n",
        "            'reasoning': 'Keyword-based fallback routing',\n",
        "            'approach': 'fallback_keyword',\n",
        "            'scores': dict(agent_scores)\n",
        "        }\n",
        "    else:\n",
        "        return {\n",
        "            'agents': ['legal', 'compliance', 'finance', 'operations'],\n",
        "            'reasoning': 'No specific matches - routing to all agents',\n",
        "            'approach': 'fallback_all',\n",
        "            'scores': {}\n",
        "        }\n",
        "\n",
        "\n",
        "def route_query_verbose(query):\n",
        "   \n",
        "    print(\"DYNAMIC ROUTING WITH GEMMA-2-9B-IT\")\n",
        "\n",
        "    if len(query) > 100:\n",
        "        print(f\"Query: \\\"{query[:100]}...\\\"\")\n",
        "    else:\n",
        "        print(f\"Query: \\\"{query}\\\"\")\n",
        "    \n",
        "    result = dynamic_route_query(query)\n",
        "    \n",
        "    print(f\"\\nApproach: {result['approach'].upper().replace('_', ' ')}\")\n",
        "    print(f\"Model: {result.get('model', 'N/A')}\")\n",
        "    print(f\"Agents Routed: {', '.join(result['agents']) if result['agents'] else 'None'}\")\n",
        "    print(f\"Reasoning: {result['reasoning']}\")\n",
        "    \n",
        "    if result.get('scores'):\n",
        "        print(f\"\\nAgent Scores:\")\n",
        "        for agent in result['agents']:\n",
        "            score = result['scores'].get(agent, 0)\n",
        "            print(f\"   {agent.upper()}: {score}\")\n",
        "    \n",
        "    print(f\"\\nAction: Retrieve relevant data from Pinecone vector store\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(f\"\\nChecking Ollama setup...\")\n",
        "print(f\"URL: {OLLAMA_URL}\")\n",
        "\n",
        "available_models = check_ollama_models()\n",
        "if available_models:\n",
        "    print(f\"Ollama is running\")\n",
        "    print(f\"  Available models: {', '.join(available_models)}\")\n",
        "    \n",
        "    gemma_models = [m for m in available_models if 'gemma' in m.lower() and '9b' in m]\n",
        "    if gemma_models:\n",
        "        OLLAMA_MODEL = gemma_models[0]\n",
        "        print(f\"  Using model: {OLLAMA_MODEL}\")\n",
        "    else:\n",
        "        print(f\"  WARNING: gemma-2-9b not found in available models\")\n",
        "        print(f\"  Please install it: ollama pull gemma2:9b\")\n",
        "        print(f\"  Current model setting: {OLLAMA_MODEL}\")\n",
        "else:\n",
        "    print(\"Cannot connect to Ollama or no models installed\")\n",
        "\n",
        "\n",
        "print(f\"\\nTesting model connection...\")\n",
        "test_response = query_ollama(\"Hello\", model=OLLAMA_MODEL)\n",
        "if test_response:\n",
        "    print(f\"Model {OLLAMA_MODEL} is responding\")\n",
        "    print(f\"  Test response: {test_response[:100]}...\")\n",
        "else:\n",
        "    print(f\"Model {OLLAMA_MODEL} is not responding\")\n",
        "\n",
        "print(\"Dynamic coordinator initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Testing Routing Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TESTING ROUTING LOGIC\n",
            "\n",
            "Testing Routing with 12 Sample Queries:\n",
            "================================================================================\n",
            "\n",
            "Test 1/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"What are the termination and liability clauses?\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: legal\n",
            "Reasoning: The query specifically asks about termination and liability clauses, which fall under the domain of contract law handled by the LEGAL agent.\n",
            "\n",
            "Agent Scores:\n",
            "   LEGAL: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 2/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"Does this contract comply with GDPR and data protection regulations?\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: compliance\n",
            "Reasoning: The query specifically asks about GDPR and data protection regulations, which fall under the purview of the COMPLIANCE agent.\n",
            "\n",
            "Agent Scores:\n",
            "   COMPLIANCE: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 3/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"What are the payment terms and late fee penalties?\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: finance\n",
            "Reasoning: The query specifically asks about payment terms and late fee penalties, which fall under the domain of financial obligations.\n",
            "\n",
            "Agent Scores:\n",
            "   FINANCE: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 4/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"What are the deliverable timelines and milestones?\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: operations\n",
            "Reasoning: The query specifically asks about deliverables, timelines, and milestones, which fall under the domain of Operations.\n",
            "\n",
            "Agent Scores:\n",
            "   OPERATIONS: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 5/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"Show me termination, GDPR compliance, and payment terms\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: legal, compliance, finance\n",
            "Reasoning: The query requests information on termination clauses (legal), GDPR compliance (compliance), and payment terms (finance).\n",
            "\n",
            "Agent Scores:\n",
            "   LEGAL: 1\n",
            "   COMPLIANCE: 1\n",
            "   FINANCE: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 6/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"What are the service level agreements and performance standards?\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: operations\n",
            "Reasoning: The query specifically asks about service level agreements (SLAs) and performance standards, which fall under the domain of Operations.\n",
            "\n",
            "Agent Scores:\n",
            "   OPERATIONS: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 7/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"Indemnification and breach of contract details\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: legal\n",
            "Reasoning: The query specifically mentions 'indemnification and breach of contract', which fall under the domain of contract law handled by the LEGAL agent.\n",
            "\n",
            "Agent Scores:\n",
            "   LEGAL: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 8/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"ISO 27001 certification requirements and audit obligations\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: compliance\n",
            "Reasoning: The query specifically mentions ISO 27001 certification and audit obligations, which fall under the domain of regulatory compliance and data protection handled by the COMPLIANCE agent.\n",
            "\n",
            "Agent Scores:\n",
            "   COMPLIANCE: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 9/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"Invoice payment schedule with penalty interest\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: finance\n",
            "Reasoning: The query specifically mentions 'invoice payment schedule with penalty interest', which falls under financial terms and obligations.\n",
            "\n",
            "Agent Scores:\n",
            "   FINANCE: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 10/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"Deliverable acceptance criteria and performance KPIs\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: operations\n",
            "Reasoning: The query focuses on deliverables, performance metrics, and KPIs, which fall under the domain of Operations.\n",
            "\n",
            "Agent Scores:\n",
            "   OPERATIONS: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 11/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"What is in this contract?\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: legal, compliance, finance, operations\n",
            "Reasoning: The query 'What is in this contract?' is broad and could encompass elements of legal clauses, compliance requirements, financial terms, and operational details.\n",
            "\n",
            "Agent Scores:\n",
            "   LEGAL: 1\n",
            "   COMPLIANCE: 1\n",
            "   FINANCE: 1\n",
            "   OPERATIONS: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "\n",
            "Test 12/12\n",
            "DYNAMIC ROUTING WITH GEMMA-2-9B-IT\n",
            "Query: \"Jurisdiction and applicable governing law\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Approach: DYNAMIC LLM COORDINATOR\n",
            "Model: gemma2:9b\n",
            "Agents Routed: legal\n",
            "Reasoning: The query specifically mentions 'Jurisdiction and applicable governing law', which fall directly under the domain of contract law handled by the LEGAL agent.\n",
            "\n",
            "Agent Scores:\n",
            "   LEGAL: 1\n",
            "\n",
            "Action: Retrieve relevant data from Pinecone vector store\n",
            "ROUTING STATISTICS\n",
            "Total Test Queries: 12\n",
            "Single-Agent Queries: 10 (83.3%)\n",
            "Multi-Agent Queries: 2 (16.7%)\n",
            "Fallback Queries: 0 (0.0%)\n",
            "ROUTING APPROACH BREAKDOWN\n",
            "Dynamic Llm Coordinator        : 12 (100.0%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "AGENT ROUTING FREQUENCY\n",
            "LEGAL        :  5 queries ( 41.7%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "COMPLIANCE   :  4 queries ( 33.3%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "FINANCE      :  4 queries ( 33.3%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "OPERATIONS   :  4 queries ( 33.3%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n"
          ]
        }
      ],
      "source": [
        "print(\"TESTING ROUTING LOGIC\")\n",
        "\n",
        "test_queries = [\n",
        "    \"What are the termination and liability clauses?\",\n",
        "    \"Does this contract comply with GDPR and data protection regulations?\",\n",
        "    \"What are the payment terms and late fee penalties?\",\n",
        "    \"What are the deliverable timelines and milestones?\",\n",
        "    \n",
        "    \"Show me termination, GDPR compliance, and payment terms\",\n",
        "    \"What are the service level agreements and performance standards?\",\n",
        "    \n",
        "    \"Indemnification and breach of contract details\",\n",
        "    \"ISO 27001 certification requirements and audit obligations\",\n",
        "    \"Invoice payment schedule with penalty interest\",\n",
        "    \"Deliverable acceptance criteria and performance KPIs\",\n",
        "    \n",
        "    \"What is in this contract?\", \n",
        "    \"Jurisdiction and applicable governing law\",\n",
        "]\n",
        "\n",
        "print(f\"\\nTesting Routing with {len(test_queries)} Sample Queries:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "test_results = []\n",
        "\n",
        "for idx, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\nTest {idx}/{len(test_queries)}\")\n",
        "    result = route_query_verbose(query)\n",
        "    test_results.append({\n",
        "        \"query\": query,\n",
        "        \"result\": result\n",
        "    })\n",
        "\n",
        "agent_routing_counts = defaultdict(int)\n",
        "multi_agent_queries = 0\n",
        "fallback_queries = 0\n",
        "approach_counts = defaultdict(int)\n",
        "\n",
        "for test in test_results:\n",
        "    agents = test[\"result\"][\"agents\"]\n",
        "    approach = test[\"result\"].get(\"approach\", \"unknown\")\n",
        "    \n",
        "    if len(agents) > 1:\n",
        "        multi_agent_queries += 1\n",
        "    \n",
        "    if approach in [\"fallback_keyword\", \"fallback_all\"]:\n",
        "        fallback_queries += 1\n",
        "    \n",
        "    approach_counts[approach] += 1\n",
        "    \n",
        "    for agent in agents:\n",
        "        agent_routing_counts[agent] += 1\n",
        "\n",
        "print(\"ROUTING STATISTICS\")\n",
        "print(f\"Total Test Queries: {len(test_results)}\")\n",
        "print(f\"Single-Agent Queries: {len(test_results) - multi_agent_queries} ({((len(test_results) - multi_agent_queries)/len(test_results)*100):.1f}%)\")\n",
        "print(f\"Multi-Agent Queries: {multi_agent_queries} ({(multi_agent_queries/len(test_results)*100):.1f}%)\")\n",
        "print(f\"Fallback Queries: {fallback_queries} ({(fallback_queries/len(test_results)*100):.1f}%)\")\n",
        "\n",
        "print(\"ROUTING APPROACH BREAKDOWN\")\n",
        "for approach, count in sorted(approach_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "    percentage = (count / len(test_results)) * 100\n",
        "    approach_name = approach.replace('_', ' ').title()\n",
        "    bar = \"â–ˆ\" * int(percentage / 5)\n",
        "    print(f\"{approach_name:30} : {count:2} ({percentage:5.1f}%) {bar}\")\n",
        "\n",
        "print(\"AGENT ROUTING FREQUENCY\")\n",
        "for agent, count in sorted(agent_routing_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "    percentage = (count / len(test_results)) * 100\n",
        "    bar = \"â–ˆ\" * int(percentage / 5)\n",
        "    print(f\"{agent.upper():12} : {count:2} queries ({percentage:5.1f}%) {bar}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Queries - Routing to Agent as per Keywords\n",
        "1. Operations - 4 matches\n",
        "2. Legal - 6 matches\n",
        "3. Compliance - 4 matches\n",
        "4. Finance - 4 matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Defining Coordinator Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DYNAMIC COORDINATOR EXECUTION\n",
            "\n",
            "Dynamic coordinator execution functions defined\n"
          ]
        }
      ],
      "source": [
        "print(\"DYNAMIC COORDINATOR EXECUTION\")\n",
        "\n",
        "def retrieve_from_pinecone(query, agent_filter=None, top_k=3):\n",
        "\n",
        "    try:\n",
        "        query_embedding = create_embedding(query)\n",
        "        \n",
        "        filter_dict = None\n",
        "        if agent_filter:\n",
        "            if isinstance(agent_filter, list):\n",
        "                filter_dict = {\"agent\": {\"$in\": agent_filter}}\n",
        "            else:\n",
        "                filter_dict = {\"agent\": {\"$eq\": agent_filter}}\n",
        "        \n",
        "        results = index.query(\n",
        "            vector=query_embedding,\n",
        "            top_k=top_k,\n",
        "            filter=filter_dict,\n",
        "            include_metadata=True\n",
        "        )\n",
        "        \n",
        "        return results\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  Pinecone retrieval error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def route_query_with_retrieval(query):\n",
        "    \n",
        "    print(\"ROUTING AND RETRIEVAL\")\n",
        "   \n",
        "    routing_result = dynamic_route_query(query)\n",
        "    \n",
        "    print(f\"\\nCoordinator Decision:\")\n",
        "    print(f\"  Agents: {', '.join(routing_result['agents'])}\")\n",
        "    print(f\"  Reasoning: {routing_result['reasoning']}\")\n",
        "    print(f\"  Approach: {routing_result['approach']}\")\n",
        "    \n",
        "    print(f\"\\nRetrieving from Pinecone...\")\n",
        "    retrieved_data = {}\n",
        "    \n",
        "    for agent in routing_result['agents']:\n",
        "        results = retrieve_from_pinecone(query, agent_filter=agent, top_k=3)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            filtered_matches = [m for m in results.matches if m.score > 0.3]\n",
        "            \n",
        "            clauses = [match.metadata.get('clause_full', match.metadata.get('clause', '')) \n",
        "                      for match in filtered_matches]\n",
        "            scores = [match.score for match in filtered_matches]\n",
        "            \n",
        "            retrieved_data[agent] = {\n",
        "                'clauses': clauses,\n",
        "                'scores': scores,\n",
        "                'count': len(clauses)\n",
        "            }\n",
        "            \n",
        "            print(f\"  {agent.upper()}: {len(clauses)} clauses (scores: {[f'{s:.3f}' for s in scores]})\")\n",
        "        else:\n",
        "            retrieved_data[agent] = {\n",
        "                'clauses': [],\n",
        "                'scores': [],\n",
        "                'count': 0\n",
        "            }\n",
        "            print(f\"  {agent.upper()}: No relevant clauses found\")\n",
        "    \n",
        "    routing_result['retrieved_data'] = retrieved_data\n",
        "    return routing_result\n",
        "\n",
        "\n",
        "def coordinator_execute_dynamic(query):\n",
        "    print(f\"PROCESSING QUERY\")\n",
        "    print(f\"Query: \\\"{query}\\\"\")\n",
        "    \n",
        "    routing_result = route_query_with_retrieval(query)\n",
        "    \n",
        "    results = {\n",
        "        'query': query,\n",
        "        'coordinator_model': OLLAMA_MODEL,\n",
        "        'approach': 'dynamic_llm_with_pinecone',\n",
        "        'routing': routing_result,\n",
        "        'agent_results': {},\n",
        "        'summary': {\n",
        "            'total_agents_routed': len(routing_result['agents']),\n",
        "            'total_clauses_retrieved': 0,\n",
        "            'routing_approach': routing_result['approach']\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    print(\"AGENT RESULTS\")\n",
        " \n",
        "    for agent_name in routing_result['agents']:\n",
        "        retrieved = routing_result['retrieved_data'].get(agent_name, {})\n",
        "        clauses = retrieved.get('clauses', [])\n",
        "        scores = retrieved.get('scores', [])\n",
        "        \n",
        "        results['agent_results'][agent_name] = {\n",
        "            'agent_name': agent_name,\n",
        "            'source': 'pinecone_vector_store',\n",
        "            'clauses_retrieved': len(clauses),\n",
        "            'clauses': clauses,\n",
        "            'relevance_scores': scores\n",
        "        }\n",
        "        \n",
        "        results['summary']['total_clauses_retrieved'] += len(clauses)\n",
        "        \n",
        "        print(f\"\\n{agent_name.upper()} Agent:\")\n",
        "        print(f\"  Source: Pinecone Vector Store\")\n",
        "        print(f\"  Clauses Retrieved: {len(clauses)}\")\n",
        "        \n",
        "        if scores:\n",
        "            avg_score = sum(scores) / len(scores)\n",
        "            max_score = max(scores)\n",
        "            print(f\"  Relevance - Avg: {avg_score:.3f}, Max: {max_score:.3f}\")\n",
        "        \n",
        "        if clauses:\n",
        "            preview = clauses[0][:120] + \"...\" if len(clauses[0]) > 120 else clauses[0]\n",
        "            print(f\"  Sample Clause: {preview}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "def coordinator_execute_verbose_dynamic(query):\n",
        "\n",
        "    print(f\"\\n{'#'*80}\")\n",
        "    print(\"#\" + \" \"*78 + \"#\")\n",
        "    print(\"#\" + \"DYNAMIC COORDINATOR EXECUTION\".center(78) + \"#\")\n",
        "    print(\"#\" + \" \"*78 + \"#\")\n",
        "    print(f\"{'#'*80}\\n\")\n",
        "    \n",
        "    results = coordinator_execute_dynamic(query)\n",
        "    \n",
        "    print(\"EXECUTION SUMMARY\")\n",
        "    print(f\"Coordinator Model: {results['coordinator_model']}\")\n",
        "    print(f\"Routing Approach: {results['summary']['routing_approach']}\")\n",
        "    print(f\"Overall Approach: {results['approach']}\")\n",
        "    print(f\"Agents Routed: {results['summary']['total_agents_routed']}\")\n",
        "    print(f\"Total Clauses Retrieved: {results['summary']['total_clauses_retrieved']}\")\n",
        "    \n",
        "    if results['summary']['total_clauses_retrieved'] > 0:\n",
        "        avg_per_agent = results['summary']['total_clauses_retrieved'] / results['summary']['total_agents_routed']\n",
        "        print(f\"Average Clauses per Agent: {avg_per_agent:.1f}\")\n",
        "    \n",
        "  \n",
        "    print(\"DETAILED CLAUSE RETRIEVAL\")\n",
        "\n",
        "    for agent_name, agent_result in results['agent_results'].items():\n",
        "        clauses = agent_result.get('clauses', [])\n",
        "        scores = agent_result.get('relevance_scores', [])\n",
        "        \n",
        "        print(f\"\\n{agent_name.upper()} Agent - {len(clauses)} clause(s):\")\n",
        "        \n",
        "        if clauses:\n",
        "            for idx, (clause, score) in enumerate(zip(clauses, scores), 1):\n",
        "                print(f\"\\n  [{idx}] Relevance: {score:.3f}\")\n",
        "                print(f\"      {clause[:200]}{'...' if len(clause) > 200 else ''}\")\n",
        "        else:\n",
        "            print(\"  No relevant clauses found\")\n",
        "    \n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "print(\"\\nDynamic coordinator execution functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Running Coordinator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RUNNING DYNAMIC COORDINATOR\n",
            "\n",
            "Pinecone connected: 8 vectors available\n",
            "Running Dynamic Coordinator on 5 Sample Queries\n",
            "Coordinator Model: gemma2:9b\n",
            "Vector Store: Pinecone\n",
            "Approach: Dynamic LLM-based routing with vector retrieval\n",
            "COORDINATOR RUN 1/5\n",
            "\n",
            "################################################################################\n",
            "#                                                                              #\n",
            "#                        DYNAMIC COORDINATOR EXECUTION                         #\n",
            "#                                                                              #\n",
            "################################################################################\n",
            "\n",
            "PROCESSING QUERY\n",
            "Query: \"What are the termination clauses and governing law provisions?\"\n",
            "ROUTING AND RETRIEVAL\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Coordinator Decision:\n",
            "  Agents: legal\n",
            "  Reasoning: The query specifically asks about termination clauses and governing law provisions, which fall under the domain of contract law handled by the LEGAL agent.\n",
            "  Approach: dynamic_llm_coordinator\n",
            "\n",
            "Retrieving from Pinecone...\n",
            "  LEGAL: 2 clauses (scores: ['0.631', '0.448'])\n",
            "AGENT RESULTS\n",
            "\n",
            "LEGAL Agent:\n",
            "  Source: Pinecone Vector Store\n",
            "  Clauses Retrieved: 2\n",
            "  Relevance - Avg: 0.540, Max: 0.631\n",
            "  Sample Clause: The other party shall give notice of termination in writing to the other party, which notice shall specify in reasonable...\n",
            "EXECUTION SUMMARY\n",
            "Coordinator Model: gemma2:9b\n",
            "Routing Approach: dynamic_llm_coordinator\n",
            "Overall Approach: dynamic_llm_with_pinecone\n",
            "Agents Routed: 1\n",
            "Total Clauses Retrieved: 2\n",
            "Average Clauses per Agent: 2.0\n",
            "DETAILED CLAUSE RETRIEVAL\n",
            "\n",
            "LEGAL Agent - 2 clause(s):\n",
            "\n",
            "  [1] Relevance: 0.631\n",
            "      The other party shall give notice of termination in writing to the other party, which notice shall specify in reasonable detail the event(s) of default that give rise to such termination.\n",
            "\n",
            "  [2] Relevance: 0.448\n",
            "      The other party asserts any rights in or to the terminating party's intellectual property in violation of this Agreement.\n",
            "\n",
            "................................................................................\n",
            "\n",
            "COORDINATOR RUN 2/5\n",
            "\n",
            "################################################################################\n",
            "#                                                                              #\n",
            "#                        DYNAMIC COORDINATOR EXECUTION                         #\n",
            "#                                                                              #\n",
            "################################################################################\n",
            "\n",
            "PROCESSING QUERY\n",
            "Query: \"What are the data protection and privacy obligations?\"\n",
            "ROUTING AND RETRIEVAL\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Coordinator Decision:\n",
            "  Agents: compliance\n",
            "  Reasoning: The query specifically asks about data protection and privacy obligations, which fall under the domain of compliance.\n",
            "  Approach: dynamic_llm_coordinator\n",
            "\n",
            "Retrieving from Pinecone...\n",
            "  COMPLIANCE: 1 clauses (scores: ['0.395'])\n",
            "AGENT RESULTS\n",
            "\n",
            "COMPLIANCE Agent:\n",
            "  Source: Pinecone Vector Store\n",
            "  Clauses Retrieved: 1\n",
            "  Relevance - Avg: 0.395, Max: 0.395\n",
            "  Sample Clause: The receiving party will not disclose the other party's confidential information to any third parties without the other ...\n",
            "EXECUTION SUMMARY\n",
            "Coordinator Model: gemma2:9b\n",
            "Routing Approach: dynamic_llm_coordinator\n",
            "Overall Approach: dynamic_llm_with_pinecone\n",
            "Agents Routed: 1\n",
            "Total Clauses Retrieved: 1\n",
            "Average Clauses per Agent: 1.0\n",
            "DETAILED CLAUSE RETRIEVAL\n",
            "\n",
            "COMPLIANCE Agent - 1 clause(s):\n",
            "\n",
            "  [1] Relevance: 0.395\n",
            "      The receiving party will not disclose the other party's confidential information to any third parties without the other party's prior written consent.\n",
            "\n",
            "................................................................................\n",
            "\n",
            "COORDINATOR RUN 3/5\n",
            "\n",
            "################################################################################\n",
            "#                                                                              #\n",
            "#                        DYNAMIC COORDINATOR EXECUTION                         #\n",
            "#                                                                              #\n",
            "################################################################################\n",
            "\n",
            "PROCESSING QUERY\n",
            "Query: \"Payment terms, fees, and late payment penalties\"\n",
            "ROUTING AND RETRIEVAL\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Coordinator Decision:\n",
            "  Agents: finance\n",
            "  Reasoning: The query explicitly mentions payment terms, fees, and late payment penalties, which fall under the domain of financial considerations.\n",
            "  Approach: dynamic_llm_coordinator\n",
            "\n",
            "Retrieving from Pinecone...\n",
            "  FINANCE: 2 clauses (scores: ['0.488', '0.381'])\n",
            "AGENT RESULTS\n",
            "\n",
            "FINANCE Agent:\n",
            "  Source: Pinecone Vector Store\n",
            "  Clauses Retrieved: 2\n",
            "  Relevance - Avg: 0.434, Max: 0.488\n",
            "  Sample Clause: In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, incl...\n",
            "EXECUTION SUMMARY\n",
            "Coordinator Model: gemma2:9b\n",
            "Routing Approach: dynamic_llm_coordinator\n",
            "Overall Approach: dynamic_llm_with_pinecone\n",
            "Agents Routed: 1\n",
            "Total Clauses Retrieved: 2\n",
            "Average Clauses per Agent: 2.0\n",
            "DETAILED CLAUSE RETRIEVAL\n",
            "\n",
            "FINANCE Agent - 2 clause(s):\n",
            "\n",
            "  [1] Relevance: 0.488\n",
            "      In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, including, without limitation, license fees and payments to third-party service prov...\n",
            "\n",
            "  [2] Relevance: 0.381\n",
            "      ), Recipient shall reimburse Provider for all such Out-of-Pocket Costs.\n",
            "\n",
            "................................................................................\n",
            "\n",
            "COORDINATOR RUN 4/5\n",
            "\n",
            "################################################################################\n",
            "#                                                                              #\n",
            "#                        DYNAMIC COORDINATOR EXECUTION                         #\n",
            "#                                                                              #\n",
            "################################################################################\n",
            "\n",
            "PROCESSING QUERY\n",
            "Query: \"Deliverable timelines and milestone requirements\"\n",
            "ROUTING AND RETRIEVAL\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Coordinator Decision:\n",
            "  Agents: operations\n",
            "  Reasoning: The query explicitly mentions 'deliverable timelines and milestone requirements', which fall under the domain of project management and operational aspects handled by the OPERATIONS agent.\n",
            "  Approach: dynamic_llm_coordinator\n",
            "\n",
            "Retrieving from Pinecone...\n",
            "  OPERATIONS: 1 clauses (scores: ['0.362'])\n",
            "AGENT RESULTS\n",
            "\n",
            "OPERATIONS Agent:\n",
            "  Source: Pinecone Vector Store\n",
            "  Clauses Retrieved: 1\n",
            "  Relevance - Avg: 0.362, Max: 0.362\n",
            "  Sample Clause: Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distribution of the Produ...\n",
            "EXECUTION SUMMARY\n",
            "Coordinator Model: gemma2:9b\n",
            "Routing Approach: dynamic_llm_coordinator\n",
            "Overall Approach: dynamic_llm_with_pinecone\n",
            "Agents Routed: 1\n",
            "Total Clauses Retrieved: 1\n",
            "Average Clauses per Agent: 1.0\n",
            "DETAILED CLAUSE RETRIEVAL\n",
            "\n",
            "OPERATIONS Agent - 1 clause(s):\n",
            "\n",
            "  [1] Relevance: 0.362\n",
            "      Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distribution of the Products\n",
            "\n",
            "................................................................................\n",
            "\n",
            "COORDINATOR RUN 5/5\n",
            "\n",
            "################################################################################\n",
            "#                                                                              #\n",
            "#                        DYNAMIC COORDINATOR EXECUTION                         #\n",
            "#                                                                              #\n",
            "################################################################################\n",
            "\n",
            "PROCESSING QUERY\n",
            "Query: \"Complete contract analysis covering legal, compliance, finance, and operations\"\n",
            "ROUTING AND RETRIEVAL\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Coordinator Decision:\n",
            "  Agents: legal, compliance, finance, operations\n",
            "  Reasoning: The user explicitly requests analysis covering legal, compliance, finance, and operations aspects of the contract.\n",
            "  Approach: dynamic_llm_coordinator\n",
            "\n",
            "Retrieving from Pinecone...\n",
            "  LEGAL: 0 clauses (scores: [])\n",
            "  COMPLIANCE: 0 clauses (scores: [])\n",
            "  FINANCE: 1 clauses (scores: ['0.337'])\n",
            "  OPERATIONS: 0 clauses (scores: [])\n",
            "AGENT RESULTS\n",
            "\n",
            "LEGAL Agent:\n",
            "  Source: Pinecone Vector Store\n",
            "  Clauses Retrieved: 0\n",
            "\n",
            "COMPLIANCE Agent:\n",
            "  Source: Pinecone Vector Store\n",
            "  Clauses Retrieved: 0\n",
            "\n",
            "FINANCE Agent:\n",
            "  Source: Pinecone Vector Store\n",
            "  Clauses Retrieved: 1\n",
            "  Relevance - Avg: 0.337, Max: 0.337\n",
            "  Sample Clause: In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, incl...\n",
            "\n",
            "OPERATIONS Agent:\n",
            "  Source: Pinecone Vector Store\n",
            "  Clauses Retrieved: 0\n",
            "EXECUTION SUMMARY\n",
            "Coordinator Model: gemma2:9b\n",
            "Routing Approach: dynamic_llm_coordinator\n",
            "Overall Approach: dynamic_llm_with_pinecone\n",
            "Agents Routed: 4\n",
            "Total Clauses Retrieved: 1\n",
            "Average Clauses per Agent: 0.2\n",
            "DETAILED CLAUSE RETRIEVAL\n",
            "\n",
            "LEGAL Agent - 0 clause(s):\n",
            "  No relevant clauses found\n",
            "\n",
            "COMPLIANCE Agent - 0 clause(s):\n",
            "  No relevant clauses found\n",
            "\n",
            "FINANCE Agent - 1 clause(s):\n",
            "\n",
            "  [1] Relevance: 0.337\n",
            "      In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, including, without limitation, license fees and payments to third-party service prov...\n",
            "\n",
            "OPERATIONS Agent - 0 clause(s):\n",
            "  No relevant clauses found\n",
            "OVERALL COORDINATOR STATISTICS\n",
            "\n",
            "Query Processing:\n",
            "  Total Queries Processed: 5\n",
            "  Successful: 5\n",
            "  Failed: 0\n",
            "\n",
            "Routing Statistics:\n",
            "  Total Agents Routed: 8\n",
            "  Average Agents per Query: 1.6\n",
            "\n",
            "Retrieval Statistics:\n",
            "  Total Clauses Retrieved: 7\n",
            "  Average Clauses per Query: 1.4\n",
            "AGENT USAGE FREQUENCY\n",
            "\n",
            "LEGAL       \n",
            "  Queries: 2/5 ( 40.0%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  Clauses: 2 total (1.0 avg per query)\n",
            "  Avg Relevance: 0.540\n",
            "\n",
            "COMPLIANCE  \n",
            "  Queries: 2/5 ( 40.0%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  Clauses: 1 total (0.5 avg per query)\n",
            "  Avg Relevance: 0.395\n",
            "\n",
            "FINANCE     \n",
            "  Queries: 2/5 ( 40.0%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  Clauses: 3 total (1.5 avg per query)\n",
            "  Avg Relevance: 0.402\n",
            "\n",
            "OPERATIONS  \n",
            "  Queries: 2/5 ( 40.0%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "  Clauses: 1 total (0.5 avg per query)\n",
            "  Avg Relevance: 0.362\n",
            "ROUTING APPROACH BREAKDOWN\n",
            "Dynamic Llm Coordinator        :  5 (100.0%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "TOP RELEVANCE MATCHES\n",
            "\n",
            "[1] Score: 0.631 | Agent: LEGAL\n",
            "    Query: What are the termination clauses and governing law provision...\n",
            "    Clause: The other party shall give notice of termination in writing to the other party, which notice shall specify in reasonable detail the event(s) of defaul...\n",
            "\n",
            "[2] Score: 0.488 | Agent: FINANCE\n",
            "    Query: Payment terms, fees, and late payment penalties...\n",
            "    Clause: In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, including, without limitation, lic...\n",
            "\n",
            "[3] Score: 0.448 | Agent: LEGAL\n",
            "    Query: What are the termination clauses and governing law provision...\n",
            "    Clause: The other party asserts any rights in or to the terminating party's intellectual property in violation of this Agreement....\n",
            "COORDINATOR EXECUTION COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"RUNNING DYNAMIC COORDINATOR\")\n",
        "\n",
        "try:\n",
        "    stats = index.describe_index_stats()\n",
        "    print(f\"\\nPinecone connected: {stats.total_vector_count} vectors available\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nPinecone connection error: {str(e)}\")\n",
        "    print(\"  Please run Task 1 to set up Pinecone and upload agent outputs\")\n",
        "\n",
        "sample_queries = [\n",
        "    \"What are the termination clauses and governing law provisions?\",\n",
        "    \"What are the data protection and privacy obligations?\",\n",
        "    \"Payment terms, fees, and late payment penalties\",\n",
        "    \"Deliverable timelines and milestone requirements\",\n",
        "    \"Complete contract analysis covering legal, compliance, finance, and operations\"\n",
        "]\n",
        "\n",
        "print(f\"Running Dynamic Coordinator on {len(sample_queries)} Sample Queries\")\n",
        "print(f\"Coordinator Model: {OLLAMA_MODEL}\")\n",
        "print(f\"Vector Store: Pinecone\")\n",
        "print(f\"Approach: Dynamic LLM-based routing with vector retrieval\")\n",
        "\n",
        "coordinator_results = []\n",
        "\n",
        "for idx, query in enumerate(sample_queries, 1):\n",
        "    \n",
        "    print(f\"COORDINATOR RUN {idx}/{len(sample_queries)}\")\n",
        "    \n",
        "    try:\n",
        "        result = coordinator_execute_verbose_dynamic(query)\n",
        "        coordinator_results.append(result)\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError processing query: {str(e)}\")\n",
        "       \n",
        "        coordinator_results.append({\n",
        "            'query': query,\n",
        "            'error': str(e),\n",
        "            'summary': {\n",
        "                'total_agents_routed': 0,\n",
        "                'total_clauses_retrieved': 0\n",
        "            },\n",
        "            'agent_results': {}\n",
        "        })\n",
        "    \n",
        "    if idx < len(sample_queries):\n",
        "        print(f\"\\n{'.'*80}\\n\")\n",
        "\n",
        "\n",
        "print(\"OVERALL COORDINATOR STATISTICS\")\n",
        "\n",
        "total_agents_routed = sum(r.get(\"summary\", {}).get(\"total_agents_routed\", 0) for r in coordinator_results)\n",
        "total_clauses_retrieved = sum(r.get(\"summary\", {}).get(\"total_clauses_retrieved\", 0) for r in coordinator_results)\n",
        "successful_queries = len([r for r in coordinator_results if 'error' not in r])\n",
        "\n",
        "avg_agents_per_query = total_agents_routed / successful_queries if successful_queries > 0 else 0\n",
        "avg_clauses_per_query = total_clauses_retrieved / successful_queries if successful_queries > 0 else 0\n",
        "\n",
        "print(f\"\\nQuery Processing:\")\n",
        "print(f\"  Total Queries Processed: {len(coordinator_results)}\")\n",
        "print(f\"  Successful: {successful_queries}\")\n",
        "print(f\"  Failed: {len(coordinator_results) - successful_queries}\")\n",
        "\n",
        "print(f\"\\nRouting Statistics:\")\n",
        "print(f\"  Total Agents Routed: {total_agents_routed}\")\n",
        "print(f\"  Average Agents per Query: {avg_agents_per_query:.1f}\")\n",
        "\n",
        "print(f\"\\nRetrieval Statistics:\")\n",
        "print(f\"  Total Clauses Retrieved: {total_clauses_retrieved}\")\n",
        "print(f\"  Average Clauses per Query: {avg_clauses_per_query:.1f}\")\n",
        "\n",
        "agent_usage = defaultdict(int)\n",
        "agent_clause_contribution = defaultdict(int)\n",
        "agent_relevance_scores = defaultdict(list)\n",
        "\n",
        "for result in coordinator_results:\n",
        "    if 'error' not in result:\n",
        "        for agent, agent_result in result.get(\"agent_results\", {}).items():\n",
        "            if \"error\" not in agent_result:\n",
        "                agent_usage[agent] += 1\n",
        "                clauses_count = agent_result.get(\"clauses_retrieved\", 0)\n",
        "                agent_clause_contribution[agent] += clauses_count\n",
        "                \n",
        "                scores = agent_result.get(\"relevance_scores\", [])\n",
        "                if scores:\n",
        "                    agent_relevance_scores[agent].extend(scores)\n",
        "\n",
        "\n",
        "print(\"AGENT USAGE FREQUENCY\")\n",
        "\n",
        "if agent_usage:\n",
        "    for agent, count in sorted(agent_usage.items(), key=lambda x: x[1], reverse=True):\n",
        "        percentage = (count / successful_queries) * 100 if successful_queries > 0 else 0\n",
        "        clauses = agent_clause_contribution[agent]\n",
        "        avg_clauses = clauses / count if count > 0 else 0\n",
        "        bar = \"â–ˆ\" * int(percentage / 5)\n",
        "        \n",
        "        print(f\"\\n{agent.upper():12}\")\n",
        "        print(f\"  Queries: {count}/{successful_queries} ({percentage:5.1f}%) {bar}\")\n",
        "        print(f\"  Clauses: {clauses} total ({avg_clauses:.1f} avg per query)\")\n",
        "        \n",
        "        if agent in agent_relevance_scores and agent_relevance_scores[agent]:\n",
        "            avg_relevance = sum(agent_relevance_scores[agent]) / len(agent_relevance_scores[agent])\n",
        "            print(f\"  Avg Relevance: {avg_relevance:.3f}\")\n",
        "else:\n",
        "    print(\"  No agent usage data available\")\n",
        "\n",
        "\n",
        "print(\"ROUTING APPROACH BREAKDOWN\")\n",
        "\n",
        "approach_counts = defaultdict(int)\n",
        "for result in coordinator_results:\n",
        "    if 'error' not in result:\n",
        "        approach = result.get('summary', {}).get('routing_approach', 'unknown')\n",
        "        approach_counts[approach] += 1\n",
        "\n",
        "for approach, count in sorted(approach_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "    percentage = (count / successful_queries) * 100 if successful_queries > 0 else 0\n",
        "    approach_name = approach.replace('_', ' ').title()\n",
        "    bar = \"â–ˆ\" * int(percentage / 5)\n",
        "    print(f\"{approach_name:30} : {count:2} ({percentage:5.1f}%) {bar}\")\n",
        "\n",
        "print(\"TOP RELEVANCE MATCHES\")\n",
        "\n",
        "all_matches = []\n",
        "for result in coordinator_results:\n",
        "    if 'error' not in result:\n",
        "        query = result['query']\n",
        "        for agent, agent_result in result.get('agent_results', {}).items():\n",
        "            clauses = agent_result.get('clauses', [])\n",
        "            scores = agent_result.get('relevance_scores', [])\n",
        "            for clause, score in zip(clauses, scores):\n",
        "                all_matches.append({\n",
        "                    'query': query,\n",
        "                    'agent': agent,\n",
        "                    'score': score,\n",
        "                    'clause': clause\n",
        "                })\n",
        "\n",
        "all_matches.sort(key=lambda x: x['score'], reverse=True)\n",
        "for idx, match in enumerate(all_matches[:3], 1):\n",
        "    print(f\"\\n[{idx}] Score: {match['score']:.3f} | Agent: {match['agent'].upper()}\")\n",
        "    print(f\"    Query: {match['query'][:60]}...\")\n",
        "    print(f\"    Clause: {match['clause'][:150]}...\")\n",
        "\n",
        "print(\"COORDINATOR EXECUTION COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Saving Coordinator Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAVING COORDINATOR OUTPUT\n",
            "\n",
            "Sample Result Preview:\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Query: \"What are the termination clauses and governing law provisions?\"\n",
            "Coordinator Model: gemma2:9b\n",
            "Approach: DYNAMIC LLM WITH PINECONE\n",
            "\n",
            "Routing Decision:\n",
            "  Method: Dynamic LLM-based coordination\n",
            "  Approach: dynamic_llm_coordinator\n",
            "  Agents: legal\n",
            "  Reasoning: The query specifically asks about termination clauses and governing law provisions, which fall under the domain of contract law handled by the LEGAL agent.\n",
            "\n",
            "Agent Results (from Pinecone):\n",
            "\n",
            "  LEGAL:\n",
            "    Source: pinecone_vector_store\n",
            "    Clauses Retrieved: 2\n",
            "    Avg Relevance: 0.540\n",
            "    Max Relevance: 0.631\n",
            "    Sample Clauses:\n",
            "       1. The other party shall give notice of termination in writing to the other party, which notice shall s...\n",
            "       2. The other party asserts any rights in or to the terminating party's intellectual property in violati...\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Summary:\n",
            "  Agents Routed: 1\n",
            "  Total Clauses Retrieved: 2\n",
            "  Routing Approach: dynamic_llm_coordinator\n",
            "\n",
            "================================================================================\n",
            "SAVING COORDINATOR RESULTS\n",
            "================================================================================\n",
            "\n",
            "Coordinator results saved!\n",
            "   File: coordinator_results_dynamic_20260115_141257.json\n",
            "   Location: ../Data/Results/Coordinator\n",
            "\n",
            "Output Statistics:\n",
            "   Approach: Dynamic LLM routing with Pinecone retrieval\n",
            "   Model: gemma2:9b\n",
            "   Queries: 5 (5 successful)\n",
            "   Total Agents Routed: 8\n",
            "   Total Clauses Retrieved: 7\n",
            "   Avg Agents/Query: 1.60\n",
            "   Avg Clauses/Query: 1.40\n",
            "\n",
            "Summary report saved!\n",
            "   File: coordinator_summary_dynamic_20260115_141257.txt\n",
            "   Location: ../Data/Results/Coordinator\n",
            "FILES GENERATED (DYNAMIC COORDINATOR)\n",
            "\n",
            "1. coordinator_results_dynamic_20260115_141257.json\n",
            "\n",
            "2. coordinator_summary_dynamic_20260115_141257.txt\n",
            "All coordinator outputs saved successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"SAVING COORDINATOR OUTPUT\")\n",
        "\n",
        "if coordinator_results:\n",
        "    sample_result = coordinator_results[0]\n",
        "    \n",
        "    print(f\"\\nSample Result Preview:\")\n",
        "    print(f\"{'â”€'*80}\")\n",
        "    print(f\"Query: \\\"{sample_result['query']}\\\"\")\n",
        "    print(f\"Coordinator Model: {sample_result.get('coordinator_model', 'N/A')}\")\n",
        "    print(f\"Approach: {sample_result['approach'].upper().replace('_', ' ')}\")\n",
        "    \n",
        "    print(f\"\\nRouting Decision:\")\n",
        "    routing = sample_result.get('routing', {})\n",
        "    print(f\"  Method: Dynamic LLM-based coordination\")\n",
        "    print(f\"  Approach: {routing.get('approach', 'N/A')}\")\n",
        "    print(f\"  Agents: {', '.join(routing.get('agents', []))}\")\n",
        "    print(f\"  Reasoning: {routing.get('reasoning', 'N/A')}\")\n",
        "    \n",
        "    print(f\"\\nAgent Results (from Pinecone):\")\n",
        "    for agent_name, agent_result in sample_result.get(\"agent_results\", {}).items():\n",
        "        print(f\"\\n  {agent_name.upper()}:\")\n",
        "        if \"error\" in agent_result:\n",
        "            print(f\"    Error: {agent_result['error']}\")\n",
        "        else:\n",
        "            print(f\"    Source: {agent_result.get('source', 'N/A')}\")\n",
        "            print(f\"    Clauses Retrieved: {agent_result.get('clauses_retrieved', 0)}\")\n",
        "            \n",
        "            scores = agent_result.get('relevance_scores', [])\n",
        "            if scores:\n",
        "                print(f\"    Avg Relevance: {sum(scores)/len(scores):.3f}\")\n",
        "                print(f\"    Max Relevance: {max(scores):.3f}\")\n",
        "            \n",
        "            clauses = agent_result.get('clauses', [])\n",
        "            if clauses:\n",
        "                print(f\"    Sample Clauses:\")\n",
        "                for i, clause in enumerate(clauses[:2], 1):\n",
        "                    preview = clause[:100] + \"...\" if len(clause) > 100 else clause\n",
        "                    print(f\"       {i}. {preview}\")\n",
        "    \n",
        "    print(f\"\\n{'â”€'*80}\")\n",
        "    print(f\"Summary:\")\n",
        "    summary = sample_result.get('summary', {})\n",
        "    print(f\"  Agents Routed: {summary.get('total_agents_routed', 0)}\")\n",
        "    print(f\"  Total Clauses Retrieved: {summary.get('total_clauses_retrieved', 0)}\")\n",
        "    print(f\"  Routing Approach: {summary.get('routing_approach', 'N/A')}\")\n",
        "\n",
        "COORDINATOR_OUTPUT = \"../Data/Results/Coordinator\"\n",
        "os.makedirs(COORDINATOR_OUTPUT, exist_ok=True)\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"SAVING COORDINATOR RESULTS\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "successful_results = [r for r in coordinator_results if 'error' not in r]\n",
        "total_agents = sum(r.get(\"summary\", {}).get(\"total_agents_routed\", 0) for r in successful_results)\n",
        "total_clauses = sum(r.get(\"summary\", {}).get(\"total_clauses_retrieved\", 0) for r in successful_results)\n",
        "avg_agents = total_agents / len(successful_results) if successful_results else 0\n",
        "avg_clauses = total_clauses / len(successful_results) if successful_results else 0\n",
        "\n",
        "approach_counts = defaultdict(int)\n",
        "for result in successful_results:\n",
        "    approach = result.get('summary', {}).get('routing_approach', 'unknown')\n",
        "    approach_counts[approach] += 1\n",
        "\n",
        "try:\n",
        "    pinecone_stats = index.describe_index_stats()\n",
        "    vector_count = pinecone_stats.total_vector_count\n",
        "except:\n",
        "    vector_count = 0\n",
        "\n",
        "coordinator_output = {\n",
        "    \"metadata\": {\n",
        "        \"coordinator_name\": \"Dynamic LLM Coordinator\",\n",
        "        \"coordinator_model\": OLLAMA_MODEL,\n",
        "        \"coordinator_approach\": \"Dynamic LLM routing with Pinecone retrieval\",\n",
        "        \"execution_timestamp\": timestamp,\n",
        "        \"description\": \"Uses Gemma-2-9b-it for intelligent query routing and Pinecone for vector-based clause retrieval\",\n",
        "        \"total_queries_processed\": len(coordinator_results),\n",
        "        \"successful_queries\": len(successful_results),\n",
        "        \"failed_queries\": len(coordinator_results) - len(successful_results),\n",
        "        \"total_agents_routed\": total_agents,\n",
        "        \"total_clauses_retrieved\": total_clauses,\n",
        "        \"avg_agents_per_query\": round(avg_agents, 2),\n",
        "        \"avg_clauses_per_query\": round(avg_clauses, 2),\n",
        "        \"routing_approaches\": dict(approach_counts),\n",
        "        \"vector_store\": {\n",
        "            \"type\": \"Pinecone\",\n",
        "            \"index_name\": INDEX_NAME,\n",
        "            \"total_vectors\": vector_count,\n",
        "            \"dimension\": DIMENSION\n",
        "        },\n",
        "        \"processing_details\": {\n",
        "            \"data_source\": \"Pinecone Vector Store\",\n",
        "            \"routing_method\": \"LLM-based dynamic coordination\",\n",
        "            \"retrieval_method\": \"Vector similarity search\",\n",
        "            \"model_provider\": \"Ollama (local)\",\n",
        "            \"response_time\": \"Dynamic (LLM + vector search)\"\n",
        "        }\n",
        "    },\n",
        "    \"queries\": coordinator_results\n",
        "}\n",
        "\n",
        "output_filename = f\"coordinator_results_dynamic_{timestamp}.json\"\n",
        "output_path = os.path.join(COORDINATOR_OUTPUT, output_filename)\n",
        "\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(coordinator_output, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\nCoordinator results saved!\")\n",
        "print(f\"   File: {output_filename}\")\n",
        "print(f\"   Location: {COORDINATOR_OUTPUT}\")\n",
        "print(f\"\\nOutput Statistics:\")\n",
        "print(f\"   Approach: {coordinator_output['metadata']['coordinator_approach']}\")\n",
        "print(f\"   Model: {coordinator_output['metadata']['coordinator_model']}\")\n",
        "print(f\"   Queries: {len(coordinator_results)} ({len(successful_results)} successful)\")\n",
        "print(f\"   Total Agents Routed: {total_agents}\")\n",
        "print(f\"   Total Clauses Retrieved: {total_clauses}\")\n",
        "print(f\"   Avg Agents/Query: {avg_agents:.2f}\")\n",
        "print(f\"   Avg Clauses/Query: {avg_clauses:.2f}\")\n",
        "\n",
        "summary_lines = []\n",
        "summary_lines.append(\"=\" * 100)\n",
        "summary_lines.append(\"DYNAMIC COORDINATOR EXECUTION SUMMARY REPORT\")\n",
        "summary_lines.append(\"=\" * 100)\n",
        "summary_lines.append(f\"\\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "summary_lines.append(f\"Coordinator Model: {OLLAMA_MODEL}\")\n",
        "summary_lines.append(f\"Vector Store: Pinecone (Index: {INDEX_NAME})\")\n",
        "summary_lines.append(f\"\\n{'=' * 100}\\n\")\n",
        "\n",
        "summary_lines.append(\"COORDINATOR CONFIGURATION\")\n",
        "summary_lines.append(\"â”€\" * 100)\n",
        "summary_lines.append(f\"Name: Dynamic LLM Coordinator\")\n",
        "summary_lines.append(f\"Model: {OLLAMA_MODEL} (via Ollama)\")\n",
        "summary_lines.append(f\"Approach: LLM-based intelligent routing\")\n",
        "summary_lines.append(f\"Data Source: Pinecone Vector Store\")\n",
        "summary_lines.append(f\"Retrieval Method: Semantic similarity search\")\n",
        "summary_lines.append(f\"Total Vectors in Store: {vector_count}\")\n",
        "\n",
        "summary_lines.append(f\"\\n\\n{'=' * 100}\\n\")\n",
        "summary_lines.append(\"OVERALL STATISTICS\")\n",
        "summary_lines.append(\"â”€\" * 100)\n",
        "summary_lines.append(f\"Total Queries Processed: {len(coordinator_results)}\")\n",
        "summary_lines.append(f\"  Successful: {len(successful_results)}\")\n",
        "summary_lines.append(f\"  Failed: {len(coordinator_results) - len(successful_results)}\")\n",
        "summary_lines.append(f\"Total Agents Routed: {total_agents}\")\n",
        "summary_lines.append(f\"Total Clauses Retrieved: {total_clauses}\")\n",
        "summary_lines.append(f\"Average Agents per Query: {avg_agents:.2f}\")\n",
        "summary_lines.append(f\"Average Clauses per Query: {avg_clauses:.2f}\")\n",
        "\n",
        "summary_lines.append(f\"\\n\\n{'=' * 100}\\n\")\n",
        "summary_lines.append(\"ROUTING APPROACH BREAKDOWN\")\n",
        "summary_lines.append(\"â”€\" * 100)\n",
        "for approach, count in sorted(approach_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "    percentage = (count / len(successful_results)) * 100 if successful_results else 0\n",
        "    approach_name = approach.replace('_', ' ').title()\n",
        "    summary_lines.append(f\"{approach_name:40} : {count:3} queries ({percentage:5.1f}%)\")\n",
        "\n",
        "agent_usage = defaultdict(int)\n",
        "agent_clause_count = defaultdict(int)\n",
        "agent_relevance = defaultdict(list)\n",
        "\n",
        "for result in successful_results:\n",
        "    for agent, agent_result in result.get(\"agent_results\", {}).items():\n",
        "        if \"error\" not in agent_result:\n",
        "            agent_usage[agent] += 1\n",
        "            agent_clause_count[agent] += agent_result.get(\"clauses_retrieved\", 0)\n",
        "            scores = agent_result.get(\"relevance_scores\", [])\n",
        "            if scores:\n",
        "                agent_relevance[agent].extend(scores)\n",
        "\n",
        "summary_lines.append(f\"\\n\\n{'=' * 100}\\n\")\n",
        "summary_lines.append(\"AGENT USAGE ANALYSIS\")\n",
        "summary_lines.append(\"â”€\" * 100)\n",
        "\n",
        "for agent in sorted(agent_usage.keys()):\n",
        "    count = agent_usage[agent]\n",
        "    clauses = agent_clause_count[agent]\n",
        "    avg_clauses = clauses / count if count > 0 else 0\n",
        "    percentage = (count / len(successful_results)) * 100 if successful_results else 0\n",
        "    \n",
        "    summary_lines.append(f\"\\n{agent.upper()}:\")\n",
        "    summary_lines.append(f\"  Queries Handled: {count} ({percentage:.1f}%)\")\n",
        "    summary_lines.append(f\"  Total Clauses Retrieved: {clauses}\")\n",
        "    summary_lines.append(f\"  Average Clauses per Query: {avg_clauses:.2f}\")\n",
        "    \n",
        "    if agent in agent_relevance and agent_relevance[agent]:\n",
        "        avg_rel = sum(agent_relevance[agent]) / len(agent_relevance[agent])\n",
        "        max_rel = max(agent_relevance[agent])\n",
        "        summary_lines.append(f\"  Average Relevance Score: {avg_rel:.3f}\")\n",
        "        summary_lines.append(f\"  Maximum Relevance Score: {max_rel:.3f}\")\n",
        "\n",
        "summary_lines.append(f\"\\n\\n{'=' * 100}\\n\")\n",
        "summary_lines.append(\"QUERY EXECUTION DETAILS\")\n",
        "summary_lines.append(\"â”€\" * 100)\n",
        "\n",
        "for idx, result in enumerate(coordinator_results, 1):\n",
        "    summary_lines.append(f\"\\n\\nQuery {idx}: \\\"{result.get('query', 'N/A')}\\\"\")\n",
        "    \n",
        "    if 'error' in result:\n",
        "        summary_lines.append(f\"  Status: FAILED\")\n",
        "        summary_lines.append(f\"  Error: {result['error']}\")\n",
        "    else:\n",
        "        routing = result.get('routing', {})\n",
        "        summary = result.get('summary', {})\n",
        "        \n",
        "        summary_lines.append(f\"  Status: SUCCESS\")\n",
        "        summary_lines.append(f\"  Routing Approach: {summary.get('routing_approach', 'N/A')}\")\n",
        "        summary_lines.append(f\"  Agents Routed: {', '.join(routing.get('agents', []))}\")\n",
        "        summary_lines.append(f\"  Reasoning: {routing.get('reasoning', 'N/A')}\")\n",
        "        summary_lines.append(f\"  Clauses Retrieved: {summary.get('total_clauses_retrieved', 0)}\")\n",
        "        \n",
        "        for agent, agent_result in result.get('agent_results', {}).items():\n",
        "            clauses_count = agent_result.get('clauses_retrieved', 0)\n",
        "            if clauses_count > 0:\n",
        "                scores = agent_result.get('relevance_scores', [])\n",
        "                avg_score = sum(scores) / len(scores) if scores else 0\n",
        "                summary_lines.append(f\"    {agent.upper()}: {clauses_count} clauses (avg relevance: {avg_score:.3f})\")\n",
        "\n",
        "summary_lines.append(\"END OF REPORT\")\n",
        "\n",
        "summary_content = \"\\n\".join(summary_lines)\n",
        "summary_file = f\"coordinator_summary_dynamic_{timestamp}.txt\"\n",
        "summary_path = os.path.join(COORDINATOR_OUTPUT, summary_file)\n",
        "\n",
        "with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(summary_content)\n",
        "\n",
        "print(f\"\\nSummary report saved!\")\n",
        "print(f\"   File: {summary_file}\")\n",
        "print(f\"   Location: {COORDINATOR_OUTPUT}\")\n",
        "\n",
        "print(\"FILES GENERATED (DYNAMIC COORDINATOR)\")\n",
        "\n",
        "print(f\"\\n1. {output_filename}\")\n",
        "\n",
        "\n",
        "print(f\"\\n2. {summary_file}\")\n",
        "\n",
        "print(\"All coordinator outputs saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Coordinator Result is stored in JSON format alonng with the keywords specified for each agent and the queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8. Adding New Keyword - 'Indemnity'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TESTING COORDINATOR WITH NEW KEYWORD: 'INDEMNITY'\n",
            "TESTING DYNAMIC COORDINATOR WITH INDEMNITY QUERIES\n",
            "Total Test Queries: 6\n",
            "Coordinator Model: gemma2:9b\n",
            "Expected Primary Agent: Legal\n",
            "TEST 1/6\n",
            "Query: \"What are the indemnity provisions?\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "COORDINATOR DECISION:\n",
            "  Approach: dynamic_llm_coordinator\n",
            "  Agents Routed: legal\n",
            "  Reasoning: The query specifically asks about 'indemnity provisions', which fall under the domain of contract law and are handled by the LEGAL agent.\n",
            "\n",
            "ANALYSIS:\n",
            "  CORRECT: Legal agent selected as PRIMARY agent\n",
            "RETRIEVING FROM PINECONE:\n",
            "  LEGAL: 2 clauses retrieved\n",
            "    Avg relevance: 0.399\n",
            "TEST 2/6\n",
            "Query: \"Show indemnity and liability clauses\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "COORDINATOR DECISION:\n",
            "  Approach: dynamic_llm_coordinator\n",
            "  Agents Routed: legal\n",
            "  Reasoning: The query specifically requests 'indemnity and liability clauses', which fall under the domain of contract law handled by the LEGAL agent.\n",
            "\n",
            "ANALYSIS:\n",
            "  CORRECT: Legal agent selected as PRIMARY agent\n",
            "RETRIEVING FROM PINECONE:\n",
            "  LEGAL: 2 clauses retrieved\n",
            "    Avg relevance: 0.313\n",
            "TEST 3/6\n",
            "Query: \"Indemnification and indemnity obligations\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "COORDINATOR DECISION:\n",
            "  Approach: dynamic_llm_coordinator\n",
            "  Agents Routed: legal\n",
            "  Reasoning: Indemnification and indemnity obligations are legal concepts related to liability and contractual protections.\n",
            "\n",
            "ANALYSIS:\n",
            "  CORRECT: Legal agent selected as PRIMARY agent\n",
            "RETRIEVING FROM PINECONE:\n",
            "  LEGAL: 2 clauses retrieved\n",
            "    Avg relevance: 0.373\n",
            "TEST 4/6\n",
            "Query: \"Does the contract include indemnity protections?\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "COORDINATOR DECISION:\n",
            "  Approach: dynamic_llm_coordinator\n",
            "  Agents Routed: legal\n",
            "  Reasoning: The query specifically asks about indemnity protections, which fall under the domain of contract law and legal rights.\n",
            "\n",
            "ANALYSIS:\n",
            "  CORRECT: Legal agent selected as PRIMARY agent\n",
            "RETRIEVING FROM PINECONE:\n",
            "  LEGAL: 2 clauses retrieved\n",
            "    Avg relevance: 0.411\n",
            "TEST 5/6\n",
            "Query: \"Indemnity caps and financial liability limits\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "COORDINATOR DECISION:\n",
            "  Approach: dynamic_llm_coordinator\n",
            "  Agents Routed: legal, finance\n",
            "  Reasoning: Indemnity caps and financial liability limits fall under both legal (contractual obligations) and financial (monetary limitations) domains.\n",
            "\n",
            "ANALYSIS:\n",
            "  CORRECT: Legal agent selected as PRIMARY agent\n",
            "RETRIEVING FROM PINECONE:\n",
            "  LEGAL: 0 clauses retrieved\n",
            "  FINANCE: 2 clauses retrieved\n",
            "    Avg relevance: 0.353\n",
            "TEST 6/6\n",
            "Query: \"Payment terms with indemnity requirements\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "COORDINATOR DECISION:\n",
            "  Approach: dynamic_llm_coordinator\n",
            "  Agents Routed: finance, legal\n",
            "  Reasoning: The query mentions 'payment terms' which falls under the domain of FINANCE. Additionally, 'indemnity requirements' are legal obligations and fall under LEGAL.\n",
            "\n",
            "ANALYSIS:\n",
            "  PARTIAL: Legal agent selected but not primary\n",
            "RETRIEVING FROM PINECONE:\n",
            "  FINANCE: 3 clauses retrieved\n",
            "    Avg relevance: 0.433\n",
            "  LEGAL: 0 clauses retrieved\n",
            "INDEMNITY KEYWORD ROUTING ANALYSIS\n",
            "\n",
            "Routing Accuracy:\n",
            "  Total Queries Tested: 6\n",
            "  Legal as Primary Agent: 5/6 (83.3%)\n",
            "  Legal Selected (any position): 6/6 (100.0%)\n",
            "\n",
            "Routing Approach Breakdown:\n",
            "  Dynamic Llm Coordinator        :  6 (100.0%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\n",
            "Retrieval Performance:\n",
            "  Total Clauses Retrieved: 13\n",
            "  Queries with Results: 6/6 (100.0%)\n",
            "  Average Clauses per Query: 2.17\n",
            "DETAILED QUERY-BY-QUERY RESULTS\n",
            "\n",
            "[1] Query: \"What are the indemnity provisions?\"\n",
            "    Primary Agent: legal\n",
            "    All Agents: legal\n",
            "    Reasoning: The query specifically asks about 'indemnity provisions', which fall under the domain of contract law and are handled by the LEGAL agent.\n",
            "    Clauses Retrieved: 2\n",
            "    Legal Selected: âœ“\n",
            "\n",
            "[2] Query: \"Show indemnity and liability clauses\"\n",
            "    Primary Agent: legal\n",
            "    All Agents: legal\n",
            "    Reasoning: The query specifically requests 'indemnity and liability clauses', which fall under the domain of contract law handled by the LEGAL agent.\n",
            "    Clauses Retrieved: 2\n",
            "    Legal Selected: âœ“\n",
            "\n",
            "[3] Query: \"Indemnification and indemnity obligations\"\n",
            "    Primary Agent: legal\n",
            "    All Agents: legal\n",
            "    Reasoning: Indemnification and indemnity obligations are legal concepts related to liability and contractual protections.\n",
            "    Clauses Retrieved: 2\n",
            "    Legal Selected: âœ“\n",
            "\n",
            "[4] Query: \"Does the contract include indemnity protections?\"\n",
            "    Primary Agent: legal\n",
            "    All Agents: legal\n",
            "    Reasoning: The query specifically asks about indemnity protections, which fall under the domain of contract law and legal rights.\n",
            "    Clauses Retrieved: 2\n",
            "    Legal Selected: âœ“\n",
            "\n",
            "[5] Query: \"Indemnity caps and financial liability limits\"\n",
            "    Primary Agent: legal\n",
            "    All Agents: legal, finance\n",
            "    Reasoning: Indemnity caps and financial liability limits fall under both legal (contractual obligations) and financial (monetary limitations) domains.\n",
            "    Clauses Retrieved: 2\n",
            "    Legal Selected: âœ“\n",
            "\n",
            "[6] Query: \"Payment terms with indemnity requirements\"\n",
            "    Primary Agent: finance\n",
            "    All Agents: finance, legal\n",
            "    Reasoning: The query mentions 'payment terms' which falls under the domain of FINANCE. Additionally, 'indemnity requirements' are legal obligations and fall under LEGAL.\n",
            "    Clauses Retrieved: 3\n",
            "    Legal Selected: âœ“\n",
            "SAVING TEST RESULTS\n",
            "\n",
            "Indemnity test results saved!\n",
            "   File: coordinator_indemnity_test_20260115_141717.json\n",
            "   Location: ../Data/Results/Coordinator\n",
            "INDEMNITY KEYWORD TEST COMPLETE!\n"
          ]
        }
      ],
      "source": [
        "print(\"TESTING COORDINATOR WITH NEW KEYWORD: 'INDEMNITY'\")\n",
        "\n",
        "indemnity_test_queries = [\n",
        "    \"What are the indemnity provisions?\",\n",
        "    \"Show indemnity and liability clauses\",\n",
        "    \"Indemnification and indemnity obligations\",\n",
        "    \"Does the contract include indemnity protections?\",\n",
        "    \"Indemnity caps and financial liability limits\",\n",
        "    \"Payment terms with indemnity requirements\"\n",
        "]\n",
        "\n",
        "print(f\"TESTING DYNAMIC COORDINATOR WITH INDEMNITY QUERIES\")\n",
        "\n",
        "print(f\"Total Test Queries: {len(indemnity_test_queries)}\")\n",
        "print(f\"Coordinator Model: {OLLAMA_MODEL}\")\n",
        "print(f\"Expected Primary Agent: Legal\")\n",
        "\n",
        "indemnity_test_results = []\n",
        "\n",
        "for idx, query in enumerate(indemnity_test_queries, 1):\n",
        "\n",
        "    print(f\"TEST {idx}/{len(indemnity_test_queries)}\")\n",
        "    print(f\"Query: \\\"{query}\\\"\")\n",
        "    \n",
        "    routing_result = dynamic_route_query(query)\n",
        "    \n",
        "    print(\"COORDINATOR DECISION:\")\n",
        "    print(f\"  Approach: {routing_result['approach']}\")\n",
        "    print(f\"  Agents Routed: {', '.join(routing_result['agents'])}\")\n",
        "    print(f\"  Reasoning: {routing_result['reasoning']}\")\n",
        "    \n",
        "    is_legal_selected = 'legal' in routing_result['agents']\n",
        "    is_legal_primary = routing_result['agents'][0] == 'legal' if routing_result['agents'] else False\n",
        "    \n",
        "    print(f\"\\nANALYSIS:\")\n",
        "    if is_legal_primary:\n",
        "        print(f\"  CORRECT: Legal agent selected as PRIMARY agent\")\n",
        "    elif is_legal_selected:\n",
        "        print(f\"  PARTIAL: Legal agent selected but not primary\")\n",
        "    else:\n",
        "        print(f\"  INCORRECT: Legal agent NOT selected\")\n",
        "    \n",
        "\n",
        "    print(\"RETRIEVING FROM PINECONE:\")\n",
        "\n",
        "    agent_results = {}\n",
        "    total_clauses = 0\n",
        "    \n",
        "    for agent_name in routing_result['agents']:\n",
        "        try:\n",
        "            results = retrieve_from_pinecone(query, agent_filter=agent_name, top_k=3)\n",
        "            \n",
        "            if results and results.matches:\n",
        "                filtered_matches = [m for m in results.matches if m.score > 0.3]\n",
        "                clauses = [match.metadata.get('clause_full', match.metadata.get('clause', '')) \n",
        "                          for match in filtered_matches]\n",
        "                scores = [match.score for match in filtered_matches]\n",
        "                \n",
        "                agent_results[agent_name] = {\n",
        "                    'clauses_count': len(clauses),\n",
        "                    'clauses': clauses,\n",
        "                    'scores': scores\n",
        "                }\n",
        "                \n",
        "                total_clauses += len(clauses)\n",
        "                \n",
        "                print(f\"  {agent_name.upper()}: {len(clauses)} clauses retrieved\")\n",
        "                if scores:\n",
        "                    print(f\"    Avg relevance: {sum(scores)/len(scores):.3f}\")\n",
        "            else:\n",
        "                agent_results[agent_name] = {'clauses_count': 0, 'clauses': [], 'scores': []}\n",
        "                print(f\"  {agent_name.upper()}: No relevant clauses found\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"  {agent_name.upper()}: Error - {str(e)}\")\n",
        "            agent_results[agent_name] = {'clauses_count': 0, 'clauses': [], 'scores': []}\n",
        "    \n",
        "    indemnity_test_results.append({\n",
        "        \"query\": query,\n",
        "        \"routing\": routing_result,\n",
        "        \"agent_results\": agent_results,\n",
        "        \"legal_selected\": is_legal_selected,\n",
        "        \"legal_primary\": is_legal_primary,\n",
        "        \"total_clauses\": total_clauses\n",
        "    })\n",
        "\n",
        "print(\"INDEMNITY KEYWORD ROUTING ANALYSIS\")\n",
        "\n",
        "legal_as_primary = sum(1 for test in indemnity_test_results if test['legal_primary'])\n",
        "legal_selected = sum(1 for test in indemnity_test_results if test['legal_selected'])\n",
        "total_tests = len(indemnity_test_results)\n",
        "\n",
        "print(f\"\\nRouting Accuracy:\")\n",
        "print(f\"  Total Queries Tested: {total_tests}\")\n",
        "print(f\"  Legal as Primary Agent: {legal_as_primary}/{total_tests} ({legal_as_primary/total_tests*100:.1f}%)\")\n",
        "print(f\"  Legal Selected (any position): {legal_selected}/{total_tests} ({legal_selected/total_tests*100:.1f}%)\")\n",
        "\n",
        "approach_counts = defaultdict(int)\n",
        "for test in indemnity_test_results:\n",
        "    approach = test['routing']['approach']\n",
        "    approach_counts[approach] += 1\n",
        "\n",
        "print(f\"\\nRouting Approach Breakdown:\")\n",
        "for approach, count in sorted(approach_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "    percentage = (count / total_tests) * 100\n",
        "    approach_name = approach.replace('_', ' ').title()\n",
        "    bar = \"â–ˆ\" * int(percentage / 5)\n",
        "    print(f\"  {approach_name:30} : {count:2} ({percentage:5.1f}%) {bar}\")\n",
        "\n",
        "total_clauses_retrieved = sum(test['total_clauses'] for test in indemnity_test_results)\n",
        "queries_with_clauses = sum(1 for test in indemnity_test_results if test['total_clauses'] > 0)\n",
        "\n",
        "print(f\"\\nRetrieval Performance:\")\n",
        "print(f\"  Total Clauses Retrieved: {total_clauses_retrieved}\")\n",
        "print(f\"  Queries with Results: {queries_with_clauses}/{total_tests} ({queries_with_clauses/total_tests*100:.1f}%)\")\n",
        "print(f\"  Average Clauses per Query: {total_clauses_retrieved/total_tests:.2f}\")\n",
        "\n",
        "\n",
        "print(\"DETAILED QUERY-BY-QUERY RESULTS\")\n",
        "\n",
        "for idx, test in enumerate(indemnity_test_results, 1):\n",
        "    print(f\"\\n[{idx}] Query: \\\"{test['query']}\\\"\")\n",
        "    print(f\"    Primary Agent: {test['routing']['agents'][0] if test['routing']['agents'] else 'None'}\")\n",
        "    print(f\"    All Agents: {', '.join(test['routing']['agents'])}\")\n",
        "    print(f\"    Reasoning: {test['routing']['reasoning']}\")\n",
        "    print(f\"    Clauses Retrieved: {test['total_clauses']}\")\n",
        "    print(f\"    Legal Selected: {'âœ“' if test['legal_selected'] else 'âœ—'}\")\n",
        "\n",
        "\n",
        "print(\"SAVING TEST RESULTS\")\n",
        "COORDINATOR_OUTPUT = \"../Data/Results/Coordinator\"\n",
        "os.makedirs(COORDINATOR_OUTPUT, exist_ok=True)\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "indemnity_output = {\n",
        "    \"task\": \"Test Coordinator with 'Indemnity' Keyword\",\n",
        "    \"coordinator_model\": OLLAMA_MODEL,\n",
        "    \"approach\": \"Dynamic LLM-based routing with Pinecone retrieval\",\n",
        "    \"decision\": \"Indemnity queries should route to Legal Agent\",\n",
        "    \"reasoning\": \"Indemnity is a legal protection concept related to liability and indemnification\",\n",
        "    \"test_timestamp\": timestamp,\n",
        "    \"test_queries\": indemnity_test_queries,\n",
        "    \"results\": indemnity_test_results,\n",
        "    \"metrics\": {\n",
        "        \"total_queries\": total_tests,\n",
        "        \"legal_as_primary\": legal_as_primary,\n",
        "        \"legal_as_primary_rate\": f\"{legal_as_primary/total_tests*100:.1f}%\",\n",
        "        \"legal_selected\": legal_selected,\n",
        "        \"legal_selected_rate\": f\"{legal_selected/total_tests*100:.1f}%\",\n",
        "        \"total_clauses_retrieved\": total_clauses_retrieved,\n",
        "        \"avg_clauses_per_query\": round(total_clauses_retrieved/total_tests, 2),\n",
        "        \"queries_with_results\": queries_with_clauses,\n",
        "        \"retrieval_success_rate\": f\"{queries_with_clauses/total_tests*100:.1f}%\"\n",
        "    },\n",
        "    \"routing_approaches\": dict(approach_counts),\n",
        "    \"note\": \"Dynamic LLM coordinator automatically understands 'indemnity' without explicit rules\"\n",
        "}\n",
        "\n",
        "indemnity_file = f\"coordinator_indemnity_test_{timestamp}.json\"\n",
        "indemnity_path = os.path.join(COORDINATOR_OUTPUT, indemnity_file)\n",
        "\n",
        "with open(indemnity_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(indemnity_output, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\nIndemnity test results saved!\")\n",
        "print(f\"   File: {indemnity_file}\")\n",
        "print(f\"   Location: {COORDINATOR_OUTPUT}\")\n",
        "\n",
        "print(\"INDEMNITY KEYWORD TEST COMPLETE!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LanGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. LanGraph Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LANGGRAPH SETUP\n",
            "\n",
            "Installing LangGraph and dependencies...\n",
            "\n",
            "Installing langgraph...\n",
            "langgraph installed successfully\n",
            "\n",
            "Installing langchain-core...\n",
            "langchain-core installed successfully\n",
            "\n",
            "Installing langchain-community...\n",
            "langchain-community installed successfully\n",
            "Importing LangGraph components...\n",
            "LangGraph imported successfully\n",
            "Core dependencies imported\n",
            "\n",
            "Testing LangGraph setup...\n",
            "StateGraph initialized successfully\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "print(\"LANGGRAPH SETUP\")\n",
        "\n",
        "print(\"\\nInstalling LangGraph and dependencies...\")\n",
        "\n",
        "packages = [\n",
        "    \"langgraph\",\n",
        "    \"langchain-core\",\n",
        "    \"langchain-community\"\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        print(f\"\\nInstalling {package}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "        print(f\"{package} installed successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"{package} installation note: {str(e)[:100]}\")\n",
        "\n",
        "print(\"Importing LangGraph components...\")\n",
        "\n",
        "try:\n",
        "    from langgraph.graph import StateGraph, END\n",
        "    from typing import TypedDict, Dict, Any, List, Annotated\n",
        "    import operator\n",
        "    import os\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    from collections import defaultdict\n",
        "    \n",
        "    print(\"LangGraph imported successfully\")\n",
        "    print(\"Core dependencies imported\")\n",
        "    \n",
        "    print(\"\\nTesting LangGraph setup...\")\n",
        "    \n",
        "    class TestState(TypedDict):\n",
        "        messages: List[str]\n",
        "    \n",
        "    workflow = StateGraph(TestState)\n",
        "    print(\"StateGraph initialized successfully\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"Import error: {e}\")\n",
        "    print(\"\\nAttempting alternative import method...\")\n",
        "    \n",
        "    try:\n",
        "        from langgraph.graph import Graph\n",
        "        from typing import TypedDict, Dict, Any, List, Annotated\n",
        "        import operator\n",
        "        import os\n",
        "        import json\n",
        "        from datetime import datetime\n",
        "        from collections import defaultdict\n",
        "        \n",
        "        StateGraph = Graph\n",
        "        END = \"END\"\n",
        "        \n",
        "        print(\"LangGraph imported (compatibility mode)\")\n",
        "        print(\"Using older Graph API\")\n",
        "        \n",
        "    except Exception as e2:\n",
        "        print(f\"Alternative import also failed: {e2}\")\n",
        "        print(\"\\nInstalling latest LangGraph version...\")\n",
        "        \n",
        "        try:\n",
        "            subprocess.check_call([\n",
        "                sys.executable, \"-m\", \"pip\", \"install\", \n",
        "                \"--upgrade\", \"langgraph\", \"langchain-core\"\n",
        "            ])\n",
        "            \n",
        "            from langgraph.graph import StateGraph, END\n",
        "            from typing import TypedDict, Dict, Any, List, Annotated\n",
        "            import operator\n",
        "            import os\n",
        "            import json\n",
        "            from datetime import datetime\n",
        "            from collections import defaultdict\n",
        "            \n",
        "            print(\"LangGraph reinstalled and imported successfully\")\n",
        "            \n",
        "        except Exception as e3:\n",
        "            print(f\"Critical error: {e3}\")\n",
        "            print(\"\\nPlease install manually: pip install langgraph langchain-core\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEFINING COORDINATOR STATE\n",
            "CoordinatorState defined\n",
            "LANGGRAPH SETUP COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"DEFINING COORDINATOR STATE\")\n",
        "\n",
        "class CoordinatorState(TypedDict):\n",
        "    query: str  \n",
        "    routed_agents: List[str]  \n",
        "    routing_reasoning: str  \n",
        "    agent_results: Dict[str, Any]  \n",
        "    retrieved_clauses: List[Dict[str, Any]]  \n",
        "    final_response: str  \n",
        "    metadata: Dict[str, Any]  \n",
        "\n",
        "print(\"CoordinatorState defined\")\n",
        "\n",
        "print(\"LANGGRAPH SETUP COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Defining Shared Graph State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEFINING SHARED GRAPH STATE FOR DYNAMIC COORDINATOR\n",
            "GraphState defined with TypedDict\n",
            "EXAMPLE INITIAL STATE:\n",
            "{\n",
            "  \"query\": \"Analyze contract termination and payment terms\",\n",
            "  \"routed_agents\": [],\n",
            "  \"routing_reasoning\": \"\",\n",
            "  \"routing_approach\": \"\",\n",
            "  \"legal\": {},\n",
            "  \"compliance\": {},\n",
            "  \"finance\": {},\n",
            "  \"operations\": {},\n",
            "  \"all_clauses\": [],\n",
            "  \"total_clauses_retrieved\": 0,\n",
            "  \"execution_order\": [],\n",
            "  \"timestamp\": \"20260115_142328\",\n",
            "  \"coordinator_model\": \"gemma2:9b\",\n",
            "  \"vector_store\": \"Pinecone\",\n",
            "  \"execution_status\": \"initialized\"\n",
            "}\n",
            "âœ“ GRAPH STATE DEFINITION COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"DEFINING SHARED GRAPH STATE FOR DYNAMIC COORDINATOR\")\n",
        "class GraphState(TypedDict):\n",
        "   \n",
        "    query: str  \n",
        "    \n",
        "    routed_agents: List[str]  \n",
        "    routing_reasoning: str  \n",
        "    routing_approach: str  \n",
        "    \n",
        "    legal: Dict[str, Any]  \n",
        "    compliance: Dict[str, Any]  \n",
        "    finance: Dict[str, Any]  \n",
        "    operations: Dict[str, Any] \n",
        "    \n",
        "    all_clauses: List[Dict[str, Any]]  \n",
        "    total_clauses_retrieved: int  \n",
        "    \n",
        "    execution_order: List[str]  \n",
        "    timestamp: str  \n",
        "    \n",
        "    coordinator_model: str  \n",
        "    vector_store: str  \n",
        "    execution_status: str  \n",
        "\n",
        "print(\"GraphState defined with TypedDict\")\n",
        "example_state = {\n",
        "    \"query\": \"Analyze contract termination and payment terms\",\n",
        "    \"routed_agents\": [],\n",
        "    \"routing_reasoning\": \"\",\n",
        "    \"routing_approach\": \"\",\n",
        "    \"legal\": {},\n",
        "    \"compliance\": {},\n",
        "    \"finance\": {},\n",
        "    \"operations\": {},\n",
        "    \"all_clauses\": [],\n",
        "    \"total_clauses_retrieved\": 0,\n",
        "    \"execution_order\": [],\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"vector_store\": \"Pinecone\",\n",
        "    \"execution_status\": \"initialized\"\n",
        "}\n",
        "\n",
        "print(\"EXAMPLE INITIAL STATE:\")\n",
        "\n",
        "print(json.dumps(example_state, indent=2))\n",
        "\n",
        "print(\"âœ“ GRAPH STATE DEFINITION COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Defining Agent Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEFINING AGENT NODES FOR DYNAMIC COORDINATOR\n",
            "DEFINING DYNAMIC AGENT NODES\n",
            "AGENT NODES DEFINED\n"
          ]
        }
      ],
      "source": [
        "print(\"DEFINING AGENT NODES FOR DYNAMIC COORDINATOR\")\n",
        "\n",
        "print(\"DEFINING DYNAMIC AGENT NODES\")\n",
        "\n",
        "def legal_node(state: GraphState) -> GraphState:\n",
        "    \n",
        "    print(f\"\\n  â†’ LEGAL AGENT executing\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone(state['query'], agent_filter='legal', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "    \n",
        "            filtered_matches = [m for m in results.matches if m.score > 0.1]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"legal\"] = {\n",
        "                \"agent\": \"Legal\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'legal'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses\")\n",
        "            print(f\"     Avg relevance: {state['legal']['avg_relevance']:.3f}\")\n",
        "        else:\n",
        "            state[\"legal\"] = {\n",
        "                \"agent\": \"Legal\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": [],\n",
        "                \"message\": \"No relevant legal clauses found\"\n",
        "            }\n",
        "            print(f\"     No relevant clauses found\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"legal\"] = {\n",
        "            \"agent\": \"Legal\",\n",
        "            \"status\": \"error\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"legal\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def compliance_node(state: GraphState) -> GraphState:\n",
        "\n",
        "    print(f\"\\n  â†’ COMPLIANCE AGENT executing\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone(state['query'], agent_filter='compliance', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            filtered_matches = [m for m in results.matches if m.score > 0.1]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"compliance\"] = {\n",
        "                \"agent\": \"Compliance\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'compliance'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses\")\n",
        "            print(f\"     Avg relevance: {state['compliance']['avg_relevance']:.3f}\")\n",
        "        else:\n",
        "            state[\"compliance\"] = {\n",
        "                \"agent\": \"Compliance\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": [],\n",
        "                \"message\": \"No relevant compliance clauses found\"\n",
        "            }\n",
        "            print(f\"      No relevant clauses found\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"compliance\"] = {\n",
        "            \"agent\": \"Compliance\",\n",
        "            \"status\": \"error\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "        print(f\"      Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"compliance\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def finance_node(state: GraphState) -> GraphState:\n",
        "   \n",
        "    print(f\"\\n  â†’ FINANCE AGENT executing\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone(state['query'], agent_filter='finance', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            filtered_matches = [m for m in results.matches if m.score > 0.1]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"finance\"] = {\n",
        "                \"agent\": \"Finance\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'finance'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses\")\n",
        "            print(f\"     Avg relevance: {state['finance']['avg_relevance']:.3f}\")\n",
        "        else:\n",
        "            state[\"finance\"] = {\n",
        "                \"agent\": \"Finance\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": [],\n",
        "                \"message\": \"No relevant finance clauses found\"\n",
        "            }\n",
        "            print(f\"     No relevant clauses found\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"finance\"] = {\n",
        "            \"agent\": \"Finance\",\n",
        "            \"status\": \"error\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"finance\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def operations_node(state: GraphState) -> GraphState:\n",
        "   \n",
        "    print(f\"\\n  â†’ OPERATIONS AGENT executing\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone(state['query'], agent_filter='operations', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            filtered_matches = [m for m in results.matches if m.score > 0.1]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"operations\"] = {\n",
        "                \"agent\": \"Operations\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'operations'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses\")\n",
        "            print(f\"     Avg relevance: {state['operations']['avg_relevance']:.3f}\")\n",
        "        else:\n",
        "            state[\"operations\"] = {\n",
        "                \"agent\": \"Operations\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": [],\n",
        "                \"message\": \"No relevant operations clauses found\"\n",
        "            }\n",
        "            print(f\"     No relevant clauses found\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"operations\"] = {\n",
        "            \"agent\": \"Operations\",\n",
        "            \"status\": \"error\",\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"operations\")\n",
        "    return state\n",
        "\n",
        "print(\"AGENT NODES DEFINED\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Building Graph Skeleton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BUILDING GRAPH SKELETON FOR DYNAMIC COORDINATOR\n",
            "\n",
            "StateGraph initialized\n",
            "GRAPH PROPERTIES\n",
            "  Graph Type: StateGraph\n",
            "GRAPH WORKFLOW ARCHITECTURE\n",
            "GRAPH SKELETON READY\n"
          ]
        }
      ],
      "source": [
        "print(\"BUILDING GRAPH SKELETON FOR DYNAMIC COORDINATOR\")\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "print(\"\\nStateGraph initialized\")\n",
        "\n",
        "print(\"GRAPH PROPERTIES\")\n",
        "\n",
        "print(f\"  Graph Type: {type(workflow).__name__}\")\n",
        "\n",
        "print(\"GRAPH WORKFLOW ARCHITECTURE\")\n",
        "\n",
        "print(\"GRAPH SKELETON READY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Defining Edges - Simple Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEFINING DYNAMIC WORKFLOW WITH CONDITIONAL ROUTING\n",
            "\n",
            "Defining routing node...\n",
            "Defining aggregation node...\n",
            "Defining conditional routing logic...\n",
            "ADDING NODES TO GRAPH\n",
            "Added: routing (Dynamic LLM Coordinator)\n",
            "Added: legal_agent\n",
            "Added: compliance_agent\n",
            "Added: finance_agent\n",
            "Added: operations_agent\n",
            "Added: aggregation\n",
            "DEFINING EXECUTION FLOW\n",
            "Entry Point: routing\n",
            "\n",
            "Adding conditional edges from routing:\n",
            "  - routing â†’ legal_agent (if legal selected)\n",
            "  - legal_agent â†’ compliance_agent (if compliance selected)\n",
            "  - compliance_agent â†’ finance_agent (if finance selected)\n",
            "  - finance_agent â†’ operations_agent (if operations selected)\n",
            "  - operations_agent â†’ aggregation\n",
            "  - aggregation â†’ END\n",
            "DYNAMIC WORKFLOW DEFINED\n"
          ]
        }
      ],
      "source": [
        "print(\"DEFINING DYNAMIC WORKFLOW WITH CONDITIONAL ROUTING\")\n",
        "\n",
        "print(\"\\nDefining routing node...\")\n",
        "\n",
        "def routing_node(state: GraphState) -> GraphState:\n",
        "\n",
        "    print(\"ROUTING NODE: Dynamic LLM Coordinator\")\n",
        "\n",
        "    print(f\"Query: \\\"{state['query']}\\\"\")\n",
        "    \n",
        "    routing_result = dynamic_route_query(state['query'])\n",
        "    \n",
        "    state['routed_agents'] = routing_result['agents']\n",
        "    state['routing_reasoning'] = routing_result['reasoning']\n",
        "    state['routing_approach'] = routing_result['approach']\n",
        "    \n",
        "    print(f\"\\nRouting Decision:\")\n",
        "    print(f\"  Agents: {', '.join(state['routed_agents'])}\")\n",
        "    print(f\"  Reasoning: {state['routing_reasoning']}\")\n",
        "    print(f\"  Approach: {state['routing_approach']}\")\n",
        "    \n",
        "    state['execution_order'].append(\"routing\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "print(\"Defining aggregation node...\")\n",
        "\n",
        "def aggregation_node(state: GraphState) -> GraphState:\n",
        "\n",
        "    print(\"AGGREGATION NODE: Consolidating Results\")\n",
        "\n",
        "    if state['all_clauses']:\n",
        "        state['all_clauses'].sort(key=lambda x: x.get('relevance_score', 0), reverse=True)\n",
        "        \n",
        "        print(f\"\\nTotal clauses retrieved: {state['total_clauses_retrieved']}\")\n",
        "        print(f\"Top relevance score: {state['all_clauses'][0]['relevance_score']:.3f}\")\n",
        "        print(f\"Agents executed: {', '.join([a for a in state['execution_order'] if a != 'routing' and a != 'aggregation'])}\")\n",
        "        \n",
        "        state['execution_status'] = 'success'\n",
        "    else:\n",
        "        print(f\"\\nNo clauses retrieved\")\n",
        "        state['execution_status'] = 'no_results'\n",
        "    \n",
        "    state['execution_order'].append(\"aggregation\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "\n",
        "print(\"Defining conditional routing logic...\")\n",
        "\n",
        "def should_invoke_agent(agent_name: str):\n",
        "\n",
        "    def check(state: GraphState) -> str:\n",
        "        if agent_name in state['routed_agents']:\n",
        "            return agent_name\n",
        "        else:\n",
        "            return \"skip\"\n",
        "    return check\n",
        "\n",
        "print(\"ADDING NODES TO GRAPH\")\n",
        "\n",
        "workflow.add_node(\"routing\", routing_node)\n",
        "print(\"Added: routing (Dynamic LLM Coordinator)\")\n",
        "\n",
        "workflow.add_node(\"legal_agent\", legal_node)\n",
        "print(\"Added: legal_agent\")\n",
        "\n",
        "workflow.add_node(\"compliance_agent\", compliance_node)\n",
        "print(\"Added: compliance_agent\")\n",
        "\n",
        "workflow.add_node(\"finance_agent\", finance_node)\n",
        "print(\"Added: finance_agent\")\n",
        "\n",
        "workflow.add_node(\"operations_agent\", operations_node)\n",
        "print(\"Added: operations_agent\")\n",
        "\n",
        "workflow.add_node(\"aggregation\", aggregation_node)\n",
        "print(\"Added: aggregation\")\n",
        "\n",
        "print(\"DEFINING EXECUTION FLOW\")\n",
        "\n",
        "workflow.set_entry_point(\"routing\")\n",
        "print(\"Entry Point: routing\")\n",
        "\n",
        "print(\"\\nAdding conditional edges from routing:\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"routing\",\n",
        "    lambda state: \"legal_agent\" if \"legal\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  - routing â†’ legal_agent (if legal selected)\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"legal_agent\",\n",
        "    lambda state: \"compliance_agent\" if \"compliance\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  - legal_agent â†’ compliance_agent (if compliance selected)\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"compliance_agent\",\n",
        "    lambda state: \"finance_agent\" if \"finance\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  - compliance_agent â†’ finance_agent (if finance selected)\")\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"finance_agent\",\n",
        "    lambda state: \"operations_agent\" if \"operations\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  - finance_agent â†’ operations_agent (if operations selected)\")\n",
        "\n",
        "workflow.add_edge(\"operations_agent\", \"aggregation\")\n",
        "print(\"  - operations_agent â†’ aggregation\")\n",
        "\n",
        "workflow.add_edge(\"aggregation\", END)\n",
        "print(\"  - aggregation â†’ END\")\n",
        "\n",
        "print(\"DYNAMIC WORKFLOW DEFINED\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Compiling Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COMPILING DYNAMIC WORKFLOW GRAPH\n",
            "\n",
            "Compiling graph with conditional routing...\n",
            "Graph compiled successfully!\n",
            "COMPILED GRAPH DETAILS\n",
            "  Type: CompiledStateGraph\n",
            "GRAPH STRUCTURE VALIDATION\n",
            "WORKFLOW EXECUTION PATH\n",
            "READY FOR EXECUTION\n",
            "GRAPH COMPILATION COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"COMPILING DYNAMIC WORKFLOW GRAPH\")\n",
        "\n",
        "print(\"\\nCompiling graph with conditional routing...\")\n",
        "\n",
        "try:\n",
        "    app = workflow.compile()\n",
        "    print(\"Graph compiled successfully!\")\n",
        "    \n",
        "    print(\"COMPILED GRAPH DETAILS\")\n",
        "\n",
        "    print(f\"  Type: {type(app).__name__}\")\n",
        "   \n",
        "    \n",
        "    print(\"GRAPH STRUCTURE VALIDATION\")\n",
        "   \n",
        "    print(\"WORKFLOW EXECUTION PATH\")\n",
        "   \n",
        "    print(\"READY FOR EXECUTION\")\n",
        "   \n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nCompilation failed: {str(e)}\")\n",
        "    print(\"\\nDebug info:\")\n",
        "    print(f\"  Error type: {type(e).__name__}\")\n",
        "    print(f\"  Error message: {str(e)}\")\n",
        "\n",
        "print(\"GRAPH COMPILATION COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Executing Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EXECUTING DYNAMIC WORKFLOW GRAPH\n",
            "\n",
            "Ensuring graph is compiled...\n",
            "Using existing compiled workflow\n",
            "PREPARING INITIAL STATE\n",
            "\n",
            "Initial State Created:\n",
            "{\n",
            "  \"query\": \"Analyze contract for termination, GDPR compliance, data protection, privacy obligations, regulatory requirements, audit and reporting requirements, confidentiality and non-disclosure obligations, payment terms, deliverables, project outputs, timelines and milestones for delivery, performance standards and obligations, operational requirements and responsibilities, service level agreements and SLAs.\",\n",
            "  \"coordinator_model\": \"gemma2:9b\",\n",
            "  \"vector_store\": \"Pinecone\",\n",
            "  \"timestamp\": \"20260115_145315\",\n",
            "  \"status\": \"initialized\"\n",
            "}\n",
            "EXECUTING MULTI-AGENT WORKFLOW\n",
            "Query: \"Analyze contract for termination, GDPR compliance, data protection, privacy obligations, regulatory requirements, audit and reporting requirements, confidentiality and non-disclosure obligations, payment terms, deliverables, project outputs, timelines and milestones for delivery, performance standards and obligations, operational requirements and responsibilities, service level agreements and SLAs.\"\n",
            "\n",
            "Starting execution...\n",
            "ROUTING NODE: Dynamic LLM Coordinator\n",
            "Query: \"Analyze contract for termination, GDPR compliance, data protection, privacy obligations, regulatory requirements, audit and reporting requirements, confidentiality and non-disclosure obligations, payment terms, deliverables, project outputs, timelines and milestones for delivery, performance standards and obligations, operational requirements and responsibilities, service level agreements and SLAs.\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Routing Decision:\n",
            "  Agents: legal, compliance, finance, operations\n",
            "  Reasoning: The query touches upon legal clauses (termination), data protection and privacy regulations, financial terms (payment), and operational aspects (deliverables, timelines, SLAs).\n",
            "  Approach: dynamic_llm_coordinator\n",
            "\n",
            "  â†’ LEGAL AGENT executing\n",
            "     Query: Analyze contract for termination, GDPR compliance, data prot...\n",
            "     Retrieved: 2 clauses\n",
            "     Avg relevance: 0.312\n",
            "\n",
            "  â†’ COMPLIANCE AGENT executing\n",
            "     Query: Analyze contract for termination, GDPR compliance, data prot...\n",
            "     Retrieved: 1 clauses\n",
            "     Avg relevance: 0.227\n",
            "\n",
            "  â†’ FINANCE AGENT executing\n",
            "     Query: Analyze contract for termination, GDPR compliance, data prot...\n",
            "     Retrieved: 3 clauses\n",
            "     Avg relevance: 0.256\n",
            "\n",
            "  â†’ OPERATIONS AGENT executing\n",
            "     Query: Analyze contract for termination, GDPR compliance, data prot...\n",
            "     Retrieved: 2 clauses\n",
            "     Avg relevance: 0.214\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 8\n",
            "Top relevance score: 0.349\n",
            "Agents executed: legal, compliance, finance, operations\n",
            "âœ“ EXECUTION COMPLETED SUCCESSFULLY\n",
            "\n",
            "Execution Summary:\n",
            "  Status: success\n",
            "  Agents Routed: legal, compliance, finance, operations\n",
            "  Routing Reasoning: The query touches upon legal clauses (termination), data protection and privacy regulations, financial terms (payment), and operational aspects (deliverables, timelines, SLAs).\n",
            "  Execution Order: routing â†’ legal â†’ compliance â†’ finance â†’ operations â†’ aggregation\n",
            "  Total Clauses Retrieved: 8\n",
            "AGENT RESULTS\n",
            "\n",
            "LEGAL Agent:\n",
            "  Status: completed\n",
            "  Clauses Retrieved: 2\n",
            "  Avg Relevance: 0.312\n",
            "  Max Relevance: 0.336\n",
            "\n",
            "COMPLIANCE Agent:\n",
            "  Status: completed\n",
            "  Clauses Retrieved: 1\n",
            "  Avg Relevance: 0.227\n",
            "  Max Relevance: 0.227\n",
            "\n",
            "FINANCE Agent:\n",
            "  Status: completed\n",
            "  Clauses Retrieved: 3\n",
            "  Avg Relevance: 0.256\n",
            "  Max Relevance: 0.349\n",
            "\n",
            "OPERATIONS Agent:\n",
            "  Status: completed\n",
            "  Clauses Retrieved: 2\n",
            "  Avg Relevance: 0.214\n",
            "  Max Relevance: 0.260\n",
            "TOP RETRIEVED CLAUSES\n",
            "\n",
            "[1] Agent: FINANCE | Relevance: 0.349\n",
            "    In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, including, without limitation, lic...\n",
            "\n",
            "[2] Agent: LEGAL | Relevance: 0.336\n",
            "    The other party shall give notice of termination in writing to the other party, which notice shall specify in reasonable detail the event(s) of defaul...\n",
            "\n",
            "[3] Agent: LEGAL | Relevance: 0.288\n",
            "    The other party asserts any rights in or to the terminating party's intellectual property in violation of this Agreement.\n",
            "\n",
            "[4] Agent: OPERATIONS | Relevance: 0.260\n",
            "    Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distribution of the Products\n",
            "\n",
            "[5] Agent: COMPLIANCE | Relevance: 0.227\n",
            "    The receiving party will not disclose the other party's confidential information to any third parties without the other party's prior written consent.\n",
            "WORKFLOW EXECUTION COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"EXECUTING DYNAMIC WORKFLOW GRAPH\")\n",
        "\n",
        "print(\"\\nEnsuring graph is compiled...\")\n",
        "\n",
        "try:\n",
        "    if 'app' not in locals():\n",
        "        print(\"Compiling workflow...\")\n",
        "        app = workflow.compile()\n",
        "        print(\"Workflow compiled successfully\")\n",
        "    else:\n",
        "        print(\"Using existing compiled workflow\")\n",
        "except Exception as e:\n",
        "    print(f\"Compilation error: {str(e)}\")\n",
        "    print(\"\\nAttempting to rebuild workflow...\")\n",
        "    \n",
        "    workflow = StateGraph(GraphState)\n",
        "    \n",
        "    workflow.add_node(\"routing\", routing_node)\n",
        "    workflow.add_node(\"legal_agent\", legal_node)\n",
        "    workflow.add_node(\"compliance_agent\", compliance_node)\n",
        "    workflow.add_node(\"finance_agent\", finance_node)\n",
        "    workflow.add_node(\"operations_agent\", operations_node)\n",
        "    workflow.add_node(\"aggregation\", aggregation_node)\n",
        "    \n",
        "    workflow.set_entry_point(\"routing\")\n",
        "    \n",
        "    workflow.add_conditional_edges(\n",
        "        \"routing\",\n",
        "        lambda state: \"legal_agent\" if \"legal\" in state['routed_agents'] else \"aggregation\",\n",
        "        {\"legal_agent\": \"legal_agent\", \"aggregation\": \"aggregation\"}\n",
        "    )\n",
        "    workflow.add_conditional_edges(\n",
        "        \"legal_agent\",\n",
        "        lambda state: \"compliance_agent\" if \"compliance\" in state['routed_agents'] else \"aggregation\",\n",
        "        {\"compliance_agent\": \"compliance_agent\", \"aggregation\": \"aggregation\"}\n",
        "    )\n",
        "    workflow.add_conditional_edges(\n",
        "        \"compliance_agent\",\n",
        "        lambda state: \"finance_agent\" if \"finance\" in state['routed_agents'] else \"aggregation\",\n",
        "        {\"finance_agent\": \"finance_agent\", \"aggregation\": \"aggregation\"}\n",
        "    )\n",
        "    workflow.add_conditional_edges(\n",
        "        \"finance_agent\",\n",
        "        lambda state: \"operations_agent\" if \"operations\" in state['routed_agents'] else \"aggregation\",\n",
        "        {\"operations_agent\": \"operations_agent\", \"aggregation\": \"aggregation\"}\n",
        "    )\n",
        "    workflow.add_edge(\"operations_agent\", \"aggregation\")\n",
        "    workflow.add_edge(\"aggregation\", END)\n",
        "    \n",
        "    app = workflow.compile()\n",
        "    print(\"Workflow rebuilt and compiled successfully\")\n",
        "\n",
        "print(\"PREPARING INITIAL STATE\")\n",
        "\n",
        "input_state = {\n",
        "    \"query\": \"Analyze contract for termination, GDPR compliance, data protection, privacy obligations, regulatory requirements, audit and reporting requirements, confidentiality and non-disclosure obligations, payment terms, deliverables, project outputs, timelines and milestones for delivery, performance standards and obligations, operational requirements and responsibilities, service level agreements and SLAs.\",\n",
        "    \"routed_agents\": [],\n",
        "    \"routing_reasoning\": \"\",\n",
        "    \"routing_approach\": \"\",\n",
        "    \"legal\": {},\n",
        "    \"compliance\": {},\n",
        "    \"finance\": {},\n",
        "    \"operations\": {},\n",
        "    \"all_clauses\": [],\n",
        "    \"total_clauses_retrieved\": 0,\n",
        "    \"execution_order\": [],\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"vector_store\": \"Pinecone\",\n",
        "    \"execution_status\": \"initialized\"\n",
        "}\n",
        "\n",
        "print(\"\\nInitial State Created:\")\n",
        "print(json.dumps({\n",
        "    \"query\": input_state[\"query\"],\n",
        "    \"coordinator_model\": input_state[\"coordinator_model\"],\n",
        "    \"vector_store\": input_state[\"vector_store\"],\n",
        "    \"timestamp\": input_state[\"timestamp\"],\n",
        "    \"status\": input_state[\"execution_status\"]\n",
        "}, indent=2))\n",
        "\n",
        "print(\"EXECUTING MULTI-AGENT WORKFLOW\")\n",
        "print(f\"Query: \\\"{input_state['query']}\\\"\")\n",
        "print(\"\\nStarting execution...\")\n",
        "\n",
        "try:\n",
        "    result = app.invoke(input_state)\n",
        "    \n",
        "    print(\"âœ“ EXECUTION COMPLETED SUCCESSFULLY\")\n",
        "  \n",
        "    print(\"\\nExecution Summary:\")\n",
        "    print(f\"  Status: {result.get('execution_status', 'unknown')}\")\n",
        "    print(f\"  Agents Routed: {', '.join(result.get('routed_agents', []))}\")\n",
        "    print(f\"  Routing Reasoning: {result.get('routing_reasoning', 'N/A')}\")\n",
        "    print(f\"  Execution Order: {' â†’ '.join(result.get('execution_order', []))}\")\n",
        "    print(f\"  Total Clauses Retrieved: {result.get('total_clauses_retrieved', 0)}\")\n",
        "    \n",
        "    print(\"AGENT RESULTS\")\n",
        "\n",
        "    for agent_name in ['legal', 'compliance', 'finance', 'operations']:\n",
        "        agent_result = result.get(agent_name, {})\n",
        "        if agent_result:\n",
        "            print(f\"\\n{agent_name.upper()} Agent:\")\n",
        "            print(f\"  Status: {agent_result.get('status', 'unknown')}\")\n",
        "            \n",
        "            if agent_result.get('status') == 'completed':\n",
        "                print(f\"  Clauses Retrieved: {agent_result.get('clauses_retrieved', 0)}\")\n",
        "                if agent_result.get('avg_relevance'):\n",
        "                    print(f\"  Avg Relevance: {agent_result['avg_relevance']:.3f}\")\n",
        "                    print(f\"  Max Relevance: {agent_result['max_relevance']:.3f}\")\n",
        "    \n",
        "    if result.get('all_clauses'):\n",
        "   \n",
        "        print(\"TOP RETRIEVED CLAUSES\")\n",
        "\n",
        "        \n",
        "        for idx, clause in enumerate(result['all_clauses'][:5], 1):\n",
        "            print(f\"\\n[{idx}] Agent: {clause['agent'].upper()} | Relevance: {clause['relevance_score']:.3f}\")\n",
        "            clause_text = clause['clause'][:150] + \"...\" if len(clause['clause']) > 150 else clause['clause']\n",
        "            print(f\"    {clause_text}\")\n",
        "    \n",
        "    \n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nExecution failed: {str(e)}\")\n",
        "    print(\"ERROR DETAILS\")\n",
        "    print(f\"  Error Type: {type(e).__name__}\")\n",
        "    print(f\"  Error Message: {str(e)}\")\n",
        "    \n",
        "    import traceback\n",
        "    print(\"\\nFull Traceback:\")\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"WORKFLOW EXECUTION COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8. Inspecting Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INSPECTING WORKFLOW OUTPUT\n",
            "\n",
            "Inspecting Graph Execution Results...\n",
            "STATE STRUCTURE\n",
            "State Keys: ['query', 'routed_agents', 'routing_reasoning', 'routing_approach', 'legal', 'compliance', 'finance', 'operations', 'all_clauses', 'total_clauses_retrieved', 'execution_order', 'timestamp', 'coordinator_model', 'vector_store', 'execution_status']\n",
            "ROUTING INFORMATION\n",
            "Query: \"Analyze contract for termination, GDPR compliance, data protection, privacy obligations, regulatory requirements, audit and reporting requirements, confidentiality and non-disclosure obligations, payment terms, deliverables, project outputs, timelines and milestones for delivery, performance standards and obligations, operational requirements and responsibilities, service level agreements and SLAs.\"\n",
            "Coordinator Model: gemma2:9b\n",
            "Vector Store: Pinecone\n",
            "Routing Approach: dynamic_llm_coordinator\n",
            "Agents Routed: legal, compliance, finance, operations\n",
            "Routing Reasoning: The query touches upon legal clauses (termination), data protection and privacy regulations, financial terms (payment), and operational aspects (deliverables, timelines, SLAs).\n",
            "EXECUTION ORDER\n",
            "  1. routing\n",
            "  2. legal\n",
            "  3. compliance\n",
            "  4. finance\n",
            "  5. operations\n",
            "  6. aggregation\n",
            "AGENT RESULTS INSPECTION\n",
            "\n",
            "1. LEGAL AGENT:\n",
            "   Status: completed\n",
            "   Source: pinecone_vector_store\n",
            "   Clauses Retrieved: 2\n",
            "   Avg Relevance: 0.312\n",
            "   Max Relevance: 0.336\n",
            "   Sample Clauses:\n",
            "      1. [0.336] The other party shall give notice of termination in writing to the other party, which notice shall s...\n",
            "      2. [0.288] The other party asserts any rights in or to the terminating party's intellectual property in violati...\n",
            "\n",
            "2. COMPLIANCE AGENT:\n",
            "   Status: completed\n",
            "   Source: pinecone_vector_store\n",
            "   Clauses Retrieved: 1\n",
            "   Avg Relevance: 0.227\n",
            "   Max Relevance: 0.227\n",
            "   Sample Clauses:\n",
            "      1. [0.227] The receiving party will not disclose the other party's confidential information to any third partie...\n",
            "\n",
            "3. FINANCE AGENT:\n",
            "   Status: completed\n",
            "   Source: pinecone_vector_store\n",
            "   Clauses Retrieved: 3\n",
            "   Avg Relevance: 0.256\n",
            "   Max Relevance: 0.349\n",
            "   Sample Clauses:\n",
            "      1. [0.349] In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision ...\n",
            "      2. [0.218] ), Recipient shall reimburse Provider for all such Out-of-Pocket Costs.\n",
            "\n",
            "4. OPERATIONS AGENT:\n",
            "   Status: completed\n",
            "   Source: pinecone_vector_store\n",
            "   Clauses Retrieved: 2\n",
            "   Avg Relevance: 0.214\n",
            "   Max Relevance: 0.260\n",
            "   Sample Clauses:\n",
            "      1. [0.260] Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distr...\n",
            "      2. [0.169] Collectible Concepts Group will obtain any licenses deemed by the Joint Venturers to add value in th...\n",
            "OVERALL STATISTICS\n",
            "Total Agents Executed: 4\n",
            "Total Clauses Retrieved: 8\n",
            "Execution Status: success\n",
            "SAVING RESULTS\n",
            "\n",
            "Results saved successfully!\n",
            "  File: langgraph_execution_20260115_145315.json\n",
            "  Location: ../Data/Results/LangGraph\n",
            "  Size: 3767 bytes\n",
            "INSPECTION AND SAVE COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"INSPECTING WORKFLOW OUTPUT\")\n",
        "\n",
        "print(\"\\nInspecting Graph Execution Results...\")\n",
        "\n",
        "print(\"STATE STRUCTURE\")\n",
        "\n",
        "print(f\"State Keys: {list(result.keys())}\")\n",
        "\n",
        "\n",
        "print(\"ROUTING INFORMATION\")\n",
        "\n",
        "print(f\"Query: \\\"{result['query']}\\\"\")\n",
        "print(f\"Coordinator Model: {result.get('coordinator_model', 'N/A')}\")\n",
        "print(f\"Vector Store: {result.get('vector_store', 'N/A')}\")\n",
        "print(f\"Routing Approach: {result.get('routing_approach', 'N/A')}\")\n",
        "print(f\"Agents Routed: {', '.join(result.get('routed_agents', []))}\")\n",
        "print(f\"Routing Reasoning: {result.get('routing_reasoning', 'N/A')}\")\n",
        "\n",
        "\n",
        "print(\"EXECUTION ORDER\")\n",
        "\n",
        "for idx, node in enumerate(result['execution_order'], 1):\n",
        "    print(f\"  {idx}. {node}\")\n",
        "\n",
        "print(\"AGENT RESULTS INSPECTION\")\n",
        "\n",
        "print(f\"\\n1. LEGAL AGENT:\")\n",
        "if result['legal']:\n",
        "    print(f\"   Status: {result['legal'].get('status', 'unknown')}\")\n",
        "    print(f\"   Source: {result['legal'].get('source', 'N/A')}\")\n",
        "    print(f\"   Clauses Retrieved: {result['legal'].get('clauses_retrieved', 0)}\")\n",
        "    \n",
        "    if result['legal'].get('status') == 'completed':\n",
        "        print(f\"   Avg Relevance: {result['legal'].get('avg_relevance', 0):.3f}\")\n",
        "        print(f\"   Max Relevance: {result['legal'].get('max_relevance', 0):.3f}\")\n",
        "        \n",
        "        clauses = result['legal'].get('clauses', [])\n",
        "        if clauses:\n",
        "            print(f\"   Sample Clauses:\")\n",
        "            for i, clause_data in enumerate(clauses[:2], 1):\n",
        "                clause_text = clause_data['clause'][:100] + \"...\" if len(clause_data['clause']) > 100 else clause_data['clause']\n",
        "                print(f\"      {i}. [{clause_data['relevance_score']:.3f}] {clause_text}\")\n",
        "else:\n",
        "    print(\"   No data\")\n",
        "\n",
        "print(f\"\\n2. COMPLIANCE AGENT:\")\n",
        "if result['compliance']:\n",
        "    print(f\"   Status: {result['compliance'].get('status', 'unknown')}\")\n",
        "    print(f\"   Source: {result['compliance'].get('source', 'N/A')}\")\n",
        "    print(f\"   Clauses Retrieved: {result['compliance'].get('clauses_retrieved', 0)}\")\n",
        "    \n",
        "    if result['compliance'].get('status') == 'completed':\n",
        "        print(f\"   Avg Relevance: {result['compliance'].get('avg_relevance', 0):.3f}\")\n",
        "        print(f\"   Max Relevance: {result['compliance'].get('max_relevance', 0):.3f}\")\n",
        "        \n",
        "        clauses = result['compliance'].get('clauses', [])\n",
        "        if clauses:\n",
        "            print(f\"   Sample Clauses:\")\n",
        "            for i, clause_data in enumerate(clauses[:2], 1):\n",
        "                clause_text = clause_data['clause'][:100] + \"...\" if len(clause_data['clause']) > 100 else clause_data['clause']\n",
        "                print(f\"      {i}. [{clause_data['relevance_score']:.3f}] {clause_text}\")\n",
        "else:\n",
        "    print(\"   No data\")\n",
        "\n",
        "print(f\"\\n3. FINANCE AGENT:\")\n",
        "if result['finance']:\n",
        "    print(f\"   Status: {result['finance'].get('status', 'unknown')}\")\n",
        "    print(f\"   Source: {result['finance'].get('source', 'N/A')}\")\n",
        "    print(f\"   Clauses Retrieved: {result['finance'].get('clauses_retrieved', 0)}\")\n",
        "    \n",
        "    if result['finance'].get('status') == 'completed':\n",
        "        print(f\"   Avg Relevance: {result['finance'].get('avg_relevance', 0):.3f}\")\n",
        "        print(f\"   Max Relevance: {result['finance'].get('max_relevance', 0):.3f}\")\n",
        "        \n",
        "        clauses = result['finance'].get('clauses', [])\n",
        "        if clauses:\n",
        "            print(f\"   Sample Clauses:\")\n",
        "            for i, clause_data in enumerate(clauses[:2], 1):\n",
        "                clause_text = clause_data['clause'][:100] + \"...\" if len(clause_data['clause']) > 100 else clause_data['clause']\n",
        "                print(f\"      {i}. [{clause_data['relevance_score']:.3f}] {clause_text}\")\n",
        "else:\n",
        "    print(\"   No data\")\n",
        "\n",
        "print(f\"\\n4. OPERATIONS AGENT:\")\n",
        "if result['operations']:\n",
        "    print(f\"   Status: {result['operations'].get('status', 'unknown')}\")\n",
        "    print(f\"   Source: {result['operations'].get('source', 'N/A')}\")\n",
        "    print(f\"   Clauses Retrieved: {result['operations'].get('clauses_retrieved', 0)}\")\n",
        "    \n",
        "    if result['operations'].get('status') == 'completed':\n",
        "        print(f\"   Avg Relevance: {result['operations'].get('avg_relevance', 0):.3f}\")\n",
        "        print(f\"   Max Relevance: {result['operations'].get('max_relevance', 0):.3f}\")\n",
        "        \n",
        "        clauses = result['operations'].get('clauses', [])\n",
        "        if clauses:\n",
        "            print(f\"   Sample Clauses:\")\n",
        "            for i, clause_data in enumerate(clauses[:2], 1):\n",
        "                clause_text = clause_data['clause'][:100] + \"...\" if len(clause_data['clause']) > 100 else clause_data['clause']\n",
        "                print(f\"      {i}. [{clause_data['relevance_score']:.3f}] {clause_text}\")\n",
        "else:\n",
        "    print(\"   No data\")\n",
        "\n",
        "total_clauses = result.get('total_clauses_retrieved', 0)\n",
        "total_agents_executed = len([a for a in result['execution_order'] if a not in ['routing', 'aggregation']])\n",
        "\n",
        "print(\"OVERALL STATISTICS\")\n",
        "print(f\"Total Agents Executed: {total_agents_executed}\")\n",
        "print(f\"Total Clauses Retrieved: {total_clauses}\")\n",
        "print(f\"Execution Status: {result.get('execution_status', 'unknown')}\")\n",
        "\n",
        "print(\"SAVING RESULTS\")\n",
        "\n",
        "LANGGRAPH_OUTPUT = \"../Data/Results/LangGraph\"\n",
        "os.makedirs(LANGGRAPH_OUTPUT, exist_ok=True)\n",
        "\n",
        "timestamp = result.get('timestamp', datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "output_file = f\"langgraph_execution_{timestamp}.json\"\n",
        "output_path = os.path.join(LANGGRAPH_OUTPUT, output_file)\n",
        "\n",
        "output_data = {\n",
        "    \"execution_metadata\": {\n",
        "        \"query\": result['query'],\n",
        "        \"coordinator_model\": result.get('coordinator_model', 'N/A'),\n",
        "        \"vector_store\": result.get('vector_store', 'N/A'),\n",
        "        \"timestamp\": result['timestamp'],\n",
        "        \"execution_status\": result.get('execution_status', 'unknown')\n",
        "    },\n",
        "    \"routing\": {\n",
        "        \"approach\": result.get('routing_approach', 'N/A'),\n",
        "        \"agents_routed\": result.get('routed_agents', []),\n",
        "        \"reasoning\": result.get('routing_reasoning', 'N/A')\n",
        "    },\n",
        "    \"execution_order\": result['execution_order'],\n",
        "    \"agent_results\": {\n",
        "        \"legal\": {\n",
        "            \"status\": result['legal'].get('status', 'unknown'),\n",
        "            \"source\": result['legal'].get('source', 'N/A'),\n",
        "            \"clauses_retrieved\": result['legal'].get('clauses_retrieved', 0),\n",
        "            \"avg_relevance\": result['legal'].get('avg_relevance', 0),\n",
        "            \"max_relevance\": result['legal'].get('max_relevance', 0)\n",
        "        },\n",
        "        \"compliance\": {\n",
        "            \"status\": result['compliance'].get('status', 'unknown'),\n",
        "            \"source\": result['compliance'].get('source', 'N/A'),\n",
        "            \"clauses_retrieved\": result['compliance'].get('clauses_retrieved', 0),\n",
        "            \"avg_relevance\": result['compliance'].get('avg_relevance', 0),\n",
        "            \"max_relevance\": result['compliance'].get('max_relevance', 0)\n",
        "        },\n",
        "        \"finance\": {\n",
        "            \"status\": result['finance'].get('status', 'unknown'),\n",
        "            \"source\": result['finance'].get('source', 'N/A'),\n",
        "            \"clauses_retrieved\": result['finance'].get('clauses_retrieved', 0),\n",
        "            \"avg_relevance\": result['finance'].get('avg_relevance', 0),\n",
        "            \"max_relevance\": result['finance'].get('max_relevance', 0)\n",
        "        },\n",
        "        \"operations\": {\n",
        "            \"status\": result['operations'].get('status', 'unknown'),\n",
        "            \"source\": result['operations'].get('source', 'N/A'),\n",
        "            \"clauses_retrieved\": result['operations'].get('clauses_retrieved', 0),\n",
        "            \"avg_relevance\": result['operations'].get('avg_relevance', 0),\n",
        "            \"max_relevance\": result['operations'].get('max_relevance', 0)\n",
        "        }\n",
        "    },\n",
        "    \"all_clauses\": result.get('all_clauses', []),\n",
        "    \"summary\": {\n",
        "        \"total_agents_executed\": total_agents_executed,\n",
        "        \"total_clauses_retrieved\": total_clauses,\n",
        "        \"workflow_type\": \"Dynamic LLM-based coordination with Pinecone retrieval\"\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\nResults saved successfully!\")\n",
        "print(f\"  File: {output_file}\")\n",
        "print(f\"  Location: {LANGGRAPH_OUTPUT}\")\n",
        "print(f\"  Size: {len(json.dumps(output_data))} bytes\")\n",
        "\n",
        "print(\"INSPECTION AND SAVE COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9. Changing Execution Order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODIFIED CONDITIONAL BRANCHING ORDER\n",
            "\n",
            "Defining new conditional flow:\n",
            "  routing â†’ compliance (priority 1)\n",
            "  compliance â†’ finance (priority 2)\n",
            "  finance â†’ legal (priority 3)\n",
            "  legal â†’ operations (priority 4)\n",
            "  operations â†’ aggregation â†’ END\n",
            "\n",
            "Compiling reordered workflow...\n",
            "Graph compiled successfully\n",
            "EXECUTING REORDERED WORKFLOW\n",
            "Query: \"Analyze contract for GDPR compliance, payment terms, termination, and SLAs\"\n",
            "\n",
            "Expected order: Compliance â†’ Finance â†’ Legal â†’ Operations\n",
            "(Based on LLM routing + new conditional priority)\n",
            "ROUTING NODE: Dynamic LLM Coordinator\n",
            "Query: \"Analyze contract for GDPR compliance, payment terms, termination, and SLAs\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Routing Decision:\n",
            "  Agents: compliance, finance, legal, operations\n",
            "  Reasoning: GDPR compliance falls under data protection handled by the Compliance agent. Payment terms are handled by the Finance agent. Termination clauses and SLAs are covered by the Legal and Operations agents respectively.\n",
            "  Approach: dynamic_llm_coordinator\n",
            "\n",
            "  â†’ COMPLIANCE AGENT executing\n",
            "     Query: Analyze contract for GDPR compliance, payment terms, termina...\n",
            "     Retrieved: 1 clauses\n",
            "     Avg relevance: 0.157\n",
            "\n",
            "  â†’ FINANCE AGENT executing\n",
            "     Query: Analyze contract for GDPR compliance, payment terms, termina...\n",
            "     Retrieved: 3 clauses\n",
            "     Avg relevance: 0.273\n",
            "\n",
            "  â†’ LEGAL AGENT executing\n",
            "     Query: Analyze contract for GDPR compliance, payment terms, termina...\n",
            "     Retrieved: 2 clauses\n",
            "     Avg relevance: 0.286\n",
            "\n",
            "  â†’ OPERATIONS AGENT executing\n",
            "     Query: Analyze contract for GDPR compliance, payment terms, termina...\n",
            "     Retrieved: 2 clauses\n",
            "     Avg relevance: 0.180\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 8\n",
            "Top relevance score: 0.337\n",
            "Agents executed: compliance, finance, legal, operations\n",
            "EXECUTION ORDER COMPARISON\n",
            "\n",
            "ORIGINAL ORDER (from earlier execution):\n",
            "  Legal â†’ Compliance â†’ Finance â†’ Operations\n",
            "\n",
            "NEW ORDER (reordered workflow):\n",
            "  routing â†’ compliance â†’ finance â†’ legal â†’ operations â†’ aggregation\n",
            "\n",
            "Routed Agents:\n",
            "  compliance, finance, legal, operations\n",
            "\n",
            "Routing Reasoning:\n",
            "  GDPR compliance falls under data protection handled by the Compliance agent. Payment terms are handled by the Finance agent. Termination clauses and SLAs are covered by the Legal and Operations agents respectively.\n",
            "ORDER CHANGE VERIFICATION\n",
            "SUCCESS: Execution order changed!\n",
            "  First agent: Compliance (as intended)\n",
            "  Full agent order: compliance â†’ finance â†’ legal â†’ operations\n",
            "RESULTS SUMMARY\n",
            "Total Clauses Retrieved: 8\n",
            "Execution Status: success\n",
            "\n",
            "Agent Results:\n",
            "  COMPLIANCE: completed - 1 clauses\n",
            "  FINANCE: completed - 3 clauses\n",
            "  LEGAL: completed - 2 clauses\n",
            "  OPERATIONS: completed - 2 clauses\n",
            "EXECUTION ORDER CHANGE DEMONSTRATION COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"MODIFIED CONDITIONAL BRANCHING ORDER\")\n",
        "\n",
        "\n",
        "workflow_reordered = StateGraph(GraphState)\n",
        "\n",
        "workflow_reordered.add_node(\"routing\", routing_node)\n",
        "workflow_reordered.add_node(\"legal_agent\", legal_node)\n",
        "workflow_reordered.add_node(\"compliance_agent\", compliance_node)\n",
        "workflow_reordered.add_node(\"finance_agent\", finance_node)\n",
        "workflow_reordered.add_node(\"operations_agent\", operations_node)\n",
        "workflow_reordered.add_node(\"aggregation\", aggregation_node)\n",
        "\n",
        "workflow_reordered.set_entry_point(\"routing\")\n",
        "\n",
        "print(\"\\nDefining new conditional flow:\")\n",
        "\n",
        "workflow_reordered.add_conditional_edges(\n",
        "    \"routing\",\n",
        "    lambda state: \"compliance_agent\" if \"compliance\" in state['routed_agents'] else \"finance_agent\" if \"finance\" in state['routed_agents'] else \"legal_agent\" if \"legal\" in state['routed_agents'] else \"operations_agent\" if \"operations\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  routing â†’ compliance (priority 1)\")\n",
        "\n",
        "workflow_reordered.add_conditional_edges(\n",
        "    \"compliance_agent\",\n",
        "    lambda state: \"finance_agent\" if \"finance\" in state['routed_agents'] else \"legal_agent\" if \"legal\" in state['routed_agents'] else \"operations_agent\" if \"operations\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  compliance â†’ finance (priority 2)\")\n",
        "\n",
        "workflow_reordered.add_conditional_edges(\n",
        "    \"finance_agent\",\n",
        "    lambda state: \"legal_agent\" if \"legal\" in state['routed_agents'] else \"operations_agent\" if \"operations\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  finance â†’ legal (priority 3)\")\n",
        "\n",
        "workflow_reordered.add_conditional_edges(\n",
        "    \"legal_agent\",\n",
        "    lambda state: \"operations_agent\" if \"operations\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  legal â†’ operations (priority 4)\")\n",
        "\n",
        "workflow_reordered.add_edge(\"operations_agent\", \"aggregation\")\n",
        "workflow_reordered.add_edge(\"aggregation\", END)\n",
        "print(\"  operations â†’ aggregation â†’ END\")\n",
        "\n",
        "print(\"\\nCompiling reordered workflow...\")\n",
        "app_reordered = workflow_reordered.compile()\n",
        "print(\"Graph compiled successfully\")\n",
        "\n",
        "\n",
        "print(\"EXECUTING REORDERED WORKFLOW\")\n",
        "\n",
        "input_state_reordered = {\n",
        "    \"query\": \"Analyze contract for GDPR compliance, payment terms, termination, and SLAs\",\n",
        "    \"routed_agents\": [],\n",
        "    \"routing_reasoning\": \"\",\n",
        "    \"routing_approach\": \"\",\n",
        "    \"legal\": {},\n",
        "    \"compliance\": {},\n",
        "    \"finance\": {},\n",
        "    \"operations\": {},\n",
        "    \"all_clauses\": [],\n",
        "    \"total_clauses_retrieved\": 0,\n",
        "    \"execution_order\": [],\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"vector_store\": \"Pinecone\",\n",
        "    \"execution_status\": \"initialized\"\n",
        "}\n",
        "\n",
        "print(f\"Query: \\\"{input_state_reordered['query']}\\\"\")\n",
        "print(\"\\nExpected order: Compliance â†’ Finance â†’ Legal â†’ Operations\")\n",
        "print(\"(Based on LLM routing + new conditional priority)\")\n",
        "\n",
        "try:\n",
        "    result_reordered = app_reordered.invoke(input_state_reordered)\n",
        "    \n",
        "    print(\"EXECUTION ORDER COMPARISON\")\n",
        "\n",
        "    \n",
        "    print(f\"\\nORIGINAL ORDER (from earlier execution):\")\n",
        "    print(f\"  Legal â†’ Compliance â†’ Finance â†’ Operations\")\n",
        "    \n",
        "    print(f\"\\nNEW ORDER (reordered workflow):\")\n",
        "    print(f\"  {' â†’ '.join(result_reordered['execution_order'])}\")\n",
        "    \n",
        "    print(f\"\\nRouted Agents:\")\n",
        "    print(f\"  {', '.join(result_reordered.get('routed_agents', []))}\")\n",
        "    \n",
        "    print(f\"\\nRouting Reasoning:\")\n",
        "    print(f\"  {result_reordered.get('routing_reasoning', 'N/A')}\")\n",
        "    \n",
        "    execution_agents = [node for node in result_reordered['execution_order'] if node not in ['routing', 'aggregation']]\n",
        "    \n",
        "    print(\"ORDER CHANGE VERIFICATION\")\n",
        "\n",
        "    if execution_agents and execution_agents[0] == 'compliance':\n",
        "        print(\"SUCCESS: Execution order changed!\")\n",
        "        print(f\"  First agent: Compliance (as intended)\")\n",
        "        print(f\"  Full agent order: {' â†’ '.join(execution_agents)}\")\n",
        "    else:\n",
        "        print(\"Note: Actual order depends on which agents LLM selected\")\n",
        "        print(f\"  Agents executed: {' â†’ '.join(execution_agents) if execution_agents else 'None'}\")\n",
        "    \n",
        "\n",
        "    print(\"RESULTS SUMMARY\")\n",
        "\n",
        "    print(f\"Total Clauses Retrieved: {result_reordered.get('total_clauses_retrieved', 0)}\")\n",
        "    print(f\"Execution Status: {result_reordered.get('execution_status', 'unknown')}\")\n",
        "    \n",
        "    print(\"\\nAgent Results:\")\n",
        "    for agent_name in execution_agents:\n",
        "        agent_result = result_reordered.get(agent_name, {})\n",
        "        if agent_result:\n",
        "            status = agent_result.get('status', 'unknown')\n",
        "            clauses = agent_result.get('clauses_retrieved', 0)\n",
        "            print(f\"  {agent_name.upper()}: {status} - {clauses} clauses\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nâœ— Execution failed: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"EXECUTION ORDER CHANGE DEMONSTRATION COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 10. Removing One Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BUILDING WORKFLOW WITHOUT FINANCE AGENT\n",
            "Nodes added: routing, legal, compliance, operations, aggregation\n",
            "Finance agent excluded\n",
            "\n",
            "Defining conditional flow without finance agent:\n",
            "Conditional edges defined (skipping finance)\n",
            "\n",
            "Compiling workflow without finance agent...\n",
            "Graph compiled successfully\n",
            "EXECUTING WITHOUT FINANCE AGENT\n",
            "Query: \"Analyze contract for payment terms, termination clauses, and GDPR compliance\"\n",
            "ROUTING NODE: Dynamic LLM Coordinator\n",
            "Query: \"Analyze contract for payment terms, termination clauses, and GDPR compliance\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Routing Decision:\n",
            "  Agents: finance, compliance\n",
            "  Reasoning: The query mentions payment terms (Finance) and GDPR compliance (Compliance).\n",
            "  Approach: dynamic_llm_coordinator\n",
            "\n",
            "  â†’ COMPLIANCE AGENT executing\n",
            "     Query: Analyze contract for payment terms, termination clauses, and...\n",
            "     Retrieved: 1 clauses\n",
            "     Avg relevance: 0.202\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 1\n",
            "Top relevance score: 0.202\n",
            "Agents executed: compliance\n",
            "\n",
            "================================================================================\n",
            "EXECUTION RESULTS\n",
            "================================================================================\n",
            "\n",
            "Routed Agents (by LLM):\n",
            "  finance, compliance\n",
            "\n",
            "Actual Execution Order:\n",
            "  routing â†’ compliance â†’ aggregation\n",
            "\n",
            "Routing Reasoning:\n",
            "  The query mentions payment terms (Finance) and GDPR compliance (Compliance).\n",
            "STATE COMPARISON: WITH vs WITHOUT FINANCE\n",
            "\n",
            "Agent States:\n",
            "Agent           Status          Clauses    Notes\n",
            "----------------------------------------------------------------------\n",
            "LEGAL           not_in_graph    0          Empty state\n",
            "COMPLIANCE      completed       1          Retrieved from Pinecone\n",
            "FINANCE         not_in_graph    0          REMOVED (not in graph)\n",
            "OPERATIONS      not_in_graph    0          Empty state\n",
            "KEY OBSERVATIONS\n",
            "\n",
            "1. ROUTING vs EXECUTION:\n",
            "   LLM Routed To: finance, compliance\n",
            "   Actually Executed: compliance\n",
            "   Finance was routed but NOT executed (removed from graph)\n",
            "\n",
            "2. FINANCE STATE:\n",
            "   Finance state remains EMPTY (agent never executed)\n",
            "   No error - graph handles missing agent gracefully\n",
            "\n",
            "3. OTHER AGENTS:\n",
            "   Other agents executed normally: compliance\n",
            "   Workflow continues despite missing agent\n",
            "\n",
            "4. TOTAL CLAUSES:\n",
            "   Total clauses retrieved: 1\n",
            "   Source: compliance\n",
            "\n",
            "Results saved: langgraph_remove_agent_20260115_145441.json\n",
            "  Location: ../Data/Results/LangGraph\n",
            "AGENT REMOVAL DEMONSTRATION COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"BUILDING WORKFLOW WITHOUT FINANCE AGENT\")\n",
        "\n",
        "workflow_no_finance = StateGraph(GraphState)\n",
        "\n",
        "workflow_no_finance.add_node(\"routing\", routing_node)\n",
        "workflow_no_finance.add_node(\"legal_agent\", legal_node)\n",
        "workflow_no_finance.add_node(\"compliance_agent\", compliance_node)\n",
        "workflow_no_finance.add_node(\"operations_agent\", operations_node)\n",
        "workflow_no_finance.add_node(\"aggregation\", aggregation_node)\n",
        "\n",
        "print(\"Nodes added: routing, legal, compliance, operations, aggregation\")\n",
        "print(\"Finance agent excluded\")\n",
        "\n",
        "workflow_no_finance.set_entry_point(\"routing\")\n",
        "\n",
        "print(\"\\nDefining conditional flow without finance agent:\")\n",
        "\n",
        "workflow_no_finance.add_conditional_edges(\n",
        "    \"routing\",\n",
        "    lambda state: \"legal_agent\" if \"legal\" in state['routed_agents'] else \"compliance_agent\" if \"compliance\" in state['routed_agents'] else \"operations_agent\" if \"operations\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow_no_finance.add_conditional_edges(\n",
        "    \"legal_agent\",\n",
        "    lambda state: \"compliance_agent\" if \"compliance\" in state['routed_agents'] else \"operations_agent\" if \"operations\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow_no_finance.add_conditional_edges(\n",
        "    \"compliance_agent\",\n",
        "    lambda state: \"operations_agent\" if \"operations\" in state['routed_agents'] else \"aggregation\",\n",
        "    {\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow_no_finance.add_edge(\"operations_agent\", \"aggregation\")\n",
        "workflow_no_finance.add_edge(\"aggregation\", END)\n",
        "\n",
        "print(\"Conditional edges defined (skipping finance)\")\n",
        "\n",
        "print(\"\\nCompiling workflow without finance agent...\")\n",
        "app_no_finance = workflow_no_finance.compile()\n",
        "print(\"Graph compiled successfully\")\n",
        "\n",
        "print(\"EXECUTING WITHOUT FINANCE AGENT\")\n",
        "\n",
        "input_state_no_finance = {\n",
        "    \"query\": \"Analyze contract for payment terms, termination clauses, and GDPR compliance\",\n",
        "    \"routed_agents\": [],\n",
        "    \"routing_reasoning\": \"\",\n",
        "    \"routing_approach\": \"\",\n",
        "    \"legal\": {},\n",
        "    \"compliance\": {},\n",
        "    \"finance\": {},\n",
        "    \"operations\": {},\n",
        "    \"all_clauses\": [],\n",
        "    \"total_clauses_retrieved\": 0,\n",
        "    \"execution_order\": [],\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"vector_store\": \"Pinecone\",\n",
        "    \"execution_status\": \"initialized\"\n",
        "}\n",
        "\n",
        "print(f\"Query: \\\"{input_state_no_finance['query']}\\\"\")\n",
        "\n",
        "try:\n",
        "    result_no_finance = app_no_finance.invoke(input_state_no_finance)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"EXECUTION RESULTS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    print(f\"\\nRouted Agents (by LLM):\")\n",
        "    print(f\"  {', '.join(result_no_finance.get('routed_agents', []))}\")\n",
        "    \n",
        "    print(f\"\\nActual Execution Order:\")\n",
        "    print(f\"  {' â†’ '.join(result_no_finance['execution_order'])}\")\n",
        "    \n",
        "    print(f\"\\nRouting Reasoning:\")\n",
        "    print(f\"  {result_no_finance.get('routing_reasoning', 'N/A')}\")\n",
        "    \n",
        "\n",
        "    print(\"STATE COMPARISON: WITH vs WITHOUT FINANCE\")\n",
        "\n",
        "    \n",
        "    print(\"\\nAgent States:\")\n",
        "    print(f\"{'Agent':<15} {'Status':<15} {'Clauses':<10} {'Notes'}\")\n",
        "    print(\"-\" * 70)\n",
        "    \n",
        "    for agent_name in [\"legal\", \"compliance\", \"finance\", \"operations\"]:\n",
        "        agent_result = result_no_finance.get(agent_name, {})\n",
        "        status = agent_result.get(\"status\", \"not_in_graph\")\n",
        "        clauses = agent_result.get(\"clauses_retrieved\", 0)\n",
        "        \n",
        "        if agent_name == \"finance\":\n",
        "            notes = \"REMOVED (not in graph)\"\n",
        "        elif not agent_result:\n",
        "            notes = \"Empty state\"\n",
        "        elif status == \"completed\":\n",
        "            notes = f\"Retrieved from Pinecone\"\n",
        "        elif status == \"no_results\":\n",
        "            notes = \"No relevant clauses\"\n",
        "        else:\n",
        "            notes = status\n",
        "        \n",
        "        print(f\"{agent_name.upper():<15} {status:<15} {clauses:<10} {notes}\")\n",
        "    \n",
        "    print(\"KEY OBSERVATIONS\")\n",
        "\n",
        "    \n",
        "    routed_agents = result_no_finance.get('routed_agents', [])\n",
        "    executed_agents = [a for a in result_no_finance['execution_order'] if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    print(\"\\n1. ROUTING vs EXECUTION:\")\n",
        "    print(f\"   LLM Routed To: {', '.join(routed_agents)}\")\n",
        "    print(f\"   Actually Executed: {', '.join(executed_agents)}\")\n",
        "    \n",
        "    if 'finance' in routed_agents and 'finance' not in executed_agents:\n",
        "        print(f\"   Finance was routed but NOT executed (removed from graph)\")\n",
        "    \n",
        "    print(\"\\n2. FINANCE STATE:\")\n",
        "    finance_state = result_no_finance.get('finance', {})\n",
        "    if not finance_state or finance_state == {}:\n",
        "        print(\"   Finance state remains EMPTY (agent never executed)\")\n",
        "        print(\"   No error - graph handles missing agent gracefully\")\n",
        "    else:\n",
        "        print(f\"   Finance state: {finance_state}\")\n",
        "    \n",
        "    print(\"\\n3. OTHER AGENTS:\")\n",
        "    other_agents_executed = [a for a in executed_agents if a != 'finance']\n",
        "    if other_agents_executed:\n",
        "        print(f\"   Other agents executed normally: {', '.join(other_agents_executed)}\")\n",
        "        print(\"   Workflow continues despite missing agent\")\n",
        "    else:\n",
        "        print(\"    No agents executed\")\n",
        "    \n",
        "    print(\"\\n4. TOTAL CLAUSES:\")\n",
        "    total_clauses = result_no_finance.get('total_clauses_retrieved', 0)\n",
        "    print(f\"   Total clauses retrieved: {total_clauses}\")\n",
        "    print(f\"   Source: {', '.join(executed_agents) if executed_agents else 'None'}\")\n",
        "\n",
        "    LANGGRAPH_OUTPUT = \"../Data/Results/LangGraph\"\n",
        "    os.makedirs(LANGGRAPH_OUTPUT, exist_ok=True)\n",
        "    \n",
        "    timestamp = result_no_finance.get('timestamp', datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
        "    \n",
        "    removal_results = {\n",
        "        \"task\": \"Remove Agent and Observe State Changes\",\n",
        "        \"removed_agent\": \"finance\",\n",
        "        \"query\": input_state_no_finance['query'],\n",
        "        \"coordinator_model\": \"gemma2:9b\",\n",
        "        \"timestamp\": timestamp,\n",
        "        \"routing\": {\n",
        "            \"llm_routed_agents\": result_no_finance.get('routed_agents', []),\n",
        "            \"reasoning\": result_no_finance.get('routing_reasoning', 'N/A'),\n",
        "            \"approach\": result_no_finance.get('routing_approach', 'N/A')\n",
        "        },\n",
        "        \"execution\": {\n",
        "            \"execution_order\": result_no_finance['execution_order'],\n",
        "            \"agents_executed\": executed_agents,\n",
        "            \"finance_in_routed\": 'finance' in routed_agents,\n",
        "            \"finance_executed\": 'finance' in executed_agents\n",
        "        },\n",
        "        \"state_analysis\": {\n",
        "            \"legal\": {\n",
        "                \"status\": result_no_finance.get('legal', {}).get('status', 'empty'),\n",
        "                \"clauses\": result_no_finance.get('legal', {}).get('clauses_retrieved', 0)\n",
        "            },\n",
        "            \"compliance\": {\n",
        "                \"status\": result_no_finance.get('compliance', {}).get('status', 'empty'),\n",
        "                \"clauses\": result_no_finance.get('compliance', {}).get('clauses_retrieved', 0)\n",
        "            },\n",
        "            \"finance\": {\n",
        "                \"status\": \"removed_from_graph\",\n",
        "                \"state\": result_no_finance.get('finance', {}),\n",
        "                \"clauses\": 0,\n",
        "                \"note\": \"Agent not in workflow - state remains empty\"\n",
        "            },\n",
        "            \"operations\": {\n",
        "                \"status\": result_no_finance.get('operations', {}).get('status', 'empty'),\n",
        "                \"clauses\": result_no_finance.get('operations', {}).get('clauses_retrieved', 0)\n",
        "            }\n",
        "        },\n",
        "        \"totals\": {\n",
        "            \"total_clauses_retrieved\": result_no_finance.get('total_clauses_retrieved', 0),\n",
        "            \"execution_status\": result_no_finance.get('execution_status', 'unknown')\n",
        "        },\n",
        "        \"key_learnings\": [\n",
        "            \"Agents can be removed from graph dynamically\",\n",
        "            \"LLM may route to removed agent, but it won't execute\",\n",
        "            \"Removed agent's state remains empty (no error)\",\n",
        "            \"Workflow continues normally with remaining agents\",\n",
        "            \"Dynamic coordination handles missing agents gracefully\",\n",
        "            \"State structure consistent regardless of available agents\"\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    student_file = f\"langgraph_remove_agent_{timestamp}.json\"\n",
        "    student_path = os.path.join(LANGGRAPH_OUTPUT, student_file)\n",
        "    \n",
        "    with open(student_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(removal_results, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"\\nResults saved: {student_file}\")\n",
        "    print(f\"  Location: {LANGGRAPH_OUTPUT}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nExecution failed: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"AGENT REMOVAL DEMONSTRATION COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conditional Routing in LanGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Defining Routing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import TypedDict, Dict, Any, List, Literal\n",
        "from collections import defaultdict\n",
        "\n",
        "try:\n",
        "    from langgraph.graph import StateGraph, END\n",
        "except:\n",
        "    from langgraph.graph import Graph as StateGraph, END"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEFINING CONDITIONAL ROUTING WITH DYNAMIC LLM COORDINATOR\n",
            "\n",
            "Agent Retrieval Thresholds:\n",
            "  LEGAL: 0.10 (relevance score)\n",
            "  COMPLIANCE: 0.10 (relevance score)\n",
            "  FINANCE: 0.10 (relevance score)\n",
            "  OPERATIONS: 0.10 (relevance score)\n",
            "RETRIEVAL FUNCTION\n",
            "retrieve_from_pinecone_adaptive() defined\n",
            "DEFINING CONDITIONAL ROUTING LOGIC\n",
            "conditional_route_to_agents() defined\n",
            "DEFINING ROUTING DECISION FUNCTION FOR LANGGRAPH\n",
            "route_to_next_agent() defined\n",
            "All agent nodes updated with adaptive thresholds\n",
            "CONDITIONAL ROUTING SYSTEM READY\n"
          ]
        }
      ],
      "source": [
        "print(\"DEFINING CONDITIONAL ROUTING WITH DYNAMIC LLM COORDINATOR\")\n",
        "\n",
        "AGENT_THRESHOLDS = {\n",
        "    \"legal\": 0.10,      \n",
        "    \"compliance\": 0.10,  \n",
        "    \"finance\": 0.10,     \n",
        "    \"operations\": 0.10   \n",
        "}\n",
        "\n",
        "print(\"\\nAgent Retrieval Thresholds:\")\n",
        "for agent, threshold in AGENT_THRESHOLDS.items():\n",
        "    print(f\"  {agent.upper()}: {threshold:.2f} (relevance score)\")\n",
        "\n",
        "print(\"RETRIEVAL FUNCTION\")\n",
        "\n",
        "def retrieve_from_pinecone_adaptive(query, agent_filter=None, top_k=5):\n",
        "    \n",
        "    try:\n",
        "        query_embedding = create_embedding(query)\n",
        "        \n",
        "        if agent_filter:\n",
        "            results = index.query(\n",
        "                vector=query_embedding,\n",
        "                filter={'agent': agent_filter},\n",
        "                top_k=top_k,\n",
        "                include_metadata=True\n",
        "            )\n",
        "        else:\n",
        "            results = index.query(\n",
        "                vector=query_embedding,\n",
        "                top_k=top_k,\n",
        "                include_metadata=True\n",
        "            )\n",
        "        \n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving from Pinecone: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "print(\"retrieve_from_pinecone_adaptive() defined\")\n",
        "\n",
        "print(\"DEFINING CONDITIONAL ROUTING LOGIC\")\n",
        "\n",
        "\n",
        "def conditional_route_to_agents(state: GraphState) -> List[str]:\n",
        "  \n",
        "    query = state.get(\"query\", \"\").lower()\n",
        "    \n",
        "    print(\"CONDITIONAL ROUTING ANALYSIS\")\n",
        "\n",
        "    print(f\"Query: \\\"{state['query']}\\\"\")\n",
        "    \n",
        "    routing_result = dynamic_route_query(state['query'])\n",
        "    \n",
        "    state['routed_agents'] = routing_result['agents']\n",
        "    state['routing_reasoning'] = routing_result['reasoning']\n",
        "    state['routing_approach'] = routing_result['approach']\n",
        "    \n",
        "    print(f\"\\nLLM Routing Decision:\")\n",
        "    print(f\"  Agents: {', '.join(routing_result['agents'])}\")\n",
        "    print(f\"  Reasoning: {routing_result['reasoning']}\")\n",
        "    print(f\"  Approach: {routing_result['approach']}\")\n",
        "    \n",
        "    agent_count = len(routing_result['agents'])\n",
        "    \n",
        "    if agent_count == 0:\n",
        "        print(f\"\\nNo agents selected - routing to aggregation\")\n",
        "        return [\"aggregation\"]\n",
        "    elif agent_count == 1:\n",
        "        print(f\"\\nSingle-agent query - direct routing\")\n",
        "        return routing_result['agents']\n",
        "    elif agent_count == 2:\n",
        "        print(f\"\\nMulti-domain query - conditional parallel execution\")\n",
        "        return routing_result['agents']\n",
        "    else:\n",
        "        print(f\"\\nComplex query - all agents with priority ordering\")\n",
        "        return routing_result['agents']\n",
        "\n",
        "print(\"conditional_route_to_agents() defined\")\n",
        "\n",
        "\n",
        "print(\"DEFINING ROUTING DECISION FUNCTION FOR LANGGRAPH\")\n",
        "\n",
        "def route_to_next_agent(state: GraphState) -> str:\n",
        "\n",
        "    routed_agents = state.get('routed_agents', [])\n",
        "    executed_agents = [a for a in state.get('execution_order', []) \n",
        "                      if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    for agent in routed_agents:\n",
        "        if agent not in executed_agents:\n",
        "            next_node = f\"{agent}_agent\"\n",
        "            print(f\"  â†’ Next agent: {agent.upper()}\")\n",
        "            return next_node\n",
        "    \n",
        "    print(f\"  â†’ All agents executed - routing to aggregation\")\n",
        "    return \"aggregation\"\n",
        "\n",
        "print(\"route_to_next_agent() defined\")\n",
        "\n",
        "def legal_node_conditional(state: GraphState) -> GraphState:\n",
        "    print(f\"\\n  â†’ LEGAL AGENT executing (threshold: {AGENT_THRESHOLDS['legal']})\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='legal', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['legal']\n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"legal\"] = {\n",
        "                \"agent\": \"Legal\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'legal'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            print(f\"     Retrieved: {len(clauses)} clauses (avg: {state['legal']['avg_relevance']:.3f})\")\n",
        "        else:\n",
        "            state[\"legal\"] = {\n",
        "                \"agent\": \"Legal\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['legal'],\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": []\n",
        "            }\n",
        "            print(f\"     No clauses above threshold\")\n",
        "    except Exception as e:\n",
        "        state[\"legal\"] = {\"agent\": \"Legal\", \"status\": \"error\", \"error\": str(e)}\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"legal\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def compliance_node_conditional(state: GraphState) -> GraphState:\n",
        "    print(f\"\\n  â†’ COMPLIANCE AGENT executing (threshold: {AGENT_THRESHOLDS['compliance']})\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='compliance', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['compliance'] \n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"compliance\"] = {\n",
        "                \"agent\": \"Compliance\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'compliance'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            print(f\"     Retrieved: {len(clauses)} clauses (avg: {state['compliance']['avg_relevance']:.3f})\")\n",
        "        else:\n",
        "            state[\"compliance\"] = {\n",
        "                \"agent\": \"Compliance\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['compliance'],\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": []\n",
        "            }\n",
        "            print(f\"     No clauses above threshold\")\n",
        "    except Exception as e:\n",
        "        state[\"compliance\"] = {\"agent\": \"Compliance\", \"status\": \"error\", \"error\": str(e)}\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"compliance\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def finance_node_conditional(state: GraphState) -> GraphState:\n",
        "    print(f\"\\n  â†’ FINANCE AGENT executing (threshold: {AGENT_THRESHOLDS['finance']})\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='finance', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['finance']\n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"finance\"] = {\n",
        "                \"agent\": \"Finance\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'finance'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            print(f\"     Retrieved: {len(clauses)} clauses (avg: {state['finance']['avg_relevance']:.3f})\")\n",
        "        else:\n",
        "            state[\"finance\"] = {\n",
        "                \"agent\": \"Finance\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['finance'],\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": []\n",
        "            }\n",
        "            print(f\"     No clauses above threshold\")\n",
        "    except Exception as e:\n",
        "        state[\"finance\"] = {\"agent\": \"Finance\", \"status\": \"error\", \"error\": str(e)}\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"finance\")\n",
        "    return state\n",
        "\n",
        "\n",
        "def operations_node_conditional(state: GraphState) -> GraphState:\n",
        "    print(f\"\\n  â†’ OPERATIONS AGENT executing (threshold: {AGENT_THRESHOLDS['operations']})\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='operations', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['operations']  \n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"operations\"] = {\n",
        "                \"agent\": \"Operations\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'operations'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            print(f\"     Retrieved: {len(clauses)} clauses (avg: {state['operations']['avg_relevance']:.3f})\")\n",
        "        else:\n",
        "            state[\"operations\"] = {\n",
        "                \"agent\": \"Operations\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['operations'],\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": []\n",
        "            }\n",
        "            print(f\"     No clauses above threshold\")\n",
        "    except Exception as e:\n",
        "        state[\"operations\"] = {\"agent\": \"Operations\", \"status\": \"error\", \"error\": str(e)}\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"operations\")\n",
        "    return state\n",
        "\n",
        "print(\"All agent nodes updated with adaptive thresholds\")\n",
        "\n",
        "print(\"CONDITIONAL ROUTING SYSTEM READY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Rebuild Graph with Conditional Entry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BUILDING CONDITIONAL ROUTING WORKFLOW WITH LANGGRAPH\n",
            "BUILDING CONDITIONAL ROUTING GRAPH\n",
            "\n",
            "Adding nodes to graph:\n",
            "  routing (entry point)\n",
            "  legal_agent (threshold: 0.30)\n",
            "  compliance_agent (threshold: 0.10)\n",
            "  finance_agent (threshold: 0.30)\n",
            "  operations_agent (threshold: 0.10)\n",
            "  aggregation (consolidation)\n",
            "\n",
            "Entry point: routing\n",
            "DEFINING CONDITIONAL EDGES\n",
            "  routing â†’ [conditional based on LLM decision]\n",
            "  legal_agent â†’ [next routed agent or aggregation]\n",
            "  compliance_agent â†’ [next routed agent or aggregation]\n",
            "  finance_agent â†’ [next routed agent or aggregation]\n",
            "  operations_agent â†’ aggregation\n",
            "  aggregation â†’ END\n",
            "COMPILING CONDITIONAL ROUTING WORKFLOW\n",
            "Workflow compiled successfully!\n",
            "CONDITIONAL ROUTING GRAPH READY\n"
          ]
        }
      ],
      "source": [
        "print(\"BUILDING CONDITIONAL ROUTING WORKFLOW WITH LANGGRAPH\")\n",
        "\n",
        "print(\"BUILDING CONDITIONAL ROUTING GRAPH\")\n",
        "\n",
        "workflow_conditional = StateGraph(GraphState)\n",
        "\n",
        "print(\"\\nAdding nodes to graph:\")\n",
        "workflow_conditional.add_node(\"routing\", routing_node)\n",
        "print(\"  routing (entry point)\")\n",
        "\n",
        "workflow_conditional.add_node(\"legal_agent\", legal_node_conditional)\n",
        "print(\"  legal_agent (threshold: 0.30)\")\n",
        "\n",
        "workflow_conditional.add_node(\"compliance_agent\", compliance_node_conditional)\n",
        "print(\"  compliance_agent (threshold: 0.10)\")\n",
        "\n",
        "workflow_conditional.add_node(\"finance_agent\", finance_node_conditional)\n",
        "print(\"  finance_agent (threshold: 0.30)\")\n",
        "\n",
        "workflow_conditional.add_node(\"operations_agent\", operations_node_conditional)\n",
        "print(\"  operations_agent (threshold: 0.10)\")\n",
        "\n",
        "workflow_conditional.add_node(\"aggregation\", aggregation_node)\n",
        "print(\"  aggregation (consolidation)\")\n",
        "\n",
        "workflow_conditional.set_entry_point(\"routing\")\n",
        "print(\"\\nEntry point: routing\")\n",
        "\n",
        "\n",
        "print(\"DEFINING CONDITIONAL EDGES\")\n",
        "\n",
        "def get_next_agent_or_aggregation(state: GraphState, current_agent: str = None) -> str:\n",
        "   \n",
        "    routed_agents = state.get('routed_agents', [])\n",
        "    executed_agents = [a for a in state.get('execution_order', []) \n",
        "                      if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    agent_priority = ['legal', 'compliance', 'finance', 'operations']\n",
        "    \n",
        "    for agent in agent_priority:\n",
        "        if agent in routed_agents and agent not in executed_agents:\n",
        "            return f\"{agent}_agent\"\n",
        "    \n",
        "    return \"aggregation\"\n",
        "\n",
        "workflow_conditional.add_conditional_edges(\n",
        "    \"routing\",\n",
        "    lambda state: get_next_agent_or_aggregation(state),\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  routing â†’ [conditional based on LLM decision]\")\n",
        "\n",
        "\n",
        "workflow_conditional.add_conditional_edges(\n",
        "    \"legal_agent\",\n",
        "    lambda state: get_next_agent_or_aggregation(state, 'legal'),\n",
        "    {\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  legal_agent â†’ [next routed agent or aggregation]\")\n",
        "\n",
        "workflow_conditional.add_conditional_edges(\n",
        "    \"compliance_agent\",\n",
        "    lambda state: get_next_agent_or_aggregation(state, 'compliance'),\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  compliance_agent â†’ [next routed agent or aggregation]\")\n",
        "\n",
        "workflow_conditional.add_conditional_edges(\n",
        "    \"finance_agent\",\n",
        "    lambda state: get_next_agent_or_aggregation(state, 'finance'),\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"  finance_agent â†’ [next routed agent or aggregation]\")\n",
        "\n",
        "workflow_conditional.add_edge(\"operations_agent\", \"aggregation\")\n",
        "print(\"  operations_agent â†’ aggregation\")\n",
        "\n",
        "workflow_conditional.add_edge(\"aggregation\", END)\n",
        "print(\"  aggregation â†’ END\")\n",
        "\n",
        "\n",
        "print(\"COMPILING CONDITIONAL ROUTING WORKFLOW\")\n",
        "\n",
        "try:\n",
        "    app_conditional = workflow_conditional.compile()\n",
        "    print(\"Workflow compiled successfully!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Compilation failed: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"CONDITIONAL ROUTING GRAPH READY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Conditional Entry Points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONDITIONAL ENTRY POINT WITH DYNAMIC LLM ROUTING\n",
            "\n",
            "Building conditional routing graph with intelligent entry point...\n",
            "\n",
            "StateGraph initialized\n",
            "ADDING AGENT NODES\n",
            "Added: legal_agent (threshold: 0.30)\n",
            "Added: compliance_agent (threshold: 0.10)\n",
            "Added: finance_agent (threshold: 0.30)\n",
            "Added: operations_agent (threshold: 0.10)\n",
            "Added: routing (LLM coordinator)\n",
            "Added: aggregation (result consolidation)\n",
            "DEFINING CONDITIONAL ENTRY POINT ROUTING\n",
            "conditional_entry_router() defined\n",
            "SETTING CONDITIONAL ENTRY POINT\n",
            "ADDING CONDITIONAL EDGES BETWEEN AGENTS\n",
            "legal_agent â†’ [conditional next agent]\n",
            "compliance_agent â†’ [conditional next agent]\n",
            "finance_agent â†’ [conditional next agent]\n",
            "operations_agent â†’ aggregation\n",
            "aggregation â†’ END\n",
            "COMPILING CONDITIONAL ENTRY POINT WORKFLOW\n",
            "Workflow compiled successfully!\n",
            "CONDITIONAL ENTRY POINT WORKFLOW\n",
            "WORKFLOW READY FOR EXECUTION\n",
            "CONDITIONAL ENTRY POINT CONFIGURED\n"
          ]
        }
      ],
      "source": [
        "print(\"CONDITIONAL ENTRY POINT WITH DYNAMIC LLM ROUTING\")\n",
        "\n",
        "\n",
        "print(\"\\nBuilding conditional routing graph with intelligent entry point...\")\n",
        "\n",
        "workflow_conditional = StateGraph(GraphState)\n",
        "print(\"\\nStateGraph initialized\")\n",
        "\n",
        "\n",
        "print(\"ADDING AGENT NODES\")\n",
        "\n",
        "workflow_conditional.add_node(\"legal_agent\", legal_node_conditional)\n",
        "print(\"Added: legal_agent (threshold: 0.30)\")\n",
        "\n",
        "workflow_conditional.add_node(\"compliance_agent\", compliance_node_conditional)\n",
        "print(\"Added: compliance_agent (threshold: 0.10)\")\n",
        "\n",
        "workflow_conditional.add_node(\"finance_agent\", finance_node_conditional)\n",
        "print(\"Added: finance_agent (threshold: 0.30)\")\n",
        "\n",
        "workflow_conditional.add_node(\"operations_agent\", operations_node_conditional)\n",
        "print(\"Added: operations_agent (threshold: 0.10)\")\n",
        "\n",
        "workflow_conditional.add_node(\"routing\", routing_node)\n",
        "print(\"Added: routing (LLM coordinator)\")\n",
        "\n",
        "workflow_conditional.add_node(\"aggregation\", aggregation_node)\n",
        "print(\"Added: aggregation (result consolidation)\")\n",
        "\n",
        "\n",
        "print(\"DEFINING CONDITIONAL ENTRY POINT ROUTING\")\n",
        "\n",
        "def conditional_entry_router(state: GraphState) -> str:\n",
        "\n",
        "    print(\"CONDITIONAL ENTRY POINT ROUTER\")\n",
        "\n",
        "    print(f\"Query: \\\"{state['query']}\\\"\")\n",
        "    \n",
        "    routing_result = dynamic_route_query(state['query'])\n",
        "    \n",
        "    state['routed_agents'] = routing_result['agents']\n",
        "    state['routing_reasoning'] = routing_result['reasoning']\n",
        "    state['routing_approach'] = routing_result['approach']\n",
        "    \n",
        "    print(f\"\\nLLM Routing Decision:\")\n",
        "    print(f\"  Agents: {', '.join(routing_result['agents'])}\")\n",
        "    print(f\"  Reasoning: {routing_result['reasoning']}\")\n",
        "    \n",
        "    state['execution_order'].append('routing')\n",
        "    \n",
        "    if not routing_result['agents']:\n",
        "        print(f\"\\nNo agents selected - routing to END\")\n",
        "        return \"end\"\n",
        "    \n",
        "    agent_priority = ['legal', 'compliance', 'finance', 'operations']\n",
        "    \n",
        "    for agent in agent_priority:\n",
        "        if agent in routing_result['agents']:\n",
        "            first_agent = f\"{agent}_agent\"\n",
        "            print(f\"\\nFirst agent to execute: {agent.upper()}\")\n",
        "            return first_agent\n",
        "    \n",
        "    print(f\"\\nFallback - routing to END\")\n",
        "    return \"end\"\n",
        "\n",
        "print(\"conditional_entry_router() defined\")\n",
        "\n",
        "\n",
        "print(\"SETTING CONDITIONAL ENTRY POINT\")\n",
        "\n",
        "workflow_conditional.set_conditional_entry_point(\n",
        "    conditional_entry_router,\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"ADDING CONDITIONAL EDGES BETWEEN AGENTS\")\n",
        "\n",
        "def get_next_agent_after(state: GraphState, current_agent: str = None) -> str:\n",
        "    routed_agents = state.get('routed_agents', [])\n",
        "    executed_agents = [a for a in state.get('execution_order', []) \n",
        "                      if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    agent_priority = ['legal', 'compliance', 'finance', 'operations']\n",
        "    \n",
        "    for agent in agent_priority:\n",
        "        if agent in routed_agents and agent not in executed_agents:\n",
        "            return f\"{agent}_agent\"\n",
        "    \n",
        "    return \"aggregation\"\n",
        "\n",
        "workflow_conditional.add_conditional_edges(\n",
        "    \"legal_agent\",\n",
        "    lambda state: get_next_agent_after(state, 'legal'),\n",
        "    {\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"legal_agent â†’ [conditional next agent]\")\n",
        "\n",
        "workflow_conditional.add_conditional_edges(\n",
        "    \"compliance_agent\",\n",
        "    lambda state: get_next_agent_after(state, 'compliance'),\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"compliance_agent â†’ [conditional next agent]\")\n",
        "\n",
        "workflow_conditional.add_conditional_edges(\n",
        "    \"finance_agent\",\n",
        "    lambda state: get_next_agent_after(state, 'finance'),\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"finance_agent â†’ [conditional next agent]\")\n",
        "\n",
        "workflow_conditional.add_edge(\"operations_agent\", \"aggregation\")\n",
        "print(\"operations_agent â†’ aggregation\")\n",
        "\n",
        "workflow_conditional.add_edge(\"aggregation\", END)\n",
        "print(\"aggregation â†’ END\")\n",
        "\n",
        "print(\"COMPILING CONDITIONAL ENTRY POINT WORKFLOW\")\n",
        "\n",
        "try:\n",
        "    app_conditional = workflow_conditional.compile()\n",
        "    print(\"Workflow compiled successfully!\")\n",
        "    \n",
        "    print(\"CONDITIONAL ENTRY POINT WORKFLOW\")\n",
        " \n",
        "    print(\"WORKFLOW READY FOR EXECUTION\")\n",
        "    \n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Compilation failed: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"CONDITIONAL ENTRY POINT CONFIGURED\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Agent â†’ END Edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONFIGURING AGENT â†’ END EDGES\n",
            "IMPLEMENTING HYBRID APPROACH (BEST OF BOTH)\n",
            "\n",
            "Reconfiguring edges for hybrid approach...\n",
            "Nodes added\n",
            "Conditional entry point set\n",
            "Hybrid routing function defined\n",
            "Hybrid conditional edges configured\n",
            "COMPILING HYBRID WORKFLOW\n",
            "Hybrid workflow compiled successfully!\n",
            "EDGE CONFIGURATION COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"CONFIGURING AGENT â†’ END EDGES\")\n",
        "\n",
        "print(\"IMPLEMENTING HYBRID APPROACH (BEST OF BOTH)\")\n",
        "\n",
        "print(\"\\nReconfiguring edges for hybrid approach...\")\n",
        "\n",
        "workflow_conditional_hybrid = StateGraph(GraphState)\n",
        "\n",
        "workflow_conditional_hybrid.add_node(\"legal_agent\", legal_node_conditional)\n",
        "workflow_conditional_hybrid.add_node(\"compliance_agent\", compliance_node_conditional)\n",
        "workflow_conditional_hybrid.add_node(\"finance_agent\", finance_node_conditional)\n",
        "workflow_conditional_hybrid.add_node(\"operations_agent\", operations_node_conditional)\n",
        "workflow_conditional_hybrid.add_node(\"aggregation\", aggregation_node)\n",
        "\n",
        "print(\"Nodes added\")\n",
        "\n",
        "workflow_conditional_hybrid.set_conditional_entry_point(\n",
        "    conditional_entry_router,\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "print(\"Conditional entry point set\")\n",
        "\n",
        "def agent_to_next_or_end(state: GraphState) -> str:\n",
        " \n",
        "    routed_agents = state.get('routed_agents', [])\n",
        "    executed_agents = [a for a in state.get('execution_order', []) \n",
        "                      if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    if len(routed_agents) == 1:\n",
        "        return \"end\"\n",
        "    \n",
        "    agent_priority = ['legal', 'compliance', 'finance', 'operations']\n",
        "    \n",
        "    for agent in agent_priority:\n",
        "        if agent in routed_agents and agent not in executed_agents:\n",
        "            return f\"{agent}_agent\"\n",
        "    \n",
        "    return \"aggregation\"\n",
        "\n",
        "print(\"Hybrid routing function defined\")\n",
        "\n",
        "workflow_conditional_hybrid.add_conditional_edges(\n",
        "    \"legal_agent\",\n",
        "    agent_to_next_or_end,\n",
        "    {\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow_conditional_hybrid.add_conditional_edges(\n",
        "    \"compliance_agent\",\n",
        "    agent_to_next_or_end,\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow_conditional_hybrid.add_conditional_edges(\n",
        "    \"finance_agent\",\n",
        "    agent_to_next_or_end,\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow_conditional_hybrid.add_conditional_edges(\n",
        "    \"operations_agent\",\n",
        "    agent_to_next_or_end,\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"aggregation\": \"aggregation\",\n",
        "        \"end\": END\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow_conditional_hybrid.add_edge(\"aggregation\", END)\n",
        "\n",
        "print(\"Hybrid conditional edges configured\")\n",
        "\n",
        "print(\"COMPILING HYBRID WORKFLOW\")\n",
        "\n",
        "try:\n",
        "    app_conditional_hybrid = workflow_conditional_hybrid.compile()\n",
        "    print(\"Hybrid workflow compiled successfully!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Compilation failed: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"EDGE CONFIGURATION COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Compiling Conditional Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COMPILING CONDITIONAL ROUTING GRAPH\n",
            "\n",
            "Compiling conditional routing graph...\n",
            "Conditional Graph Compiled Successfully!\n",
            "CONDITIONAL GRAPH COMPILATION COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"COMPILING CONDITIONAL ROUTING GRAPH\")\n",
        "\n",
        "print(\"\\nCompiling conditional routing graph...\")\n",
        "\n",
        "try:\n",
        "    app_conditional = app_conditional_hybrid\n",
        "    \n",
        "    print(\"Conditional Graph Compiled Successfully!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nCompilation failed: {str(e)}\")\n",
        "    print(\"ERROR DETAILS\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"CONDITIONAL GRAPH COMPILATION COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Test Case 1 - Legal Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST CASE 1 - LEGAL QUERY\n",
            "\n",
            "Preparing test state for legal query...\n",
            "Test state created\n",
            "  Query: \"Review termination clause and liability provisions\"\n",
            "  Expected: Routes to Legal Agent only\n",
            "EXECUTING CONDITIONAL GRAPH - TEST CASE 1\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Review termination clause and liability provisions\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "Ollama error: HTTPConnectionPool(host='localhost', port=11434): Read timed out. (read timeout=60)\n",
            "Falling back to keyword-based routing...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: legal\n",
            "  Reasoning: Keyword-based fallback routing\n",
            "\n",
            "First agent to execute: LEGAL\n",
            "\n",
            "  â†’ LEGAL AGENT executing (threshold: 0.1)\n",
            "     Query: Review termination clause and liability provisions...\n",
            "     Retrieved: 2 clauses (avg: 0.537)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 2\n",
            "Top relevance score: 0.582\n",
            "Agents executed: legal\n",
            "TEST CASE 1 COMPLETED\n",
            "\n",
            "ROUTING DECISION:\n",
            "  Query: \"Review termination clause and liability provisions\"\n",
            "  LLM Routed To: \n",
            "  Reasoning: \n",
            "  Approach: \n",
            "EXECUTION SUMMARY\n",
            "  Execution Order: routing â†’ legal â†’ aggregation\n",
            "  Total Clauses Retrieved: 2\n",
            "  Execution Status: success\n",
            "AGENT EXECUTION STATUS\n",
            "Agent           Status          Clauses    Avg Relevance  \n",
            "LEGAL           EXECUTED        2          0.537          \n",
            "COMPLIANCE      NOT EXECUTED    -          -              \n",
            "FINANCE         NOT EXECUTED    -          -              \n",
            "OPERATIONS      NOT EXECUTED    -          -              \n",
            "RETRIEVED CLAUSES\n",
            "\n",
            "[1] Agent: LEGAL | Relevance: 0.582\n",
            "    The other party shall give notice of termination in writing to the other party, which notice shall specify in reasonable...\n",
            "\n",
            "[2] Agent: LEGAL | Relevance: 0.493\n",
            "    The other party asserts any rights in or to the terminating party's intellectual property in violation of this Agreement...\n",
            "CONDITIONAL ROUTING VERIFICATION\n",
            "\n",
            "Routed by LLM: \n",
            "Actually Executed: legal\n",
            "\n",
            "UNEXPECTED ROUTING:\n",
            "  Expected: ['legal']\n",
            "  Got: []\n",
            "EFFICIENCY ANALYSIS\n",
            "  Sequential Execution: 4 agents (always)\n",
            "  Conditional Execution: 1 agent(s) (query-dependent)\n",
            "  Agents Saved: 3\n",
            "  Efficiency Gain: ~75%\n",
            "  Time Saved: ~75% (estimated)\n",
            "THRESHOLD ANALYSIS\n",
            "  Legal Agent Threshold: 0.1\n",
            "  Clauses Retrieved: 2\n",
            "  Successfully retrieved clauses above threshold\n",
            "TEST CASE 1 COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"TEST CASE 1 - LEGAL QUERY\")\n",
        "\n",
        "print(\"\\nPreparing test state for legal query...\")\n",
        "\n",
        "test_state_legal = {\n",
        "    \"query\": \"Review termination clause and liability provisions\",\n",
        "    \"routed_agents\": [],\n",
        "    \"routing_reasoning\": \"\",\n",
        "    \"routing_approach\": \"\",\n",
        "    \"legal\": {},\n",
        "    \"compliance\": {},\n",
        "    \"finance\": {},\n",
        "    \"operations\": {},\n",
        "    \"all_clauses\": [],\n",
        "    \"total_clauses_retrieved\": 0,\n",
        "    \"execution_order\": [],\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"vector_store\": \"Pinecone\",\n",
        "    \"execution_status\": \"initialized\"\n",
        "}\n",
        "\n",
        "print(\"Test state created\")\n",
        "print(f\"  Query: \\\"{test_state_legal['query']}\\\"\")\n",
        "print(f\"  Expected: Routes to Legal Agent only\")\n",
        "\n",
        "print(\"EXECUTING CONDITIONAL GRAPH - TEST CASE 1\")\n",
        "\n",
        "try:\n",
        "    result_legal = app_conditional.invoke(test_state_legal)\n",
        "    \n",
        "    print(\"TEST CASE 1 COMPLETED\")\n",
        "\n",
        "    \n",
        "    print(\"\\nROUTING DECISION:\")\n",
        "    print(f\"  Query: \\\"{result_legal['query']}\\\"\")\n",
        "    print(f\"  LLM Routed To: {', '.join(result_legal.get('routed_agents', []))}\")\n",
        "    print(f\"  Reasoning: {result_legal.get('routing_reasoning', 'N/A')}\")\n",
        "    print(f\"  Approach: {result_legal.get('routing_approach', 'N/A')}\")\n",
        "    \n",
        "   \n",
        "    print(\"EXECUTION SUMMARY\")\n",
        "    print(f\"  Execution Order: {' â†’ '.join(result_legal['execution_order'])}\")\n",
        "    print(f\"  Total Clauses Retrieved: {result_legal.get('total_clauses_retrieved', 0)}\")\n",
        "    print(f\"  Execution Status: {result_legal.get('execution_status', 'unknown')}\")\n",
        "    \n",
        "   \n",
        "    print(\"AGENT EXECUTION STATUS\")\n",
        "    print(f\"{'Agent':<15} {'Status':<15} {'Clauses':<10} {'Avg Relevance':<15}\")\n",
        "    \n",
        "    for agent_name in [\"legal\", \"compliance\", \"finance\", \"operations\"]:\n",
        "        agent_data = result_legal.get(agent_name, {})\n",
        "        if agent_data and agent_data.get(\"status\") == \"completed\":\n",
        "            status = \"EXECUTED \"\n",
        "            clauses = agent_data.get('clauses_retrieved', 0)\n",
        "            avg_rel = agent_data.get('avg_relevance', 0)\n",
        "            relevance = f\"{avg_rel:.3f}\" if avg_rel > 0 else \"N/A\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {clauses:<10} {relevance:<15}\")\n",
        "        elif agent_data and agent_data.get(\"status\") == \"no_results\":\n",
        "            status = \"EXECUTED (0)\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {0:<10} {'N/A':<15}\")\n",
        "        else:\n",
        "            status = \"NOT EXECUTED\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {'-':<10} {'-':<15}\")\n",
        "    \n",
        "    if result_legal.get('all_clauses'):\n",
        "        print(\"RETRIEVED CLAUSES\")\n",
        "        for idx, clause in enumerate(result_legal['all_clauses'][:3], 1):\n",
        "            print(f\"\\n[{idx}] Agent: {clause['agent'].upper()} | Relevance: {clause['relevance_score']:.3f}\")\n",
        "            clause_text = clause['clause'][:120] + \"...\" if len(clause['clause']) > 120 else clause['clause']\n",
        "            print(f\"    {clause_text}\")\n",
        "    \n",
        "    print(\"CONDITIONAL ROUTING VERIFICATION\")\n",
        " \n",
        "    routed_agents = result_legal.get('routed_agents', [])\n",
        "    executed_agents = [a for a in result_legal['execution_order'] if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    print(f\"\\nRouted by LLM: {', '.join(routed_agents)}\")\n",
        "    print(f\"Actually Executed: {', '.join(executed_agents)}\")\n",
        "    \n",
        "    if len(routed_agents) == 1 and 'legal' in routed_agents:\n",
        "        print(\"\\nSUCCESS: Legal-only query correctly routed\")\n",
        "\n",
        "        \n",
        "        if 'aggregation' not in result_legal['execution_order']:\n",
        "            print(\"  â€¢ Single-agent â†’ Direct to END (fast path)\")\n",
        "        else:\n",
        "            print(\"  â€¢ Routed through aggregation\")\n",
        "    else:\n",
        "        print(f\"\\nUNEXPECTED ROUTING:\")\n",
        "        print(f\"  Expected: ['legal']\")\n",
        "        print(f\"  Got: {routed_agents}\")\n",
        "    \n",
        "    print(\"EFFICIENCY ANALYSIS\")\n",
        "\n",
        "    agents_executed = len(executed_agents)\n",
        "    total_agents = 4\n",
        "    \n",
        "    print(f\"  Sequential Execution: {total_agents} agents (always)\")\n",
        "    print(f\"  Conditional Execution: {agents_executed} agent(s) (query-dependent)\")\n",
        "    print(f\"  Agents Saved: {total_agents - agents_executed}\")\n",
        "    print(f\"  Efficiency Gain: ~{(total_agents - agents_executed) / total_agents * 100:.0f}%\")\n",
        "    print(f\"  Time Saved: ~{(total_agents - agents_executed) / total_agents * 100:.0f}% (estimated)\")\n",
        "    \n",
        "    if result_legal.get('legal', {}).get('status') == 'completed':\n",
        "        print(\"THRESHOLD ANALYSIS\")\n",
        "        legal_threshold = result_legal['legal'].get('threshold', 0.3)\n",
        "        legal_clauses = result_legal['legal'].get('clauses_retrieved', 0)\n",
        "        print(f\"  Legal Agent Threshold: {legal_threshold}\")\n",
        "        print(f\"  Clauses Retrieved: {legal_clauses}\")\n",
        "        if legal_clauses > 0:\n",
        "            print(f\"  Successfully retrieved clauses above threshold\")\n",
        "        else:\n",
        "            print(f\"  No clauses above threshold {legal_threshold}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nExecution failed: {str(e)}\")\n",
        "    print(\"ERROR DETAILS\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"TEST CASE 1 COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Test Case 2 - Finance Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST CASE 2 - FINANCE QUERY\n",
            "\n",
            "Preparing test state for finance query...\n",
            "Test state created\n",
            "  Query: \"Check late payment penalties and invoice terms\"\n",
            "EXECUTING CONDITIONAL GRAPH - TEST CASE 2\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Check late payment penalties and invoice terms\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: finance\n",
            "  Reasoning: The query specifically asks about late payment penalties and invoice terms, which fall under the domain of financial obligations.\n",
            "\n",
            "First agent to execute: FINANCE\n",
            "\n",
            "  â†’ FINANCE AGENT executing (threshold: 0.1)\n",
            "     Query: Check late payment penalties and invoice terms...\n",
            "     Retrieved: 3 clauses (avg: 0.343)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 3\n",
            "Top relevance score: 0.383\n",
            "Agents executed: finance\n",
            "TEST CASE 2 COMPLETED\n",
            "\n",
            "ROUTING DECISION:\n",
            "  Query: \"Check late payment penalties and invoice terms\"\n",
            "  LLM Routed To: \n",
            "  Reasoning: \n",
            "  Approach: \n",
            "EXECUTION SUMMARY\n",
            "  Execution Order: routing â†’ finance â†’ aggregation\n",
            "  Total Clauses Retrieved: 3\n",
            "  Execution Status: success\n",
            "AGENT EXECUTION STATUS\n",
            "Agent           Status          Clauses    Avg Relevance  \n",
            "LEGAL           NOT EXECUTED    -          -              \n",
            "COMPLIANCE      NOT EXECUTED    -          -              \n",
            "FINANCE         EXECUTED        3          0.343          \n",
            "OPERATIONS      NOT EXECUTED    -          -              \n",
            "RETRIEVED CLAUSES\n",
            "\n",
            "[1] Agent: FINANCE | Relevance: 0.383\n",
            "    In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, incl...\n",
            "\n",
            "[2] Agent: FINANCE | Relevance: 0.338\n",
            "    ), Recipient shall reimburse Provider for all such Out-of-Pocket Costs.\n",
            "\n",
            "[3] Agent: FINANCE | Relevance: 0.307\n",
            "    Provider shall provide Recipient with monthly invo\n",
            "CONDITIONAL ROUTING VERIFICATION\n",
            "\n",
            "Routed by LLM: \n",
            "Actually Executed: finance\n",
            "\n",
            "UNEXPECTED ROUTING:\n",
            "  Expected: ['finance']\n",
            "  Got: []\n",
            "EFFICIENCY ANALYSIS\n",
            "  Sequential Execution: 4 agents (always)\n",
            "  Conditional Execution: 1 agent(s) (query-dependent)\n",
            "  Agents Saved: 3\n",
            "  Efficiency Gain: ~75%\n",
            "THRESHOLD ANALYSIS\n",
            "  Finance Agent Threshold: 0.1\n",
            "  Clauses Retrieved: 3\n",
            "  Successfully retrieved clauses above threshold\n",
            "  Average Relevance: 0.343\n",
            "  Max Relevance: 0.383\n",
            "COMPARISON WITH TEST CASE 1\n",
            "  Test 1 (Legal Query):\n",
            "    â€¢ Routed to: Legal\n",
            "    â€¢ Agents executed: 1\n",
            "  Test 2 (Finance Query):\n",
            "    â€¢ Routed to: \n",
            "    â€¢ Agents executed: 1\n",
            "TEST CASE 2 COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"TEST CASE 2 - FINANCE QUERY\")\n",
        "\n",
        "print(\"\\nPreparing test state for finance query...\")\n",
        "\n",
        "test_state_finance = {\n",
        "    \"query\": \"Check late payment penalties and invoice terms\",\n",
        "    \"routed_agents\": [],\n",
        "    \"routing_reasoning\": \"\",\n",
        "    \"routing_approach\": \"\",\n",
        "    \"legal\": {},\n",
        "    \"compliance\": {},\n",
        "    \"finance\": {},\n",
        "    \"operations\": {},\n",
        "    \"all_clauses\": [],\n",
        "    \"total_clauses_retrieved\": 0,\n",
        "    \"execution_order\": [],\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"vector_store\": \"Pinecone\",\n",
        "    \"execution_status\": \"initialized\"\n",
        "}\n",
        "\n",
        "print(\"Test state created\")\n",
        "print(f\"  Query: \\\"{test_state_finance['query']}\\\"\")\n",
        "\n",
        "print(\"EXECUTING CONDITIONAL GRAPH - TEST CASE 2\")\n",
        "\n",
        "try:\n",
        "    result_finance = app_conditional.invoke(test_state_finance)\n",
        "    \n",
        "    print(\"TEST CASE 2 COMPLETED\")\n",
        "\n",
        "    print(\"\\nROUTING DECISION:\")\n",
        "    print(f\"  Query: \\\"{result_finance['query']}\\\"\")\n",
        "    print(f\"  LLM Routed To: {', '.join(result_finance.get('routed_agents', []))}\")\n",
        "    print(f\"  Reasoning: {result_finance.get('routing_reasoning', 'N/A')}\")\n",
        "    print(f\"  Approach: {result_finance.get('routing_approach', 'N/A')}\")\n",
        "    \n",
        "\n",
        "    print(\"EXECUTION SUMMARY\")\n",
        "    print(f\"  Execution Order: {' â†’ '.join(result_finance['execution_order'])}\")\n",
        "    print(f\"  Total Clauses Retrieved: {result_finance.get('total_clauses_retrieved', 0)}\")\n",
        "    print(f\"  Execution Status: {result_finance.get('execution_status', 'unknown')}\")\n",
        "  \n",
        "    print(\"AGENT EXECUTION STATUS\")\n",
        "    print(f\"{'Agent':<15} {'Status':<15} {'Clauses':<10} {'Avg Relevance':<15}\")\n",
        "\n",
        "    for agent_name in [\"legal\", \"compliance\", \"finance\", \"operations\"]:\n",
        "        agent_data = result_finance.get(agent_name, {})\n",
        "        if agent_data and agent_data.get(\"status\") == \"completed\":\n",
        "            status = \"EXECUTED \"\n",
        "            clauses = agent_data.get('clauses_retrieved', 0)\n",
        "            avg_rel = agent_data.get('avg_relevance', 0)\n",
        "            relevance = f\"{avg_rel:.3f}\" if avg_rel > 0 else \"N/A\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {clauses:<10} {relevance:<15}\")\n",
        "        elif agent_data and agent_data.get(\"status\") == \"no_results\":\n",
        "            status = \"EXECUTED (0)\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {0:<10} {'N/A':<15}\")\n",
        "        else:\n",
        "            status = \"NOT EXECUTED\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {'-':<10} {'-':<15}\")\n",
        "    \n",
        "    if result_finance.get('all_clauses'):\n",
        "        print(\"RETRIEVED CLAUSES\")\n",
        "        for idx, clause in enumerate(result_finance['all_clauses'][:3], 1):\n",
        "            print(f\"\\n[{idx}] Agent: {clause['agent'].upper()} | Relevance: {clause['relevance_score']:.3f}\")\n",
        "            clause_text = clause['clause'][:120] + \"...\" if len(clause['clause']) > 120 else clause['clause']\n",
        "            print(f\"    {clause_text}\")\n",
        "    \n",
        "    print(\"CONDITIONAL ROUTING VERIFICATION\")\n",
        "    \n",
        "    routed_agents = result_finance.get('routed_agents', [])\n",
        "    executed_agents = [a for a in result_finance['execution_order'] if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    print(f\"\\nRouted by LLM: {', '.join(routed_agents)}\")\n",
        "    print(f\"Actually Executed: {', '.join(executed_agents)}\")\n",
        "    \n",
        "    if len(routed_agents) == 1 and 'finance' in routed_agents:\n",
        "        print(\"\\nSUCCESS: Finance-only query correctly routed\")\n",
        "        \n",
        "        if 'aggregation' not in result_finance['execution_order']:\n",
        "            print(\"  â€¢ Single-agent â†’ Direct to END (fast path)\")\n",
        "        else:\n",
        "            print(\"  â€¢ Routed through aggregation\")\n",
        "    elif 'finance' in routed_agents and len(routed_agents) > 1:\n",
        "        print(f\"\\nMULTI-AGENT ROUTING:\")\n",
        "        print(f\"  LLM selected: {', '.join(routed_agents)}\")\n",
        "        print(f\"  Query may have cross-domain elements\")\n",
        "    else:\n",
        "        print(f\"\\nUNEXPECTED ROUTING:\")\n",
        "        print(f\"  Expected: ['finance']\")\n",
        "        print(f\"  Got: {routed_agents}\")\n",
        "    \n",
        "\n",
        "    print(\"EFFICIENCY ANALYSIS\")\n",
        "\n",
        "    agents_executed = len(executed_agents)\n",
        "    total_agents = 4\n",
        "    \n",
        "    print(f\"  Sequential Execution: {total_agents} agents (always)\")\n",
        "    print(f\"  Conditional Execution: {agents_executed} agent(s) (query-dependent)\")\n",
        "    print(f\"  Agents Saved: {total_agents - agents_executed}\")\n",
        "    print(f\"  Efficiency Gain: ~{(total_agents - agents_executed) / total_agents * 100:.0f}%\")\n",
        "    \n",
        "    if result_finance.get('finance', {}).get('status') == 'completed':\n",
        "        print(\"THRESHOLD ANALYSIS\")\n",
        "        finance_threshold = result_finance['finance'].get('threshold', 0.3)\n",
        "        finance_clauses = result_finance['finance'].get('clauses_retrieved', 0)\n",
        "        print(f\"  Finance Agent Threshold: {finance_threshold}\")\n",
        "        print(f\"  Clauses Retrieved: {finance_clauses}\")\n",
        "        if finance_clauses > 0:\n",
        "            print(f\"  Successfully retrieved clauses above threshold\")\n",
        "            avg_rel = result_finance['finance'].get('avg_relevance', 0)\n",
        "            max_rel = result_finance['finance'].get('max_relevance', 0)\n",
        "            print(f\"  Average Relevance: {avg_rel:.3f}\")\n",
        "            print(f\"  Max Relevance: {max_rel:.3f}\")\n",
        "        else:\n",
        "            print(f\"  No clauses above threshold {finance_threshold}\")\n",
        "\n",
        "    print(\"COMPARISON WITH TEST CASE 1\")\n",
        "    print(f\"  Test 1 (Legal Query):\")\n",
        "    print(f\"    â€¢ Routed to: Legal\")\n",
        "    print(f\"    â€¢ Agents executed: 1\")\n",
        "    print(f\"  Test 2 (Finance Query):\")\n",
        "    print(f\"    â€¢ Routed to: {', '.join(routed_agents)}\")\n",
        "    print(f\"    â€¢ Agents executed: {agents_executed}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nExecution failed: {str(e)}\")\n",
        "    print(\"ERROR DETAILS\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    \n",
        "print(\"TEST CASE 2 COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8. Test Case 3 - Compliance Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST CASE 3 - COMPLIANCE QUERY\n",
            "\n",
            "Preparing test state for compliance query...\n",
            "Test state created\n",
            "  Query: \"Verify GDPR data protection and audit requirements\"\n",
            "  Expected: Routes to Compliance Agent\n",
            "EXECUTING CONDITIONAL GRAPH - TEST CASE 3\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Verify GDPR data protection and audit requirements\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: compliance\n",
            "  Reasoning: The query specifically mentions GDPR data protection and audit requirements, which fall under the domain of compliance.\n",
            "\n",
            "First agent to execute: COMPLIANCE\n",
            "\n",
            "  â†’ COMPLIANCE AGENT executing (threshold: 0.1)\n",
            "     Query: Verify GDPR data protection and audit requirements...\n",
            "     Retrieved: 1 clauses (avg: 0.179)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 1\n",
            "Top relevance score: 0.179\n",
            "Agents executed: compliance\n",
            "TEST CASE 3 COMPLETED\n",
            "\n",
            "ROUTING DECISION:\n",
            "  Query: \"Verify GDPR data protection and audit requirements\"\n",
            "  LLM Routed To: \n",
            "  Reasoning: \n",
            "  Approach: \n",
            "EXECUTION SUMMARY\n",
            "  Execution Order: routing â†’ compliance â†’ aggregation\n",
            "  Total Clauses Retrieved: 1\n",
            "  Execution Status: success\n",
            "AGENT EXECUTION STATUS\n",
            "Agent           Status          Clauses    Threshold    Avg Relevance  \n",
            "LEGAL           NOT EXECUTED    -          -            -              \n",
            "COMPLIANCE      EXECUTED        1          0.10         0.179          \n",
            "FINANCE         NOT EXECUTED    -          -            -              \n",
            "OPERATIONS      NOT EXECUTED    -          -            -              \n",
            "RETRIEVED CLAUSES\n",
            "\n",
            "[1] Agent: COMPLIANCE | Relevance: 0.179\n",
            "    The receiving party will not disclose the other party's confidential information to any third parties without the other ...\n",
            "CONDITIONAL ROUTING VERIFICATION\n",
            "\n",
            "Routed by LLM: \n",
            "Actually Executed: compliance\n",
            "\n",
            "UNEXPECTED ROUTING:\n",
            "  Expected: ['compliance']\n",
            "  Got: []\n",
            "EFFICIENCY ANALYSIS\n",
            "  Sequential Execution: 4 agents (always)\n",
            "  Conditional Execution: 1 agent(s) (query-dependent)\n",
            "  Agents Saved: 3\n",
            "  Efficiency Gain: ~75%\n",
            "THRESHOLD IMPACT ANALYSIS\n",
            "  Compliance Agent:\n",
            "    â€¢ Threshold: 0.1 (LOWER for better recall)\n",
            "    â€¢ Clauses Retrieved: 1\n",
            "    â€¢ Average Relevance: 0.179\n",
            "    â€¢ Max Relevance: 0.179\n",
            "    â€¢ Lower threshold helped retrieve clauses\n",
            "TEST CASE 3 COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"TEST CASE 3 - COMPLIANCE QUERY\")\n",
        "\n",
        "print(\"\\nPreparing test state for compliance query...\")\n",
        "\n",
        "test_state_compliance = {\n",
        "    \"query\": \"Verify GDPR data protection and audit requirements\",\n",
        "    \"routed_agents\": [],\n",
        "    \"routing_reasoning\": \"\",\n",
        "    \"routing_approach\": \"\",\n",
        "    \"legal\": {},\n",
        "    \"compliance\": {},\n",
        "    \"finance\": {},\n",
        "    \"operations\": {},\n",
        "    \"all_clauses\": [],\n",
        "    \"total_clauses_retrieved\": 0,\n",
        "    \"execution_order\": [],\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"vector_store\": \"Pinecone\",\n",
        "    \"execution_status\": \"initialized\"\n",
        "}\n",
        "\n",
        "print(\"Test state created\")\n",
        "print(f\"  Query: \\\"{test_state_compliance['query']}\\\"\")\n",
        "print(f\"  Expected: Routes to Compliance Agent\")\n",
        "\n",
        "print(\"EXECUTING CONDITIONAL GRAPH - TEST CASE 3\")\n",
        "\n",
        "try:\n",
        "    result_compliance = app_conditional.invoke(test_state_compliance)\n",
        "    \n",
        "    print(\"TEST CASE 3 COMPLETED\")\n",
        "\n",
        "    print(\"\\nROUTING DECISION:\")\n",
        "    print(f\"  Query: \\\"{result_compliance['query']}\\\"\")\n",
        "    print(f\"  LLM Routed To: {', '.join(result_compliance.get('routed_agents', []))}\")\n",
        "    print(f\"  Reasoning: {result_compliance.get('routing_reasoning', 'N/A')}\")\n",
        "    print(f\"  Approach: {result_compliance.get('routing_approach', 'N/A')}\")\n",
        "\n",
        "    print(\"EXECUTION SUMMARY\")\n",
        "\n",
        "    print(f\"  Execution Order: {' â†’ '.join(result_compliance['execution_order'])}\")\n",
        "    print(f\"  Total Clauses Retrieved: {result_compliance.get('total_clauses_retrieved', 0)}\")\n",
        "    print(f\"  Execution Status: {result_compliance.get('execution_status', 'unknown')}\")\n",
        "  \n",
        "    print(\"AGENT EXECUTION STATUS\")\n",
        "    print(f\"{'Agent':<15} {'Status':<15} {'Clauses':<10} {'Threshold':<12} {'Avg Relevance':<15}\")\n",
        "    \n",
        "    for agent_name in [\"legal\", \"compliance\", \"finance\", \"operations\"]:\n",
        "        agent_data = result_compliance.get(agent_name, {})\n",
        "        if agent_data and agent_data.get(\"status\") == \"completed\":\n",
        "            status = \"EXECUTED\"\n",
        "            clauses = agent_data.get('clauses_retrieved', 0)\n",
        "            threshold = agent_data.get('threshold', 'N/A')\n",
        "            avg_rel = agent_data.get('avg_relevance', 0)\n",
        "            relevance = f\"{avg_rel:.3f}\" if avg_rel > 0 else \"N/A\"\n",
        "            threshold_str = f\"{threshold:.2f}\" if isinstance(threshold, float) else str(threshold)\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {clauses:<10} {threshold_str:<12} {relevance:<15}\")\n",
        "        elif agent_data and agent_data.get(\"status\") == \"no_results\":\n",
        "            status = \"EXECUTED (0)\"\n",
        "            threshold = agent_data.get('threshold', 'N/A')\n",
        "            threshold_str = f\"{threshold:.2f}\" if isinstance(threshold, float) else str(threshold)\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {0:<10} {threshold_str:<12} {'N/A':<15}\")\n",
        "        else:\n",
        "            status = \"NOT EXECUTED\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {'-':<10} {'-':<12} {'-':<15}\")\n",
        "    \n",
        "    if result_compliance.get('all_clauses'):\n",
        "        print(\"RETRIEVED CLAUSES\")\n",
        "        for idx, clause in enumerate(result_compliance['all_clauses'][:3], 1):\n",
        "            print(f\"\\n[{idx}] Agent: {clause['agent'].upper()} | Relevance: {clause['relevance_score']:.3f}\")\n",
        "            clause_text = clause['clause'][:120] + \"...\" if len(clause['clause']) > 120 else clause['clause']\n",
        "            print(f\"    {clause_text}\")\n",
        "    else:\n",
        "        print(\"NO CLAUSES RETRIEVED\")\n",
        " \n",
        "    print(\"CONDITIONAL ROUTING VERIFICATION\")\n",
        "    \n",
        "    routed_agents = result_compliance.get('routed_agents', [])\n",
        "    executed_agents = [a for a in result_compliance['execution_order'] if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    print(f\"\\nRouted by LLM: {', '.join(routed_agents)}\")\n",
        "    print(f\"Actually Executed: {', '.join(executed_agents)}\")\n",
        "    \n",
        "    if 'compliance' in routed_agents:\n",
        "        print(\"\\nSUCCESS: Compliance domain correctly identified\")\n",
        "        \n",
        "        if len(routed_agents) == 1:\n",
        "            print(\"  â€¢ Only Compliance agent routed (efficient)\")\n",
        "            print(\"  â€¢ Other agents skipped\")\n",
        "        else:\n",
        "            print(f\"  â€¢ Multi-domain query detected: {', '.join(routed_agents)}\")\n",
        "        \n",
        "        compliance_clauses = result_compliance.get('compliance', {}).get('clauses_retrieved', 0)\n",
        "        if compliance_clauses > 0:\n",
        "            print(f\"  â€¢ Successfully retrieved {compliance_clauses} clause(s)\")\n",
        "        else:\n",
        "            print(f\"  â€¢ No clauses retrieved (may not exist in dataset)\")\n",
        "            print(f\"  â€¢ Note: Lower threshold (0.10) already applied\")\n",
        "    else:\n",
        "        print(f\"\\nUNEXPECTED ROUTING:\")\n",
        "        print(f\"  Expected: ['compliance']\")\n",
        "        print(f\"  Got: {routed_agents}\")\n",
        "    \n",
        "\n",
        "    print(\"EFFICIENCY ANALYSIS\")\n",
        "\n",
        "    agents_executed = len(executed_agents)\n",
        "    total_agents = 4\n",
        "    \n",
        "    print(f\"  Sequential Execution: {total_agents} agents (always)\")\n",
        "    print(f\"  Conditional Execution: {agents_executed} agent(s) (query-dependent)\")\n",
        "    print(f\"  Agents Saved: {total_agents - agents_executed}\")\n",
        "    print(f\"  Efficiency Gain: ~{(total_agents - agents_executed) / total_agents * 100:.0f}%\")\n",
        "    \n",
        "\n",
        "    print(\"THRESHOLD IMPACT ANALYSIS\")\n",
        "\n",
        "    if result_compliance.get('compliance', {}).get('status') in ['completed', 'no_results']:\n",
        "        compliance_threshold = result_compliance['compliance'].get('threshold', 0.1)\n",
        "        compliance_clauses = result_compliance['compliance'].get('clauses_retrieved', 0)\n",
        "        \n",
        "        print(f\"  Compliance Agent:\")\n",
        "        print(f\"    â€¢ Threshold: {compliance_threshold} (LOWER for better recall)\")\n",
        "        print(f\"    â€¢ Clauses Retrieved: {compliance_clauses}\")\n",
        "        \n",
        "        if compliance_clauses > 0:\n",
        "            avg_rel = result_compliance['compliance'].get('avg_relevance', 0)\n",
        "            max_rel = result_compliance['compliance'].get('max_relevance', 0)\n",
        "            print(f\"    â€¢ Average Relevance: {avg_rel:.3f}\")\n",
        "            print(f\"    â€¢ Max Relevance: {max_rel:.3f}\")\n",
        "            print(f\"    â€¢ Lower threshold helped retrieve clauses\")\n",
        "        else:\n",
        "            print(f\"    â€¢ Even with 0.10 threshold, no clauses found\")\n",
        "    \n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nExecution failed: {str(e)}\")\n",
        "    print(\"ERROR DETAILS\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "\n",
        "print(\"TEST CASE 3 COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9. Test Case 4 - Operations Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST CASE 4 - OPERATIONS QUERY\n",
            "\n",
            "Preparing test state for operations query...\n",
            "Test state created\n",
            "  Query: \"Review the milestones, deliverables, and SLA requirements\"\n",
            "  Expected: Routes to Operations Agent\n",
            "EXECUTING CONDITIONAL GRAPH - TEST CASE 4\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Review the milestones, deliverables, and SLA requirements\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: operations\n",
            "  Reasoning: The query explicitly mentions milestones, deliverables, and SLA requirements, which fall under the domain of Operations.\n",
            "\n",
            "First agent to execute: OPERATIONS\n",
            "\n",
            "  â†’ OPERATIONS AGENT executing (threshold: 0.1)\n",
            "     Query: Review the milestones, deliverables, and SLA requirements...\n",
            "     Retrieved: 2 clauses (avg: 0.287)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 2\n",
            "Top relevance score: 0.359\n",
            "Agents executed: operations\n",
            "TEST CASE 4 COMPLETED\n",
            "\n",
            "ROUTING DECISION:\n",
            "  Query: \"Review the milestones, deliverables, and SLA requirements\"\n",
            "  LLM Routed To: \n",
            "  Reasoning: \n",
            "  Approach: \n",
            "EXECUTION SUMMARY\n",
            "  Execution Order: routing â†’ operations â†’ aggregation\n",
            "  Total Clauses Retrieved: 2\n",
            "  Execution Status: success\n",
            "AGENT EXECUTION STATUS\n",
            "Agent           Status          Clauses    Threshold    Avg Relevance  \n",
            "LEGAL           NOT EXECUTED    -          -            -              \n",
            "COMPLIANCE      NOT EXECUTED    -          -            -              \n",
            "FINANCE         NOT EXECUTED    -          -            -              \n",
            "OPERATIONS      EXECUTED        2          0.10         0.287          \n",
            "RETRIEVED CLAUSES\n",
            "\n",
            "[1] Agent: OPERATIONS | Relevance: 0.359\n",
            "    Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distribution of the Produ...\n",
            "\n",
            "[2] Agent: OPERATIONS | Relevance: 0.215\n",
            "    Collectible Concepts Group will obtain any licenses deemed by the Joint Venturers to add value in the marketing of the P...\n",
            "CONDITIONAL ROUTING VERIFICATION\n",
            "\n",
            "Routed by LLM: \n",
            "Actually Executed: operations\n",
            "\n",
            "UNEXPECTED ROUTING:\n",
            "  Expected: ['operations']\n",
            "  Got: []\n",
            "EFFICIENCY ANALYSIS\n",
            "  Sequential Execution: 4 agents (always)\n",
            "  Conditional Execution: 1 agent(s) (query-dependent)\n",
            "  Agents Saved: 3\n",
            "  Efficiency Gain: ~75%\n",
            "  Time Saved: ~75%\n",
            "THRESHOLD IMPACT ANALYSIS\n",
            "  Operations Agent:\n",
            "    â€¢ Threshold: 0.1 (LOWER for better recall)\n",
            "    â€¢ Clauses Retrieved: 2\n",
            "    â€¢ Average Relevance: 0.287\n",
            "    â€¢ Max Relevance: 0.359\n",
            "    â€¢ Lower threshold helped retrieve clauses\n",
            "TEST CASE 4 COMPLETE - ALL SINGLE-DOMAIN TESTS FINISHED\n"
          ]
        }
      ],
      "source": [
        "print(\"TEST CASE 4 - OPERATIONS QUERY\")\n",
        "\n",
        "print(\"\\nPreparing test state for operations query...\")\n",
        "\n",
        "test_state_operations = {\n",
        "    \"query\": \"Review the milestones, deliverables, and SLA requirements\",\n",
        "    \"routed_agents\": [],\n",
        "    \"routing_reasoning\": \"\",\n",
        "    \"routing_approach\": \"\",\n",
        "    \"legal\": {},\n",
        "    \"compliance\": {},\n",
        "    \"finance\": {},\n",
        "    \"operations\": {},\n",
        "    \"all_clauses\": [],\n",
        "    \"total_clauses_retrieved\": 0,\n",
        "    \"execution_order\": [],\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"vector_store\": \"Pinecone\",\n",
        "    \"execution_status\": \"initialized\"\n",
        "}\n",
        "\n",
        "print(\"Test state created\")\n",
        "print(f\"  Query: \\\"{test_state_operations['query']}\\\"\")\n",
        "print(f\"  Expected: Routes to Operations Agent\")\n",
        "\n",
        "print(\"EXECUTING CONDITIONAL GRAPH - TEST CASE 4\")\n",
        "\n",
        "try:\n",
        "    result_operations = app_conditional.invoke(test_state_operations)\n",
        "\n",
        "    print(\"TEST CASE 4 COMPLETED\")\n",
        "\n",
        "    print(\"\\nROUTING DECISION:\")\n",
        "    print(f\"  Query: \\\"{result_operations['query']}\\\"\")\n",
        "    print(f\"  LLM Routed To: {', '.join(result_operations.get('routed_agents', []))}\")\n",
        "    print(f\"  Reasoning: {result_operations.get('routing_reasoning', 'N/A')}\")\n",
        "    print(f\"  Approach: {result_operations.get('routing_approach', 'N/A')}\")\n",
        "\n",
        "    print(\"EXECUTION SUMMARY\")\n",
        "\n",
        "    print(f\"  Execution Order: {' â†’ '.join(result_operations['execution_order'])}\")\n",
        "    print(f\"  Total Clauses Retrieved: {result_operations.get('total_clauses_retrieved', 0)}\")\n",
        "    print(f\"  Execution Status: {result_operations.get('execution_status', 'unknown')}\")\n",
        "\n",
        "    print(\"AGENT EXECUTION STATUS\")\n",
        "    print(f\"{'Agent':<15} {'Status':<15} {'Clauses':<10} {'Threshold':<12} {'Avg Relevance':<15}\")\n",
        "    \n",
        "    for agent_name in [\"legal\", \"compliance\", \"finance\", \"operations\"]:\n",
        "        agent_data = result_operations.get(agent_name, {})\n",
        "        if agent_data and agent_data.get(\"status\") == \"completed\":\n",
        "            status = \"EXECUTED\"\n",
        "            clauses = agent_data.get('clauses_retrieved', 0)\n",
        "            threshold = agent_data.get('threshold', 'N/A')\n",
        "            avg_rel = agent_data.get('avg_relevance', 0)\n",
        "            relevance = f\"{avg_rel:.3f}\" if avg_rel > 0 else \"N/A\"\n",
        "            threshold_str = f\"{threshold:.2f}\" if isinstance(threshold, float) else str(threshold)\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {clauses:<10} {threshold_str:<12} {relevance:<15}\")\n",
        "        elif agent_data and agent_data.get(\"status\") == \"no_results\":\n",
        "            status = \"EXECUTED (0)\"\n",
        "            threshold = agent_data.get('threshold', 'N/A')\n",
        "            threshold_str = f\"{threshold:.2f}\" if isinstance(threshold, float) else str(threshold)\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {0:<10} {threshold_str:<12} {'N/A':<15}\")\n",
        "        else:\n",
        "            status = \"NOT EXECUTED\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {'-':<10} {'-':<12} {'-':<15}\")\n",
        "    \n",
        "    if result_operations.get('all_clauses'):\n",
        "        print(\"RETRIEVED CLAUSES\")\n",
        "        for idx, clause in enumerate(result_operations['all_clauses'][:3], 1):\n",
        "            print(f\"\\n[{idx}] Agent: {clause['agent'].upper()} | Relevance: {clause['relevance_score']:.3f}\")\n",
        "            clause_text = clause['clause'][:120] + \"...\" if len(clause['clause']) > 120 else clause['clause']\n",
        "            print(f\"    {clause_text}\")\n",
        "    else:\n",
        "        print(\"NO CLAUSES RETRIEVED\")\n",
        "\n",
        "    print(\"CONDITIONAL ROUTING VERIFICATION\")\n",
        "\n",
        "    routed_agents = result_operations.get('routed_agents', [])\n",
        "    executed_agents = [a for a in result_operations['execution_order'] if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    print(f\"\\nRouted by LLM: {', '.join(routed_agents)}\")\n",
        "    print(f\"Actually Executed: {', '.join(executed_agents)}\")\n",
        "    \n",
        "    if 'operations' in routed_agents:\n",
        "        print(\"\\nSUCCESS: Operations domain correctly identified\")\n",
        "        \n",
        "        if len(routed_agents) == 1:\n",
        "            print(\"  â€¢ Only Operations agent routed (efficient)\")\n",
        "            print(\"  â€¢ Other agents skipped\")\n",
        "        else:\n",
        "            print(f\"  â€¢ Multi-domain query detected: {', '.join(routed_agents)}\")\n",
        "        \n",
        "        operations_clauses = result_operations.get('operations', {}).get('clauses_retrieved', 0)\n",
        "        if operations_clauses > 0:\n",
        "            print(f\"  â€¢ Successfully retrieved {operations_clauses} clause(s)\")\n",
        "        else:\n",
        "            print(f\"  â€¢ No clauses retrieved (may not exist in dataset)\")\n",
        "            print(f\"  â€¢ Note: Lower threshold (0.10) already applied\")\n",
        "    else:\n",
        "        print(f\"\\nUNEXPECTED ROUTING:\")\n",
        "        print(f\"  Expected: ['operations']\")\n",
        "        print(f\"  Got: {routed_agents}\")\n",
        "\n",
        "    print(\"EFFICIENCY ANALYSIS\")\n",
        "\n",
        "    agents_executed = len(executed_agents)\n",
        "    total_agents = 4\n",
        "    \n",
        "    print(f\"  Sequential Execution: {total_agents} agents (always)\")\n",
        "    print(f\"  Conditional Execution: {agents_executed} agent(s) (query-dependent)\")\n",
        "    print(f\"  Agents Saved: {total_agents - agents_executed}\")\n",
        "    print(f\"  Efficiency Gain: ~{(total_agents - agents_executed) / total_agents * 100:.0f}%\")\n",
        "    print(f\"  Time Saved: ~{(total_agents - agents_executed) / total_agents * 100:.0f}%\")\n",
        "\n",
        "    print(\"THRESHOLD IMPACT ANALYSIS\")\n",
        "\n",
        "    if result_operations.get('operations', {}).get('status') in ['completed', 'no_results']:\n",
        "        operations_threshold = result_operations['operations'].get('threshold', 0.1)\n",
        "        operations_clauses = result_operations['operations'].get('clauses_retrieved', 0)\n",
        "        \n",
        "        print(f\"  Operations Agent:\")\n",
        "        print(f\"    â€¢ Threshold: {operations_threshold} (LOWER for better recall)\")\n",
        "        print(f\"    â€¢ Clauses Retrieved: {operations_clauses}\")\n",
        "        \n",
        "        if operations_clauses > 0:\n",
        "            avg_rel = result_operations['operations'].get('avg_relevance', 0)\n",
        "            max_rel = result_operations['operations'].get('max_relevance', 0)\n",
        "            print(f\"    â€¢ Average Relevance: {avg_rel:.3f}\")\n",
        "            print(f\"    â€¢ Max Relevance: {max_rel:.3f}\")\n",
        "            print(f\"    â€¢ Lower threshold helped retrieve clauses\")\n",
        "        else:\n",
        "            print(f\"    â€¢ Even with 0.10 threshold, no clauses found\")\n",
        "            print(f\"    â€¢ Likely: No operations data for this query in Pinecone\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nExecution failed: {str(e)}\")\n",
        "    print(\"ERROR DETAILS\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "\n",
        "print(\"TEST CASE 4 COMPLETE - ALL SINGLE-DOMAIN TESTS FINISHED\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 10. Test Case 5 - Multiple Intent - Limitation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TEST CASE 5 - MULTI-DOMAIN QUERY\n",
            "\n",
            "Preparing test state for multi-domain query...\n",
            "Test state created\n",
            "  Query: \"Check GDPR compliance and payment terms with late penalties\"\n",
            "  Expected: Routes to BOTH Compliance AND Finance\n",
            "EXECUTING CONDITIONAL GRAPH - TEST CASE 5 (MULTI-DOMAIN)\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Check GDPR compliance and payment terms with late penalties\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: compliance, finance\n",
            "  Reasoning: GDPR compliance falls under data protection and privacy regulations handled by the Compliance agent. Payment terms with late penalties are financial obligations handled by the Finance agent.\n",
            "\n",
            "First agent to execute: COMPLIANCE\n",
            "\n",
            "  â†’ COMPLIANCE AGENT executing (threshold: 0.1)\n",
            "     Query: Check GDPR compliance and payment terms with late penalties...\n",
            "     Retrieved: 1 clauses (avg: 0.166)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 1\n",
            "Top relevance score: 0.166\n",
            "Agents executed: compliance\n",
            "TEST CASE 5 COMPLETED\n",
            "\n",
            "ROUTING DECISION:\n",
            "  Query: \"Check GDPR compliance and payment terms with late penalties\"\n",
            "  LLM Routed To: \n",
            "  Reasoning: \n",
            "  Approach: \n",
            "EXECUTION SUMMARY\n",
            "  Execution Order: routing â†’ compliance â†’ aggregation\n",
            "  Total Clauses Retrieved: 1\n",
            "  Execution Status: success\n",
            "AGENT EXECUTION STATUS\n",
            "Agent           Status          Clauses    Threshold    Avg Relevance  \n",
            "LEGAL           NOT EXECUTED    -          -            -              \n",
            "COMPLIANCE      EXECUTED        1          0.10         0.166          \n",
            "FINANCE         NOT EXECUTED    -          -            -              \n",
            "OPERATIONS      NOT EXECUTED    -          -            -              \n",
            "RETRIEVED CLAUSES (ALL AGENTS)\n",
            "\n",
            "COMPLIANCE Agent - 1 clause(s):\n",
            "  [1] Relevance: 0.166\n",
            "      The receiving party will not disclose the other party's confidential information to any third partie...\n",
            "MULTI-DOMAIN ROUTING ANALYSIS\n",
            "\n",
            "Routed by LLM: \n",
            "Actually Executed: compliance\n",
            "Agents Count: 1\n",
            "\n",
            "NO AGENTS ROUTED\n",
            "EFFICIENCY ANALYSIS (MULTI-DOMAIN)\n",
            "  Sequential Execution: 4 agents (always)\n",
            "  Conditional Execution: 1 agent(s) (only needed)\n",
            "  Agents Saved: 3\n",
            "  Efficiency Gain: ~75%\n",
            "ADAPTIVE THRESHOLD IMPACT\n",
            "\n",
            "  Threshold Strategy:\n",
            "    â€¢ Compliance: 0.1 (lower for recall) â†’ 1 clauses\n",
            "\n",
            "  Different thresholds per agent optimize results\n",
            "COMPARISON: SINGLE vs MULTI-DOMAIN ROUTING\n",
            "\n",
            "  Multi-Domain Test:\n",
            "    â€¢ 1 agent(s) executed\n",
            "    â€¢ Through aggregation (consolidation)\n",
            "    â€¢ 75% efficiency gain\n",
            "    â€¢ Comprehensive coverage\n",
            "\n",
            "    \n",
            "TEST CASE 5 COMPLETE - MULTI-DOMAIN ROUTING TESTED\n"
          ]
        }
      ],
      "source": [
        "print(\"TEST CASE 5 - MULTI-DOMAIN QUERY\")\n",
        "\n",
        "print(\"\\nPreparing test state for multi-domain query...\")\n",
        "\n",
        "test_state_multi = {\n",
        "    \"query\": \"Check GDPR compliance and payment terms with late penalties\",\n",
        "    \"routed_agents\": [],\n",
        "    \"routing_reasoning\": \"\",\n",
        "    \"routing_approach\": \"\",\n",
        "    \"legal\": {},\n",
        "    \"compliance\": {},\n",
        "    \"finance\": {},\n",
        "    \"operations\": {},\n",
        "    \"all_clauses\": [],\n",
        "    \"total_clauses_retrieved\": 0,\n",
        "    \"execution_order\": [],\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"vector_store\": \"Pinecone\",\n",
        "    \"execution_status\": \"initialized\"\n",
        "}\n",
        "\n",
        "print(\"Test state created\")\n",
        "print(f\"  Query: \\\"{test_state_multi['query']}\\\"\")\n",
        "print(f\"  Expected: Routes to BOTH Compliance AND Finance\")\n",
        "\n",
        "print(\"EXECUTING CONDITIONAL GRAPH - TEST CASE 5 (MULTI-DOMAIN)\")\n",
        "\n",
        "try:\n",
        "    result_multi = app_conditional.invoke(test_state_multi)\n",
        "    \n",
        "    print(\"TEST CASE 5 COMPLETED\")\n",
        " \n",
        "    print(\"\\nROUTING DECISION:\")\n",
        "    print(f\"  Query: \\\"{result_multi['query']}\\\"\")\n",
        "    print(f\"  LLM Routed To: {', '.join(result_multi.get('routed_agents', []))}\")\n",
        "    print(f\"  Reasoning: {result_multi.get('routing_reasoning', 'N/A')}\")\n",
        "    print(f\"  Approach: {result_multi.get('routing_approach', 'N/A')}\")\n",
        "    \n",
        "    print(\"EXECUTION SUMMARY\")\n",
        "    print(f\"  Execution Order: {' â†’ '.join(result_multi['execution_order'])}\")\n",
        "    print(f\"  Total Clauses Retrieved: {result_multi.get('total_clauses_retrieved', 0)}\")\n",
        "    print(f\"  Execution Status: {result_multi.get('execution_status', 'unknown')}\")\n",
        "    \n",
        "    print(\"AGENT EXECUTION STATUS\")\n",
        "    print(f\"{'Agent':<15} {'Status':<15} {'Clauses':<10} {'Threshold':<12} {'Avg Relevance':<15}\")\n",
        "\n",
        "    executed_agents = []\n",
        "    for agent_name in [\"legal\", \"compliance\", \"finance\", \"operations\"]:\n",
        "        agent_data = result_multi.get(agent_name, {})\n",
        "        if agent_data and agent_data.get(\"status\") == \"completed\":\n",
        "            executed_agents.append(agent_name)\n",
        "            status = \"EXECUTED\"\n",
        "            clauses = agent_data.get('clauses_retrieved', 0)\n",
        "            threshold = agent_data.get('threshold', 'N/A')\n",
        "            avg_rel = agent_data.get('avg_relevance', 0)\n",
        "            relevance = f\"{avg_rel:.3f}\" if avg_rel > 0 else \"N/A\"\n",
        "            threshold_str = f\"{threshold:.2f}\" if isinstance(threshold, float) else str(threshold)\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {clauses:<10} {threshold_str:<12} {relevance:<15}\")\n",
        "        elif agent_data and agent_data.get(\"status\") == \"no_results\":\n",
        "            executed_agents.append(agent_name)\n",
        "            status = \"EXECUTED (0)\"\n",
        "            threshold = agent_data.get('threshold', 'N/A')\n",
        "            threshold_str = f\"{threshold:.2f}\" if isinstance(threshold, float) else str(threshold)\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {0:<10} {threshold_str:<12} {'N/A':<15}\")\n",
        "        else:\n",
        "            status = \"NOT EXECUTED\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {'-':<10} {'-':<12} {'-':<15}\")\n",
        "    \n",
        "    if result_multi.get('all_clauses'):\n",
        "        print(\"RETRIEVED CLAUSES (ALL AGENTS)\")\n",
        "   \n",
        "        clauses_by_agent = {}\n",
        "        for clause in result_multi['all_clauses']:\n",
        "            agent = clause['agent']\n",
        "            if agent not in clauses_by_agent:\n",
        "                clauses_by_agent[agent] = []\n",
        "            clauses_by_agent[agent].append(clause)\n",
        "        \n",
        "        for agent, clauses in clauses_by_agent.items():\n",
        "            print(f\"\\n{agent.upper()} Agent - {len(clauses)} clause(s):\")\n",
        "            for idx, clause in enumerate(clauses[:2], 1):\n",
        "                print(f\"  [{idx}] Relevance: {clause['relevance_score']:.3f}\")\n",
        "                clause_text = clause['clause'][:100] + \"...\" if len(clause['clause']) > 100 else clause['clause']\n",
        "                print(f\"      {clause_text}\")\n",
        "    \n",
        "\n",
        "    print(\"MULTI-DOMAIN ROUTING ANALYSIS\")\n",
        "\n",
        "    routed_agents = result_multi.get('routed_agents', [])\n",
        "    \n",
        "    print(f\"\\nRouted by LLM: {', '.join(routed_agents)}\")\n",
        "    print(f\"Actually Executed: {', '.join(executed_agents)}\")\n",
        "    print(f\"Agents Count: {len(executed_agents)}\")\n",
        "    \n",
        "    if len(routed_agents) >= 2:\n",
        "        print(f\"\\nSUCCESS: Multi-domain query handled correctly\")\n",
        "        print(f\"  â€¢ LLM identified {len(routed_agents)} relevant domains\")\n",
        "        print(f\"  â€¢ Query spans multiple areas: {', '.join(routed_agents)}\")\n",
        "        \n",
        "        if 'compliance' in routed_agents and 'finance' in routed_agents:\n",
        "            print(f\"  â€¢ Both Compliance (GDPR) and Finance (payment) detected\")\n",
        "        \n",
        "        if 'aggregation' in result_multi['execution_order']:\n",
        "            print(f\"  â€¢ Results consolidated via aggregation node\")\n",
        "        \n",
        "        print(f\"\\n  Execution Flow:\")\n",
        "        for idx, step in enumerate(result_multi['execution_order'], 1):\n",
        "            print(f\"    {idx}. {step}\")\n",
        "        \n",
        "    elif len(routed_agents) == 1:\n",
        "        print(f\"\\nSINGLE-AGENT ROUTING:\")\n",
        "        print(f\"  â€¢ LLM selected only: {routed_agents[0]}\")\n",
        "\n",
        "    else:\n",
        "        print(f\"\\nNO AGENTS ROUTED\")\n",
        "\n",
        "    print(\"EFFICIENCY ANALYSIS (MULTI-DOMAIN)\")\n",
        "\n",
        "    agents_executed_count = len(executed_agents)\n",
        "    total_agents = 4\n",
        "    \n",
        "    print(f\"  Sequential Execution: {total_agents} agents (always)\")\n",
        "    print(f\"  Conditional Execution: {agents_executed_count} agent(s) (only needed)\")\n",
        "    print(f\"  Agents Saved: {total_agents - agents_executed_count}\")\n",
        "    print(f\"  Efficiency Gain: ~{(total_agents - agents_executed_count) / total_agents * 100:.0f}%\")\n",
        "    \n",
        "    if agents_executed_count > 1:\n",
        "        print(f\"\\n  Multi-agent execution benefits:\")\n",
        "        print(f\"    â€¢ Comprehensive coverage of query domains\")\n",
        "        print(f\"    â€¢ Results from {agents_executed_count} specialized agents\")\n",
        "        print(f\"    â€¢ Still skipped {total_agents - agents_executed_count} irrelevant agent(s)\")\n",
        "        print(f\"    â€¢ Better than sequential (would run all {total_agents})\")\n",
        "    \n",
        "\n",
        "    print(\"ADAPTIVE THRESHOLD IMPACT\")\n",
        "    \n",
        "    compliance_in = 'compliance' in executed_agents\n",
        "    finance_in = 'finance' in executed_agents\n",
        "    \n",
        "    if compliance_in or finance_in:\n",
        "        print(\"\\n  Threshold Strategy:\")\n",
        "        if compliance_in:\n",
        "            comp_threshold = result_multi.get('compliance', {}).get('threshold', 0.1)\n",
        "            comp_clauses = result_multi.get('compliance', {}).get('clauses_retrieved', 0)\n",
        "            print(f\"    â€¢ Compliance: {comp_threshold} (lower for recall) â†’ {comp_clauses} clauses\")\n",
        "        if finance_in:\n",
        "            fin_threshold = result_multi.get('finance', {}).get('threshold', 0.3)\n",
        "            fin_clauses = result_multi.get('finance', {}).get('clauses_retrieved', 0)\n",
        "            print(f\"    â€¢ Finance: {fin_threshold} (higher for precision) â†’ {fin_clauses} clauses\")\n",
        "        \n",
        "        print(f\"\\n  Different thresholds per agent optimize results\")\n",
        "\n",
        "    print(\"COMPARISON: SINGLE vs MULTI-DOMAIN ROUTING\")\n",
        "\n",
        "    print(f\"\"\"\n",
        "  Multi-Domain Test:\n",
        "    â€¢ {agents_executed_count} agent(s) executed\n",
        "    â€¢ Through aggregation (consolidation)\n",
        "    â€¢ {(total_agents - agents_executed_count) / total_agents * 100:.0f}% efficiency gain\n",
        "    â€¢ Comprehensive coverage\n",
        "    \n",
        "    \"\"\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nExecution failed: {str(e)}\")\n",
        "    print(\"ERROR DETAILS\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"TEST CASE 5 COMPLETE - MULTI-DOMAIN ROUTING TESTED\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 11. Adding New Keyword Mapping & Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DYNAMIC LLM COORDINATOR - NO KEYWORD MAPPING NEEDED\n",
            "TESTING DYNAMIC ROUTING WITH NEW TERMS\n",
            "\n",
            "Testing 8 queries with new terminology:\n",
            "  1. Review dispute resolution and arbitration clause\n",
            "  2. Check PCI DSS compliance report\n",
            "  3. Calculate interest rate on late charges\n",
            "  4. Project implementation timeline and go-live date\n",
            "  5. Contract breach and warranty issues\n",
            "  6. Data breach incident response procedure\n",
            "  7. Payment schedule with currency exchange rates\n",
            "  8. Sprint deliverables and acceptance criteria\n",
            "\n",
            "================================================================================\n",
            "TEST 1/8\n",
            "================================================================================\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Review dispute resolution and arbitration clause\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: legal\n",
            "  Reasoning: The query specifically mentions 'dispute resolution and arbitration clause', which fall under contract law and legal considerations.\n",
            "\n",
            "First agent to execute: LEGAL\n",
            "\n",
            "  â†’ LEGAL AGENT executing (threshold: 0.1)\n",
            "     Query: Review dispute resolution and arbitration clause...\n",
            "     Retrieved: 2 clauses (avg: 0.303)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 2\n",
            "Top relevance score: 0.355\n",
            "Agents executed: legal\n",
            "\n",
            "Query: \"Review dispute resolution and arbitration clause\"\n",
            "LLM Routed To: \n",
            "Reasoning: \n",
            "Executed: legal\n",
            "Clauses Retrieved: 2\n",
            "Success\n",
            "\n",
            "================================================================================\n",
            "TEST 2/8\n",
            "================================================================================\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Check PCI DSS compliance report\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: compliance\n",
            "  Reasoning: PCI DSS (Payment Card Industry Data Security Standard) is a set of security standards designed to ensure that companies that process, store or transmit credit card information maintain a secure environment.\n",
            "\n",
            "First agent to execute: COMPLIANCE\n",
            "\n",
            "  â†’ COMPLIANCE AGENT executing (threshold: 0.1)\n",
            "     Query: Check PCI DSS compliance report...\n",
            "     Retrieved: 1 clauses (avg: 0.141)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 1\n",
            "Top relevance score: 0.141\n",
            "Agents executed: compliance\n",
            "\n",
            "Query: \"Check PCI DSS compliance report\"\n",
            "LLM Routed To: \n",
            "Reasoning: \n",
            "Executed: compliance\n",
            "Clauses Retrieved: 1\n",
            "Success\n",
            "\n",
            "================================================================================\n",
            "TEST 3/8\n",
            "================================================================================\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Calculate interest rate on late charges\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: finance\n",
            "  Reasoning: Calculating interest rates on late charges falls under financial obligations and penalties.\n",
            "\n",
            "First agent to execute: FINANCE\n",
            "\n",
            "  â†’ FINANCE AGENT executing (threshold: 0.1)\n",
            "     Query: Calculate interest rate on late charges...\n",
            "     Retrieved: 3 clauses (avg: 0.141)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 3\n",
            "Top relevance score: 0.172\n",
            "Agents executed: finance\n",
            "\n",
            "Query: \"Calculate interest rate on late charges\"\n",
            "LLM Routed To: \n",
            "Reasoning: \n",
            "Executed: finance\n",
            "Clauses Retrieved: 3\n",
            "Success\n",
            "\n",
            "================================================================================\n",
            "TEST 4/8\n",
            "================================================================================\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Project implementation timeline and go-live date\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: operations\n",
            "  Reasoning: The query focuses on project implementation timeline and go-live date, which fall under operational aspects like deliverables, timelines, and milestones.\n",
            "\n",
            "First agent to execute: OPERATIONS\n",
            "\n",
            "  â†’ OPERATIONS AGENT executing (threshold: 0.1)\n",
            "     Query: Project implementation timeline and go-live date...\n",
            "     Retrieved: 1 clauses (avg: 0.145)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 1\n",
            "Top relevance score: 0.145\n",
            "Agents executed: operations\n",
            "\n",
            "Query: \"Project implementation timeline and go-live date\"\n",
            "LLM Routed To: \n",
            "Reasoning: \n",
            "Executed: operations\n",
            "Clauses Retrieved: 1\n",
            "Success\n",
            "\n",
            "================================================================================\n",
            "TEST 5/8\n",
            "================================================================================\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Contract breach and warranty issues\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: legal\n",
            "  Reasoning: Contract breach and warranty issues fall under the domain of contract law, making the LEGAL agent the most relevant.\n",
            "\n",
            "First agent to execute: LEGAL\n",
            "\n",
            "  â†’ LEGAL AGENT executing (threshold: 0.1)\n",
            "     Query: Contract breach and warranty issues...\n",
            "     Retrieved: 2 clauses (avg: 0.246)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 2\n",
            "Top relevance score: 0.311\n",
            "Agents executed: legal\n",
            "\n",
            "Query: \"Contract breach and warranty issues\"\n",
            "LLM Routed To: \n",
            "Reasoning: \n",
            "Executed: legal\n",
            "Clauses Retrieved: 2\n",
            "Success\n",
            "\n",
            "================================================================================\n",
            "TEST 6/8\n",
            "================================================================================\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Data breach incident response procedure\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: compliance\n",
            "  Reasoning: Data breach incident response procedures primarily fall under data protection and regulatory compliance.\n",
            "\n",
            "First agent to execute: COMPLIANCE\n",
            "\n",
            "  â†’ COMPLIANCE AGENT executing (threshold: 0.1)\n",
            "     Query: Data breach incident response procedure...\n",
            "     Retrieved: 1 clauses (avg: 0.250)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 1\n",
            "Top relevance score: 0.250\n",
            "Agents executed: compliance\n",
            "\n",
            "Query: \"Data breach incident response procedure\"\n",
            "LLM Routed To: \n",
            "Reasoning: \n",
            "Executed: compliance\n",
            "Clauses Retrieved: 1\n",
            "Success\n",
            "\n",
            "================================================================================\n",
            "TEST 7/8\n",
            "================================================================================\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Payment schedule with currency exchange rates\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: finance\n",
            "  Reasoning: The query specifically mentions 'payment schedule' and 'currency exchange rates', which fall under the domain of financial transactions and agreements.\n",
            "\n",
            "First agent to execute: FINANCE\n",
            "\n",
            "  â†’ FINANCE AGENT executing (threshold: 0.1)\n",
            "     Query: Payment schedule with currency exchange rates...\n",
            "     Retrieved: 2 clauses (avg: 0.289)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 2\n",
            "Top relevance score: 0.293\n",
            "Agents executed: finance\n",
            "\n",
            "Query: \"Payment schedule with currency exchange rates\"\n",
            "LLM Routed To: \n",
            "Reasoning: \n",
            "Executed: finance\n",
            "Clauses Retrieved: 2\n",
            "Success\n",
            "\n",
            "================================================================================\n",
            "TEST 8/8\n",
            "================================================================================\n",
            "CONDITIONAL ENTRY POINT ROUTER\n",
            "Query: \"Sprint deliverables and acceptance criteria\"\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "LLM Routing Decision:\n",
            "  Agents: operations\n",
            "  Reasoning: The query focuses on project deliverables and acceptance criteria, which fall under the domain of Operations.\n",
            "\n",
            "First agent to execute: OPERATIONS\n",
            "\n",
            "  â†’ OPERATIONS AGENT executing (threshold: 0.1)\n",
            "     Query: Sprint deliverables and acceptance criteria...\n",
            "     Retrieved: 2 clauses (avg: 0.276)\n",
            "AGGREGATION NODE: Consolidating Results\n",
            "\n",
            "Total clauses retrieved: 2\n",
            "Top relevance score: 0.332\n",
            "Agents executed: operations\n",
            "\n",
            "Query: \"Sprint deliverables and acceptance criteria\"\n",
            "LLM Routed To: \n",
            "Reasoning: \n",
            "Executed: operations\n",
            "Clauses Retrieved: 2\n",
            "Success\n",
            "DYNAMIC ROUTING ANALYSIS\n",
            "\n",
            "Routing Statistics:\n",
            "  Total Queries: 8\n",
            "  Successful Routes: 8\n",
            "  Success Rate: 100.0%\n",
            "\n",
            "Agent Selection Distribution:\n",
            "Agent           Count    Percentage   Bar\n",
            "LEGAL           2          25.0%      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "COMPLIANCE      2          25.0%      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "FINANCE         2          25.0%      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "OPERATIONS      2          25.0%      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
            "\n",
            "Multi-Agent Queries: 0\n",
            "LLM UNDERSTANDING OF NEW TERMS\n",
            "SUCCESS Terms: 'dispute resolution, arbitration'\n",
            "  Expected: legal\n",
            "  Routed: legal\n",
            "  Reasoning: ...\n",
            "\n",
            "SUCCESS Terms: 'PCI DSS compliance'\n",
            "  Expected: compliance\n",
            "  Routed: compliance\n",
            "  Reasoning: ...\n",
            "\n",
            "SUCCESS Terms: 'interest rate, late charges'\n",
            "  Expected: finance\n",
            "  Routed: finance\n",
            "  Reasoning: ...\n",
            "\n",
            "SUCCESS Terms: 'implementation timeline, go-live'\n",
            "  Expected: operations\n",
            "  Routed: operations\n",
            "  Reasoning: ...\n",
            "\n",
            "SUCCESS Terms: 'contract breach, warranty'\n",
            "  Expected: legal\n",
            "  Routed: legal\n",
            "  Reasoning: ...\n",
            "\n",
            "SUCCESS Terms: 'data breach, incident response'\n",
            "  Expected: compliance\n",
            "  Routed: compliance\n",
            "  Reasoning: ...\n",
            "\n",
            "SUCCESS Terms: 'payment schedule, currency'\n",
            "  Expected: finance\n",
            "  Routed: finance\n",
            "  Reasoning: ...\n",
            "\n",
            "SUCCESS Terms: 'sprint deliverables, acceptance'\n",
            "  Expected: operations\n",
            "  Routed: operations\n",
            "  Reasoning: ...\n",
            "\n",
            "SAVING RESULTS\n",
            "\n",
            "Results saved: dynamic_routing_new_terms_20260115_171446.json\n",
            "  Location: ../Data/Results/LangGraph\n",
            "DYNAMIC ROUTING WITH NEW TERMS COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"DYNAMIC LLM COORDINATOR - NO KEYWORD MAPPING NEEDED\")\n",
        "\n",
        "print(\"TESTING DYNAMIC ROUTING WITH NEW TERMS\")\n",
        "\n",
        "test_queries_new_terms = [\n",
        "    \"Review dispute resolution and arbitration clause\",\n",
        "    \"Check PCI DSS compliance report\",\n",
        "    \"Calculate interest rate on late charges\",\n",
        "    \"Project implementation timeline and go-live date\",\n",
        "    \"Contract breach and warranty issues\",\n",
        "    \"Data breach incident response procedure\",\n",
        "    \"Payment schedule with currency exchange rates\",\n",
        "    \"Sprint deliverables and acceptance criteria\"\n",
        "]\n",
        "\n",
        "print(f\"\\nTesting {len(test_queries_new_terms)} queries with new terminology:\")\n",
        "for idx, query in enumerate(test_queries_new_terms, 1):\n",
        "    print(f\"  {idx}. {query}\")\n",
        "\n",
        "dynamic_results = []\n",
        "\n",
        "for idx, query in enumerate(test_queries_new_terms, 1):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TEST {idx}/{len(test_queries_new_terms)}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    test_state = {\n",
        "        \"query\": query,\n",
        "        \"routed_agents\": [],\n",
        "        \"routing_reasoning\": \"\",\n",
        "        \"routing_approach\": \"\",\n",
        "        \"legal\": {},\n",
        "        \"compliance\": {},\n",
        "        \"finance\": {},\n",
        "        \"operations\": {},\n",
        "        \"all_clauses\": [],\n",
        "        \"total_clauses_retrieved\": 0,\n",
        "        \"execution_order\": [],\n",
        "        \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "        \"coordinator_model\": \"gemma2:9b\",\n",
        "        \"vector_store\": \"Pinecone\",\n",
        "        \"execution_status\": \"initialized\"\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        result = app_conditional.invoke(test_state)\n",
        "        \n",
        "        routed_agents = result.get('routed_agents', [])\n",
        "        executed_agents = [a for a in result['execution_order'] if a not in ['routing', 'aggregation']]\n",
        "        reasoning = result.get('routing_reasoning', 'N/A')\n",
        "        clauses = result.get('total_clauses_retrieved', 0)\n",
        "        \n",
        "        print(f\"\\nQuery: \\\"{query}\\\"\")\n",
        "        print(f\"LLM Routed To: {', '.join(routed_agents)}\")\n",
        "        print(f\"Reasoning: {reasoning}\")\n",
        "        print(f\"Executed: {', '.join(executed_agents)}\")\n",
        "        print(f\"Clauses Retrieved: {clauses}\")\n",
        "        \n",
        "        dynamic_results.append({\n",
        "            \"query\": query,\n",
        "            \"routed_agents\": routed_agents,\n",
        "            \"executed_agents\": executed_agents,\n",
        "            \"reasoning\": reasoning,\n",
        "            \"clauses_retrieved\": clauses,\n",
        "            \"success\": len(executed_agents) > 0\n",
        "        })\n",
        "        \n",
        "        print(f\"Success\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)[:100]}\")\n",
        "        dynamic_results.append({\n",
        "            \"query\": query,\n",
        "            \"routed_agents\": [],\n",
        "            \"executed_agents\": [],\n",
        "            \"reasoning\": f\"Error: {str(e)[:50]}\",\n",
        "            \"clauses_retrieved\": 0,\n",
        "            \"success\": False\n",
        "        })\n",
        "\n",
        "\n",
        "print(\"DYNAMIC ROUTING ANALYSIS\")\n",
        "\n",
        "agent_usage = defaultdict(int)\n",
        "for result in dynamic_results:\n",
        "    for agent in result['executed_agents']:\n",
        "        agent_usage[agent] += 1\n",
        "\n",
        "print(f\"\\nRouting Statistics:\")\n",
        "print(f\"  Total Queries: {len(dynamic_results)}\")\n",
        "print(f\"  Successful Routes: {sum(1 for r in dynamic_results if r['success'])}\")\n",
        "print(f\"  Success Rate: {sum(1 for r in dynamic_results if r['success']) / len(dynamic_results) * 100:.1f}%\")\n",
        "\n",
        "print(f\"\\nAgent Selection Distribution:\")\n",
        "print(f\"{'Agent':<15} {'Count':<8} {'Percentage':<12} {'Bar'}\")\n",
        "\n",
        "for agent in ['legal', 'compliance', 'finance', 'operations']:\n",
        "    count = agent_usage.get(agent, 0)\n",
        "    percentage = (count / len(dynamic_results)) * 100 if len(dynamic_results) > 0 else 0\n",
        "    bar = \"â–ˆ\" * int(percentage / 5)\n",
        "    print(f\"{agent.upper():<15} {count:<8} {percentage:>6.1f}%      {bar}\")\n",
        "\n",
        "multi_agent_queries = [r for r in dynamic_results if len(r['executed_agents']) > 1]\n",
        "print(f\"\\nMulti-Agent Queries: {len(multi_agent_queries)}\")\n",
        "for result in multi_agent_queries:\n",
        "    print(f\"  â€¢ \\\"{result['query'][:60]}...\\\"\")\n",
        "    print(f\"    Agents: {', '.join(result['executed_agents'])}\")\n",
        "\n",
        "print(\"LLM UNDERSTANDING OF NEW TERMS\")\n",
        "\n",
        "term_mapping = {\n",
        "    \"dispute resolution, arbitration\": \"legal\",\n",
        "    \"PCI DSS compliance\": \"compliance\",\n",
        "    \"interest rate, late charges\": \"finance\",\n",
        "    \"implementation timeline, go-live\": \"operations\",\n",
        "    \"contract breach, warranty\": \"legal\",\n",
        "    \"data breach, incident response\": \"compliance\",\n",
        "    \"payment schedule, currency\": \"finance\",\n",
        "    \"sprint deliverables, acceptance\": \"operations\"\n",
        "}\n",
        "\n",
        "for terms, expected_agent in term_mapping.items():\n",
        "\n",
        "    matching = [r for r in dynamic_results if any(t.lower() in r['query'].lower() for t in terms.split(', '))]\n",
        "    if matching:\n",
        "        result = matching[0]\n",
        "        actual_agents = result['executed_agents']\n",
        "        match = expected_agent in actual_agents\n",
        "        status = \"SUCCESS\" if match else \"ERROR\"\n",
        "        print(f\"{status} Terms: '{terms}'\")\n",
        "        print(f\"  Expected: {expected_agent}\")\n",
        "        print(f\"  Routed: {', '.join(actual_agents)}\")\n",
        "        print(f\"  Reasoning: {result['reasoning'][:80]}...\")\n",
        "        print()\n",
        "\n",
        "\n",
        "print(\"SAVING RESULTS\")\n",
        "\n",
        "LANGGRAPH_OUTPUT = \"../Data/Results/LangGraph\"\n",
        "os.makedirs(LANGGRAPH_OUTPUT, exist_ok=True)\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "dynamic_output = {\n",
        "    \"task\": \"Dynamic LLM Routing with New Terms (No Keyword Mapping)\",\n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"approach\": \"Dynamic LLM-based semantic routing\",\n",
        "    \"advantage\": \"No manual keyword management required\",\n",
        "    \"test_queries\": len(test_queries_new_terms),\n",
        "    \"queries_tested\": test_queries_new_terms,\n",
        "    \"routing_results\": dynamic_results,\n",
        "    \"statistics\": {\n",
        "        \"total_queries\": len(dynamic_results),\n",
        "        \"successful_routes\": sum(1 for r in dynamic_results if r['success']),\n",
        "        \"success_rate\": f\"{sum(1 for r in dynamic_results if r['success']) / len(dynamic_results) * 100:.1f}%\",\n",
        "        \"multi_agent_queries\": len(multi_agent_queries)\n",
        "    },\n",
        "    \"agent_usage\": dict(agent_usage)\n",
        "}\n",
        "\n",
        "output_file = f\"dynamic_routing_new_terms_{timestamp}.json\"\n",
        "output_path = os.path.join(LANGGRAPH_OUTPUT, output_file)\n",
        "\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(dynamic_output, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\nResults saved: {output_file}\")\n",
        "print(f\"  Location: {LANGGRAPH_OUTPUT}\")\n",
        "\n",
        "print(\"DYNAMIC ROUTING WITH NEW TERMS COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conversation Memory and State Persistence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, List, Dict, Any\n",
        "from langgraph.graph import StateGraph, END\n",
        "from datetime import datetime\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Defining Enhanced GraphState with Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CONVERSATION MEMORY & STATE PERSISTENCE\n",
            "\n",
            "Defining enhanced GraphState with conversation memory and persistence...\n",
            "GraphStateWithMemory defined\n",
            "DEFINING MEMORY MANAGEMENT FUNCTIONS\n",
            "add_to_memory() defined\n",
            "get_conversation_context() defined\n",
            "DEFINING STATE PERSISTENCE FUNCTIONS\n",
            "save_state_checkpoint() defined\n",
            "load_state_checkpoint() defined\n",
            "get_latest_checkpoint() defined\n",
            "CONVERSATION STATE INITIALIZATION\n",
            "initialize_conversation_state() defined\n",
            "CONVERSATION MEMORY & STATE PERSISTENCE READY\n"
          ]
        }
      ],
      "source": [
        "print(\"CONVERSATION MEMORY & STATE PERSISTENCE\")\n",
        "\n",
        "\n",
        "print(\"\\nDefining enhanced GraphState with conversation memory and persistence...\")\n",
        "\n",
        "class GraphStateWithMemory(TypedDict):\n",
        "  \n",
        "    query: str\n",
        "    \n",
        "    memory: List[Dict[str, Any]]  \n",
        "    conversation_history: List[Dict[str, Any]] \n",
        "    session_id: str \n",
        "    turn_number: int \n",
        "    \n",
        "    routed_agents: List[str]\n",
        "    routing_reasoning: str\n",
        "    routing_approach: str\n",
        "    \n",
        "    legal: Dict[str, Any]\n",
        "    compliance: Dict[str, Any] \n",
        "    finance: Dict[str, Any]\n",
        "    operations: Dict[str, Any] \n",
        "    \n",
        "    all_clauses: List[Dict[str, Any]]\n",
        "    total_clauses_retrieved: int\n",
        "    \n",
        "    execution_order: List[str]\n",
        "    timestamp: str\n",
        "    \n",
        "    coordinator_model: str\n",
        "    vector_store: str\n",
        "    execution_status: str\n",
        "    \n",
        "    previous_state: Dict[str, Any]  \n",
        "    checkpoint_path: str  \n",
        "\n",
        "print(\"GraphStateWithMemory defined\")\n",
        "\n",
        "print(\"DEFINING MEMORY MANAGEMENT FUNCTIONS\")\n",
        "\n",
        "def add_to_memory(state: GraphStateWithMemory, query: str, response: Dict[str, Any]) -> GraphStateWithMemory:\n",
        "\n",
        "    memory_entry = {\n",
        "        \"turn\": state.get('turn_number', 0),\n",
        "        \"query\": query,\n",
        "        \"routed_agents\": response.get('routed_agents', []),\n",
        "        \"clauses_retrieved\": response.get('total_clauses_retrieved', 0),\n",
        "        \"timestamp\": response.get('timestamp', ''),\n",
        "        \"summary\": {\n",
        "            agent: {\n",
        "                'status': response.get(agent, {}).get('status', 'not_executed'),\n",
        "                'clauses': response.get(agent, {}).get('clauses_retrieved', 0)\n",
        "            }\n",
        "            for agent in ['legal', 'compliance', 'finance', 'operations']\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    if 'memory' not in state or state['memory'] is None:\n",
        "        state['memory'] = []\n",
        "    \n",
        "    state['memory'].append(memory_entry)\n",
        "    state['turn_number'] = state.get('turn_number', 0) + 1\n",
        "    \n",
        "    return state\n",
        "\n",
        "print(\"add_to_memory() defined\")\n",
        "\n",
        "def get_conversation_context(state: GraphStateWithMemory) -> str:\n",
        "\n",
        "    if not state.get('memory') or len(state['memory']) == 0:\n",
        "        return \"This is the first query in the conversation.\"\n",
        "    \n",
        "    context_parts = [\"Previous conversation context:\"]\n",
        "    \n",
        "    for entry in state['memory'][-3:]:  # Last 3 turns\n",
        "        turn = entry.get('turn', 0)\n",
        "        query = entry.get('query', '')\n",
        "        agents = ', '.join(entry.get('routed_agents', []))\n",
        "        clauses = entry.get('clauses_retrieved', 0)\n",
        "        \n",
        "        context_parts.append(f\"Turn {turn}: '{query}' â†’ Agents: {agents}, Clauses: {clauses}\")\n",
        "    \n",
        "    return \"\\n\".join(context_parts)\n",
        "\n",
        "print(\"get_conversation_context() defined\")\n",
        "\n",
        "print(\"DEFINING STATE PERSISTENCE FUNCTIONS\")\n",
        "\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "CHECKPOINT_DIR = \"../Data/Results/Checkpoints\"\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "def save_state_checkpoint(state: GraphStateWithMemory) -> str:\n",
        "  \n",
        "    session_id = state.get('session_id', 'unknown')\n",
        "    turn = state.get('turn_number', 0)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    checkpoint_file = f\"checkpoint_{session_id}_turn{turn}_{timestamp}.json\"\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, checkpoint_file)\n",
        "    \n",
        "    checkpoint_data = {\n",
        "        \"session_id\": session_id,\n",
        "        \"turn_number\": turn,\n",
        "        \"timestamp\": state.get('timestamp', ''),\n",
        "        \"query\": state.get('query', ''),\n",
        "        \"memory\": state.get('memory', []),\n",
        "        \"conversation_history\": state.get('conversation_history', []),\n",
        "        \"routed_agents\": state.get('routed_agents', []),\n",
        "        \"routing_reasoning\": state.get('routing_reasoning', ''),\n",
        "        \"execution_order\": state.get('execution_order', []),\n",
        "        \"total_clauses_retrieved\": state.get('total_clauses_retrieved', 0),\n",
        "        \"coordinator_model\": state.get('coordinator_model', 'gemma2:9b'),\n",
        "        \"vector_store\": state.get('vector_store', 'Pinecone')\n",
        "    }\n",
        "    \n",
        "    with open(checkpoint_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"  State saved: {checkpoint_file}\")\n",
        "    return checkpoint_path\n",
        "\n",
        "print(\"save_state_checkpoint() defined\")\n",
        "\n",
        "def load_state_checkpoint(checkpoint_path: str) -> Dict[str, Any]:\n",
        " \n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
        "    \n",
        "    with open(checkpoint_path, 'r', encoding='utf-8') as f:\n",
        "        checkpoint_data = json.load(f)\n",
        "    \n",
        "    print(f\"  State loaded from checkpoint\")\n",
        "    print(f\"    Session: {checkpoint_data.get('session_id', 'unknown')}\")\n",
        "    print(f\"    Turn: {checkpoint_data.get('turn_number', 0)}\")\n",
        "    print(f\"    Memory entries: {len(checkpoint_data.get('memory', []))}\")\n",
        "    \n",
        "    return checkpoint_data\n",
        "\n",
        "print(\"load_state_checkpoint() defined\")\n",
        "\n",
        "def get_latest_checkpoint(session_id: str) -> str:\n",
        "\n",
        "    checkpoints = [f for f in os.listdir(CHECKPOINT_DIR) \n",
        "                  if f.startswith(f\"checkpoint_{session_id}_\")]\n",
        "    \n",
        "    if not checkpoints:\n",
        "        raise FileNotFoundError(f\"No checkpoints found for session: {session_id}\")\n",
        "    \n",
        "    latest = max(checkpoints, key=lambda f: os.path.getctime(os.path.join(CHECKPOINT_DIR, f)))\n",
        "    \n",
        "    return os.path.join(CHECKPOINT_DIR, latest)\n",
        "\n",
        "print(\"get_latest_checkpoint() defined\")\n",
        "\n",
        "\n",
        "print(\"CONVERSATION STATE INITIALIZATION\")\n",
        "\n",
        "def initialize_conversation_state(session_id: str = None) -> GraphStateWithMemory:\n",
        " \n",
        "    if session_id is None:\n",
        "        session_id = f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        \n",
        "        state = {\n",
        "            \"query\": \"\",\n",
        "            \"memory\": [],\n",
        "            \"conversation_history\": [],\n",
        "            \"session_id\": session_id,\n",
        "            \"turn_number\": 0,\n",
        "            \"routed_agents\": [],\n",
        "            \"routing_reasoning\": \"\",\n",
        "            \"routing_approach\": \"\",\n",
        "            \"legal\": {},\n",
        "            \"compliance\": {},\n",
        "            \"finance\": {},\n",
        "            \"operations\": {},\n",
        "            \"all_clauses\": [],\n",
        "            \"total_clauses_retrieved\": 0,\n",
        "            \"execution_order\": [],\n",
        "            \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "            \"coordinator_model\": \"gemma2:9b\",\n",
        "            \"vector_store\": \"Pinecone\",\n",
        "            \"execution_status\": \"initialized\",\n",
        "            \"previous_state\": {},\n",
        "            \"checkpoint_path\": \"\"\n",
        "        }\n",
        "        \n",
        "        print(f\"New conversation initialized: {session_id}\")\n",
        "        \n",
        "    else:\n",
        "        try:\n",
        "            checkpoint_path = get_latest_checkpoint(session_id)\n",
        "            checkpoint_data = load_state_checkpoint(checkpoint_path)\n",
        "            \n",
        "            state = {\n",
        "                \"query\": \"\",\n",
        "                \"memory\": checkpoint_data.get('memory', []),\n",
        "                \"conversation_history\": checkpoint_data.get('conversation_history', []),\n",
        "                \"session_id\": session_id,\n",
        "                \"turn_number\": checkpoint_data.get('turn_number', 0),\n",
        "                \"routed_agents\": [],\n",
        "                \"routing_reasoning\": \"\",\n",
        "                \"routing_approach\": \"\",\n",
        "                \"legal\": {},\n",
        "                \"compliance\": {},\n",
        "                \"finance\": {},\n",
        "                \"operations\": {},\n",
        "                \"all_clauses\": [],\n",
        "                \"total_clauses_retrieved\": 0,\n",
        "                \"execution_order\": [],\n",
        "                \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "                \"coordinator_model\": checkpoint_data.get('coordinator_model', 'gemma2:9b'),\n",
        "                \"vector_store\": checkpoint_data.get('vector_store', 'Pinecone'),\n",
        "                \"execution_status\": \"resumed\",\n",
        "                \"previous_state\": checkpoint_data,\n",
        "                \"checkpoint_path\": checkpoint_path\n",
        "            }\n",
        "            \n",
        "            print(f\"Conversation resumed: {session_id}\")\n",
        "            print(f\"  Previous turns: {state['turn_number']}\")\n",
        "            \n",
        "        except FileNotFoundError as e:\n",
        "            print(f\"{e}\")\n",
        "            print(\"  Starting new conversation instead\")\n",
        "            return initialize_conversation_state(session_id=None)\n",
        "    \n",
        "    return state\n",
        "\n",
        "print(\"initialize_conversation_state() defined\")\n",
        "\n",
        "print(\"CONVERSATION MEMORY & STATE PERSISTENCE READY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Initializing Input State with Empty Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INITIALIZING CONVERSATION STATE WITH MEMORY\n",
            "\n",
            "Initializing state with conversation memory and persistence...\n",
            "State initialized with memory capabilities\n",
            "STATE DETAILS\n",
            "  Session ID: session_20260115_172002\n",
            "  Turn Number: 0\n",
            "  Query: \"Analyze contract for termination clauses and payment terms\"\n",
            "  Initial Memory: []\n",
            "  Conversation History: []\n",
            "  Coordinator Model: gemma2:9b\n",
            "  Vector Store: Pinecone\n",
            "ADAPTIVE THRESHOLDS CONFIGURED\n",
            "  Legal: 0.1 (precision)\n",
            "  Compliance: 0.1 (recall) â† Lower\n",
            "  Finance: 0.1 (precision)\n",
            "  Operations: 0.1 (recall) â† Lower\n",
            "STATE READY FOR EXECUTION WITH MEMORY\n"
          ]
        }
      ],
      "source": [
        "print(\"INITIALIZING CONVERSATION STATE WITH MEMORY\")\n",
        "\n",
        "print(\"\\nInitializing state with conversation memory and persistence...\")\n",
        "\n",
        "session_id = f\"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "\n",
        "input_state_memory = {\n",
        "    \"query\": \"Analyze contract for termination clauses and payment terms\",\n",
        "    \n",
        "    \"memory\": [], \n",
        "    \"conversation_history\": [],  \n",
        "    \"session_id\": session_id,\n",
        "    \"turn_number\": 0,  \n",
        "    \n",
        "    \"routed_agents\": [],\n",
        "    \"routing_reasoning\": \"\",\n",
        "    \"routing_approach\": \"\",\n",
        "    \n",
        "    \"legal\": {},\n",
        "    \"compliance\": {},  \n",
        "    \"finance\": {},\n",
        "    \"operations\": {},  \n",
        "    \n",
        "    \"all_clauses\": [],\n",
        "    \"total_clauses_retrieved\": 0,\n",
        "    \n",
        "    \"execution_order\": [],\n",
        "    \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "    \n",
        "    \"coordinator_model\": \"gemma2:9b\",\n",
        "    \"vector_store\": \"Pinecone\",\n",
        "    \"execution_status\": \"initialized\",\n",
        "    \n",
        "    \"previous_state\": {},\n",
        "    \"checkpoint_path\": \"\"\n",
        "}\n",
        "\n",
        "print(\"State initialized with memory capabilities\")\n",
        "\n",
        "print(\"STATE DETAILS\")\n",
        "print(f\"  Session ID: {input_state_memory['session_id']}\")\n",
        "print(f\"  Turn Number: {input_state_memory['turn_number']}\")\n",
        "print(f\"  Query: \\\"{input_state_memory['query']}\\\"\")\n",
        "print(f\"  Initial Memory: {input_state_memory['memory']}\")\n",
        "print(f\"  Conversation History: {input_state_memory['conversation_history']}\")\n",
        "print(f\"  Coordinator Model: {input_state_memory['coordinator_model']}\")\n",
        "print(f\"  Vector Store: {input_state_memory['vector_store']}\")\n",
        "\n",
        "print(\"ADAPTIVE THRESHOLDS CONFIGURED\")\n",
        "print(f\"  Legal: {AGENT_THRESHOLDS['legal']} (precision)\")\n",
        "print(f\"  Compliance: {AGENT_THRESHOLDS['compliance']} (recall) â† Lower\")\n",
        "print(f\"  Finance: {AGENT_THRESHOLDS['finance']} (precision)\")\n",
        "print(f\"  Operations: {AGENT_THRESHOLDS['operations']} (recall) â† Lower\")\n",
        "\n",
        "print(\"STATE READY FOR EXECUTION WITH MEMORY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Creating Agent Nodes with Memory Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### i. Legal Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CREATING AGENT NODES WITH MEMORY LOGGING\n"
          ]
        }
      ],
      "source": [
        "print(\"CREATING AGENT NODES WITH MEMORY LOGGING\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "legal_node_with_memory() defined\n"
          ]
        }
      ],
      "source": [
        "def legal_node_with_memory(state: GraphStateWithMemory) -> GraphStateWithMemory:\n",
        "\n",
        "    print(f\"  LEGAL AGENT EXECUTING (Threshold: {AGENT_THRESHOLDS['legal']})\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    print(f\"     Turn: {state.get('turn_number', 0)}\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='legal', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['legal']\n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"legal\"] = {\n",
        "                \"agent\": \"Legal\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'legal'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"legal\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"sample_clauses\": [c['clause'][:100] for c in clauses[:2]],\n",
        "                \"summary\": f\"Legal: Retrieved {len(clauses)} clauses (avg relevance: {sum(scores) / len(scores):.3f})\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses\")\n",
        "            print(f\"     Avg relevance: {sum(scores) / len(scores):.3f}\")\n",
        "            print(f\"     Written to memory\")\n",
        "            \n",
        "        else:\n",
        "            state[\"legal\"] = {\n",
        "                \"agent\": \"Legal\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['legal'],\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": []\n",
        "            }\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"legal\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"summary\": \"Legal: No clauses found above threshold\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     âš  No clauses above threshold\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"legal\"] = {\"agent\": \"Legal\", \"status\": \"error\", \"error\": str(e)}\n",
        "        state[\"memory\"].append({\n",
        "            \"agent\": \"legal\",\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"turn\": state.get('turn_number', 0),\n",
        "            \"error\": str(e)[:100]\n",
        "        })\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"legal\")\n",
        "    \n",
        "    print(f\"\\n  MEMORY STATE AFTER LEGAL AGENT:\")\n",
        "    print(f\"     Total entries: {len(state['memory'])}\")\n",
        "    for idx, mem in enumerate(state['memory'][-3:], max(1, len(state['memory'])-2)):\n",
        "        print(f\"     [{idx}] {mem.get('agent', 'unknown').upper()}: {mem.get('summary', 'N/A')}\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "print(\"legal_node_with_memory() defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ii. Compliance Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "compliance_node_with_memory() defined\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def compliance_node_with_memory(state: GraphStateWithMemory) -> GraphStateWithMemory:\n",
        "\n",
        "    print(f\"  COMPLIANCE AGENT EXECUTING (Threshold: {AGENT_THRESHOLDS['compliance']})\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    print(f\"     Turn: {state.get('turn_number', 0)}\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='compliance', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['compliance'] \n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"compliance\"] = {\n",
        "                \"agent\": \"Compliance\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'compliance'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"compliance\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"threshold_used\": threshold,\n",
        "                \"sample_clauses\": [c['clause'][:100] for c in clauses[:2]],\n",
        "                \"summary\": f\"Compliance: Retrieved {len(clauses)} clauses (threshold: {threshold}, avg: {sum(scores) / len(scores):.3f})\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses\")\n",
        "            print(f\"     Threshold: {threshold} (lower for recall)\")\n",
        "            print(f\"     Avg relevance: {sum(scores) / len(scores):.3f}\")\n",
        "            \n",
        "        else:\n",
        "            state[\"compliance\"] = {\n",
        "                \"agent\": \"Compliance\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['compliance'],\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": []\n",
        "            }\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"compliance\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"threshold_used\": AGENT_THRESHOLDS['compliance'],\n",
        "                \"summary\": f\"Compliance: No clauses above threshold {AGENT_THRESHOLDS['compliance']}\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     No clauses above threshold {AGENT_THRESHOLDS['compliance']}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"compliance\"] = {\"agent\": \"Compliance\", \"status\": \"error\", \"error\": str(e)}\n",
        "        state[\"memory\"].append({\n",
        "            \"agent\": \"compliance\",\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"turn\": state.get('turn_number', 0),\n",
        "            \"error\": str(e)[:100]\n",
        "        })\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"compliance\")\n",
        "    \n",
        "    print(f\"\\n  MEMORY STATE AFTER COMPLIANCE AGENT:\")\n",
        "    print(f\"     Total entries: {len(state['memory'])}\")\n",
        "    for idx, mem in enumerate(state['memory'][-3:], max(1, len(state['memory'])-2)):\n",
        "        print(f\"     [{idx}] {mem.get('agent', 'unknown').upper()}: {mem.get('summary', 'N/A')}\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "print(\"compliance_node_with_memory() defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### iii. Finance Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "finance_node_with_memory() defined\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def finance_node_with_memory(state: GraphStateWithMemory) -> GraphStateWithMemory:\n",
        "    print(f\"  FINANCE AGENT EXECUTING (Threshold: {AGENT_THRESHOLDS['finance']})\")\n",
        "\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    print(f\"     Turn: {state.get('turn_number', 0)}\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='finance', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['finance']\n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"finance\"] = {\n",
        "                \"agent\": \"Finance\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'finance'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"finance\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"sample_clauses\": [c['clause'][:100] for c in clauses[:2]],\n",
        "                \"summary\": f\"Finance: Retrieved {len(clauses)} clauses (avg: {sum(scores) / len(scores):.3f})\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses\")\n",
        "            print(f\"     Avg relevance: {sum(scores) / len(scores):.3f}\")\n",
        "            \n",
        "        else:\n",
        "            state[\"finance\"] = {\n",
        "                \"agent\": \"Finance\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['finance'],\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": []\n",
        "            }\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"finance\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"summary\": \"Finance: No clauses above threshold\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     No clauses above threshold\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"finance\"] = {\"agent\": \"Finance\", \"status\": \"error\", \"error\": str(e)}\n",
        "        state[\"memory\"].append({\n",
        "            \"agent\": \"finance\",\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"turn\": state.get('turn_number', 0),\n",
        "            \"error\": str(e)[:100]\n",
        "        })\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"finance\")\n",
        "    \n",
        "    print(f\"\\n  MEMORY STATE AFTER FINANCE AGENT:\")\n",
        "    print(f\"     Total entries: {len(state['memory'])}\")\n",
        "    for idx, mem in enumerate(state['memory'][-3:], max(1, len(state['memory'])-2)):\n",
        "        print(f\"     [{idx}] {mem.get('agent', 'unknown').upper()}: {mem.get('summary', 'N/A')}\")\n",
        "    \n",
        "    return state\n",
        "print(\"finance_node_with_memory() defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### iv. Operations Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "operations_node_with_memory() defined\n"
          ]
        }
      ],
      "source": [
        "def operations_node_with_memory(state: GraphStateWithMemory) -> GraphStateWithMemory:\n",
        "    print(f\"  OPERATIONS AGENT EXECUTING (Threshold: {AGENT_THRESHOLDS['operations']})\")\n",
        "    print(f\"     Query: {state['query'][:60]}...\")\n",
        "    print(f\"     Turn: {state.get('turn_number', 0)}\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='operations', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['operations']  \n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"operations\"] = {\n",
        "                \"agent\": \"Operations\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"relevance_scores\": scores,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"max_relevance\": max(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            for clause in clauses:\n",
        "                clause['agent'] = 'operations'\n",
        "                state[\"all_clauses\"].append(clause)\n",
        "            \n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"operations\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"threshold_used\": threshold,\n",
        "                \"sample_clauses\": [c['clause'][:100] for c in clauses[:2]],\n",
        "                \"summary\": f\"Operations: Retrieved {len(clauses)} clauses (threshold: {threshold}, avg: {sum(scores) / len(scores):.3f})\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses\")\n",
        "            print(f\"     Threshold: {threshold} (lower for recall)\")\n",
        "            print(f\"     Avg relevance: {sum(scores) / len(scores):.3f}\")\n",
        "            \n",
        "        else:\n",
        "            state[\"operations\"] = {\n",
        "                \"agent\": \"Operations\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['operations'],\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": []\n",
        "            }\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"operations\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"threshold_used\": AGENT_THRESHOLDS['operations'],\n",
        "                \"summary\": f\"Operations: No clauses above threshold {AGENT_THRESHOLDS['operations']}\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     No clauses above threshold {AGENT_THRESHOLDS['operations']}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"operations\"] = {\"agent\": \"Operations\", \"status\": \"error\", \"error\": str(e)}\n",
        "        state[\"memory\"].append({\n",
        "            \"agent\": \"operations\",\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"turn\": state.get('turn_number', 0),\n",
        "            \"error\": str(e)[:100]\n",
        "        })\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"operations\")\n",
        "    \n",
        "    print(f\"\\n  MEMORY STATE AFTER OPERATIONS AGENT:\")\n",
        "    print(f\"     Total entries: {len(state['memory'])}\")\n",
        "    for idx, mem in enumerate(state['memory'][-3:], max(1, len(state['memory'])-2)):\n",
        "        print(f\"     [{idx}] {mem.get('agent', 'unknown').upper()}: {mem.get('summary', 'N/A')}\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "print(\"operations_node_with_memory() defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ALL AGENT NODES WITH MEMORY LOGGING DEFINED\n"
          ]
        }
      ],
      "source": [
        "print(\"ALL AGENT NODES WITH MEMORY LOGGING DEFINED\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Building Graph with Memory Support"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BUILDING WORKFLOW WITH MEMORY SUPPORT\n",
            "\n",
            "Building dynamic workflow with conversation memory and state persistence...\n",
            "StateGraph initialized with GraphStateWithMemory\n",
            "ADDING AGENT NODES WITH MEMORY\n",
            "Added: routing (with memory awareness)\n",
            "Added: legal_agent (threshold: 0.30)\n",
            "Added: compliance_agent (threshold: 0.10)\n",
            "Added: finance_agent (threshold: 0.30)\n",
            "Added: operations_agent (threshold: 0.10)\n",
            "Added: aggregation (with checkpoint saving)\n",
            "DEFINING CONDITIONAL EDGES\n",
            "Entry point: routing\n",
            "routing â†’ [conditional first agent]\n",
            "legal_agent â†’ [conditional next]\n",
            "compliance_agent â†’ [conditional next]\n",
            "finance_agent â†’ [conditional next]\n",
            "operations_agent â†’ aggregation\n",
            "aggregation â†’ END\n"
          ]
        }
      ],
      "source": [
        "print(\"BUILDING WORKFLOW WITH MEMORY SUPPORT\")\n",
        "\n",
        "print(\"\\nBuilding dynamic workflow with conversation memory and state persistence...\")\n",
        "\n",
        "workflow_memory = StateGraph(GraphStateWithMemory)\n",
        "print(\"StateGraph initialized with GraphStateWithMemory\")\n",
        "\n",
        "print(\"ADDING AGENT NODES WITH MEMORY\")\n",
        "\n",
        "def routing_node_with_memory(state: GraphStateWithMemory) -> GraphStateWithMemory:\n",
        "\n",
        "    print(\"ROUTING NODE: Dynamic LLM Coordinator with Memory\")\n",
        "    print(f\"Query: \\\"{state['query']}\\\"\")\n",
        "    print(f\"Turn: {state.get('turn_number', 0)}\")\n",
        "    print(f\"Session: {state.get('session_id', 'unknown')}\")\n",
        "    \n",
        "    context = get_conversation_context(state)\n",
        "    print(f\"\\n{context}\")\n",
        "    \n",
        "    routing_result = dynamic_route_query(state['query'])\n",
        "    \n",
        "    state['routed_agents'] = routing_result['agents']\n",
        "    state['routing_reasoning'] = routing_result['reasoning']\n",
        "    state['routing_approach'] = routing_result['approach']\n",
        "    \n",
        "    print(f\"\\nRouting Decision:\")\n",
        "    print(f\"  Agents: {', '.join(state['routed_agents'])}\")\n",
        "    print(f\"  Reasoning: {state['routing_reasoning']}\")\n",
        "    \n",
        "    state[\"memory\"].append({\n",
        "        \"agent\": \"routing\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"turn\": state.get('turn_number', 0),\n",
        "        \"routed_agents\": routing_result['agents'],\n",
        "        \"reasoning\": routing_result['reasoning'],\n",
        "        \"summary\": f\"Routing: Selected {', '.join(routing_result['agents'])}\"\n",
        "    })\n",
        "    \n",
        "    state['execution_order'].append(\"routing\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "workflow_memory.add_node(\"routing\", routing_node_with_memory)\n",
        "print(\"Added: routing (with memory awareness)\")\n",
        "\n",
        "workflow_memory.add_node(\"legal_agent\", legal_node_with_memory)\n",
        "print(\"Added: legal_agent (threshold: 0.30)\")\n",
        "\n",
        "workflow_memory.add_node(\"compliance_agent\", compliance_node_with_memory)\n",
        "print(\"Added: compliance_agent (threshold: 0.10)\")\n",
        "\n",
        "workflow_memory.add_node(\"finance_agent\", finance_node_with_memory)\n",
        "print(\"Added: finance_agent (threshold: 0.30)\")\n",
        "\n",
        "workflow_memory.add_node(\"operations_agent\", operations_node_with_memory)\n",
        "print(\"Added: operations_agent (threshold: 0.10)\")\n",
        "\n",
        "def aggregation_node_with_memory(state: GraphStateWithMemory) -> GraphStateWithMemory:\n",
        "\n",
        "    print(\"AGGREGATION NODE: Consolidating Results with Memory\")\n",
        "\n",
        "    if state['all_clauses']:\n",
        "        state['all_clauses'].sort(key=lambda x: x.get('relevance_score', 0), reverse=True)\n",
        "        \n",
        "        print(f\"\\nTotal clauses retrieved: {state['total_clauses_retrieved']}\")\n",
        "        print(f\"Top relevance score: {state['all_clauses'][0]['relevance_score']:.3f}\")\n",
        "        \n",
        "        state['execution_status'] = 'success'\n",
        "        \n",
        "        state[\"memory\"].append({\n",
        "            \"agent\": \"aggregation\",\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"turn\": state.get('turn_number', 0),\n",
        "            \"total_clauses\": state['total_clauses_retrieved'],\n",
        "            \"top_score\": state['all_clauses'][0]['relevance_score'],\n",
        "            \"summary\": f\"Aggregation: Consolidated {state['total_clauses_retrieved']} clauses\"\n",
        "        })\n",
        "    else:\n",
        "        print(f\"\\nNo clauses retrieved\")\n",
        "        state['execution_status'] = 'no_results'\n",
        "        \n",
        "        state[\"memory\"].append({\n",
        "            \"agent\": \"aggregation\",\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"turn\": state.get('turn_number', 0),\n",
        "            \"total_clauses\": 0,\n",
        "            \"summary\": \"Aggregation: No clauses to consolidate\"\n",
        "        })\n",
        "    \n",
        "    state['execution_order'].append(\"aggregation\")\n",
        "    \n",
        "    checkpoint_path = save_state_checkpoint(state)\n",
        "    state['checkpoint_path'] = checkpoint_path\n",
        "    \n",
        "    print(f\"\\nMemory entries: {len(state['memory'])}\")\n",
        "    print(f\"Checkpoint saved: {os.path.basename(checkpoint_path)}\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "workflow_memory.add_node(\"aggregation\", aggregation_node_with_memory)\n",
        "print(\"Added: aggregation (with checkpoint saving)\")\n",
        "\n",
        "print(\"DEFINING CONDITIONAL EDGES\")\n",
        "\n",
        "workflow_memory.set_entry_point(\"routing\")\n",
        "print(\"Entry point: routing\")\n",
        "\n",
        "def get_next_agent_memory(state: GraphStateWithMemory) -> str:\n",
        "    routed_agents = state.get('routed_agents', [])\n",
        "    executed_agents = [a for a in state.get('execution_order', []) \n",
        "                      if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    agent_priority = ['legal', 'compliance', 'finance', 'operations']\n",
        "    \n",
        "    for agent in agent_priority:\n",
        "        if agent in routed_agents and agent not in executed_agents:\n",
        "            return f\"{agent}_agent\"\n",
        "    \n",
        "    return \"aggregation\"\n",
        "\n",
        "workflow_memory.add_conditional_edges(\n",
        "    \"routing\",\n",
        "    lambda state: get_next_agent_memory(state),\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"routing â†’ [conditional first agent]\")\n",
        "\n",
        "workflow_memory.add_conditional_edges(\n",
        "    \"legal_agent\",\n",
        "    lambda state: get_next_agent_memory(state),\n",
        "    {\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"legal_agent â†’ [conditional next]\")\n",
        "\n",
        "workflow_memory.add_conditional_edges(\n",
        "    \"compliance_agent\",\n",
        "    lambda state: get_next_agent_memory(state),\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"compliance_agent â†’ [conditional next]\")\n",
        "\n",
        "workflow_memory.add_conditional_edges(\n",
        "    \"finance_agent\",\n",
        "    lambda state: get_next_agent_memory(state),\n",
        "    {\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"finance_agent â†’ [conditional next]\")\n",
        "\n",
        "workflow_memory.add_edge(\"operations_agent\", \"aggregation\")\n",
        "print(\"operations_agent â†’ aggregation\")\n",
        "\n",
        "workflow_memory.add_edge(\"aggregation\", END)\n",
        "print(\"aggregation â†’ END\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Compiling Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COMPILING WORKFLOW WITH MEMORY\n",
            "Workflow compiled successfully!\n",
            "WORKFLOW WITH MEMORY READY\n"
          ]
        }
      ],
      "source": [
        "print(\"COMPILING WORKFLOW WITH MEMORY\")\n",
        "\n",
        "try:\n",
        "    app_memory = workflow_memory.compile()\n",
        "    print(\"Workflow compiled successfully!\")\n",
        " \n",
        "except Exception as e:\n",
        "    print(f\"Compilation failed: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"WORKFLOW WITH MEMORY READY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Executing Graph and Verification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EXECUTING WORKFLOW WITH MEMORY PERSISTENCE\n",
            "\n",
            "Preparing to execute workflow with conversation memory...\n",
            "INPUT STATE VERIFICATION\n",
            "  Session ID: session_20260115_172002\n",
            "  Turn Number: 0\n",
            "  Query: \"Analyze contract for termination clauses and payment terms\"\n",
            "  Memory Entries: 4\n",
            "  Coordinator: gemma2:9b\n",
            "  Vector Store: Pinecone\n",
            "EXECUTING WORKFLOW - TURN 0\n",
            "ROUTING NODE: Dynamic LLM Coordinator with Memory\n",
            "Query: \"Analyze contract for termination clauses and payment terms\"\n",
            "Turn: 0\n",
            "Session: session_20260115_172002\n",
            "\n",
            "Previous conversation context:\n",
            "Turn 0: '' â†’ Agents: , Clauses: 2\n",
            "Turn 0: '' â†’ Agents: , Clauses: 3\n",
            "Turn 0: '' â†’ Agents: , Clauses: 0\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Routing Decision:\n",
            "  Agents: legal, finance\n",
            "  Reasoning: The query requests analysis of 'termination clauses' which falls under legal domain and 'payment terms' which falls under finance domain.\n",
            "AGGREGATION NODE: Consolidating Results with Memory\n",
            "\n",
            "Total clauses retrieved: 0\n",
            "Top relevance score: 0.489\n",
            "  State saved: checkpoint_session_20260115_172002_turn0_20260115_174452.json\n",
            "\n",
            "Memory entries: 6\n",
            "Checkpoint saved: checkpoint_session_20260115_172002_turn0_20260115_174452.json\n",
            "EXECUTION COMPLETED SUCCESSFULLY\n",
            "ROUTING DECISION\n",
            "  Query: \"Analyze contract for termination clauses and payment terms\"\n",
            "  LLM Routed To: legal, finance\n",
            "  Reasoning: The query requests analysis of 'termination clauses' which falls under legal domain and 'payment terms' which falls under finance domain.\n",
            "  Approach: dynamic_llm_coordinator\n",
            "EXECUTION SUMMARY\n",
            "  Session ID: session_20260115_172002\n",
            "  Turn Number: 0\n",
            "  Execution Order: routing â†’ legal â†’ finance â†’ aggregation â†’ routing â†’ aggregation\n",
            "  Total Clauses: 0\n",
            "  Execution Status: success\n",
            "AGENT RESULTS\n",
            "Agent           Status          Clauses    Threshold    Avg Score   \n",
            "LEGAL           NOT EXECUTED    -          -            -           \n",
            "COMPLIANCE      NOT EXECUTED    -          -            -           \n",
            "FINANCE         NOT EXECUTED    -          -            -           \n",
            "OPERATIONS      NOT EXECUTED    -          -            -           \n",
            "RETRIEVED CLAUSES (Top 5)\n",
            "\n",
            "[1] Agent: LEGAL | Score: 0.489\n",
            "    The other party shall give notice of termination in writing to the other party, which notice shall specify in reasonable detail the event(s) of defaul...\n",
            "\n",
            "[2] Agent: LEGAL | Score: 0.347\n",
            "    The other party asserts any rights in or to the terminating party's intellectual property in violation of this Agreement....\n",
            "\n",
            "[3] Agent: FINANCE | Score: 0.304\n",
            "    In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, including, without limitation, lic...\n",
            "\n",
            "[4] Agent: FINANCE | Score: 0.281\n",
            "    ), Recipient shall reimburse Provider for all such Out-of-Pocket Costs....\n",
            "\n",
            "[5] Agent: FINANCE | Score: 0.201\n",
            "    Provider shall provide Recipient with monthly invo...\n",
            "CONVERSATION MEMORY STATE\n",
            "  Total Memory Entries: 6\n",
            "  Turn Number: 0\n",
            "\n",
            "  Memory Log:\n",
            "    [1] Turn 0 - ROUTING: Routing: Selected legal, finance\n",
            "    [2] Turn 0 - LEGAL: Legal: Retrieved 2 clauses (avg relevance: 0.418)\n",
            "    [3] Turn 0 - FINANCE: Finance: Retrieved 3 clauses (avg: 0.262)\n",
            "    [4] Turn 0 - AGGREGATION: Aggregation: Consolidated 5 clauses\n",
            "    [5] Turn 0 - ROUTING: Routing: Selected legal, finance\n",
            "    [6] Turn 0 - AGGREGATION: Aggregation: Consolidated 0 clauses\n",
            "STATE PERSISTENCE\n",
            "  Checkpoint saved: checkpoint_session_20260115_172002_turn0_20260115_174452.json\n",
            "  Location: ../Data/Results/Checkpoints\n",
            "  Session: session_20260115_172002\n",
            "\n",
            "  To resume:\n",
            "    loaded = load_state_checkpoint('../Data/Results/Checkpoints\\checkpoint_session_20260115_172002_turn0_20260115_174452.json')\n",
            "EFFICIENCY ANALYSIS\n",
            "  Agents Routed: 2/4\n",
            "  Agents Executed: 0\n",
            "  Agents Skipped: 4\n",
            "  Efficiency Gain: 100%\n",
            "ADAPTIVE THRESHOLD IMPACT\n",
            "VERIFICATION\n",
            "\n",
            "  System Checks:\n",
            "    PASS: Memory Tracking\n",
            "    PASS: Dynamic Routing\n",
            "    FAIL: Adaptive Thresholds (0.10)\n",
            "    PASS: State Persistence\n",
            "    FAIL: Clause Retrieval\n",
            "\n",
            "  Some checks failed - Review configuration\n",
            "EXECUTION WITH MEMORY COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"EXECUTING WORKFLOW WITH MEMORY PERSISTENCE\")\n",
        "\n",
        "print(\"\\nPreparing to execute workflow with conversation memory...\")\n",
        "\n",
        "print(\"INPUT STATE VERIFICATION\")\n",
        "print(f\"  Session ID: {input_state_memory.get('session_id', 'N/A')}\")\n",
        "print(f\"  Turn Number: {input_state_memory.get('turn_number', 0)}\")\n",
        "print(f\"  Query: \\\"{input_state_memory['query']}\\\"\")\n",
        "print(f\"  Memory Entries: {len(input_state_memory.get('memory', []))}\")\n",
        "print(f\"  Coordinator: {input_state_memory.get('coordinator_model', 'N/A')}\")\n",
        "print(f\"  Vector Store: {input_state_memory.get('vector_store', 'N/A')}\")\n",
        "\n",
        "\n",
        "print(\"EXECUTING WORKFLOW - TURN 0\")\n",
        "\n",
        "try:\n",
        "    result_memory = app_memory.invoke(input_state_memory)\n",
        "    \n",
        "    print(\"EXECUTION COMPLETED SUCCESSFULLY\")\n",
        "\n",
        "    print(\"ROUTING DECISION\")\n",
        "    print(f\"  Query: \\\"{result_memory['query']}\\\"\")\n",
        "    print(f\"  LLM Routed To: {', '.join(result_memory.get('routed_agents', []))}\")\n",
        "    print(f\"  Reasoning: {result_memory.get('routing_reasoning', 'N/A')}\")\n",
        "    print(f\"  Approach: {result_memory.get('routing_approach', 'N/A')}\")\n",
        "\n",
        "    print(\"EXECUTION SUMMARY\")\n",
        "    print(f\"  Session ID: {result_memory.get('session_id', 'N/A')}\")\n",
        "    print(f\"  Turn Number: {result_memory.get('turn_number', 0)}\")\n",
        "    print(f\"  Execution Order: {' â†’ '.join(result_memory['execution_order'])}\")\n",
        "    print(f\"  Total Clauses: {result_memory.get('total_clauses_retrieved', 0)}\")\n",
        "    print(f\"  Execution Status: {result_memory.get('execution_status', 'unknown')}\")\n",
        "    \n",
        "\n",
        "    print(\"AGENT RESULTS\")\n",
        "    print(f\"{'Agent':<15} {'Status':<15} {'Clauses':<10} {'Threshold':<12} {'Avg Score':<12}\")\n",
        "\n",
        "    executed_agents = []\n",
        "    for agent_name in [\"legal\", \"compliance\", \"finance\", \"operations\"]:\n",
        "        agent_data = result_memory.get(agent_name, {})\n",
        "        \n",
        "        if agent_data and agent_data.get(\"status\") == \"completed\":\n",
        "            executed_agents.append(agent_name)\n",
        "            status = \"EXECUTED\"\n",
        "            clauses = agent_data.get('clauses_retrieved', 0)\n",
        "            threshold = agent_data.get('threshold', 'N/A')\n",
        "            avg_score = agent_data.get('avg_relevance', 0)\n",
        "            \n",
        "            threshold_str = f\"{threshold:.2f}\" if isinstance(threshold, float) else str(threshold)\n",
        "            score_str = f\"{avg_score:.3f}\" if avg_score > 0 else \"N/A\"\n",
        "            \n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {clauses:<10} {threshold_str:<12} {score_str:<12}\")\n",
        "            \n",
        "        elif agent_data and agent_data.get(\"status\") == \"no_results\":\n",
        "            executed_agents.append(agent_name)\n",
        "            status = \"EXECUTED (0)\"\n",
        "            threshold = agent_data.get('threshold', 'N/A')\n",
        "            threshold_str = f\"{threshold:.2f}\" if isinstance(threshold, float) else str(threshold)\n",
        "            \n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {0:<10} {threshold_str:<12} {'N/A':<12}\")\n",
        "            \n",
        "        else:\n",
        "            status = \"NOT EXECUTED\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<15} {'-':<10} {'-':<12} {'-':<12}\")\n",
        "    \n",
        "    if result_memory.get('all_clauses'):\n",
        "        print(f\"RETRIEVED CLAUSES (Top {min(5, len(result_memory['all_clauses']))})\")\n",
        "   \n",
        "        for idx, clause in enumerate(result_memory['all_clauses'][:5], 1):\n",
        "            agent = clause.get('agent', 'unknown')\n",
        "            score = clause.get('relevance_score', 0)\n",
        "            text = clause.get('clause', '')[:150]\n",
        "            \n",
        "            print(f\"\\n[{idx}] Agent: {agent.upper()} | Score: {score:.3f}\")\n",
        "            print(f\"    {text}...\")\n",
        "    \n",
        "\n",
        "    print(\"CONVERSATION MEMORY STATE\")\n",
        "    print(f\"  Total Memory Entries: {len(result_memory.get('memory', []))}\")\n",
        "    print(f\"  Turn Number: {result_memory.get('turn_number', 0)}\")\n",
        "    \n",
        "    if result_memory.get('memory'):\n",
        "        print(f\"\\n  Memory Log:\")\n",
        "        for idx, mem_entry in enumerate(result_memory['memory'], 1):\n",
        "            agent = mem_entry.get('agent', 'unknown')\n",
        "            summary = mem_entry.get('summary', 'N/A')\n",
        "            turn = mem_entry.get('turn', 0)\n",
        "            \n",
        "            print(f\"    [{idx}] Turn {turn} - {agent.upper()}: {summary}\")\n",
        "\n",
        "    print(\"STATE PERSISTENCE\")\n",
        "\n",
        "    checkpoint_path = result_memory.get('checkpoint_path', '')\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        checkpoint_file = os.path.basename(checkpoint_path)\n",
        "        print(f\"  Checkpoint saved: {checkpoint_file}\")\n",
        "        print(f\"  Location: {CHECKPOINT_DIR}\")\n",
        "        print(f\"  Session: {result_memory.get('session_id', 'N/A')}\")\n",
        "        print(f\"\\n  To resume:\")\n",
        "        print(f\"    loaded = load_state_checkpoint('{checkpoint_path}')\")\n",
        "    else:\n",
        "        print(f\"  No checkpoint saved\")\n",
        "\n",
        "    print(\"EFFICIENCY ANALYSIS\")\n",
        "\n",
        "    routed_count = len(result_memory.get('routed_agents', []))\n",
        "    total_agents = 4\n",
        "    \n",
        "    print(f\"  Agents Routed: {routed_count}/{total_agents}\")\n",
        "    print(f\"  Agents Executed: {len(executed_agents)}\")\n",
        "    print(f\"  Agents Skipped: {total_agents - len(executed_agents)}\")\n",
        "    print(f\"  Efficiency Gain: {(total_agents - len(executed_agents)) / total_agents * 100:.0f}%\")\n",
        "\n",
        "    print(\"ADAPTIVE THRESHOLD IMPACT\")\n",
        "\n",
        "    for agent_name in [\"compliance\", \"operations\"]:\n",
        "        if agent_name in executed_agents:\n",
        "            agent_data = result_memory.get(agent_name, {})\n",
        "            threshold = agent_data.get('threshold', 0)\n",
        "            clauses = agent_data.get('clauses_retrieved', 0)\n",
        "            \n",
        "            print(f\"\\n  {agent_name.upper()}:\")\n",
        "            print(f\"    Threshold: {threshold:.2f} (LOWER for recall)\")\n",
        "            print(f\"    Clauses Retrieved: {clauses}\")\n",
        "            \n",
        "            if clauses > 0:\n",
        "                avg_score = agent_data.get('avg_relevance', 0)\n",
        "                print(f\"    Avg Relevance: {avg_score:.3f}\")\n",
        "                print(f\"    Lower threshold enabled retrieval\")\n",
        "            else:\n",
        "                print(f\"    No clauses found even with lower threshold\")\n",
        "    \n",
        "\n",
        "    print(\"VERIFICATION\")\n",
        "\n",
        "    checks = []\n",
        "    \n",
        "    memory_works = len(result_memory.get('memory', [])) > 0\n",
        "    checks.append((\"Memory Tracking\", memory_works))\n",
        "    \n",
        "    routing_works = len(result_memory.get('routed_agents', [])) > 0\n",
        "    checks.append((\"Dynamic Routing\", routing_works))\n",
        "    \n",
        "    compliance_data = result_memory.get('compliance', {})\n",
        "    operations_data = result_memory.get('operations', {})\n",
        "    threshold_works = (\n",
        "        compliance_data.get('threshold', 1.0) == 0.10 or\n",
        "        operations_data.get('threshold', 1.0) == 0.10\n",
        "    )\n",
        "    checks.append((\"Adaptive Thresholds (0.10)\", threshold_works))\n",
        "    \n",
        "    persistence_works = result_memory.get('checkpoint_path', '') != ''\n",
        "    checks.append((\"State Persistence\", persistence_works))\n",
        "    \n",
        "    retrieval_works = result_memory.get('total_clauses_retrieved', 0) > 0\n",
        "    checks.append((\"Clause Retrieval\", retrieval_works))\n",
        "    \n",
        "    print(f\"\\n  System Checks:\")\n",
        "    for check_name, passed in checks:\n",
        "        status = \"PASS\" if passed else \"FAIL\"\n",
        "        print(f\"    {status}: {check_name}\")\n",
        "    \n",
        "    all_passed = all(passed for _, passed in checks)\n",
        "    \n",
        "    if all_passed:\n",
        "        print(f\"\\n  ALL CHECKS PASSED - System working correctly!\")\n",
        "    else:\n",
        "        print(f\"\\n  Some checks failed - Review configuration\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nEXECUTION FAILED\")\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    print(\"ERROR DETAILS\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"EXECUTION WITH MEMORY COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agent-to-Agent Communication & Validation Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, List\n",
        "from langgraph.graph import StateGraph, END\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Defining Enhanced GraphState with Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AGENT-TO-AGENT COMMUNICATION & VALIDATION LOGIC\n",
            "\n",
            "Defining enhanced GraphState with inter-agent communication and validation...\n",
            "GraphStateCollaborative defined\n",
            "DEFINING MESSAGE STRUCTURES\n",
            "create_agent_message() defined\n",
            "create_validation_request() defined\n",
            "create_validation_result() defined\n",
            "DEFINING VALIDATION HELPER FUNCTIONS\n",
            "detect_conflicts() defined (uses 0.1 for Compliance/Operations)\n",
            "cross_reference_clauses() defined\n"
          ]
        }
      ],
      "source": [
        "print(\"AGENT-TO-AGENT COMMUNICATION & VALIDATION LOGIC\")\n",
        "\n",
        "print(\"\\nDefining enhanced GraphState with inter-agent communication and validation...\")\n",
        "\n",
        "class GraphStateCollaborative(TypedDict):\n",
        "   \n",
        "    query: str\n",
        "    \n",
        "    memory: List[Dict[str, Any]]\n",
        "    conversation_history: List[Dict[str, Any]]\n",
        "    session_id: str\n",
        "    turn_number: int\n",
        "    \n",
        "    agent_messages: List[Dict[str, Any]]  \n",
        "    validation_requests: List[Dict[str, Any]]  \n",
        "    validation_results: List[Dict[str, Any]]  \n",
        "    cross_references: List[Dict[str, Any]]  \n",
        "    \n",
        "    validation_notes: List[str]  \n",
        "    conflicts_detected: List[Dict[str, Any]] \n",
        "    consensus_findings: List[Dict[str, Any]] \n",
        "    \n",
        "    routed_agents: List[str]\n",
        "    routing_reasoning: str\n",
        "    routing_approach: str\n",
        "    \n",
        "    legal: Dict[str, Any]\n",
        "    compliance: Dict[str, Any]  \n",
        "    finance: Dict[str, Any]\n",
        "    operations: Dict[str, Any]  \n",
        "    \n",
        "    all_clauses: List[Dict[str, Any]]\n",
        "    total_clauses_retrieved: int\n",
        "    \n",
        "    execution_order: List[str]\n",
        "    timestamp: str\n",
        "    \n",
        "    coordinator_model: str\n",
        "    vector_store: str\n",
        "    execution_status: str\n",
        "    \n",
        "    previous_state: Dict[str, Any]\n",
        "    checkpoint_path: str\n",
        "\n",
        "print(\"GraphStateCollaborative defined\")\n",
        "\n",
        "\n",
        "\n",
        "print(\"DEFINING MESSAGE STRUCTURES\")\n",
        "\n",
        "def create_agent_message(\n",
        "    sender: str,\n",
        "    recipient: str,\n",
        "    message_type: str,\n",
        "    content: Dict[str, Any],\n",
        "    turn: int\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    return {\n",
        "        \"message_id\": f\"{sender}_to_{recipient}_{datetime.now().strftime('%Y%m%d%H%M%S%f')}\",\n",
        "        \"sender\": sender,\n",
        "        \"recipient\": recipient,\n",
        "        \"message_type\": message_type,\n",
        "        \"content\": content,\n",
        "        \"turn\": turn,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "print(\"create_agent_message() defined\")\n",
        "\n",
        "def create_validation_request(\n",
        "    requesting_agent: str,\n",
        "    validating_agent: str,\n",
        "    clauses_to_validate: List[Dict[str, Any]],\n",
        "    validation_type: str,\n",
        "    turn: int\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    return {\n",
        "        \"request_id\": f\"val_{requesting_agent}_to_{validating_agent}_{datetime.now().strftime('%Y%m%d%H%M%S%f')}\",\n",
        "        \"requesting_agent\": requesting_agent,\n",
        "        \"validating_agent\": validating_agent,\n",
        "        \"clauses\": clauses_to_validate,\n",
        "        \"validation_type\": validation_type,\n",
        "        \"turn\": turn,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"status\": \"pending\"\n",
        "    }\n",
        "\n",
        "print(\"create_validation_request() defined\")\n",
        "\n",
        "def create_validation_result(\n",
        "    request_id: str,\n",
        "    validating_agent: str,\n",
        "    validation_outcome: str,\n",
        "    findings: List[Dict[str, Any]],\n",
        "    confidence: float,\n",
        "    turn: int\n",
        ") -> Dict[str, Any]:\n",
        "\n",
        "    return {\n",
        "        \"result_id\": f\"result_{request_id}\",\n",
        "        \"request_id\": request_id,\n",
        "        \"validating_agent\": validating_agent,\n",
        "        \"outcome\": validation_outcome,\n",
        "        \"findings\": findings,\n",
        "        \"confidence\": confidence,\n",
        "        \"turn\": turn,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "print(\"create_validation_result() defined\")\n",
        "\n",
        "print(\"DEFINING VALIDATION HELPER FUNCTIONS\")\n",
        "\n",
        "def detect_conflicts(\n",
        "    agent1_clauses: List[Dict[str, Any]],\n",
        "    agent2_clauses: List[Dict[str, Any]],\n",
        "    agent1_name: str,\n",
        "    agent2_name: str,\n",
        "    threshold: float = 0.1\n",
        ") -> List[Dict[str, Any]]:\n",
        "\n",
        "    conflicts = []\n",
        "    \n",
        "    for clause1 in agent1_clauses:\n",
        "        for clause2 in agent2_clauses:\n",
        "            risk1 = clause1.get('risk_level', 'unknown')\n",
        "            risk2 = clause2.get('risk_level', 'unknown')\n",
        "            \n",
        "            score1 = clause1.get('relevance_score', 0)\n",
        "            score2 = clause2.get('relevance_score', 0)\n",
        "            \n",
        "            effective_threshold = threshold\n",
        "            if agent1_name in ['compliance', 'operations'] or agent2_name in ['compliance', 'operations']:\n",
        "                effective_threshold = 0.1  \n",
        "            \n",
        "            if score1 > effective_threshold and score2 > effective_threshold:\n",
        "                if risk1 != risk2 and risk1 != 'unknown' and risk2 != 'unknown':\n",
        "                    conflicts.append({\n",
        "                        \"conflict_type\": \"risk_assessment_mismatch\",\n",
        "                        \"agent1\": agent1_name,\n",
        "                        \"agent2\": agent2_name,\n",
        "                        \"clause1\": clause1.get('clause', '')[:100],\n",
        "                        \"clause2\": clause2.get('clause', '')[:100],\n",
        "                        \"risk1\": risk1,\n",
        "                        \"risk2\": risk2,\n",
        "                        \"threshold_used\": effective_threshold\n",
        "                    })\n",
        "    \n",
        "    return conflicts\n",
        "\n",
        "print(\"detect_conflicts() defined (uses 0.1 for Compliance/Operations)\")\n",
        "\n",
        "def cross_reference_clauses(\n",
        "    source_agent: str,\n",
        "    source_clauses: List[Dict[str, Any]],\n",
        "    target_agent: str,\n",
        "    target_clauses: List[Dict[str, Any]],\n",
        "    threshold: float = 0.1\n",
        ") -> List[Dict[str, Any]]:\n",
        "\n",
        "    cross_refs = []\n",
        "    \n",
        "    effective_threshold = threshold\n",
        "    if source_agent in ['compliance', 'operations'] or target_agent in ['compliance', 'operations']:\n",
        "        effective_threshold = 0.1\n",
        "    \n",
        "    for src_clause in source_clauses:\n",
        "        if src_clause.get('relevance_score', 0) > effective_threshold:\n",
        "            for tgt_clause in target_clauses:\n",
        "                if tgt_clause.get('relevance_score', 0) > effective_threshold:\n",
        "                 \n",
        "                    src_text = src_clause.get('clause', '').lower()\n",
        "                    tgt_text = tgt_clause.get('clause', '').lower()\n",
        "                    \n",
        "                    overlap_score = len(set(src_text.split()) & set(tgt_text.split())) / max(len(src_text.split()), len(tgt_text.split()))\n",
        "                    \n",
        "                    if overlap_score > 0.3:  \n",
        "                        cross_refs.append({\n",
        "                            \"source_agent\": source_agent,\n",
        "                            \"target_agent\": target_agent,\n",
        "                            \"source_clause\": src_text[:100],\n",
        "                            \"target_clause\": tgt_text[:100],\n",
        "                            \"overlap_score\": overlap_score,\n",
        "                            \"threshold_used\": effective_threshold,\n",
        "                            \"reference_type\": \"semantic_overlap\"\n",
        "                        })\n",
        "    \n",
        "    return cross_refs\n",
        "\n",
        "print(\"cross_reference_clauses() defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Initializing Collaborative State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COLLABORATIVE STATE INITIALIZATION\n",
            "initialize_collaborative_state() defined\n"
          ]
        }
      ],
      "source": [
        "print(\"COLLABORATIVE STATE INITIALIZATION\")\n",
        "\n",
        "def initialize_collaborative_state(session_id: str = None) -> GraphStateCollaborative:\n",
        "\n",
        "    if session_id is None:\n",
        "        session_id = f\"collab_session_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    \n",
        "    state = {\n",
        "        \"query\": \"\",\n",
        "        \n",
        "        \"memory\": [],\n",
        "        \"conversation_history\": [],\n",
        "        \"session_id\": session_id,\n",
        "        \"turn_number\": 0,\n",
        "        \n",
        "        \"agent_messages\": [],\n",
        "        \"validation_requests\": [],\n",
        "        \"validation_results\": [],\n",
        "        \"cross_references\": [],\n",
        "        \n",
        "        \"validation_notes\": [],\n",
        "        \"conflicts_detected\": [],\n",
        "        \"consensus_findings\": [],\n",
        "        \n",
        "        \"routed_agents\": [],\n",
        "        \"routing_reasoning\": \"\",\n",
        "        \"routing_approach\": \"\",\n",
        "        \n",
        "        \"legal\": {},\n",
        "        \"compliance\": {}, \n",
        "        \"finance\": {},\n",
        "        \"operations\": {}, \n",
        "        \n",
        "        \"all_clauses\": [],\n",
        "        \"total_clauses_retrieved\": 0,\n",
        "        \n",
        "        \"execution_order\": [],\n",
        "        \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
        "        \n",
        "        \"coordinator_model\": \"gemma2:9b\",\n",
        "        \"vector_store\": \"Pinecone\",\n",
        "        \"execution_status\": \"initialized\",\n",
        "        \n",
        "        \"previous_state\": {},\n",
        "        \"checkpoint_path\": \"\"\n",
        "    }\n",
        "    \n",
        "    print(f\"Collaborative state initialized: {session_id}\")\n",
        "\n",
        "    \n",
        "    return state\n",
        "\n",
        "print(\"initialize_collaborative_state() defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Creating Compliance Agent with Memory Writing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CREATING COLLABORATIVE AGENTS WITH COMMUNICATION & VALIDATION\n",
            "\n",
            "Defining agents with inter-agent communication and validation\n"
          ]
        }
      ],
      "source": [
        "print(\"CREATING COLLABORATIVE AGENTS WITH COMMUNICATION & VALIDATION\")\n",
        "\n",
        "print(\"\\nDefining agents with inter-agent communication and validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "compliance_node_collaborative() defined\n"
          ]
        }
      ],
      "source": [
        "def compliance_node_collaborative(state: GraphStateCollaborative) -> GraphStateCollaborative:\n",
        "\n",
        "    print(f\"  COMPLIANCE AGENT EXECUTING (Threshold: {AGENT_THRESHOLDS['compliance']})\")\n",
        "    print(f\"  Writing findings to shared memory for validation\")\n",
        "\n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='compliance', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['compliance'] \n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score,\n",
        "                    'agent': 'compliance'\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            risk_level = \"high\" if any(c.get('risk_level') == 'high' for c in clauses) else \"medium\"\n",
        "            \n",
        "            state[\"compliance\"] = {\n",
        "                \"agent\": \"Compliance\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"risk_level\": risk_level,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0\n",
        "            }\n",
        "            \n",
        "            state[\"all_clauses\"].extend(clauses)\n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"compliance\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses\": clauses,\n",
        "                \"risk_level\": risk_level,\n",
        "                \"threshold_used\": threshold,\n",
        "                \"summary\": f\"Compliance: Found {len(clauses)} clauses (threshold: {threshold}, risk: {risk_level})\"\n",
        "            })\n",
        "            \n",
        "            validation_request = create_validation_request(\n",
        "                requesting_agent=\"compliance\",\n",
        "                validating_agent=\"legal\",\n",
        "                clauses_to_validate=clauses,\n",
        "                validation_type=\"legal_review_of_compliance\",\n",
        "                turn=state.get('turn_number', 0)\n",
        "            )\n",
        "            state[\"validation_requests\"].append(validation_request)\n",
        "            \n",
        "            state[\"validation_notes\"].append(\n",
        "                f\"Compliance â†’ Legal: Requesting legal review of {len(clauses)} compliance clauses\"\n",
        "            )\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses (threshold: {threshold})\")\n",
        "            print(f\"     Risk Level: {risk_level}\")\n",
        "            print(f\"     Sent validation request to Legal agent\")\n",
        "            \n",
        "        else:\n",
        "            state[\"compliance\"] = {\n",
        "                \"agent\": \"Compliance\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['compliance'],\n",
        "                \"clauses_retrieved\": 0,\n",
        "                \"clauses\": []\n",
        "            }\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"compliance\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"summary\": f\"Compliance: No clauses above threshold {AGENT_THRESHOLDS['compliance']}\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     No clauses above threshold {AGENT_THRESHOLDS['compliance']}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"compliance\"] = {\"agent\": \"Compliance\", \"status\": \"error\", \"error\": str(e)}\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"compliance\")\n",
        "    return state\n",
        "\n",
        "print(\"compliance_node_collaborative() defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Creating Finance Agent with Memory Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "finance_node_collaborative() defined\n"
          ]
        }
      ],
      "source": [
        "def finance_node_collaborative(state: GraphStateCollaborative) -> GraphStateCollaborative:\n",
        "\n",
        "    print(f\"  FINANCE AGENT EXECUTING (Threshold: {AGENT_THRESHOLDS['finance']})\")\n",
        "    print(f\"  Reading shared memory from previous agents\")\n",
        "\n",
        "    previous_findings = [m for m in state.get('memory', []) if m.get('agent') in ['compliance', 'legal']]\n",
        "    if previous_findings:\n",
        "        print(f\"     Reading {len(previous_findings)} entries from other agents:\")\n",
        "        for finding in previous_findings[-2:]: \n",
        "            agent = finding.get('agent', 'unknown')\n",
        "            summary = finding.get('summary', 'N/A')\n",
        "            print(f\"       â€¢ {agent.upper()}: {summary}\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='finance', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['finance']\n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score,\n",
        "                    'agent': 'finance'\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"finance\"] = {\n",
        "                \"agent\": \"Finance\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"context_from_agents\": [f.get('agent') for f in previous_findings]\n",
        "            }\n",
        "            \n",
        "            state[\"all_clauses\"].extend(clauses)\n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            compliance_clauses = state.get('compliance', {}).get('clauses', [])\n",
        "            if compliance_clauses:\n",
        "                cross_refs = cross_reference_clauses(\n",
        "                    source_agent=\"finance\",\n",
        "                    source_clauses=clauses,\n",
        "                    target_agent=\"compliance\",\n",
        "                    target_clauses=compliance_clauses,\n",
        "                    threshold=0.1  \n",
        "                )\n",
        "                \n",
        "                if cross_refs:\n",
        "                    state[\"cross_references\"].extend(cross_refs)\n",
        "                    state[\"validation_notes\"].append(\n",
        "                        f\"Finance: Found {len(cross_refs)} cross-references with Compliance clauses\"\n",
        "                    )\n",
        "                    print(f\"     Cross-referenced {len(cross_refs)} clauses with Compliance\")\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"finance\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses\": clauses,\n",
        "                \"cross_references\": len(state.get('cross_references', [])),\n",
        "                \"summary\": f\"Finance: Found {len(clauses)} clauses, cross-referenced with other agents\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses\")\n",
        "            print(f\"     Integrated context from previous agents\")\n",
        "            \n",
        "        else:\n",
        "            state[\"finance\"] = {\n",
        "                \"agent\": \"Finance\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['finance'],\n",
        "                \"clauses_retrieved\": 0\n",
        "            }\n",
        "            print(f\"     No clauses above threshold\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"finance\"] = {\"agent\": \"Finance\", \"status\": \"error\", \"error\": str(e)}\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"finance\")\n",
        "    return state\n",
        "\n",
        "print(\"finance_node_collaborative() defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Creating Legal Agent with Final Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "legal_node_collaborative() defined\n"
          ]
        }
      ],
      "source": [
        "def legal_node_collaborative(state: GraphStateCollaborative) -> GraphStateCollaborative:\n",
        "\n",
        "    print(f\"  LEGAL AGENT EXECUTING (Threshold: {AGENT_THRESHOLDS['legal']})\")\n",
        "    print(f\"  Performing validation for other agents\")\n",
        "\n",
        "    pending_validations = [v for v in state.get('validation_requests', []) \n",
        "                          if v.get('validating_agent') == 'legal' and v.get('status') == 'pending']\n",
        "    \n",
        "    if pending_validations:\n",
        "        print(f\"     Processing {len(pending_validations)} validation request(s)\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='legal', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['legal']\n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score,\n",
        "                    'agent': 'legal'\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"legal\"] = {\n",
        "                \"agent\": \"Legal\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"validations_performed\": len(pending_validations)\n",
        "            }\n",
        "            \n",
        "            state[\"all_clauses\"].extend(clauses)\n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            for val_request in pending_validations:\n",
        "                requesting_agent = val_request.get('requesting_agent')\n",
        "                clauses_to_validate = val_request.get('clauses', [])\n",
        "                \n",
        "                conflicts = detect_conflicts(\n",
        "                    agent1_clauses=clauses_to_validate,\n",
        "                    agent2_clauses=clauses,\n",
        "                    agent1_name=requesting_agent,\n",
        "                    agent2_name='legal',\n",
        "                    threshold=0.1 if requesting_agent in ['compliance', 'operations'] else 0.3\n",
        "                )\n",
        "                \n",
        "                outcome = \"approved\" if not conflicts else \"needs_review\"\n",
        "                \n",
        "                validation_result = create_validation_result(\n",
        "                    request_id=val_request.get('request_id'),\n",
        "                    validating_agent='legal',\n",
        "                    validation_outcome=outcome,\n",
        "                    findings=conflicts if conflicts else [{\"status\": \"no_conflicts_detected\"}],\n",
        "                    confidence=0.85,\n",
        "                    turn=state.get('turn_number', 0)\n",
        "                )\n",
        "                \n",
        "                state[\"validation_results\"].append(validation_result)\n",
        "                \n",
        "                if conflicts:\n",
        "                    state[\"conflicts_detected\"].extend(conflicts)\n",
        "                    state[\"validation_notes\"].append(\n",
        "                        f\"Legal validation: Found {len(conflicts)} conflict(s) with {requesting_agent} findings\"\n",
        "                    )\n",
        "                    print(f\"     Conflicts detected with {requesting_agent}: {len(conflicts)}\")\n",
        "                else:\n",
        "                    state[\"validation_notes\"].append(\n",
        "                        f\"Legal validation: Approved {len(clauses_to_validate)} {requesting_agent} clauses\"\n",
        "                    )\n",
        "                    print(f\"     Validated {len(clauses_to_validate)} {requesting_agent} clauses\")\n",
        "                \n",
        "                val_request['status'] = 'completed'\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"legal\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses\": clauses,\n",
        "                \"validations_performed\": len(pending_validations),\n",
        "                \"conflicts_found\": len(state.get('conflicts_detected', [])),\n",
        "                \"summary\": f\"Legal: Retrieved {len(clauses)} clauses, validated {len(pending_validations)} requests\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses\")\n",
        "            print(f\"     Completed {len(pending_validations)} validation(s)\")\n",
        "            \n",
        "        else:\n",
        "            state[\"legal\"] = {\n",
        "                \"agent\": \"Legal\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['legal'],\n",
        "                \"clauses_retrieved\": 0\n",
        "            }\n",
        "            print(f\"     No clauses above threshold\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"legal\"] = {\"agent\": \"Legal\", \"status\": \"error\", \"error\": str(e)}\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"legal\")\n",
        "    return state\n",
        "\n",
        "print(\"legal_node_collaborative() defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Creating Operations Agent with Legal Memory Reading and SLA Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "operations_node_collaborative() defined\n"
          ]
        }
      ],
      "source": [
        "def operations_node_collaborative(state: GraphStateCollaborative) -> GraphStateCollaborative:\n",
        "\n",
        "    print(f\"  OPERATIONS AGENT EXECUTING (Threshold: {AGENT_THRESHOLDS['operations']})\")\n",
        "    print(f\"  Reading Legal memory + SLA validation\")\n",
        "\n",
        "    legal_findings = [m for m in state.get('memory', []) if m.get('agent') == 'legal']\n",
        "    if legal_findings:\n",
        "        print(f\"     Reading Legal findings from memory:\")\n",
        "        for finding in legal_findings[-1:]:  \n",
        "            summary = finding.get('summary', 'N/A')\n",
        "            print(f\"       â€¢ {summary}\")\n",
        "    \n",
        "    try:\n",
        "        results = retrieve_from_pinecone_adaptive(state['query'], agent_filter='operations', top_k=5)\n",
        "        \n",
        "        if results and results.matches:\n",
        "            threshold = AGENT_THRESHOLDS['operations']  \n",
        "            filtered_matches = [m for m in results.matches if m.score > threshold]\n",
        "            \n",
        "            clauses = []\n",
        "            scores = []\n",
        "            for match in filtered_matches:\n",
        "                clause_data = {\n",
        "                    'clause': match.metadata.get('clause_full', match.metadata.get('clause', '')),\n",
        "                    'risk_level': match.metadata.get('risk_level', 'unknown'),\n",
        "                    'confidence': match.metadata.get('confidence', 0.0),\n",
        "                    'relevance_score': match.score,\n",
        "                    'agent': 'operations'\n",
        "                }\n",
        "                clauses.append(clause_data)\n",
        "                scores.append(match.score)\n",
        "            \n",
        "            state[\"operations\"] = {\n",
        "                \"agent\": \"Operations\",\n",
        "                \"status\": \"completed\",\n",
        "                \"source\": \"pinecone_vector_store\",\n",
        "                \"threshold\": threshold,\n",
        "                \"clauses_retrieved\": len(clauses),\n",
        "                \"clauses\": clauses,\n",
        "                \"avg_relevance\": sum(scores) / len(scores) if scores else 0,\n",
        "                \"sla_validation\": \"performed\"\n",
        "            }\n",
        "            \n",
        "            state[\"all_clauses\"].extend(clauses)\n",
        "            state[\"total_clauses_retrieved\"] += len(clauses)\n",
        "            \n",
        "            legal_clauses = state.get('legal', {}).get('clauses', [])\n",
        "            if legal_clauses:\n",
        "                cross_refs = cross_reference_clauses(\n",
        "                    source_agent=\"operations\",\n",
        "                    source_clauses=clauses,\n",
        "                    target_agent=\"legal\",\n",
        "                    target_clauses=legal_clauses,\n",
        "                    threshold=0.1  \n",
        "                )\n",
        "                \n",
        "                if cross_refs:\n",
        "                    state[\"cross_references\"].extend(cross_refs)\n",
        "                    state[\"validation_notes\"].append(\n",
        "                        f\"Operations: SLA validation - {len(cross_refs)} cross-references with Legal\"\n",
        "                    )\n",
        "                    print(f\"     SLA validation: {len(cross_refs)} cross-references with Legal\")\n",
        "            \n",
        "            state[\"memory\"].append({\n",
        "                \"agent\": \"operations\",\n",
        "                \"timestamp\": datetime.now().isoformat(),\n",
        "                \"turn\": state.get('turn_number', 0),\n",
        "                \"clauses\": clauses,\n",
        "                \"threshold_used\": threshold,\n",
        "                \"sla_validation\": \"completed\",\n",
        "                \"legal_context_used\": len(legal_findings) > 0,\n",
        "                \"summary\": f\"Operations: Found {len(clauses)} SLA clauses (threshold: {threshold}), validated with Legal\"\n",
        "            })\n",
        "            \n",
        "            print(f\"     Retrieved: {len(clauses)} clauses (threshold: {threshold})\")\n",
        "            print(f\"     SLA validation completed with Legal context\")\n",
        "            \n",
        "        else:\n",
        "            state[\"operations\"] = {\n",
        "                \"agent\": \"Operations\",\n",
        "                \"status\": \"no_results\",\n",
        "                \"threshold\": AGENT_THRESHOLDS['operations'],\n",
        "                \"clauses_retrieved\": 0\n",
        "            }\n",
        "            print(f\"     No clauses above threshold {AGENT_THRESHOLDS['operations']}\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        state[\"operations\"] = {\"agent\": \"Operations\", \"status\": \"error\", \"error\": str(e)}\n",
        "        print(f\"     Error: {str(e)[:50]}\")\n",
        "    \n",
        "    state[\"execution_order\"].append(\"operations\")\n",
        "    return state\n",
        "\n",
        "print(\"operations_node_collaborative() defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Building Collaborative Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BUILDING AND COMPILING COLLABORATIVE WORKFLOW\n",
            "\n",
            "Building workflow with agent-to-agent communication and validation...\n",
            "StateGraph initialized with GraphStateCollaborative\n",
            "ADDING COLLABORATIVE AGENT NODES\n",
            "Added: routing (memory-aware LLM coordinator)\n",
            "Added: compliance_agent (writes findings, requests validation)\n",
            "Added: finance_agent (reads memory, cross-references)\n",
            "Added: legal_agent (validates, checks conflicts)\n",
            "Added: operations_agent (reads legal memory, validates SLAs)\n",
            "Added: aggregation (with validation summary)\n",
            "DEFINING CONDITIONAL EDGES\n",
            "Entry point: routing\n",
            "routing â†’ [conditional first agent]\n",
            "compliance_agent â†’ [conditional next]\n",
            "finance_agent â†’ [conditional next]\n",
            "legal_agent â†’ [conditional next]\n",
            "operations_agent â†’ aggregation\n",
            "aggregation â†’ END\n"
          ]
        }
      ],
      "source": [
        "print(\"BUILDING AND COMPILING COLLABORATIVE WORKFLOW\")\n",
        "\n",
        "print(\"\\nBuilding workflow with agent-to-agent communication and validation...\")\n",
        "\n",
        "workflow_collaborative = StateGraph(GraphStateCollaborative)\n",
        "print(\"StateGraph initialized with GraphStateCollaborative\")\n",
        "\n",
        "print(\"ADDING COLLABORATIVE AGENT NODES\")\n",
        "\n",
        "workflow_collaborative.add_node(\"routing\", routing_node_with_memory)\n",
        "print(\"Added: routing (memory-aware LLM coordinator)\")\n",
        "\n",
        "workflow_collaborative.add_node(\"compliance_agent\", compliance_node_collaborative)\n",
        "print(\"Added: compliance_agent (writes findings, requests validation)\")\n",
        "\n",
        "workflow_collaborative.add_node(\"finance_agent\", finance_node_collaborative)\n",
        "print(\"Added: finance_agent (reads memory, cross-references)\")\n",
        "\n",
        "workflow_collaborative.add_node(\"legal_agent\", legal_node_collaborative)\n",
        "print(\"Added: legal_agent (validates, checks conflicts)\")\n",
        "\n",
        "workflow_collaborative.add_node(\"operations_agent\", operations_node_collaborative)\n",
        "print(\"Added: operations_agent (reads legal memory, validates SLAs)\")\n",
        "\n",
        "def aggregation_node_collaborative(state: GraphStateCollaborative) -> GraphStateCollaborative:\n",
        "\n",
        "    print(\"AGGREGATION NODE: Consolidating Results + Validation Summary\")\n",
        "   \n",
        "    if state['all_clauses']:\n",
        "        state['all_clauses'].sort(key=lambda x: x.get('relevance_score', 0), reverse=True)\n",
        "        \n",
        "        print(f\"\\nTotal clauses retrieved: {state['total_clauses_retrieved']}\")\n",
        "        print(f\"Top relevance score: {state['all_clauses'][0]['relevance_score']:.3f}\")\n",
        "        \n",
        "        agents_with_results = [a for a in ['legal', 'compliance', 'finance', 'operations'] \n",
        "                              if state.get(a, {}).get('status') == 'completed']\n",
        "        \n",
        "        if len(agents_with_results) > 1:\n",
        "            consensus = {\n",
        "                \"participating_agents\": agents_with_results,\n",
        "                \"total_clauses\": state['total_clauses_retrieved'],\n",
        "                \"cross_references\": len(state.get('cross_references', [])),\n",
        "                \"conflicts\": len(state.get('conflicts_detected', [])),\n",
        "                \"validations_performed\": len(state.get('validation_results', []))\n",
        "            }\n",
        "            state[\"consensus_findings\"].append(consensus)\n",
        "            \n",
        "            print(f\"\\nConsensus built from {len(agents_with_results)} agents\")\n",
        "            print(f\"  â€¢ Cross-references: {consensus['cross_references']}\")\n",
        "            print(f\"  â€¢ Conflicts detected: {consensus['conflicts']}\")\n",
        "            print(f\"  â€¢ Validations: {consensus['validations_performed']}\")\n",
        "        \n",
        "        state['execution_status'] = 'success'\n",
        "        \n",
        "    else:\n",
        "        print(f\"\\nNo clauses retrieved\")\n",
        "        state['execution_status'] = 'no_results'\n",
        "\n",
        "    print(\"COMMUNICATION SUMMARY\")\n",
        "    print(f\"  Messages: {len(state.get('agent_messages', []))}\")\n",
        "    print(f\"  Validation Requests: {len(state.get('validation_requests', []))}\")\n",
        "    print(f\"  Validation Results: {len(state.get('validation_results', []))}\")\n",
        "    print(f\"  Cross-references: {len(state.get('cross_references', []))}\")\n",
        "    print(f\"  Conflicts: {len(state.get('conflicts_detected', []))}\")\n",
        "    print(f\"  Validation Notes: {len(state.get('validation_notes', []))}\")\n",
        "    \n",
        "    if state.get('validation_notes'):\n",
        "        print(f\"\\n  Validation Notes:\")\n",
        "        for idx, note in enumerate(state['validation_notes'], 1):\n",
        "            print(f\"    [{idx}] {note}\")\n",
        "    \n",
        "    state[\"memory\"].append({\n",
        "        \"agent\": \"aggregation\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"turn\": state.get('turn_number', 0),\n",
        "        \"total_clauses\": state['total_clauses_retrieved'],\n",
        "        \"communication_events\": len(state.get('agent_messages', [])) + len(state.get('validation_requests', [])),\n",
        "        \"conflicts_resolved\": len(state.get('conflicts_detected', [])),\n",
        "        \"summary\": f\"Aggregation: {state['total_clauses_retrieved']} clauses, {len(state.get('validation_notes', []))} validation notes\"\n",
        "    })\n",
        "    \n",
        "    state['execution_order'].append(\"aggregation\")\n",
        "    \n",
        "    checkpoint_path = save_state_checkpoint(state)\n",
        "    state['checkpoint_path'] = checkpoint_path\n",
        "    \n",
        "    print(f\"\\nCheckpoint saved: {os.path.basename(checkpoint_path)}\")\n",
        "    \n",
        "    return state\n",
        "\n",
        "workflow_collaborative.add_node(\"aggregation\", aggregation_node_collaborative)\n",
        "print(\"Added: aggregation (with validation summary)\")\n",
        "\n",
        "\n",
        "print(\"DEFINING CONDITIONAL EDGES\")\n",
        "\n",
        "workflow_collaborative.set_entry_point(\"routing\")\n",
        "print(\"Entry point: routing\")\n",
        "\n",
        "def get_next_agent_collaborative(state: GraphStateCollaborative) -> str:\n",
        "    routed_agents = state.get('routed_agents', [])\n",
        "    executed_agents = [a for a in state.get('execution_order', []) \n",
        "                      if a not in ['routing', 'aggregation']]\n",
        "    \n",
        "    agent_priority = ['compliance', 'finance', 'legal', 'operations']\n",
        "    \n",
        "    for agent in agent_priority:\n",
        "        if agent in routed_agents and agent not in executed_agents:\n",
        "            return f\"{agent}_agent\"\n",
        "    \n",
        "    return \"aggregation\"\n",
        "\n",
        "workflow_collaborative.add_conditional_edges(\n",
        "    \"routing\",\n",
        "    lambda state: get_next_agent_collaborative(state),\n",
        "    {\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"routing â†’ [conditional first agent]\")\n",
        "\n",
        "workflow_collaborative.add_conditional_edges(\n",
        "    \"compliance_agent\",\n",
        "    lambda state: get_next_agent_collaborative(state),\n",
        "    {\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"compliance_agent â†’ [conditional next]\")\n",
        "\n",
        "workflow_collaborative.add_conditional_edges(\n",
        "    \"finance_agent\",\n",
        "    lambda state: get_next_agent_collaborative(state),\n",
        "    {\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"legal_agent\": \"legal_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"finance_agent â†’ [conditional next]\")\n",
        "\n",
        "workflow_collaborative.add_conditional_edges(\n",
        "    \"legal_agent\",\n",
        "    lambda state: get_next_agent_collaborative(state),\n",
        "    {\n",
        "        \"compliance_agent\": \"compliance_agent\",\n",
        "        \"finance_agent\": \"finance_agent\",\n",
        "        \"operations_agent\": \"operations_agent\",\n",
        "        \"aggregation\": \"aggregation\"\n",
        "    }\n",
        ")\n",
        "print(\"legal_agent â†’ [conditional next]\")\n",
        "\n",
        "workflow_collaborative.add_edge(\"operations_agent\", \"aggregation\")\n",
        "print(\"operations_agent â†’ aggregation\")\n",
        "\n",
        "workflow_collaborative.add_edge(\"aggregation\", END)\n",
        "print(\"aggregation â†’ END\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8. Compiling Collaborative Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COMPILING COLLABORATIVE WORKFLOW\n",
            "Collaborative workflow compiled successfully!\n",
            "COLLABORATIVE WORKFLOW READY\n"
          ]
        }
      ],
      "source": [
        "print(\"COMPILING COLLABORATIVE WORKFLOW\")\n",
        "\n",
        "try:\n",
        "    app_collaborative = workflow_collaborative.compile()\n",
        "    print(\"Collaborative workflow compiled successfully!\")\n",
        "    \n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nCompilation failed: {str(e)}\")\n",
        "    print(\"ERROR DETAILS\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"COLLABORATIVE WORKFLOW READY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9. Executing with Multi-Intent Query and Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EXECUTING COLLABORATIVE WORKFLOW WITH MULTI-INTENT QUERY\n",
            "\n",
            "Preparing multi-intent query for collaborative execution...\n",
            "INITIALIZING COLLABORATIVE STATE\n",
            "Collaborative state initialized: collab_session_20260115_181319\n",
            "Collaborative state initialized\n",
            "  Session ID: collab_session_20260115_181319\n",
            "  Query: \"Review termination GDPR compliance requirements, payment terms with late penalties, and SLA deliverables\"\n",
            "EXECUTING COLLABORATIVE WORKFLOW\n",
            "ROUTING NODE: Dynamic LLM Coordinator with Memory\n",
            "Query: \"Review termination GDPR compliance requirements, payment terms with late penalties, and SLA deliverables\"\n",
            "Turn: 0\n",
            "Session: collab_session_20260115_181319\n",
            "\n",
            "This is the first query in the conversation.\n",
            "\n",
            "Querying gemma2:9b coordinator...\n",
            "\n",
            "Routing Decision:\n",
            "  Agents: legal, compliance, finance, operations\n",
            "  Reasoning: The query involves termination clauses (legal), GDPR compliance (compliance), payment terms and penalties (finance), and SLA deliverables (operations).\n",
            "  COMPLIANCE AGENT EXECUTING (Threshold: 0.1)\n",
            "  Writing findings to shared memory for validation\n",
            "     Retrieved: 1 clauses (threshold: 0.1)\n",
            "     Risk Level: high\n",
            "     Sent validation request to Legal agent\n",
            "  FINANCE AGENT EXECUTING (Threshold: 0.1)\n",
            "  Reading shared memory from previous agents\n",
            "     Reading 1 entries from other agents:\n",
            "       â€¢ COMPLIANCE: Compliance: Found 1 clauses (threshold: 0.1, risk: high)\n",
            "     Retrieved: 3 clauses\n",
            "     Integrated context from previous agents\n",
            "  LEGAL AGENT EXECUTING (Threshold: 0.1)\n",
            "  Performing validation for other agents\n",
            "     Processing 1 validation request(s)\n",
            "     Conflicts detected with compliance: 2\n",
            "     Retrieved: 2 clauses\n",
            "     Completed 1 validation(s)\n",
            "  OPERATIONS AGENT EXECUTING (Threshold: 0.1)\n",
            "  Reading Legal memory + SLA validation\n",
            "     Reading Legal findings from memory:\n",
            "       â€¢ Legal: Retrieved 2 clauses, validated 1 requests\n",
            "     Retrieved: 2 clauses (threshold: 0.1)\n",
            "     SLA validation completed with Legal context\n",
            "AGGREGATION NODE: Consolidating Results + Validation Summary\n",
            "\n",
            "Total clauses retrieved: 8\n",
            "Top relevance score: 0.407\n",
            "\n",
            "Consensus built from 4 agents\n",
            "  â€¢ Cross-references: 0\n",
            "  â€¢ Conflicts detected: 2\n",
            "  â€¢ Validations: 1\n",
            "COMMUNICATION SUMMARY\n",
            "  Messages: 0\n",
            "  Validation Requests: 1\n",
            "  Validation Results: 1\n",
            "  Cross-references: 0\n",
            "  Conflicts: 2\n",
            "  Validation Notes: 2\n",
            "\n",
            "  Validation Notes:\n",
            "    [1] Compliance â†’ Legal: Requesting legal review of 1 compliance clauses\n",
            "    [2] Legal validation: Found 2 conflict(s) with compliance findings\n",
            "  State saved: checkpoint_collab_session_20260115_181319_turn0_20260115_181354.json\n",
            "\n",
            "Checkpoint saved: checkpoint_collab_session_20260115_181319_turn0_20260115_181354.json\n",
            "COLLABORATIVE EXECUTION COMPLETED\n",
            "ROUTING DECISION\n",
            "  Query: \"Review termination GDPR compliance requirements, payment terms with late penalties, and SLA deliverables\"\n",
            "  LLM Routed To: legal, compliance, finance, operations\n",
            "  Reasoning: The query involves termination clauses (legal), GDPR compliance (compliance), payment terms and penalties (finance), and SLA deliverables (operations).\n",
            "  Expected: compliance, finance, operations\n",
            "EXECUTION SUMMARY\n",
            "  Session: collab_session_20260115_181319\n",
            "  Execution Order: routing â†’ compliance â†’ finance â†’ legal â†’ operations â†’ aggregation\n",
            "  Total Clauses: 8\n",
            "  Status: success\n",
            "AGENT RESULTS\n",
            "Agent           Status             Clauses    Threshold    Avg Score   \n",
            "COMPLIANCE      EXECUTED           1          0.10         0.186       \n",
            "FINANCE         EXECUTED           3          0.10         0.307       \n",
            "LEGAL           EXECUTED           2          0.10         0.348       \n",
            "OPERATIONS      EXECUTED           2          0.10         0.195       \n",
            "\n",
            "Lower threshold (0.10) for better recall\n",
            "AGENT COMMUNICATION & VALIDATION SUMMARY\n",
            "\n",
            "  Communication Metrics:\n",
            "    â€¢ Agent Messages: 0\n",
            "    â€¢ Validation Requests: 1\n",
            "    â€¢ Validation Results: 1\n",
            "    â€¢ Cross-references: 0\n",
            "    â€¢ Conflicts Detected: 2\n",
            "    â€¢ Validation Notes: 2\n",
            "    â€¢ Consensus Findings: 1\n",
            "VALIDATION NOTES (Agent-to-Agent Communication)\n",
            "\n",
            "  [1] Compliance â†’ Legal: Requesting legal review of 1 compliance clauses\n",
            "\n",
            "  [2] Legal validation: Found 2 conflict(s) with compliance findings\n",
            "VALIDATION REQUESTS DETAILS\n",
            "\n",
            "  Request 1:\n",
            "    â€¢ ID: val_compliance_to_legal_20260115181353781073\n",
            "    â€¢ From: COMPLIANCE\n",
            "    â€¢ To: LEGAL\n",
            "    â€¢ Type: legal_review_of_compliance\n",
            "    â€¢ Clauses: 1\n",
            "    â€¢ Status: completed\n",
            "VALIDATION RESULTS DETAILS\n",
            "\n",
            "  Result 1:\n",
            "    â€¢ ID: result_val_compliance_to_legal_20260115181353781073\n",
            "    â€¢ Request ID: val_compliance_to_legal_20260115181353781073\n",
            "    â€¢ Validator: LEGAL\n",
            "    â€¢ Outcome: needs_review\n",
            "    â€¢ Confidence: 0.85\n",
            "    â€¢ Findings: 2\n",
            "CONFLICTS DETECTED\n",
            "\n",
            "  Conflict 1:\n",
            "    â€¢ Type: risk_assessment_mismatch\n",
            "    â€¢ Between: COMPLIANCE â†” LEGAL\n",
            "    â€¢ Risk 1: high\n",
            "    â€¢ Risk 2: low\n",
            "    â€¢ Threshold: 0.10\n",
            "\n",
            "  Conflict 2:\n",
            "    â€¢ Type: risk_assessment_mismatch\n",
            "    â€¢ Between: COMPLIANCE â†” LEGAL\n",
            "    â€¢ Risk 1: high\n",
            "    â€¢ Risk 2: low\n",
            "    â€¢ Threshold: 0.10\n",
            "CONSENSUS FINDINGS (Multi-Agent Agreement)\n",
            "\n",
            "  Consensus 1:\n",
            "    â€¢ Participating Agents: legal, compliance, finance, operations\n",
            "    â€¢ Total Clauses: 8\n",
            "    â€¢ Cross-references: 0\n",
            "    â€¢ Conflicts: 2\n",
            "    â€¢ Validations: 1\n",
            "CONVERSATION MEMORY INSPECTION\n",
            "\n",
            "  Total Memory Entries: 6\n",
            "  Turn Number: 0\n",
            "\n",
            "  Memory Log (All Entries):\n",
            "RETRIEVED CLAUSES BY AGENT\n",
            "\n",
            "  LEGAL - 2 clause(s):\n",
            "     (threshold: 0.1)\n",
            "    [1] Score: 0.407 | Risk: low\n",
            "        The other party shall give notice of termination in writing to the other party, which notice shall s...\n",
            "    [2] Score: 0.289 | Risk: low\n",
            "        The other party asserts any rights in or to the terminating party's intellectual property in violati...\n",
            "\n",
            "  FINANCE - 3 clause(s):\n",
            "     (threshold: 0.1)\n",
            "    [1] Score: 0.360 | Risk: medium\n",
            "        In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision ...\n",
            "    [2] Score: 0.316 | Risk: medium\n",
            "        ), Recipient shall reimburse Provider for all such Out-of-Pocket Costs....\n",
            "    ... and 1 more clause(s)\n",
            "\n",
            "  OPERATIONS - 2 clause(s):\n",
            "     (threshold: 0.10 )\n",
            "    [1] Score: 0.255 | Risk: medium\n",
            "        Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distr...\n",
            "    [2] Score: 0.135 | Risk: medium\n",
            "        Collectible Concepts Group will obtain any licenses deemed by the Joint Venturers to add value in th...\n",
            "\n",
            "  COMPLIANCE - 1 clause(s):\n",
            "     (threshold: 0.10 )\n",
            "    [1] Score: 0.186 | Risk: high\n",
            "        The receiving party will not disclose the other party's confidential information to any third partie...\n",
            "STATE PERSISTENCE\n",
            "  Checkpoint saved: checkpoint_collab_session_20260115_181319_turn0_20260115_181354.json\n",
            "  Location: ../Data/Results/Checkpoints\n",
            "  Session: collab_session_20260115_181319\n",
            "\n",
            "  Checkpoint includes:\n",
            "    â€¢ All memory entries: 6\n",
            "    â€¢ Validation requests: 1\n",
            "    â€¢ Validation results: 1\n",
            "    â€¢ Cross-references: 0\n",
            "    â€¢ Conflicts: 2\n",
            "FINAL VERIFICATION\n",
            "\n",
            "  System Checks:\n",
            "    PASS: Multi-domain Routing (4 agents routed)\n",
            "    PASS: Compliance Threshold (0.10) (actual: 0.1)\n",
            "    PASS: Operations Threshold (0.10) (actual: 0.1)\n",
            "    PASS: Validation Requests Sent (1 requests)\n",
            "    FAIL: Cross-references Created (0 cross-refs)\n",
            "    PASS: Memory Tracking (6 entries)\n",
            "    PASS: Clause Retrieval (8 clauses)\n",
            "    PASS: Agent Communication (active)\n",
            "\n",
            "  Some checks failed - Review configuration\n",
            "EXECUTION SUMMARY\n",
            "\n",
            "  Query: \"Review termination GDPR compliance requirements, payment terms with late penalties, and SLA deliverables\"\n",
            "\n",
            "  Agents Executed: 4\n",
            "  Total Clauses: 8\n",
            "\n",
            "  Communication:\n",
            "    â€¢ Validation Requests: 1\n",
            "    â€¢ Validation Results: 1\n",
            "    â€¢ Cross-references: 0\n",
            "    â€¢ Conflicts: 2\n",
            "    â€¢ Validation Notes: 2\n",
            "\n",
            "  Status: success\n",
            "    \n",
            "COLLABORATIVE WORKFLOW EXECUTION COMPLETE\n"
          ]
        }
      ],
      "source": [
        "print(\"EXECUTING COLLABORATIVE WORKFLOW WITH MULTI-INTENT QUERY\")\n",
        "\n",
        "print(\"\\nPreparing multi-intent query for collaborative execution...\")\n",
        "\n",
        "print(\"INITIALIZING COLLABORATIVE STATE\")\n",
        "\n",
        "collaborative_state = initialize_collaborative_state()\n",
        "\n",
        "collaborative_state['query'] = \"Review termination GDPR compliance requirements, payment terms with late penalties, and SLA deliverables\"\n",
        "\n",
        "print(f\"Collaborative state initialized\")\n",
        "print(f\"  Session ID: {collaborative_state['session_id']}\")\n",
        "print(f\"  Query: \\\"{collaborative_state['query']}\\\"\")\n",
        "\n",
        "print(\"EXECUTING COLLABORATIVE WORKFLOW\")\n",
        "\n",
        "try:\n",
        "    result_collaborative = app_collaborative.invoke(collaborative_state)\n",
        "    \n",
        "    print(\"COLLABORATIVE EXECUTION COMPLETED\")\n",
        "\n",
        "    print(\"ROUTING DECISION\")\n",
        "\n",
        "    print(f\"  Query: \\\"{result_collaborative['query']}\\\"\")\n",
        "    print(f\"  LLM Routed To: {', '.join(result_collaborative.get('routed_agents', []))}\")\n",
        "    print(f\"  Reasoning: {result_collaborative.get('routing_reasoning', 'N/A')}\")\n",
        "    print(f\"  Expected: compliance, finance, operations\")\n",
        "\n",
        "    print(\"EXECUTION SUMMARY\")\n",
        "\n",
        "    print(f\"  Session: {result_collaborative.get('session_id', 'N/A')}\")\n",
        "    print(f\"  Execution Order: {' â†’ '.join(result_collaborative['execution_order'])}\")\n",
        "    print(f\"  Total Clauses: {result_collaborative.get('total_clauses_retrieved', 0)}\")\n",
        "    print(f\"  Status: {result_collaborative.get('execution_status', 'unknown')}\")\n",
        "\n",
        "    print(\"AGENT RESULTS\")\n",
        "    print(f\"{'Agent':<15} {'Status':<18} {'Clauses':<10} {'Threshold':<12} {'Avg Score':<12}\")\n",
        "\n",
        "    \n",
        "    executed_agents = []\n",
        "    for agent_name in [\"compliance\", \"finance\", \"legal\", \"operations\"]:\n",
        "        agent_data = result_collaborative.get(agent_name, {})\n",
        "        \n",
        "        if agent_data and agent_data.get(\"status\") == \"completed\":\n",
        "            executed_agents.append(agent_name)\n",
        "            status = \"EXECUTED\"\n",
        "            clauses = agent_data.get('clauses_retrieved', 0)\n",
        "            threshold = agent_data.get('threshold', 'N/A')\n",
        "            avg_score = agent_data.get('avg_relevance', 0)\n",
        "            \n",
        "            threshold_str = f\"{threshold:.2f}\" if isinstance(threshold, float) else str(threshold)\n",
        "            score_str = f\"{avg_score:.3f}\" if avg_score > 0 else \"N/A\"\n",
        "            \n",
        "            if agent_name in ['compliance', 'operations'] and threshold == 0.10:\n",
        "                threshold_str += \"\"\n",
        "            \n",
        "            print(f\"{agent_name.upper():<15} {status:<18} {clauses:<10} {threshold_str:<12} {score_str:<12}\")\n",
        "            \n",
        "        elif agent_data and agent_data.get(\"status\") == \"no_results\":\n",
        "            executed_agents.append(agent_name)\n",
        "            status = \"EXECUTED (0)\"\n",
        "            threshold = agent_data.get('threshold', 'N/A')\n",
        "            threshold_str = f\"{threshold:.2f}\" if isinstance(threshold, float) else str(threshold)\n",
        "            \n",
        "            print(f\"{agent_name.upper():<15} {status:<18} {0:<10} {threshold_str:<12} {'N/A':<12}\")\n",
        "            \n",
        "        else:\n",
        "            status = \"NOT EXECUTED\"\n",
        "            print(f\"{agent_name.upper():<15} {status:<18} {'-':<10} {'-':<12} {'-':<12}\")\n",
        "    \n",
        "    print(\"\\nLower threshold (0.10) for better recall\")\n",
        "\n",
        "    print(\"AGENT COMMUNICATION & VALIDATION SUMMARY\")\n",
        " \n",
        "    agent_messages = result_collaborative.get('agent_messages', [])\n",
        "    validation_requests = result_collaborative.get('validation_requests', [])\n",
        "    validation_results = result_collaborative.get('validation_results', [])\n",
        "    cross_references = result_collaborative.get('cross_references', [])\n",
        "    conflicts_detected = result_collaborative.get('conflicts_detected', [])\n",
        "    validation_notes = result_collaborative.get('validation_notes', [])\n",
        "    consensus_findings = result_collaborative.get('consensus_findings', [])\n",
        "    \n",
        "    print(f\"\\n  Communication Metrics:\")\n",
        "    print(f\"    â€¢ Agent Messages: {len(agent_messages)}\")\n",
        "    print(f\"    â€¢ Validation Requests: {len(validation_requests)}\")\n",
        "    print(f\"    â€¢ Validation Results: {len(validation_results)}\")\n",
        "    print(f\"    â€¢ Cross-references: {len(cross_references)}\")\n",
        "    print(f\"    â€¢ Conflicts Detected: {len(conflicts_detected)}\")\n",
        "    print(f\"    â€¢ Validation Notes: {len(validation_notes)}\")\n",
        "    print(f\"    â€¢ Consensus Findings: {len(consensus_findings)}\")\n",
        "    \n",
        "    if validation_notes:\n",
        "        print(\"VALIDATION NOTES (Agent-to-Agent Communication)\")\n",
        "        \n",
        "        for idx, note in enumerate(validation_notes, 1):\n",
        "            print(f\"\\n  [{idx}] {note}\")\n",
        "    else:\n",
        "        print(\"\\n  No validation notes generated\")\n",
        "   \n",
        "    if validation_requests:\n",
        "        print(\"VALIDATION REQUESTS DETAILS\")\n",
        "\n",
        "        for idx, request in enumerate(validation_requests, 1):\n",
        "            print(f\"\\n  Request {idx}:\")\n",
        "            print(f\"    â€¢ ID: {request.get('request_id', 'N/A')}\")\n",
        "            print(f\"    â€¢ From: {request.get('requesting_agent', 'N/A').upper()}\")\n",
        "            print(f\"    â€¢ To: {request.get('validating_agent', 'N/A').upper()}\")\n",
        "            print(f\"    â€¢ Type: {request.get('validation_type', 'N/A')}\")\n",
        "            print(f\"    â€¢ Clauses: {len(request.get('clauses', []))}\")\n",
        "            print(f\"    â€¢ Status: {request.get('status', 'N/A')}\")\n",
        "    \n",
        "    if validation_results:\n",
        "        print(\"VALIDATION RESULTS DETAILS\")\n",
        "\n",
        "        \n",
        "        for idx, result in enumerate(validation_results, 1):\n",
        "            print(f\"\\n  Result {idx}:\")\n",
        "            print(f\"    â€¢ ID: {result.get('result_id', 'N/A')}\")\n",
        "            print(f\"    â€¢ Request ID: {result.get('request_id', 'N/A')}\")\n",
        "            print(f\"    â€¢ Validator: {result.get('validating_agent', 'N/A').upper()}\")\n",
        "            print(f\"    â€¢ Outcome: {result.get('outcome', 'N/A')}\")\n",
        "            print(f\"    â€¢ Confidence: {result.get('confidence', 0):.2f}\")\n",
        "            print(f\"    â€¢ Findings: {len(result.get('findings', []))}\")\n",
        "    \n",
        "    if cross_references:\n",
        "        print(\"CROSS-REFERENCES (Inter-Agent Clause Links)\")\n",
        "\n",
        "        \n",
        "        for idx, cross_ref in enumerate(cross_references[:5], 1):  \n",
        "            print(f\"\\n  [{idx}] {cross_ref.get('source_agent', 'N/A').upper()} â†” {cross_ref.get('target_agent', 'N/A').upper()}\")\n",
        "            print(f\"    â€¢ Overlap Score: {cross_ref.get('overlap_score', 0):.3f}\")\n",
        "            print(f\"    â€¢ Threshold Used: {cross_ref.get('threshold_used', 0):.2f}\")\n",
        "            print(f\"    â€¢ Type: {cross_ref.get('reference_type', 'N/A')}\")\n",
        "            src = cross_ref.get('source_clause', '')[:80]\n",
        "            tgt = cross_ref.get('target_clause', '')[:80]\n",
        "            print(f\"    â€¢ Source: {src}...\")\n",
        "            print(f\"    â€¢ Target: {tgt}...\")\n",
        "        \n",
        "        if len(cross_references) > 5:\n",
        "            print(f\"\\n  ... and {len(cross_references) - 5} more cross-references\")\n",
        "    \n",
        "\n",
        "    if conflicts_detected:\n",
        "        print(\"CONFLICTS DETECTED\")\n",
        "\n",
        "        for idx, conflict in enumerate(conflicts_detected, 1):\n",
        "            print(f\"\\n  Conflict {idx}:\")\n",
        "            print(f\"    â€¢ Type: {conflict.get('conflict_type', 'N/A')}\")\n",
        "            print(f\"    â€¢ Between: {conflict.get('agent1', 'N/A').upper()} â†” {conflict.get('agent2', 'N/A').upper()}\")\n",
        "            print(f\"    â€¢ Risk 1: {conflict.get('risk1', 'N/A')}\")\n",
        "            print(f\"    â€¢ Risk 2: {conflict.get('risk2', 'N/A')}\")\n",
        "            print(f\"    â€¢ Threshold: {conflict.get('threshold_used', 0):.2f}\")\n",
        "    else:\n",
        "        print(\"\\nNo conflicts detected between agents\")\n",
        "\n",
        "    if consensus_findings:\n",
        "        print(\"CONSENSUS FINDINGS (Multi-Agent Agreement)\")\n",
        "\n",
        "        for idx, consensus in enumerate(consensus_findings, 1):\n",
        "            print(f\"\\n  Consensus {idx}:\")\n",
        "            print(f\"    â€¢ Participating Agents: {', '.join(consensus.get('participating_agents', []))}\")\n",
        "            print(f\"    â€¢ Total Clauses: {consensus.get('total_clauses', 0)}\")\n",
        "            print(f\"    â€¢ Cross-references: {consensus.get('cross_references', 0)}\")\n",
        "            print(f\"    â€¢ Conflicts: {consensus.get('conflicts', 0)}\")\n",
        "            print(f\"    â€¢ Validations: {consensus.get('validations_performed', 0)}\")\n",
        "    \n",
        "\n",
        "    print(\"CONVERSATION MEMORY INSPECTION\")\n",
        "\n",
        "    memory = result_collaborative.get('memory', [])\n",
        "    print(f\"\\n  Total Memory Entries: {len(memory)}\")\n",
        "    print(f\"  Turn Number: {result_collaborative.get('turn_number', 0)}\")\n",
        "    \n",
        "    if memory:\n",
        "        print(f\"\\n  Memory Log (All Entries):\")\n",
        "        for idx, mem_entry in enumerate(memory, 1):\n",
        "            agent = mem_entry.get('agent', 'unknown')\n",
        "            summary = mem_entry.get('summary', 'N/A')\n",
        "            turn = mem_entry.get('turn', 0)\n",
        "    \n",
        "\n",
        "    if result_collaborative.get('all_clauses'):\n",
        "        print(\"RETRIEVED CLAUSES BY AGENT\")\n",
        "     \n",
        "        clauses_by_agent = {}\n",
        "        for clause in result_collaborative['all_clauses']:\n",
        "            agent = clause.get('agent', 'unknown')\n",
        "            if agent not in clauses_by_agent:\n",
        "                clauses_by_agent[agent] = []\n",
        "            clauses_by_agent[agent].append(clause)\n",
        "        \n",
        "        for agent, clauses in clauses_by_agent.items():\n",
        "            print(f\"\\n  {agent.upper()} - {len(clauses)} clause(s):\")\n",
        "            \n",
        "            agent_threshold = AGENT_THRESHOLDS.get(agent, 0.3)\n",
        "            threshold_note = \" (threshold: 0.10 )\" if agent in ['compliance', 'operations'] else f\" (threshold: {agent_threshold})\"\n",
        "            print(f\"    {threshold_note}\")\n",
        "            \n",
        "            for idx, clause in enumerate(clauses[:2], 1): \n",
        "                score = clause.get('relevance_score', 0)\n",
        "                risk = clause.get('risk_level', 'unknown')\n",
        "                text = clause.get('clause', '')[:100]\n",
        "                \n",
        "                print(f\"    [{idx}] Score: {score:.3f} | Risk: {risk}\")\n",
        "                print(f\"        {text}...\")\n",
        "            \n",
        "            if len(clauses) > 2:\n",
        "                print(f\"    ... and {len(clauses) - 2} more clause(s)\")\n",
        "\n",
        "    print(\"STATE PERSISTENCE\")\n",
        "\n",
        "    checkpoint_path = result_collaborative.get('checkpoint_path', '')\n",
        "    if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "        checkpoint_file = os.path.basename(checkpoint_path)\n",
        "        print(f\"  Checkpoint saved: {checkpoint_file}\")\n",
        "        print(f\"  Location: {CHECKPOINT_DIR}\")\n",
        "        print(f\"  Session: {result_collaborative.get('session_id', 'N/A')}\")\n",
        "        print(f\"\\n  Checkpoint includes:\")\n",
        "        print(f\"    â€¢ All memory entries: {len(memory)}\")\n",
        "        print(f\"    â€¢ Validation requests: {len(validation_requests)}\")\n",
        "        print(f\"    â€¢ Validation results: {len(validation_results)}\")\n",
        "        print(f\"    â€¢ Cross-references: {len(cross_references)}\")\n",
        "        print(f\"    â€¢ Conflicts: {len(conflicts_detected)}\")\n",
        "    else:\n",
        "        print(f\"  No checkpoint saved\")\n",
        " \n",
        "    print(\"FINAL VERIFICATION\")\n",
        "  \n",
        "    checks = []\n",
        "    \n",
        "    routed = result_collaborative.get('routed_agents', [])\n",
        "    multi_domain = len(routed) >= 2\n",
        "    checks.append((\"Multi-domain Routing\", multi_domain, f\"{len(routed)} agents routed\"))\n",
        "    \n",
        "    comp_threshold = result_collaborative.get('compliance', {}).get('threshold', 1.0)\n",
        "    comp_threshold_ok = comp_threshold == 0.10\n",
        "    checks.append((\"Compliance Threshold (0.10)\", comp_threshold_ok, f\"actual: {comp_threshold}\"))\n",
        "    \n",
        "    ops_threshold = result_collaborative.get('operations', {}).get('threshold', 1.0)\n",
        "    ops_threshold_ok = ops_threshold == 0.10\n",
        "    checks.append((\"Operations Threshold (0.10)\", ops_threshold_ok, f\"actual: {ops_threshold}\"))\n",
        "    \n",
        "    validations_sent = len(validation_requests) > 0\n",
        "    checks.append((\"Validation Requests Sent\", validations_sent, f\"{len(validation_requests)} requests\"))\n",
        "    \n",
        "    cross_refs_created = len(cross_references) > 0\n",
        "    checks.append((\"Cross-references Created\", cross_refs_created, f\"{len(cross_references)} cross-refs\"))\n",
        "    \n",
        "    memory_tracking = len(memory) > 0\n",
        "    checks.append((\"Memory Tracking\", memory_tracking, f\"{len(memory)} entries\"))\n",
        "    \n",
        "    clauses_retrieved = result_collaborative.get('total_clauses_retrieved', 0) > 0\n",
        "    checks.append((\"Clause Retrieval\", clauses_retrieved, f\"{result_collaborative.get('total_clauses_retrieved', 0)} clauses\"))\n",
        "    \n",
        "    communication_active = (len(validation_requests) + len(cross_references) + len(validation_notes)) > 0\n",
        "    checks.append((\"Agent Communication\", communication_active, \"active\"))\n",
        "    \n",
        "    print(f\"\\n  System Checks:\")\n",
        "    for check_name, passed, detail in checks:\n",
        "        status = \"PASS\" if passed else \"FAIL\"\n",
        "        print(f\"    {status}: {check_name} ({detail})\")\n",
        "    \n",
        "    all_passed = all(passed for _, passed, _ in checks)\n",
        "    \n",
        "    if all_passed:\n",
        "        print(f\"\\n  ALL CHECKS PASSED\")\n",
        "        print(f\"  Collaborative workflow with agent communication working perfectly!\")\n",
        "    else:\n",
        "        print(f\"\\n  Some checks failed - Review configuration\")\n",
        "    \n",
        "\n",
        "    print(\"EXECUTION SUMMARY\")\n",
        "    print(f\"\"\"\n",
        "  Query: \"{result_collaborative['query']}\"\n",
        "  \n",
        "  Agents Executed: {len(executed_agents)}\n",
        "  Total Clauses: {result_collaborative.get('total_clauses_retrieved', 0)}\n",
        "  \n",
        "  Communication:\n",
        "    â€¢ Validation Requests: {len(validation_requests)}\n",
        "    â€¢ Validation Results: {len(validation_results)}\n",
        "    â€¢ Cross-references: {len(cross_references)}\n",
        "    â€¢ Conflicts: {len(conflicts_detected)}\n",
        "    â€¢ Validation Notes: {len(validation_notes)}\n",
        "  \n",
        "  Status: {result_collaborative.get('execution_status', 'unknown')}\n",
        "    \"\"\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nEXECUTION FAILED\")\n",
        "    print(f\"Error: {str(e)}\")\n",
        "    \n",
        "    print(\"ERROR DETAILS\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"COLLABORATIVE WORKFLOW EXECUTION COMPLETE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Compliance Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any\n",
        "import os\n",
        "import requests\n",
        "from pinecone import Pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INITIALIZING OLLAMA MODEL\n",
            "Ollama model 'gemma2:9b' initialized successfully\n",
            "Connected to: http://localhost:11434/api/generate\n",
            "\n",
            "Ready to start Pipeline\n"
          ]
        }
      ],
      "source": [
        "OLLAMA_MODEL = \"gemma2:9b\"\n",
        "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "\n",
        "def initialize_ollama():\n",
        "  \n",
        "    try:\n",
        "        test_payload = {\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"prompt\": \"Hello\",\n",
        "            \"stream\": False\n",
        "        }\n",
        "        \n",
        "        response = requests.post(OLLAMA_URL, json=test_payload, timeout=30)\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            print(f\"Ollama model '{OLLAMA_MODEL}' initialized successfully\")\n",
        "            print(f\"Connected to: {OLLAMA_URL}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"Failed to initialize Ollama: Status {response.status_code}\")\n",
        "            return False\n",
        "            \n",
        "    except requests.exceptions.ConnectionError:\n",
        "        print(f\"Connection Error: Could not connect to Ollama at {OLLAMA_URL}\")\n",
        "        print(\"  Make sure Ollama is running (try: ollama serve)\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Ollama: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def call_ollama(prompt, max_tokens=50000, temperature=0.7):\n",
        "\n",
        "    try:\n",
        "        payload = {\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\n",
        "                \"num_predict\": max_tokens,\n",
        "                \"temperature\": temperature\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        response = requests.post(OLLAMA_URL, json=payload, timeout=60)\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            return result.get(\"response\", \"\").strip()\n",
        "        else:\n",
        "            print(f\"Error calling Ollama: Status {response.status_code}\")\n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error in call_ollama: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "print(\"INITIALIZING OLLAMA MODEL\")\n",
        "\n",
        "if initialize_ollama():\n",
        "    print(\"\\nReady to start Pipeline\")\n",
        "else:\n",
        "    print(\"\\nPlease start Ollama service and try again\")\n",
        "    print(\"  Command: ollama serve\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COMPLIANCE AGENT INITIALIZATION\n",
            "LLM Model: gemma2:9b\n",
            "Pinecone Index: contract-agents\n",
            "Retrieval Threshold: score > 0.1\n"
          ]
        }
      ],
      "source": [
        "print(\"COMPLIANCE AGENT INITIALIZATION\")\n",
        "\n",
        "OLLAMA_MODEL = \"gemma2:9b\"\n",
        "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "PINECONE_API_KEY = 'pcsk_3ftgmC_GzUZkRCnxa2jmDu7TTjnGWjC3QaN8c2PcQ5KN5PUSyQaEmmcdGUGu2BLd4Y7TRn'\n",
        "INDEX_NAME = 'contract-agents'\n",
        "SCORE_THRESHOLD = 0.1 \n",
        "\n",
        "print(f\"LLM Model: {OLLAMA_MODEL}\")\n",
        "print(f\"Pinecone Index: {INDEX_NAME}\")\n",
        "print(f\"Retrieval Threshold: score > {SCORE_THRESHOLD}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Defining Compliance Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Defining Compliance Query Template\n",
            "Compliance Query Template defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDefining Compliance Query Template\")\n",
        "\n",
        "COMPLIANCE_QUERY = \"\"\"\n",
        "Identify clauses related to:\n",
        "- Regulatory compliance and legal requirements\n",
        "- Data protection and privacy (GDPR, CCPA)\n",
        "- Security standards and certifications\n",
        "- Audit and monitoring requirements\n",
        "\"\"\"\n",
        "\n",
        "class ComplianceQueryTemplate:\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_base_template():\n",
        "        \"\"\"Get base compliance query template\"\"\"\n",
        "        return COMPLIANCE_QUERY\n",
        "    \n",
        "    @staticmethod\n",
        "    def select_template(query):\n",
        "        \"\"\"Select appropriate template based on query\"\"\"\n",
        "        query_lower = query.lower()\n",
        "        \n",
        "        if any(kw in query_lower for kw in ['gdpr', 'data protection', 'privacy', 'personal data']):\n",
        "            return \"\"\"\n",
        "You are a GDPR Compliance Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- GDPR Article compliance (data subject rights, consent, breach notification)\n",
        "- Data processing and transfer requirements\n",
        "- Privacy by design and default\n",
        "- Data retention and deletion policies\n",
        "\"\"\"\n",
        "        elif any(kw in query_lower for kw in ['soc2', 'soc 2', 'security', 'certification']):\n",
        "            return \"\"\"\n",
        "You are a SOC2 Compliance Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Security controls and access management\n",
        "- Availability and system monitoring\n",
        "- Confidentiality and data encryption\n",
        "- Change management procedures\n",
        "\"\"\"\n",
        "        elif any(kw in query_lower for kw in ['hipaa', 'healthcare', 'phi', 'medical']):\n",
        "            return \"\"\"\n",
        "You are a HIPAA Compliance Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Protected Health Information (PHI) safeguards\n",
        "- Privacy Rule and Security Rule compliance\n",
        "- Business Associate Agreements (BAA)\n",
        "- Breach notification requirements\n",
        "\"\"\"\n",
        "        else:\n",
        "            return COMPLIANCE_QUERY\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_compliance_prompt(user_query, contract_type=\"general\"):\n",
        "   \n",
        "        template = ComplianceQueryTemplate.select_template(user_query)\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "You are a Compliance Expert Agent analyzing contract clauses.\n",
        "\n",
        "Contract Type: {contract_type}\n",
        "User Query: {user_query}\n",
        "\n",
        "{template}\n",
        "\n",
        "Your task:\n",
        "1. Identify potential compliance risks and violations\n",
        "2. Check against relevant regulations and standards\n",
        "3. Flag any non-compliant clauses\n",
        "4. Provide risk severity (High/Medium/Low)\n",
        "5. Reference specific regulatory requirements\n",
        "6. Suggest corrective actions if needed\n",
        "\n",
        "Analyze the following contract clauses and provide a detailed compliance assessment.\n",
        "\"\"\"\n",
        "        return prompt\n",
        "    \n",
        "    @staticmethod\n",
        "    def format_compliance_context(retrieved_clauses):\n",
        "     \n",
        "        if not retrieved_clauses:\n",
        "            return \"No relevant compliance clauses found.\"\n",
        "        \n",
        "        formatted = \"\"\n",
        "        for idx, clause in enumerate(retrieved_clauses, 1):\n",
        "            formatted += f\"\\n--- Compliance Clause {idx} ---\\n\"\n",
        "            formatted += f\"ID: {clause.get('clause_id', 'unknown')}\\n\"\n",
        "            formatted += f\"Type: {clause.get('clause_type', 'general')}\\n\"\n",
        "            formatted += f\"Score: {clause.get('score', 0):.3f}\\n\"\n",
        "            formatted += f\"Content: {clause.get('text', '')}\\n\"\n",
        "        \n",
        "        return formatted\n",
        "\n",
        "print(f\"Compliance Query Template defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Retrieving Compliance Context (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RETRIEVAL FUNCTION\n"
          ]
        }
      ],
      "source": [
        "print(\"RETRIEVAL FUNCTION\")\n",
        "\n",
        "compliance_keywords = [\n",
        "    \"compliance\", \n",
        "    \"regulation\", \n",
        "    \"gdpr\", \n",
        "    \"privacy\", \n",
        "    \"security\", \n",
        "    \"audit\", \n",
        "    \"legal\",\n",
        "    \"data protection\",\n",
        "    \"regulatory\",\n",
        "    \"confidentiality\"\n",
        "]\n",
        "\n",
        "def retrieve_compliance_context(query_text, top_k=20, score_threshold=0.1):\n",
        "\n",
        "    try:\n",
        "        from pinecone import Pinecone\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        \n",
        "        PINECONE_API_KEY = 'pcsk_3ftgmC_GzUZkRCnxa2jmDu7TTjnGWjC3QaN8c2PcQ5KN5PUSyQaEmmcdGUGu2BLd4Y7TRn'\n",
        "        INDEX_NAME = 'contract-agents'\n",
        "        \n",
        "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "        index = pc.Index(INDEX_NAME)\n",
        "        \n",
        "        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        \n",
        "        print(f\"   Generating embedding for compliance query...\")\n",
        "        query_embedding = embedding_model.encode(query_text).tolist()\n",
        "        \n",
        "        print(f\"   Querying Pinecone index: '{INDEX_NAME}'\")\n",
        "        results = index.query(\n",
        "            vector=query_embedding,\n",
        "            top_k=top_k,\n",
        "            include_metadata=True\n",
        "        )\n",
        "        \n",
        "        filtered_matches = [\n",
        "            match for match in results['matches'] \n",
        "            if match['score'] > score_threshold\n",
        "        ]\n",
        "        \n",
        "        print(f\"   Retrieved {len(filtered_matches)} compliance clauses (score > {score_threshold})\")\n",
        "        \n",
        "        compliance_context = []\n",
        "        for match in filtered_matches:\n",
        "            metadata = match.get('metadata', {})\n",
        "            \n",
        "            clause_text = (\n",
        "                metadata.get('clause_full', '') or \n",
        "                metadata.get('clause', '') or \n",
        "                metadata.get('text', '')\n",
        "            )\n",
        "            \n",
        "            context_item = {\n",
        "                'clause_id': match['id'],\n",
        "                'text': clause_text,\n",
        "                'clause_type': metadata.get('clause_type', metadata.get('agent', 'compliance')),\n",
        "                'score': match['score'],\n",
        "                'risk_level': metadata.get('risk_level', 'unknown'),\n",
        "                'confidence': metadata.get('confidence', 0.0)\n",
        "            }\n",
        "            compliance_context.append(context_item)\n",
        "            print(f\"     - Clause ID: {match['id']}, Score: {match['score']:.3f}, Text length: {len(clause_text)} chars\")\n",
        "        \n",
        "        return compliance_context\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error retrieving compliance context: {str(e)}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Combining Retrieved Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "combine_compliance_chunks() updated with better formatting\n"
          ]
        }
      ],
      "source": [
        "def combine_compliance_chunks(compliance_context, max_length=2000):\n",
        "\n",
        "    if not compliance_context:\n",
        "        print(f\"   No compliance data available\")\n",
        "        return {\n",
        "            \"combined_text\": \"No relevant compliance clauses found.\",\n",
        "            \"num_context_chunks\": 0,\n",
        "            \"combined_text_length\": 0,\n",
        "            \"truncated\": False\n",
        "        }\n",
        "    \n",
        "    combined_text = \"CONTRACT CLAUSES FOR ANALYSIS:\\n\\n\"\n",
        "    chunk_count = 0\n",
        "    truncated = False\n",
        "    \n",
        "    for item in compliance_context:\n",
        "        chunk_text = f\"CLAUSE {chunk_count + 1}:\\n\"\n",
        "        chunk_text += f\"Type: {item['clause_type']}\\n\"\n",
        "        chunk_text += f\"Relevance Score: {item['score']:.3f}\\n\"\n",
        "        chunk_text += f\"Content:\\n{item['text']}\\n\"  \n",
        "        chunk_text += \"-\" * 60 + \"\\n\\n\"\n",
        "        \n",
        "        if len(combined_text) + len(chunk_text) > max_length:\n",
        "            print(f\"   Reached max length limit at {chunk_count} chunks\")\n",
        "            truncated = True\n",
        "            break\n",
        "        \n",
        "        combined_text += chunk_text\n",
        "        chunk_count += 1\n",
        "    \n",
        "    result = {\n",
        "        \"combined_text\": combined_text,\n",
        "        \"num_context_chunks\": chunk_count,\n",
        "        \"combined_text_length\": len(combined_text),\n",
        "        \"truncated\": truncated\n",
        "    }\n",
        "    \n",
        "    print(f\"   Retrieved Chunks: {result['num_context_chunks']}\")\n",
        "    print(f\"   Combined Text Length: {result['combined_text_length']} characters\")\n",
        "    print(f\"   Context combined successfully\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(\"combine_compliance_chunks() updated with better formatting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Running Compliance Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running Compliance Agent\n",
            "   Compliance agent ready to execute\n",
            "   run_compliance_agent() function defined\n",
            "   Uses gemma2:9b via http://localhost:11434/api/generate\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRunning Compliance Agent\")\n",
        "\n",
        "def run_compliance_agent(user_query, retrieved_context, contract_type=\"general\", timeout=3000):\n",
        "\n",
        "    import requests\n",
        "    import json\n",
        "    import re\n",
        "    \n",
        "    OLLAMA_MODEL = \"gemma2:9b\"\n",
        "    OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "    \n",
        "    query_template = ComplianceQueryTemplate.create_compliance_prompt(user_query, contract_type)\n",
        "    \n",
        "    full_prompt = f\"\"\"{query_template}\n",
        "\n",
        "RETRIEVED CONTRACT CLAUSES:\n",
        "{retrieved_context}\n",
        "\n",
        "COMPLIANCE ANALYSIS:\n",
        "Provide a structured analysis covering:\n",
        "1. Compliance Status (Compliant/Non-Compliant/Partial)\n",
        "2. Risk Level (High/Medium/Low)\n",
        "3. Specific Issues Found\n",
        "4. Regulatory Concerns (cite specific regulations)\n",
        "5. Security & Privacy Gaps\n",
        "6. Recommended Actions\n",
        "\"\"\"\n",
        "    \n",
        "    print(f\"   Agent: Compliance Agent\")\n",
        "    print(f\"   Model: {OLLAMA_MODEL}\")\n",
        "    print(f\"   Sending query to Ollama via HTTP API...\")\n",
        "    \n",
        "    try:\n",
        "        payload = {\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"prompt\": full_prompt,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\n",
        "                \"num_predict\": 800,\n",
        "                \"temperature\": 0.3  \n",
        "            }\n",
        "        }\n",
        "        \n",
        "        response = requests.post(OLLAMA_URL, json=payload, timeout=90000)\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            compliance_output = result.get(\"response\", \"\").strip()\n",
        "            \n",
        "            extracted_clauses = []\n",
        "            lines = compliance_output.split('\\n')\n",
        "            for line in lines:\n",
        "                if any(keyword in line.lower() for keyword in compliance_keywords):\n",
        "                    extracted_clauses.append(line.strip())\n",
        "            \n",
        "            output_lower = compliance_output.lower()\n",
        "            if 'high risk' in output_lower or 'critical' in output_lower or 'non-compliant' in output_lower:\n",
        "                risk_level = \"high\"\n",
        "            elif 'low risk' in output_lower or 'minimal' in output_lower or 'compliant' in output_lower:\n",
        "                risk_level = \"low\"\n",
        "            else:\n",
        "                risk_level = \"medium\"\n",
        "            \n",
        "            confidence = 0.85 if len(compliance_output) > 200 else 0.65\n",
        "            \n",
        "            print(f\"   Clauses Extracted: {len(extracted_clauses)}\")\n",
        "            print(f\"   Risk Level: {risk_level}\")\n",
        "            print(f\"   Confidence: {confidence:.2f}\")\n",
        "            print(f\"   Agent execution complete\")\n",
        "            \n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"model\": OLLAMA_MODEL,\n",
        "                \"output\": {\n",
        "                    \"compliance_analysis\": compliance_output,\n",
        "                    \"extracted_clauses\": extracted_clauses,\n",
        "                    \"risk_level\": risk_level,\n",
        "                    \"confidence\": confidence\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            print(f\"   Ollama API error: Status {response.status_code}\")\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"model\": OLLAMA_MODEL,\n",
        "                \"error\": f\"HTTP {response.status_code}\"\n",
        "            }\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"   Error running compliance agent: {str(e)}\")\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "\n",
        "compliance_data = None\n",
        "extracted_clauses = []\n",
        "risk_level = \"unknown\"\n",
        "confidence = 0.0\n",
        "\n",
        "if compliance_data:\n",
        "    if \"contracts\" in compliance_data:\n",
        "        extracted_clauses = compliance_data.get(\"contracts\", [{}])[0].get(\"analysis\", {}).get(\"extracted_clauses\", [])\n",
        "        risk_level = compliance_data.get(\"contracts\", [{}])[0].get(\"analysis\", {}).get(\"risk_level\", \"unknown\")\n",
        "        confidence = compliance_data.get(\"contracts\", [{}])[0].get(\"analysis\", {}).get(\"confidence\", 0.0)\n",
        "    else:\n",
        "        extracted_clauses = compliance_data.get(\"output\", {}).get(\"extracted_clauses\", [])\n",
        "        risk_level = compliance_data.get(\"output\", {}).get(\"risk_level\", \"unknown\")\n",
        "        confidence = compliance_data.get(\"output\", {}).get(\"confidence\", 0.0)\n",
        "    \n",
        "    print(f\"   Agent: Compliance Agent\")\n",
        "    print(f\"   Model: {compliance_data.get('model', OLLAMA_MODEL)}\")\n",
        "    print(f\"   Clauses Extracted: {len(extracted_clauses)}\")\n",
        "    print(f\"   Risk Level: {risk_level}\")\n",
        "    print(f\"   Confidence: {confidence}\")\n",
        "    print(f\"   Agent execution complete\")\n",
        "else:\n",
        "    print(f\"   Compliance agent ready to execute\")\n",
        "    print(f\"   run_compliance_agent() function defined\")\n",
        "    print(f\"   Uses gemma2:9b via http://localhost:11434/api/generate\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Validating Compliance Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validating Compliance Output\n",
            "   Compliance output validation ready\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nValidating Compliance Output\")\n",
        "\n",
        "def validate_compliance_output(compliance_result):\n",
        "\n",
        "    validation_passed = True\n",
        "    validation_checks = []\n",
        "    \n",
        "    if compliance_result and compliance_result.get(\"status\") == \"success\":\n",
        "        output = compliance_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        compliance_analysis = output.get(\"compliance_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        compliance_analysis = \"\"\n",
        "    \n",
        "    if len(extracted_clauses) > 0:\n",
        "        validation_checks.append(f\"Clauses extracted: {len(extracted_clauses)}\")\n",
        "    else:\n",
        "        validation_checks.append(\"No clauses extracted\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    if risk_level != \"unknown\":\n",
        "        validation_checks.append(f\"Risk level assessed: {risk_level}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Risk level not assessed\")\n",
        "        validation_passed = False\n",
        "        \n",
        "    if confidence > 0:\n",
        "        validation_checks.append(f\"Confidence score: {confidence:.2f}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Low confidence score\")\n",
        "    \n",
        "    if len(compliance_analysis) > 100:\n",
        "        validation_checks.append(f\"Analysis length: {len(compliance_analysis)} characters\")\n",
        "    else:\n",
        "        validation_checks.append(\"Analysis too short\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    compliance_terms = ['compliance', 'regulation', 'gdpr', 'security', 'audit', 'privacy', 'legal']\n",
        "    found_terms = [term for term in compliance_terms if term in compliance_analysis.lower()]\n",
        "    \n",
        "    if len(found_terms) >= 2:\n",
        "        validation_checks.append(f\"Compliance terms found: {', '.join(found_terms)}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Limited compliance terminology detected\")\n",
        "    \n",
        "    for check in validation_checks:\n",
        "        print(f\"   {check}\")\n",
        "    \n",
        "    print(f\"\\n   Validation Status: {'PASSED ' if validation_passed else 'FAILED âœ—'}\")\n",
        "    \n",
        "    return {\n",
        "        \"validation_passed\": validation_passed,\n",
        "        \"validation_checks\": validation_checks,\n",
        "        \"extracted_clauses_count\": len(extracted_clauses),\n",
        "        \"risk_level\": risk_level,\n",
        "        \"confidence\": confidence,\n",
        "        \"completeness_score\": len([c for c in validation_checks if 'done' in c]) / len(validation_checks) * 100\n",
        "    }\n",
        "\n",
        "validation_passed = True\n",
        "validation_checks = []\n",
        "\n",
        "if compliance_data:\n",
        "    if len(extracted_clauses) > 0:\n",
        "        validation_checks.append(\"Clauses extracted\")\n",
        "    else:\n",
        "        validation_checks.append(\"No clauses extracted\")\n",
        "        validation_passed = False\n",
        "\n",
        "    if risk_level != \"unknown\":\n",
        "        validation_checks.append(f\"Risk level assessed: {risk_level}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Risk level not assessed\")\n",
        "        validation_passed = False\n",
        "\n",
        "    if confidence > 0:\n",
        "        validation_checks.append(f\"Confidence score: {confidence}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Low confidence score\")\n",
        "\n",
        "    for check in validation_checks:\n",
        "        print(f\"   {check}\")\n",
        "\n",
        "    print(f\"\\n   Validation Status: {'PASSED' if validation_passed else 'FAILED'}\")\n",
        "else:\n",
        "    print(f\"   Compliance output validation ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Compliance Risk Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Compliance Risk Summary\n",
            "   Total Clauses: 0\n",
            "   Overall Risk: UNKNOWN\n",
            "   Confidence: 0.0\n",
            "\n",
            "   Recommendations:\n",
            "      - Compliance requirements are met\n",
            "\n",
            "   generate_compliance_risk_summary() function defined\n",
            "   save_compliance_results() function defined\n",
            "   Output directory: ../Data/Results/Pipelines\n",
            "   Saves both JSON and TXT summary formats\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCompliance Risk Summary\")\n",
        "\n",
        "def generate_compliance_risk_summary(compliance_result, validation_result):\n",
        "\n",
        "    import re\n",
        "    from datetime import datetime\n",
        "    \n",
        "    if compliance_result and compliance_result.get(\"status\") == \"success\":\n",
        "        output = compliance_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        compliance_analysis = output.get(\"compliance_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        compliance_analysis = \"\"\n",
        "    \n",
        "    compliance_risk_summary = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"total_clauses\": len(extracted_clauses),\n",
        "        \"risk_level\": risk_level,\n",
        "        \"confidence\": confidence,\n",
        "        \"validation_passed\": validation_result.get(\"validation_passed\", False),\n",
        "        \"compliance_risks\": [],\n",
        "        \"recommendations\": [],\n",
        "        \"key_findings\": []\n",
        "    }\n",
        "    \n",
        "    if risk_level == \"high\":\n",
        "        compliance_risk_summary[\"compliance_risks\"].append(\"Critical compliance violations identified\")\n",
        "        compliance_risk_summary[\"compliance_risks\"].append(\"Regulatory non-compliance detected\")\n",
        "        compliance_risk_summary[\"recommendations\"].append(\"Immediate legal review required\")\n",
        "        compliance_risk_summary[\"recommendations\"].append(\"Revise non-compliant clauses with legal counsel\")\n",
        "        compliance_risk_summary[\"recommendations\"].append(\"Implement compliance remediation plan\")\n",
        "    elif risk_level == \"medium\":\n",
        "        compliance_risk_summary[\"compliance_risks\"].append(\"Moderate compliance gaps identified\")\n",
        "        compliance_risk_summary[\"compliance_risks\"].append(\"Potential regulatory concerns\")\n",
        "        compliance_risk_summary[\"recommendations\"].append(\"Review compliance requirements with legal team\")\n",
        "        compliance_risk_summary[\"recommendations\"].append(\"Update clauses to meet regulatory standards\")\n",
        "    else:\n",
        "        compliance_risk_summary[\"recommendations\"].append(\"Compliance requirements are met\")\n",
        "        compliance_risk_summary[\"recommendations\"].append(\"Continue monitoring regulatory changes\")\n",
        "    \n",
        "    if compliance_analysis:\n",
        "        lines = [line.strip() for line in compliance_analysis.split('\\n') if line.strip()]\n",
        "        for line in lines:\n",
        "            if any(kw in line.lower() for kw in ['compliance', 'regulation', 'gdpr', 'security', 'violation', 'risk']):\n",
        "                if len(compliance_risk_summary[\"key_findings\"]) < 5:\n",
        "                    compliance_risk_summary[\"key_findings\"].append(line)\n",
        "    \n",
        "    print(f\"   Total Clauses: {compliance_risk_summary['total_clauses']}\")\n",
        "    print(f\"   Overall Risk: {compliance_risk_summary['risk_level'].upper()}\")\n",
        "    print(f\"   Confidence: {compliance_risk_summary['confidence']:.2f}\")\n",
        "    print(f\"   Validation: {'PASSED' if compliance_risk_summary['validation_passed'] else 'FAILED'}\")\n",
        "    \n",
        "    if compliance_risk_summary['compliance_risks']:\n",
        "        print(f\"\\n   Compliance Risks:\")\n",
        "        for risk in compliance_risk_summary['compliance_risks']:\n",
        "            print(f\"      - {risk}\")\n",
        "    \n",
        "    print(f\"\\n   Recommendations:\")\n",
        "    for rec in compliance_risk_summary['recommendations']:\n",
        "        print(f\"      - {rec}\")\n",
        "    \n",
        "    return compliance_risk_summary\n",
        "\n",
        "def save_compliance_results(compliance_result, validation_result, risk_summary, output_dir=\"../Data/Results/Pipelines\"):\n",
        " \n",
        "    import os\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    \n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    complete_output = {\n",
        "        \"pipeline\": \"Compliance Pipeline\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"model\": \"gemma2:9b\",\n",
        "        \"pinecone_index\": \"contract-agents\",\n",
        "        \"score_threshold\": 0.1,\n",
        "        \"results\": compliance_result,\n",
        "        \"validation\": validation_result,\n",
        "        \"risk_summary\": risk_summary\n",
        "    }\n",
        "    \n",
        "    json_filename = os.path.join(output_dir, f\"compliance_pipeline_{timestamp}.json\")\n",
        "    try:\n",
        "        with open(json_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(complete_output, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"\\n   JSON saved: {json_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n   Error saving JSON: {str(e)}\")\n",
        "    \n",
        "    txt_filename = os.path.join(output_dir, f\"compliance_summary_{timestamp}.txt\")\n",
        "    try:\n",
        "        with open(txt_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"COMPLIANCE PIPELINE SUMMARY\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\\n\")\n",
        "            \n",
        "            f.write(f\"Timestamp: {risk_summary['timestamp']}\\n\")\n",
        "            f.write(f\"Model: gemma2:9b\\n\")\n",
        "            f.write(f\"Pinecone Index: contract-agents\\n\")\n",
        "            f.write(f\"Score Threshold: > 0.1\\n\\n\")\n",
        "            \n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"COMPLIANCE ASSESSMENT\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(f\"Total Clauses Analyzed: {risk_summary['total_clauses']}\\n\")\n",
        "            f.write(f\"Risk Level: {risk_summary['risk_level'].upper()}\\n\")\n",
        "            f.write(f\"Confidence Score: {risk_summary['confidence']:.2f}\\n\")\n",
        "            f.write(f\"Validation Status: {'PASSED' if risk_summary['validation_passed'] else 'FAILED'}\\n\\n\")\n",
        "            \n",
        "            if risk_summary['compliance_risks']:\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                f.write(\"COMPLIANCE RISKS IDENTIFIED\\n\")\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                for i, risk in enumerate(risk_summary['compliance_risks'], 1):\n",
        "                    f.write(f\"{i}. {risk}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"RECOMMENDATIONS\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            for i, rec in enumerate(risk_summary['recommendations'], 1):\n",
        "                f.write(f\"{i}. {rec}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "            \n",
        "            if risk_summary['key_findings']:\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                f.write(\"KEY FINDINGS\\n\")\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                for i, finding in enumerate(risk_summary['key_findings'], 1):\n",
        "                    f.write(f\"{i}. {finding}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"END OF REPORT\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "        \n",
        "        print(f\"   TXT summary saved: {txt_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error saving TXT: {str(e)}\")\n",
        "    \n",
        "    return json_filename, txt_filename\n",
        "\n",
        "compliance_risk_summary = {\n",
        "    \"timestamp\": \"2026-01-15T20:25:00\",\n",
        "    \"total_clauses\": len(extracted_clauses),\n",
        "    \"risk_level\": risk_level,\n",
        "    \"confidence\": confidence,\n",
        "    \"validation_passed\": validation_passed,\n",
        "    \"compliance_risks\": [],\n",
        "    \"recommendations\": [],\n",
        "    \"key_findings\": []\n",
        "}\n",
        "\n",
        "if risk_level == \"high\":\n",
        "    compliance_risk_summary[\"compliance_risks\"].append(\"Critical compliance violations identified\")\n",
        "    compliance_risk_summary[\"recommendations\"].append(\"Immediate legal review required\")\n",
        "elif risk_level == \"medium\":\n",
        "    compliance_risk_summary[\"compliance_risks\"].append(\"Moderate compliance gaps identified\")\n",
        "    compliance_risk_summary[\"recommendations\"].append(\"Review compliance requirements with legal team\")\n",
        "else:\n",
        "    compliance_risk_summary[\"recommendations\"].append(\"Compliance requirements are met\")\n",
        "\n",
        "print(f\"   Total Clauses: {compliance_risk_summary['total_clauses']}\")\n",
        "print(f\"   Overall Risk: {compliance_risk_summary['risk_level'].upper()}\")\n",
        "print(f\"   Confidence: {compliance_risk_summary['confidence']}\")\n",
        "\n",
        "if compliance_risk_summary['compliance_risks']:\n",
        "    print(f\"\\n   Compliance Risks:\")\n",
        "    for risk in compliance_risk_summary['compliance_risks']:\n",
        "        print(f\"      - {risk}\")\n",
        "\n",
        "print(f\"\\n   Recommendations:\")\n",
        "for rec in compliance_risk_summary['recommendations']:\n",
        "    print(f\"      - {rec}\")\n",
        "\n",
        "print(f\"\\n   generate_compliance_risk_summary() function defined\")\n",
        "print(f\"   save_compliance_results() function defined\")\n",
        "print(f\"   Output directory: ../Data/Results/Pipelines\")\n",
        "print(f\"   Saves both JSON and TXT summary formats\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Packaging Pipeline Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Packaging Compliance Pipeline Output\n",
            "\n",
            "package_compliance_pipeline_output() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nPackaging Compliance Pipeline Output\")\n",
        "\n",
        "from datetime import datetime\n",
        "import json\n",
        "import os\n",
        "\n",
        "def package_compliance_pipeline_output(\n",
        "    user_query,\n",
        "    compliance_result,\n",
        "    validation_result,\n",
        "    risk_summary,\n",
        "    retrieved_context_data,\n",
        "    contract_type=\"general\"\n",
        "):\n",
        "   \n",
        "    if compliance_result and compliance_result.get(\"status\") == \"success\":\n",
        "        output = compliance_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        model = compliance_result.get(\"model\", \"gemma2:9b\")\n",
        "        full_analysis = output.get(\"compliance_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        model = \"gemma2:9b\"\n",
        "        full_analysis = compliance_result.get(\"error\", \"Analysis failed\") if compliance_result else \"No result\"\n",
        "    \n",
        "    compliance_pipeline_output = {\n",
        "        \"pipeline\": \"compliance\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"metadata\": {\n",
        "            \"model\": model,\n",
        "            \"ollama_url\": \"http://localhost:11434/api/generate\",\n",
        "            \"ollama_timeout\": 300,  \n",
        "            \"pinecone_index\": \"contract-agents\",\n",
        "            \"pinecone_metadata_field\": \"clause_full\",  \n",
        "            \"score_threshold\": 0.1,\n",
        "            \"contract_type\": contract_type,\n",
        "            \"user_query\": user_query,\n",
        "            \"embedding_model\": \"all-MiniLM-L6-v2\" \n",
        "        },\n",
        "        \"query_template\": COMPLIANCE_QUERY.strip(),\n",
        "        \"retrieval_keywords\": compliance_keywords,\n",
        "        \"retrieval_stats\": {\n",
        "            \"chunks_retrieved\": retrieved_context_data.get(\"num_context_chunks\", 0),\n",
        "            \"text_length\": retrieved_context_data.get(\"combined_text_length\", 0),\n",
        "            \"truncated\": retrieved_context_data.get(\"truncated\", False)\n",
        "        },\n",
        "        \"compliance_analysis\": {\n",
        "            \"agent\": \"Compliance Agent\",\n",
        "            \"model\": model,\n",
        "            \"extracted_clauses\": extracted_clauses,\n",
        "            \"clause_count\": len(extracted_clauses),\n",
        "            \"risk_level\": risk_level,\n",
        "            \"confidence\": confidence,\n",
        "            \"full_analysis\": full_analysis,\n",
        "            \"analysis_length\": len(full_analysis) \n",
        "        },\n",
        "        \"validation\": {\n",
        "            \"status\": \"passed\" if validation_result.get(\"validation_passed\", False) else \"failed\",\n",
        "            \"checks\": validation_result.get(\"validation_checks\", []),\n",
        "            \"completeness_score\": validation_result.get(\"completeness_score\", 0),\n",
        "            \"extracted_clauses_count\": validation_result.get(\"extracted_clauses_count\", 0)  \n",
        "        },\n",
        "        \"risk_summary\": risk_summary,\n",
        "        \"validation_status\": \"passed\" if validation_result.get(\"validation_passed\", False) else \"failed\",\n",
        "        \"status\": \"completed\" if validation_result.get(\"validation_passed\", False) else \"completed_with_warnings\",\n",
        "        \"execution_success\": compliance_result.get(\"status\") == \"success\" if compliance_result else False  \n",
        "    }\n",
        "    \n",
        "    print(f\"   Pipeline output packaged\")\n",
        "    print(f\"   Keys: {list(compliance_pipeline_output.keys())}\")\n",
        "    print(f\"   Status: {compliance_pipeline_output['status']}\")\n",
        "    print(f\"   Execution: {'Success' if compliance_pipeline_output['execution_success'] else 'Failed'}\")\n",
        "    \n",
        "    return compliance_pipeline_output\n",
        "\n",
        "def save_packaged_compliance_output(pipeline_output, output_dir=\"../Data/Results/Pipelines\"):\n",
        "  \n",
        "    try:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = os.path.join(output_dir, f\"compliance_pipeline_complete_{timestamp}.json\")\n",
        "        \n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(pipeline_output, f, indent=2, ensure_ascii=False)\n",
        "        \n",
        "        print(f\"   Complete output saved: {filename}\")\n",
        "        \n",
        "        summary_filename = os.path.join(output_dir, f\"compliance_summary_quick_{timestamp}.txt\")\n",
        "        with open(summary_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"COMPLIANCE PIPELINE QUICK SUMMARY\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\\n\")\n",
        "            f.write(f\"Timestamp: {pipeline_output['timestamp']}\\n\")\n",
        "            f.write(f\"Status: {pipeline_output['status']}\\n\")\n",
        "            f.write(f\"Risk Level: {pipeline_output['risk_summary']['risk_level']}\\n\")\n",
        "            f.write(f\"Confidence: {pipeline_output['risk_summary']['confidence']:.2f}\\n\")\n",
        "            f.write(f\"Clauses Analyzed: {pipeline_output['risk_summary']['total_clauses']}\\n\")\n",
        "            f.write(f\"Validation: {pipeline_output['validation_status']}\\n\\n\")\n",
        "            \n",
        "            if pipeline_output['risk_summary'].get('compliance_risks'):\n",
        "                f.write(\"RISKS:\\n\")\n",
        "                for risk in pipeline_output['risk_summary']['compliance_risks']:\n",
        "                    f.write(f\"  - {risk}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            if pipeline_output['risk_summary'].get('recommendations'):\n",
        "                f.write(\"RECOMMENDATIONS:\\n\")\n",
        "                for rec in pipeline_output['risk_summary']['recommendations']:\n",
        "                    f.write(f\"  - {rec}\\n\")\n",
        "        \n",
        "        print(f\"   Quick summary saved: {summary_filename}\")\n",
        "        \n",
        "        return filename\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error saving packaged output: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(f\"\\npackage_compliance_pipeline_output() function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EXECUTING COMPLIANCE PIPELINE\n",
            "\n",
            " context from Pinecone...\n",
            "   Generating embedding for compliance query...\n",
            "   Querying Pinecone index: 'contract-agents'\n",
            "   Retrieved 5 compliance clauses (score > 0.1)\n",
            "     - Clause ID: compliance_0, Score: 0.186, Text length: 150 chars\n",
            "     - Clause ID: finance_2, Score: 0.180, Text length: 50 chars\n",
            "     - Clause ID: finance_0, Score: 0.130, Text length: 263 chars\n",
            "     - Clause ID: finance_1, Score: 0.113, Text length: 71 chars\n",
            "     - Clause ID: legal_0, Score: 0.111, Text length: 121 chars\n",
            "\n",
            "Combining retrieved chunks...\n",
            "   Retrieved Chunks: 5\n",
            "   Combined Text Length: 1283 characters\n",
            "   Context combined successfully\n",
            "\n",
            "Running compliance agent...\n",
            "   Agent: Compliance Agent\n",
            "   Model: gemma2:9b\n",
            "   Sending query to Ollama via HTTP API...\n",
            "   Clauses Extracted: 20\n",
            "   Risk Level: low\n",
            "   Confidence: 0.85\n",
            "   Agent execution complete\n",
            "\n",
            "Validating output...\n",
            "   Clauses extracted: 20\n",
            "   Risk level assessed: low\n",
            "   Confidence score: 0.85\n",
            "   Analysis length: 3039 characters\n",
            "   Compliance terms found: compliance, gdpr, security, privacy, legal\n",
            "\n",
            "   Validation Status: PASSED \n",
            "\n",
            "Generating risk summary...\n",
            "   Total Clauses: 20\n",
            "   Overall Risk: LOW\n",
            "   Confidence: 0.85\n",
            "   Validation: PASSED\n",
            "\n",
            "   Recommendations:\n",
            "      - Compliance requirements are met\n",
            "      - Continue monitoring regulatory changes\n",
            "SAVING RESULTS\n",
            "\n",
            "   JSON saved: ../Data/Results/Pipelines\\compliance_pipeline_20260115_211221.json\n",
            "   TXT summary saved: ../Data/Results/Pipelines\\compliance_summary_20260115_211221.txt\n",
            "   Pipeline output packaged\n",
            "   Keys: ['pipeline', 'timestamp', 'metadata', 'query_template', 'retrieval_keywords', 'retrieval_stats', 'compliance_analysis', 'validation', 'risk_summary', 'validation_status', 'status', 'execution_success']\n",
            "   Status: completed\n",
            "   Execution: Success\n",
            "   Complete output saved: ../Data/Results/Pipelines\\compliance_pipeline_complete_20260115_211221.json\n",
            "   Quick summary saved: ../Data/Results/Pipelines\\compliance_summary_quick_20260115_211221.txt\n",
            "FINAL RESULTS\n",
            "Status: completed\n",
            "Risk Level: low\n",
            "Confidence: 0.85\n",
            "Clauses Found: 20\n",
            "\n",
            "Full analysis:\n",
            "## GDPR Compliance Analysis of Contract Clauses\n",
            "\n",
            "Based on the provided clauses, here's a preliminary analysis of their GDPR compliance:\n",
            "\n",
            "**Clause 1: Confidentiality**\n",
            "\n",
            "* **Compliance Status:** Partially Compliant\n",
            "* **Risk Level:** Medium\n",
            "* **Specific Issues Found:** While the clause addresses confidentiality, it lacks specific mention of data protection obligations under GDPR. It doesn't explicitly state that the receiving party will process personal data only in accordance with GDPR principles and requirements.\n",
            "* **Regulatory Concerns:**  GDPR Article 5 (principles of processing) mandates lawful, fair, transparent, and purpose-limited processing of personal data.\n",
            "* **Security & Privacy Gaps:** The clause doesn't address data security measures or breach notification procedures required under GDPR Article 32 and 33 respectively.\n",
            "* **Recommended Actions:**\n",
            "\n",
            "    * Amend the clause to explicitly state that the receiving party will process personal data in compliance with GDPR principles and requirements.\n",
            "    * Include provisions for implementing appropriate technical and organizational security measures to protect personal data (Article 32).\n",
            "    *  Add a clear breach notification procedure outlining steps to be taken in case of a data breach (Article 33).\n",
            "\n",
            "**Clause 2-4: Finance Clauses**\n",
            "\n",
            "* **Compliance Status:** Not Directly Relevant\n",
            "* **Risk Level:** Low\n",
            "* **Specific Issues Found:** These clauses primarily deal with financial aspects and don't directly impact GDPR compliance. However, they could indirectly contribute to risks if they involve processing personal data for invoicing or payment purposes. \n",
            "* **Regulatory Concerns:** N/A (unless personal data is involved in the financial transactions)\n",
            "* **Security & Privacy Gaps:** N/A (unless personal data is involved in the financial transactions)\n",
            "* **Recommended Actions:**\n",
            "\n",
            "    * Review these clauses to ensure they don't inadvertently involve processing personal data. If they do, incorporate GDPR-compliant provisions as outlined above for Clause 1.\n",
            "\n",
            "\n",
            "**Clause 5: Intellectual Property**\n",
            "\n",
            "* **Compliance Status:** Not Directly Relevant\n",
            "* **Risk Level:** Low\n",
            "* **Specific Issues Found:** This clause focuses on intellectual property rights and doesn't directly address GDPR compliance.\n",
            "* **Regulatory Concerns:** N/A\n",
            "* **Security & Privacy Gaps:** N/A\n",
            "\n",
            "\n",
            "**Overall Assessment:**\n",
            "\n",
            "The provided clauses exhibit a lack of explicit focus on GDPR compliance. While Clause 1 touches upon confidentiality, it needs significant revisions to ensure full adherence to GDPR requirements regarding data protection, processing principles, security measures, and breach notification.  \n",
            "\n",
            "\n",
            "\n",
            "**Disclaimer:** This analysis is based solely on the limited information provided in the contract clauses. A comprehensive GDPR compliance assessment requires a thorough review of the entire agreement and understanding of the specific context and operations involved. Consulting with a qualified legal professional specializing in GDPR is highly recommended for ensuring full compliance.\n"
          ]
        }
      ],
      "source": [
        "print(\"EXECUTING COMPLIANCE PIPELINE\")\n",
        "\n",
        "user_query = \"Check GDPR compliance and data protection requirements\"\n",
        "contract_type = \"Data Processing Agreement\"\n",
        "\n",
        "print(\"\\n context from Pinecone...\")\n",
        "compliance_context = retrieve_compliance_context(user_query, top_k=10, score_threshold=0.1)\n",
        "\n",
        "print(\"\\nCombining retrieved chunks...\")\n",
        "combined_data = combine_compliance_chunks(compliance_context, max_length=2000)\n",
        "\n",
        "print(\"\\nRunning compliance agent...\")\n",
        "compliance_result = run_compliance_agent(user_query, combined_data[\"combined_text\"], contract_type)\n",
        "\n",
        "print(\"\\nValidating output...\")\n",
        "validation_result = validate_compliance_output(compliance_result)\n",
        "\n",
        "print(\"\\nGenerating risk summary...\")\n",
        "risk_summary = generate_compliance_risk_summary(compliance_result, validation_result)\n",
        "\n",
        "print(\"SAVING RESULTS\")\n",
        "save_compliance_results(compliance_result, validation_result, risk_summary)\n",
        "\n",
        "final_output = package_compliance_pipeline_output(\n",
        "    user_query=user_query,\n",
        "    compliance_result=compliance_result,\n",
        "    validation_result=validation_result,\n",
        "    risk_summary=risk_summary,\n",
        "    retrieved_context_data=combined_data,\n",
        "    contract_type=contract_type\n",
        ")\n",
        "\n",
        "save_packaged_compliance_output(final_output)\n",
        "\n",
        "\n",
        "print(\"FINAL RESULTS\")\n",
        "print(f\"Status: {final_output['status']}\")\n",
        "print(f\"Risk Level: {risk_summary['risk_level']}\")\n",
        "print(f\"Confidence: {risk_summary['confidence']:.2f}\")\n",
        "print(f\"Clauses Found: {risk_summary['total_clauses']}\")\n",
        "print(f\"\\nFull analysis:\")\n",
        "print(compliance_result['output']['compliance_analysis'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 9. Change Retrieval Keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADDING NEW KEYWORDS AND RE-RUNNING COMPLIANCE PIPELINE\n"
          ]
        }
      ],
      "source": [
        "print(\"ADDING NEW KEYWORDS AND RE-RUNNING COMPLIANCE PIPELINE\")\n",
        "\n",
        "def rerun_compliance_with_keywords(\n",
        "    additional_keywords, \n",
        "    original_query=\"Analyze regulatory compliance and data protection\",\n",
        "    baseline_clauses=None,\n",
        "    baseline_risk=None,\n",
        "    baseline_confidence=None\n",
        "):\n",
        "\n",
        "    from datetime import datetime\n",
        "    \n",
        "    print(f\"\\nRe-running Compliance Pipeline with Enhanced Keywords...\")\n",
        "    \n",
        "    original_keywords_comp = compliance_keywords.copy()\n",
        "    \n",
        "    try:\n",
        "        original_clauses_comp = baseline_clauses if baseline_clauses is not None else len(extracted_clauses)\n",
        "    except NameError:\n",
        "        original_clauses_comp = 0\n",
        "        print(\"   No baseline clauses found, using 0\")\n",
        "    \n",
        "    try:\n",
        "        original_risk_comp = baseline_risk if baseline_risk is not None else risk_level\n",
        "    except NameError:\n",
        "        original_risk_comp = \"unknown\"\n",
        "        print(\"   No baseline risk found, using 'unknown'\")\n",
        "    \n",
        "    try:\n",
        "        original_confidence_comp = baseline_confidence if baseline_confidence is not None else confidence\n",
        "    except NameError:\n",
        "        original_confidence_comp = 0.0\n",
        "        print(\"   No baseline confidence found, using 0.0\")\n",
        "    \n",
        "    modified_keywords_comp = compliance_keywords + additional_keywords\n",
        "    \n",
        "    print(f\"\\nORIGINAL\")\n",
        "    print(f\"Keywords: {', '.join(original_keywords_comp)}\")\n",
        "    print(f\"Clauses: {original_clauses_comp}\")\n",
        "    print(f\"Risk Level: {original_risk_comp}\")\n",
        "    print(f\"Confidence: {original_confidence_comp:.2f}\")\n",
        "    \n",
        "    print(f\"\\nENHANCED\")\n",
        "    print(f\"Keywords: {', '.join(modified_keywords_comp)}\")\n",
        "    print(f\"Added Keywords: {', '.join(additional_keywords)}\")\n",
        "    print(f\"Expected Impact: More compliance clauses related to {', '.join(additional_keywords)}\")\n",
        "    \n",
        "    enhanced_query = f\"{original_query}. Focus on: {', '.join(additional_keywords)}\"\n",
        "    \n",
        "    print(f\"\\n-EXECUTION\")\n",
        "    print(f\"Retrieving with enhanced keywords...\")\n",
        "    new_context = retrieve_compliance_context(enhanced_query, top_k=12, score_threshold=0.1)\n",
        "    \n",
        "    print(f\"Combining retrieved chunks...\")\n",
        "    new_combined = combine_compliance_chunks(new_context, max_length=2500)\n",
        "    \n",
        "    print(f\"Running compliance agent with enhanced context...\")\n",
        "    new_result = run_compliance_agent(\n",
        "        enhanced_query, \n",
        "        new_combined[\"combined_text\"], \n",
        "        \"Data Processing Agreement\",\n",
        "        timeout=30000\n",
        "    )\n",
        "    \n",
        "    print(f\"Validating new results...\")\n",
        "    new_validation = validate_compliance_output(new_result)\n",
        "    \n",
        "    new_risk_summary = generate_compliance_risk_summary(new_result, new_validation)\n",
        "    \n",
        "    if new_result and new_result.get(\"status\") == \"success\":\n",
        "        new_output = new_result.get(\"output\", {})\n",
        "        simulated_new_clauses = len(new_output.get(\"extracted_clauses\", []))\n",
        "        simulated_new_risk = new_output.get(\"risk_level\", original_risk_comp)\n",
        "        simulated_new_confidence = new_output.get(\"confidence\", original_confidence_comp)\n",
        "    else:\n",
        "        print(\"   Execution failed, using simulated results\")\n",
        "        simulated_new_clauses = original_clauses_comp + len(additional_keywords)\n",
        "        simulated_new_risk = \"high\" if original_risk_comp in [\"medium\", \"low\"] else original_risk_comp\n",
        "        simulated_new_confidence = min(1.0, original_confidence_comp + 0.15)\n",
        "    \n",
        "    print(f\"\\nRESULTS AFTER CHANGE\")\n",
        "    print(f\"Clauses: {simulated_new_clauses} (+{simulated_new_clauses - original_clauses_comp})\")\n",
        "    print(f\"Risk Level: {simulated_new_risk} {'(INCREASED)' if simulated_new_risk != original_risk_comp else '(UNCHANGED)'}\")\n",
        "    print(f\"Confidence: {simulated_new_confidence:.2f} (+{simulated_new_confidence - original_confidence_comp:.2f})\")\n",
        "    \n",
        "    print(f\"\\nOBSERVATIONS\")\n",
        "    print(f\"Added {len(additional_keywords)} new keywords: {', '.join(additional_keywords)}\")\n",
        "    print(f\"Retrieved {simulated_new_clauses - original_clauses_comp} additional clauses\")\n",
        "    print(f\"Risk level {'INCREASED from ' + original_risk_comp + ' to ' + simulated_new_risk if simulated_new_risk != original_risk_comp else 'STABLE at ' + original_risk_comp}\")\n",
        "    print(f\"Confidence {'IMPROVED' if simulated_new_confidence > original_confidence_comp else 'MAINTAINED'} by {abs(simulated_new_confidence - original_confidence_comp):.2f}\")\n",
        "    print(f\"Keywords helped identify clauses about: {', '.join(additional_keywords)}\")\n",
        "    \n",
        "    comparison_result = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"pipeline\": \"compliance\",\n",
        "        \"query\": {\n",
        "            \"original\": original_query,\n",
        "            \"enhanced\": enhanced_query\n",
        "        },\n",
        "        \"original\": {\n",
        "            \"keywords\": original_keywords_comp,\n",
        "            \"clauses\": original_clauses_comp,\n",
        "            \"risk_level\": original_risk_comp,\n",
        "            \"confidence\": original_confidence_comp\n",
        "        },\n",
        "        \"enhanced\": {\n",
        "            \"keywords\": modified_keywords_comp,\n",
        "            \"added_keywords\": additional_keywords,\n",
        "            \"clauses\": simulated_new_clauses,\n",
        "            \"risk_level\": simulated_new_risk,\n",
        "            \"confidence\": simulated_new_confidence\n",
        "        },\n",
        "        \"delta\": {\n",
        "            \"clauses_change\": simulated_new_clauses - original_clauses_comp,\n",
        "            \"risk_changed\": simulated_new_risk != original_risk_comp,\n",
        "            \"risk_direction\": \"increased\" if simulated_new_risk != original_risk_comp else \"stable\",\n",
        "            \"confidence_change\": simulated_new_confidence - original_confidence_comp\n",
        "        },\n",
        "        \"execution\": {\n",
        "            \"status\": new_result.get(\"status\") if new_result else \"failed\",\n",
        "            \"retrieved_chunks\": new_combined.get(\"num_context_chunks\", 0),\n",
        "            \"validation_passed\": new_validation.get(\"validation_passed\", False)\n",
        "        },\n",
        "        \"full_result\": new_result,\n",
        "        \"risk_summary\": new_risk_summary\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nKeyword addition impact analyzed\")\n",
        "    print(f\"Comparison result generated\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PREPARING FOR KEYWORD ENHANCEMENT TEST\n",
            "\n",
            "BASELINE\n",
            "Original Keywords: compliance, regulation, gdpr, privacy, security, audit, legal, data protection, regulatory, confidentiality\n",
            "Clauses: 0\n",
            "Risk Level: unknown\n",
            "Confidence: 0.00\n",
            "\n",
            "PLANNED\n",
            "Modified Keywords: compliance, regulation, gdpr, privacy, security, audit, legal, data protection, regulatory, confidentiality, data breach, incident response, notification, confidentiality, non-disclosure, soc2\n",
            "Adding: data breach, incident response, notification, confidentiality, non-disclosure, soc2\n",
            "Expected Impact: Retrieve more clauses about data breaches, incident response, confidentiality\n",
            "\n",
            "SIMULATED RESULTS\n",
            "Clauses: 3 (+3)\n",
            "Risk Level: unknown (UNCHANGED)\n",
            "Confidence: 0.15 (+0.15)\n",
            "\n",
            "OBSERVATIONS\n",
            "Risk level likely to remain stable\n",
            "rerun_compliance_with_keywords() function defined\n",
            "      ['data breach', 'incident response', 'notification', 'confidentiality', 'non-disclosure', 'soc2'],\n"
          ]
        }
      ],
      "source": [
        "print(\"PREPARING FOR KEYWORD ENHANCEMENT TEST\")\n",
        "\n",
        "try:\n",
        "    original_keywords_comp = compliance_keywords\n",
        "    original_clauses_comp = len(extracted_clauses) if 'extracted_clauses' in locals() else 0\n",
        "    original_risk_comp = risk_level if 'risk_level' in locals() else \"unknown\"\n",
        "    original_confidence_comp = confidence if 'confidence' in locals() else 0.0\n",
        "except NameError:\n",
        "    print(\"No previous execution found, using default baseline\")\n",
        "    original_keywords_comp = compliance_keywords\n",
        "    original_clauses_comp = 0\n",
        "    original_risk_comp = \"unknown\"\n",
        "    original_confidence_comp = 0.0\n",
        "\n",
        "new_keywords_to_add = [\n",
        "    \"data breach\", \n",
        "    \"incident response\", \n",
        "    \"notification\",\n",
        "    \"confidentiality\", \n",
        "    \"non-disclosure\", \n",
        "    \"soc2\"\n",
        "]\n",
        "\n",
        "modified_keywords_comp = compliance_keywords + new_keywords_to_add\n",
        "\n",
        "print(f\"\\nBASELINE\")\n",
        "print(f\"Original Keywords: {', '.join(original_keywords_comp)}\")\n",
        "print(f\"Clauses: {original_clauses_comp}\")\n",
        "print(f\"Risk Level: {original_risk_comp}\")\n",
        "print(f\"Confidence: {original_confidence_comp:.2f}\")\n",
        "\n",
        "print(f\"\\nPLANNED\")\n",
        "print(f\"Modified Keywords: {', '.join(modified_keywords_comp)}\")\n",
        "print(f\"Adding: {', '.join(new_keywords_to_add)}\")\n",
        "print(f\"Expected Impact: Retrieve more clauses about data breaches, incident response, confidentiality\")\n",
        "\n",
        "simulated_new_clauses = original_clauses_comp + 3\n",
        "simulated_new_risk = \"high\" if original_risk_comp in [\"medium\", \"low\"] else original_risk_comp\n",
        "simulated_new_confidence = min(1.0, original_confidence_comp + 0.15)\n",
        "\n",
        "print(f\"\\nSIMULATED RESULTS\")\n",
        "print(f\"Clauses: {simulated_new_clauses} (+{simulated_new_clauses - original_clauses_comp})\")\n",
        "print(f\"Risk Level: {simulated_new_risk} {'(INCREASED)' if simulated_new_risk != original_risk_comp else '(UNCHANGED)'}\")\n",
        "print(f\"Confidence: {simulated_new_confidence:.2f} (+{simulated_new_confidence - original_confidence_comp:.2f})\")\n",
        "\n",
        "print(f\"\\nOBSERVATIONS\")\n",
        "print(f\"Risk level likely to {'increase' if simulated_new_risk != original_risk_comp else 'remain stable'}\")\n",
        "\n",
        "print(\"rerun_compliance_with_keywords() function defined\")\n",
        "\n",
        "print(f\"      {new_keywords_to_add},\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running ENHANCED Compliance Pipeline with new keywords...\n",
            "  Adding 6 keywords: data breach, incident response, notification, confidentiality, non-disclosure, soc2\n",
            "Retrieving...\n",
            "   Generating embedding for compliance query...\n",
            "   Querying Pinecone index: 'contract-agents'\n",
            "   Retrieved 7 compliance clauses (score > 0.1)\n",
            "     - Clause ID: compliance_0, Score: 0.303, Text length: 150 chars\n",
            "     - Clause ID: finance_0, Score: 0.242, Text length: 263 chars\n",
            "     - Clause ID: operations_1, Score: 0.240, Text length: 123 chars\n",
            "     - Clause ID: legal_0, Score: 0.228, Text length: 121 chars\n",
            "     - Clause ID: legal_1, Score: 0.226, Text length: 187 chars\n",
            "     - Clause ID: operations_0, Score: 0.149, Text length: 127 chars\n",
            "     - Clause ID: finance_1, Score: 0.129, Text length: 71 chars\n",
            "Combining...\n",
            "   Retrieved Chunks: 7\n",
            "   Combined Text Length: 1912 characters\n",
            "   Context combined successfully\n",
            "Analyzing...\n",
            "   Agent: Compliance Agent\n",
            "   Model: gemma2:9b\n",
            "   Sending query to Ollama via HTTP API...\n",
            "   Clauses Extracted: 24\n",
            "   Risk Level: low\n",
            "   Confidence: 0.85\n",
            "   Agent execution complete\n",
            "Validating...\n",
            "   Clauses extracted: 24\n",
            "   Risk level assessed: low\n",
            "   Confidence score: 0.85\n",
            "   Analysis length: 3871 characters\n",
            "   Compliance terms found: compliance, gdpr, security, privacy, legal\n",
            "\n",
            "   Validation Status: PASSED \n",
            "Risk summary...\n",
            "   Total Clauses: 24\n",
            "   Overall Risk: LOW\n",
            "   Confidence: 0.85\n",
            "   Validation: PASSED\n",
            "\n",
            "   Recommendations:\n",
            "      - Compliance requirements are met\n",
            "      - Continue monitoring regulatory changes\n",
            "\n",
            "ENHANCED: 24 clauses, low risk, 0.85 confidence\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRunning ENHANCED Compliance Pipeline with new keywords...\")\n",
        "\n",
        "new_keywords = [\"data breach\", \"incident response\", \"notification\", \n",
        "                \"confidentiality\", \"non-disclosure\", \"soc2\"]\n",
        "\n",
        "print(f\"  Adding {len(new_keywords)} keywords: {', '.join(new_keywords)}\")\n",
        "\n",
        "enhanced_query = f\"Analyze regulatory compliance and data protection. Focus on: {', '.join(new_keywords)}\"\n",
        "\n",
        "print(\"Retrieving...\")\n",
        "enhanced_context = retrieve_compliance_context(enhanced_query, top_k=12, score_threshold=0.1)\n",
        "\n",
        "print(\"Combining...\")\n",
        "enhanced_combined = combine_compliance_chunks(enhanced_context, max_length=2500)\n",
        "\n",
        "print(\"Analyzing...\")\n",
        "enhanced_result = run_compliance_agent(enhanced_query, enhanced_combined[\"combined_text\"], \"Data Processing Agreement\", timeout=300)\n",
        "\n",
        "print(\"Validating...\")\n",
        "enhanced_validation = validate_compliance_output(enhanced_result)\n",
        "\n",
        "print(\"Risk summary...\")\n",
        "enhanced_risk_summary = generate_compliance_risk_summary(enhanced_result, enhanced_validation)\n",
        "\n",
        "if enhanced_result and enhanced_result.get(\"status\") == \"success\":\n",
        "    enhanced_output = enhanced_result.get(\"output\", {})\n",
        "    enhanced_clauses = len(enhanced_output.get(\"extracted_clauses\", []))\n",
        "    enhanced_risk = enhanced_output.get(\"risk_level\", \"unknown\")\n",
        "    enhanced_confidence = enhanced_output.get(\"confidence\", 0.0)\n",
        "    print(f\"\\nENHANCED: {enhanced_clauses} clauses, {enhanced_risk} risk, {enhanced_confidence:.2f} confidence\")\n",
        "else:\n",
        "    print(f\"\\nENHANCED FAILED: {enhanced_result.get('error', 'Unknown error')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finance Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Defining Finance Query Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Defining Finance Query Template\n",
            "Finance Query Template defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDefining Finance Query Template\")\n",
        "\n",
        "FINANCE_QUERY = \"\"\"\n",
        "Identify clauses related to:\n",
        "- Payment terms and conditions\n",
        "- Fees, invoices, and billing\n",
        "- Penalties and late fees\n",
        "- Financial liability\n",
        "\"\"\"\n",
        "\n",
        "class FinanceQueryTemplate:\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_base_template():\n",
        "        \"\"\"Get base finance query template\"\"\"\n",
        "        return FINANCE_QUERY\n",
        "    \n",
        "    @staticmethod\n",
        "    def select_template(query):\n",
        "        \"\"\"Select appropriate template based on query\"\"\"\n",
        "        query_lower = query.lower()\n",
        "        \n",
        "        if any(kw in query_lower for kw in ['payment', 'invoice', 'billing']):\n",
        "            return \"\"\"\n",
        "You are a Payment Terms Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Payment schedules and due dates\n",
        "- Invoice generation and delivery\n",
        "- Payment methods and processing\n",
        "- Payment milestones and conditions\n",
        "\"\"\"\n",
        "        elif any(kw in query_lower for kw in ['fee', 'cost', 'charge', 'pricing']):\n",
        "            return \"\"\"\n",
        "You are a Fee Structure Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Fee types and amounts\n",
        "- Pricing models and tiers\n",
        "- Additional charges and surcharges\n",
        "- Cost breakdown and transparency\n",
        "\"\"\"\n",
        "        elif any(kw in query_lower for kw in ['penalty', 'late', 'interest', 'default']):\n",
        "            return \"\"\"\n",
        "You are a Penalty and Interest Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Late payment penalties\n",
        "- Interest rates and calculations\n",
        "- Default consequences\n",
        "- Grace periods and waivers\n",
        "\"\"\"\n",
        "        else:\n",
        "            return FINANCE_QUERY\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_finance_prompt(user_query, contract_type=\"general\"):\n",
        "        \"\"\"\n",
        "        Create structured finance analysis prompt\n",
        "        \n",
        "        Args:\n",
        "            user_query (str): User's finance-related query\n",
        "            contract_type (str): Type of contract being analyzed\n",
        "        \n",
        "        Returns:\n",
        "            str: Formatted finance query for gemma2:9b\n",
        "        \"\"\"\n",
        "        template = FinanceQueryTemplate.select_template(user_query)\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "You are a Financial Analyst Agent specializing in contract financial terms.\n",
        "\n",
        "Contract Type: {contract_type}\n",
        "User Query: {user_query}\n",
        "\n",
        "{template}\n",
        "\n",
        "Your task:\n",
        "1. Identify all payment terms, schedules, and conditions\n",
        "2. Analyze fee structures, billing cycles, and invoicing terms\n",
        "3. Flag penalty clauses and late payment consequences\n",
        "4. Assess financial liability and risk exposure\n",
        "5. Calculate total financial obligations where applicable\n",
        "6. Identify interest rates and compounding terms\n",
        "7. Provide clear financial risk assessment (High/Medium/Low)\n",
        "\n",
        "Analyze the following contract clauses for financial implications.\n",
        "\"\"\"\n",
        "        return prompt\n",
        "    \n",
        "    @staticmethod\n",
        "    def format_finance_context(retrieved_clauses):\n",
        "        \"\"\"Format retrieved clauses for finance analysis\"\"\"\n",
        "        if not retrieved_clauses:\n",
        "            return \"No relevant financial clauses found.\"\n",
        "        \n",
        "        formatted = \"CONTRACT FINANCIAL CLAUSES FOR ANALYSIS:\\n\\n\"\n",
        "        for idx, clause in enumerate(retrieved_clauses, 1):\n",
        "            formatted += f\"CLAUSE {idx}:\\n\"\n",
        "            formatted += f\"Type: {clause.get('clause_type', 'financial')}\\n\"\n",
        "            formatted += f\"Relevance Score: {clause.get('score', 0):.3f}\\n\"\n",
        "            formatted += f\"Content:\\n{clause.get('text', '')}\\n\"\n",
        "            formatted += \"-\" * 60 + \"\\n\\n\"\n",
        "        \n",
        "        return formatted\n",
        "\n",
        "print(f\"Finance Query Template defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Retrieving Finance Context (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Retrieving Finance Context (RAG)\n",
            "   Retrieval Keywords: payment, fee, invoice, penalty, billing, financial, cost, expense, charge, compensation, interest, rate\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRetrieving Finance Context (RAG)\")\n",
        "\n",
        "finance_keywords = [\n",
        "    \"payment\", \n",
        "    \"fee\", \n",
        "    \"invoice\", \n",
        "    \"penalty\", \n",
        "    \"billing\", \n",
        "    \"financial\",\n",
        "    \"cost\",\n",
        "    \"expense\",\n",
        "    \"charge\",\n",
        "    \"compensation\",\n",
        "    \"interest\",\n",
        "    \"rate\"\n",
        "]\n",
        "\n",
        "def retrieve_finance_context(query_text, top_k=10, score_threshold=0.1):\n",
        " \n",
        "    try:\n",
        "        from pinecone import Pinecone\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        \n",
        "        PINECONE_API_KEY = 'pcsk_3ftgmC_GzUZkRCnxa2jmDu7TTjnGWjC3QaN8c2PcQ5KN5PUSyQaEmmcdGUGu2BLd4Y7TRn'\n",
        "        INDEX_NAME = 'contract-agents'\n",
        "        \n",
        "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "        index = pc.Index(INDEX_NAME)\n",
        "        \n",
        "        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        \n",
        "        print(f\"   Generating embedding for finance query...\")\n",
        "        query_embedding = embedding_model.encode(query_text).tolist()\n",
        "        \n",
        "        print(f\"   Querying Pinecone index: '{INDEX_NAME}'\")\n",
        "        results = index.query(\n",
        "            vector=query_embedding,\n",
        "            top_k=top_k,\n",
        "            include_metadata=True\n",
        "        )\n",
        "        \n",
        "        filtered_matches = [\n",
        "            match for match in results['matches'] \n",
        "            if match['score'] > score_threshold\n",
        "        ]\n",
        "        \n",
        "        print(f\"   Retrieved {len(filtered_matches)} finance clauses (score > {score_threshold})\")\n",
        "        \n",
        "        finance_context = []\n",
        "        for match in filtered_matches:\n",
        "            metadata = match.get('metadata', {})\n",
        "            \n",
        "            clause_text = (\n",
        "                metadata.get('clause_full', '') or \n",
        "                metadata.get('clause', '') or \n",
        "                metadata.get('text', '')\n",
        "            )\n",
        "            \n",
        "            context_item = {\n",
        "                'clause_id': match['id'],\n",
        "                'text': clause_text,\n",
        "                'clause_type': metadata.get('clause_type', metadata.get('agent', 'financial')),\n",
        "                'score': match['score'],\n",
        "                'risk_level': metadata.get('risk_level', 'unknown'),\n",
        "                'confidence': metadata.get('confidence', 0.0)\n",
        "            }\n",
        "            finance_context.append(context_item)\n",
        "            print(f\"     - Clause ID: {match['id']}, Score: {match['score']:.3f}, Text length: {len(clause_text)} chars\")\n",
        "        \n",
        "        return finance_context\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error retrieving finance context: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "print(f\"   Retrieval Keywords: {', '.join(finance_keywords)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Combining Retrieved Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combining Retrieved Chunks\n",
            "   combine_finance_chunks() function ready\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCombining Retrieved Chunks\")\n",
        "\n",
        "def combine_finance_chunks(finance_context, max_length=2000):\n",
        "\n",
        "    if not finance_context:\n",
        "        print(f\"   No finance data available\")\n",
        "        return {\n",
        "            \"combined_text\": \"No relevant financial clauses found.\",\n",
        "            \"num_context_chunks\": 0,\n",
        "            \"combined_text_length\": 0,\n",
        "            \"truncated\": False\n",
        "        }\n",
        "    \n",
        "    combined_text = \"CONTRACT FINANCIAL CLAUSES FOR ANALYSIS:\\n\\n\"\n",
        "    chunk_count = 0\n",
        "    truncated = False\n",
        "    \n",
        "    for item in finance_context:\n",
        "        chunk_text = f\"CLAUSE {chunk_count + 1}:\\n\"\n",
        "        chunk_text += f\"Type: {item['clause_type']}\\n\"\n",
        "        chunk_text += f\"Relevance Score: {item['score']:.3f}\\n\"\n",
        "        chunk_text += f\"Content:\\n{item['text']}\\n\"\n",
        "        chunk_text += \"-\" * 60 + \"\\n\\n\"\n",
        "        \n",
        "        if len(combined_text) + len(chunk_text) > max_length:\n",
        "            print(f\"   Reached max length limit at {chunk_count} chunks\")\n",
        "            truncated = True\n",
        "            break\n",
        "        \n",
        "        combined_text += chunk_text\n",
        "        chunk_count += 1\n",
        "    \n",
        "    result = {\n",
        "        \"combined_text\": combined_text,\n",
        "        \"num_context_chunks\": chunk_count,\n",
        "        \"combined_text_length\": len(combined_text),\n",
        "        \"truncated\": truncated\n",
        "    }\n",
        "    \n",
        "    print(f\"   Retrieved Chunks: {result['num_context_chunks']}\")\n",
        "    print(f\"   Combined Text Length: {result['combined_text_length']} characters\")\n",
        "    print(f\"   Context combined successfully\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(f\"   combine_finance_chunks() function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Running Finance Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running Finance Agent\n",
            "   run_finance_agent() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRunning Finance Agent\")\n",
        "\n",
        "def run_finance_agent(user_query, retrieved_context, contract_type=\"general\", timeout=3600000):\n",
        "\n",
        "    import requests\n",
        "    import json\n",
        "    import re\n",
        "    \n",
        "    OLLAMA_MODEL = \"gemma2:9b\"\n",
        "    OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "    \n",
        "    query_template = FinanceQueryTemplate.create_finance_prompt(user_query, contract_type)\n",
        "    \n",
        "    full_prompt = f\"\"\"{query_template}\n",
        "\n",
        "RETRIEVED FINANCIAL CLAUSES:\n",
        "{retrieved_context}\n",
        "\n",
        "FINANCIAL ANALYSIS:\n",
        "Provide a structured analysis covering:\n",
        "1. Payment Terms (schedules, amounts, methods)\n",
        "2. Fee Structure (types, amounts, billing cycles)\n",
        "3. Penalties & Late Fees (amounts, conditions)\n",
        "4. Interest Rates (APR, compounding, calculation methods)\n",
        "5. Financial Liability (caps, obligations, risks)\n",
        "6. Risk Assessment (High/Medium/Low)\n",
        "7. Total Financial Obligations (if calculable)\n",
        "8. Key Recommendations\n",
        "\"\"\"\n",
        "    \n",
        "    print(f\"   Agent: Finance Agent\")\n",
        "    print(f\"   Model: {OLLAMA_MODEL}\")\n",
        "    print(f\"   Timeout: {timeout}s \")\n",
        "    print(f\"   Sending query to Ollama via HTTP API...\")\n",
        "    \n",
        "    try:\n",
        "        payload = {\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"prompt\": full_prompt,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\n",
        "                \"num_predict\": 800000,  \n",
        "                \"temperature\": 0.4\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        response = requests.post(OLLAMA_URL, json=payload, timeout=timeout)  \n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            finance_output = result.get(\"response\", \"\").strip()\n",
        "            \n",
        "            extracted_clauses = []\n",
        "            lines = finance_output.split('\\n')\n",
        "            for line in lines:\n",
        "                if any(keyword in line.lower() for keyword in finance_keywords):\n",
        "                    extracted_clauses.append(line.strip())\n",
        "            \n",
        "            output_lower = finance_output.lower()\n",
        "            if 'high risk' in output_lower or 'severe' in output_lower:\n",
        "                risk_level = \"high\"\n",
        "            elif 'low risk' in output_lower or 'minimal' in output_lower:\n",
        "                risk_level = \"low\"\n",
        "            else:\n",
        "                risk_level = \"medium\"\n",
        "            \n",
        "            confidence = 0.85 if len(finance_output) > 200 else 0.65\n",
        "            \n",
        "            print(f\"   Clauses Extracted: {len(extracted_clauses)}\")\n",
        "            print(f\"   Risk Level: {risk_level}\")\n",
        "            print(f\"   Confidence: {confidence:.2f}\")\n",
        "            print(f\"   Agent execution complete\")\n",
        "            \n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"model\": OLLAMA_MODEL,\n",
        "                \"output\": {\n",
        "                    \"finance_analysis\": finance_output,\n",
        "                    \"extracted_clauses\": extracted_clauses,\n",
        "                    \"risk_level\": risk_level,\n",
        "                    \"confidence\": confidence\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            print(f\"   Ollama API error: Status {response.status_code}\")\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"model\": OLLAMA_MODEL,\n",
        "                \"error\": f\"HTTP {response.status_code}\",\n",
        "                \"output\": {\n",
        "                    \"finance_analysis\": \"\",\n",
        "                    \"extracted_clauses\": [],\n",
        "                    \"risk_level\": \"unknown\",\n",
        "                    \"confidence\": 0.0\n",
        "                }\n",
        "            }\n",
        "            \n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"   Request timeout after {timeout}s\")\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"error\": f\"Timeout after {timeout}s\",\n",
        "            \"output\": {\n",
        "                \"finance_analysis\": \"\",\n",
        "                \"extracted_clauses\": [],\n",
        "                \"risk_level\": \"unknown\",\n",
        "                \"confidence\": 0.0\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"   Error running finance agent: {str(e)}\")\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"error\": str(e),\n",
        "            \"output\": {\n",
        "                \"finance_analysis\": \"\",\n",
        "                \"extracted_clauses\": [],\n",
        "                \"risk_level\": \"unknown\",\n",
        "                \"confidence\": 0.0\n",
        "            }\n",
        "        }\n",
        "\n",
        "print(f\"   run_finance_agent() function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Validating Finance Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validating Finance Output\n",
            "   validate_finance_output() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nValidating Finance Output\")\n",
        "\n",
        "def validate_finance_output(finance_result):\n",
        "\n",
        "    validation_passed = True\n",
        "    validation_checks = []\n",
        "    \n",
        "    if finance_result and finance_result.get(\"status\") == \"success\":\n",
        "        output = finance_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        finance_analysis = output.get(\"finance_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        finance_analysis = \"\"\n",
        "    \n",
        "    if len(extracted_clauses) > 0:\n",
        "        validation_checks.append(f\"Clauses extracted: {len(extracted_clauses)}\")\n",
        "    else:\n",
        "        validation_checks.append(\"No clauses extracted\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    if risk_level != \"unknown\":\n",
        "        validation_checks.append(f\"Risk level assessed: {risk_level}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Risk level not assessed\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    if confidence > 0:\n",
        "        validation_checks.append(f\"Confidence score: {confidence:.2f}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Low confidence score\")\n",
        "    \n",
        "    if len(finance_analysis) > 100:\n",
        "        validation_checks.append(f\"Analysis length: {len(finance_analysis)} characters\")\n",
        "    else:\n",
        "        validation_checks.append(\"Analysis too short\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    financial_terms = ['payment', 'fee', 'invoice', 'penalty', 'interest', 'billing', 'liability', 'cost']\n",
        "    found_terms = [term for term in financial_terms if term in finance_analysis.lower()]\n",
        "    \n",
        "    if len(found_terms) >= 2:\n",
        "        validation_checks.append(f\"Financial terms found: {', '.join(found_terms)}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Limited financial terminology detected\")\n",
        "    \n",
        "    for check in validation_checks:\n",
        "        print(f\"   {check}\")\n",
        "    \n",
        "    print(f\"\\n   Validation Status: {'PASSED' if validation_passed else 'FAILED'}\")\n",
        "    \n",
        "    return {\n",
        "        \"validation_passed\": validation_passed,\n",
        "        \"validation_checks\": validation_checks,\n",
        "        \"extracted_clauses_count\": len(extracted_clauses),\n",
        "        \"risk_level\": risk_level,\n",
        "        \"confidence\": confidence,\n",
        "        \"completeness_score\": len([c for c in validation_checks if 'done' in c]) / len(validation_checks) * 100\n",
        "    }\n",
        "\n",
        "print(f\"   validate_finance_output() function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Finance Risk Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Finance Risk Summary\n",
            "   generate_finance_risk_summary() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFinance Risk Summary\")\n",
        "\n",
        "def generate_finance_risk_summary(finance_result, validation_result):\n",
        "\n",
        "    import re\n",
        "    from datetime import datetime\n",
        "    \n",
        "    if finance_result and finance_result.get(\"status\") == \"success\":\n",
        "        output = finance_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        finance_analysis = output.get(\"finance_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        finance_analysis = \"\"\n",
        "    \n",
        "    finance_risk_summary = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"total_clauses\": len(extracted_clauses),\n",
        "        \"risk_level\": risk_level,\n",
        "        \"confidence\": confidence,\n",
        "        \"validation_passed\": validation_result.get(\"validation_passed\", False),\n",
        "        \"financial_risks\": [],\n",
        "        \"recommendations\": [],\n",
        "        \"key_findings\": []\n",
        "    }\n",
        "    \n",
        "    if risk_level == \"high\":\n",
        "        finance_risk_summary[\"financial_risks\"].append(\"High penalty exposure identified\")\n",
        "        finance_risk_summary[\"financial_risks\"].append(\"Significant financial liability detected\")\n",
        "        finance_risk_summary[\"financial_risks\"].append(\"Unfavorable interest rate terms\")\n",
        "        finance_risk_summary[\"recommendations\"].append(\"Negotiate payment term extensions\")\n",
        "        finance_risk_summary[\"recommendations\"].append(\"Review penalty clauses with legal counsel\")\n",
        "        finance_risk_summary[\"recommendations\"].append(\"Establish payment milestone safeguards\")\n",
        "        finance_risk_summary[\"recommendations\"].append(\"Request interest rate caps or reductions\")\n",
        "    elif risk_level == \"medium\":\n",
        "        finance_risk_summary[\"financial_risks\"].append(\"Moderate financial obligations\")\n",
        "        finance_risk_summary[\"financial_risks\"].append(\"Standard penalty terms apply\")\n",
        "        finance_risk_summary[\"recommendations\"].append(\"Monitor invoice timelines closely\")\n",
        "        finance_risk_summary[\"recommendations\"].append(\"Set up automated payment reminders\")\n",
        "        finance_risk_summary[\"recommendations\"].append(\"Review interest calculation methods\")\n",
        "    else:\n",
        "        finance_risk_summary[\"recommendations\"].append(\"Financial terms are favorable\")\n",
        "        finance_risk_summary[\"recommendations\"].append(\"Maintain current payment practices\")\n",
        "    \n",
        "    if finance_analysis:\n",
        "        lines = [line.strip() for line in finance_analysis.split('\\n') if line.strip()]\n",
        "        for line in lines:\n",
        "            if any(kw in line.lower() for kw in ['payment', 'fee', 'penalty', 'invoice', 'liability', 'interest', 'rate']):\n",
        "                if len(finance_risk_summary[\"key_findings\"]) < 5:\n",
        "                    finance_risk_summary[\"key_findings\"].append(line)\n",
        "    \n",
        "    print(f\"   Total Clauses: {finance_risk_summary['total_clauses']}\")\n",
        "    print(f\"   Overall Risk: {finance_risk_summary['risk_level'].upper()}\")\n",
        "    print(f\"   Confidence: {finance_risk_summary['confidence']:.2f}\")\n",
        "    print(f\"   Validation: {'PASSED' if finance_risk_summary['validation_passed'] else 'FAILED'}\")\n",
        "    \n",
        "    if finance_risk_summary['financial_risks']:\n",
        "        print(f\"\\n   Financial Risks:\")\n",
        "        for risk in finance_risk_summary['financial_risks']:\n",
        "            print(f\"      - {risk}\")\n",
        "    \n",
        "    print(f\"\\n   Recommendations:\")\n",
        "    for rec in finance_risk_summary['recommendations']:\n",
        "        print(f\"      - {rec}\")\n",
        "    \n",
        "    return finance_risk_summary\n",
        "\n",
        "def save_finance_results(finance_result, validation_result, risk_summary, output_dir=\"../Data/Results/Pipelines\"):\n",
        "\n",
        "    import os\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    \n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    complete_output = {\n",
        "        \"pipeline\": \"Finance Pipeline\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"model\": \"gemma2:9b\",\n",
        "        \"model_config\": {\n",
        "            \"timeout\": 360,\n",
        "            \"max_tokens\": 800\n",
        "        },\n",
        "        \"pinecone_index\": \"contract-agents\",\n",
        "        \"score_threshold\": 0.1,\n",
        "        \"results\": finance_result,\n",
        "        \"validation\": validation_result,\n",
        "        \"risk_summary\": risk_summary\n",
        "    }\n",
        "    \n",
        "    json_filename = os.path.join(output_dir, f\"finance_pipeline_{timestamp}.json\")\n",
        "    try:\n",
        "        with open(json_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(complete_output, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"\\n   JSON saved: {json_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n   Error saving JSON: {str(e)}\")\n",
        "    \n",
        "    txt_filename = os.path.join(output_dir, f\"finance_summary_{timestamp}.txt\")\n",
        "    try:\n",
        "        with open(txt_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"FINANCE PIPELINE SUMMARY\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\\n\")\n",
        "            \n",
        "            f.write(f\"Timestamp: {risk_summary['timestamp']}\\n\")\n",
        "            f.write(f\"Model: gemma2:9b (timeout: 360s, tokens: 800)\\n\")\n",
        "            f.write(f\"Pinecone Index: contract-agents\\n\")\n",
        "            f.write(f\"Score Threshold: > 0.1\\n\\n\")\n",
        "            \n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"RISK ASSESSMENT\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(f\"Total Clauses Analyzed: {risk_summary['total_clauses']}\\n\")\n",
        "            f.write(f\"Risk Level: {risk_summary['risk_level'].upper()}\\n\")\n",
        "            f.write(f\"Confidence Score: {risk_summary['confidence']:.2f}\\n\")\n",
        "            f.write(f\"Validation Status: {'PASSED' if risk_summary['validation_passed'] else 'FAILED'}\\n\\n\")\n",
        "            \n",
        "            if risk_summary['financial_risks']:\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                f.write(\"FINANCIAL RISKS IDENTIFIED\\n\")\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                for i, risk in enumerate(risk_summary['financial_risks'], 1):\n",
        "                    f.write(f\"{i}. {risk}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"RECOMMENDATIONS\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            for i, rec in enumerate(risk_summary['recommendations'], 1):\n",
        "                f.write(f\"{i}. {rec}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "            \n",
        "            if risk_summary['key_findings']:\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                f.write(\"KEY FINDINGS\\n\")\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                for i, finding in enumerate(risk_summary['key_findings'], 1):\n",
        "                    f.write(f\"{i}. {finding}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"END OF REPORT\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "        \n",
        "        print(f\"   TXT summary saved: {txt_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error saving TXT: {str(e)}\")\n",
        "    \n",
        "    return json_filename, txt_filename\n",
        "\n",
        "print(f\"   generate_finance_risk_summary() function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Packaging Finance Pipeline Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Packaging Finance Pipeline Output\n",
            "package_finance_pipeline_output() function defined\n",
            "save_packaged_finance_output() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nPackaging Finance Pipeline Output\")\n",
        "\n",
        "def package_finance_pipeline_output(\n",
        "    user_query,\n",
        "    finance_result,\n",
        "    validation_result,\n",
        "    risk_summary,\n",
        "    retrieved_context_data,\n",
        "    contract_type=\"general\"\n",
        "):\n",
        "    \n",
        "    if finance_result and finance_result.get(\"status\") == \"success\":\n",
        "        output = finance_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        model = finance_result.get(\"model\", \"gemma2:9b\")\n",
        "        full_analysis = output.get(\"finance_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        model = \"gemma2:9b\"\n",
        "        full_analysis = finance_result.get(\"error\", \"Analysis failed\") if finance_result else \"No result\"\n",
        "    \n",
        "    finance_pipeline_output = {\n",
        "        \"pipeline\": \"finance\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"metadata\": {\n",
        "            \"model\": model,\n",
        "            \"ollama_url\": \"http://localhost:11434/api/generate\",\n",
        "            \"ollama_timeout\": 360, \n",
        "            \"ollama_max_tokens\": 800000,  \n",
        "            \"pinecone_index\": \"contract-agents\",\n",
        "            \"pinecone_metadata_field\": \"clause_full\",\n",
        "            \"score_threshold\": 0.1,\n",
        "            \"contract_type\": contract_type,\n",
        "            \"user_query\": user_query,\n",
        "            \"embedding_model\": \"all-MiniLM-L6-v2\"\n",
        "        },\n",
        "        \"query_template\": FINANCE_QUERY.strip(),\n",
        "        \"retrieval_keywords\": finance_keywords,\n",
        "        \"retrieval_stats\": {\n",
        "            \"chunks_retrieved\": retrieved_context_data.get(\"num_context_chunks\", 0),\n",
        "            \"text_length\": retrieved_context_data.get(\"combined_text_length\", 0),\n",
        "            \"truncated\": retrieved_context_data.get(\"truncated\", False)\n",
        "        },\n",
        "        \"finance_analysis\": {\n",
        "            \"agent\": \"Finance Agent\",\n",
        "            \"model\": model,\n",
        "            \"extracted_clauses\": extracted_clauses,\n",
        "            \"clause_count\": len(extracted_clauses),\n",
        "            \"risk_level\": risk_level,\n",
        "            \"confidence\": confidence,\n",
        "            \"full_analysis\": full_analysis,\n",
        "            \"analysis_length\": len(full_analysis)\n",
        "        },\n",
        "        \"validation\": {\n",
        "            \"status\": \"passed\" if validation_result.get(\"validation_passed\", False) else \"failed\",\n",
        "            \"checks\": validation_result.get(\"validation_checks\", []),\n",
        "            \"completeness_score\": validation_result.get(\"completeness_score\", 0),\n",
        "            \"extracted_clauses_count\": validation_result.get(\"extracted_clauses_count\", 0)\n",
        "        },\n",
        "        \"risk_summary\": risk_summary,\n",
        "        \"validation_status\": \"passed\" if validation_result.get(\"validation_passed\", False) else \"failed\",\n",
        "        \"status\": \"completed\" if validation_result.get(\"validation_passed\", False) else \"completed_with_warnings\",\n",
        "        \"execution_success\": finance_result.get(\"status\") == \"success\" if finance_result else False\n",
        "    }\n",
        "    \n",
        "    print(f\"   Pipeline output packaged\")\n",
        "    print(f\"   Keys: {list(finance_pipeline_output.keys())}\")\n",
        "    print(f\"   Status: {finance_pipeline_output['status']}\")\n",
        "    print(f\"   Execution: {'Success' if finance_pipeline_output['execution_success'] else 'Failed'}\")\n",
        "    \n",
        "    return finance_pipeline_output\n",
        "\n",
        "def save_packaged_finance_output(pipeline_output, output_dir=\"../Data/Results/Pipelines\"):\n",
        "\n",
        "    try:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = os.path.join(output_dir, f\"finance_pipeline_complete_{timestamp}.json\")\n",
        "        \n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(pipeline_output, f, indent=2, ensure_ascii=False)\n",
        "        \n",
        "        print(f\"   Complete output saved: {filename}\")\n",
        "        \n",
        "        summary_filename = os.path.join(output_dir, f\"finance_summary_quick_{timestamp}.txt\")\n",
        "        with open(summary_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"FINANCE PIPELINE QUICK SUMMARY\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\\n\")\n",
        "            f.write(f\"Timestamp: {pipeline_output['timestamp']}\\n\")\n",
        "            f.write(f\"Status: {pipeline_output['status']}\\n\")\n",
        "            f.write(f\"Risk Level: {pipeline_output['risk_summary']['risk_level']}\\n\")\n",
        "            f.write(f\"Confidence: {pipeline_output['risk_summary']['confidence']:.2f}\\n\")\n",
        "            f.write(f\"Clauses Analyzed: {pipeline_output['risk_summary']['total_clauses']}\\n\")\n",
        "            f.write(f\"Validation: {pipeline_output['validation_status']}\\n\\n\")\n",
        "            \n",
        "            if pipeline_output['risk_summary'].get('financial_risks'):\n",
        "                f.write(\"RISKS:\\n\")\n",
        "                for risk in pipeline_output['risk_summary']['financial_risks']:\n",
        "                    f.write(f\"  - {risk}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            if pipeline_output['risk_summary'].get('recommendations'):\n",
        "                f.write(\"RECOMMENDATIONS:\\n\")\n",
        "                for rec in pipeline_output['risk_summary']['recommendations']:\n",
        "                    f.write(f\"  - {rec}\\n\")\n",
        "        \n",
        "        print(f\"   Quick summary saved: {summary_filename}\")\n",
        "        \n",
        "        return filename\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error saving packaged output: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(f\"package_finance_pipeline_output() function defined\")\n",
        "print(f\"save_packaged_finance_output() function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FINANCE PIPELINE EXECUTION\n",
            "\n",
            "Query: Analyze payment terms, fee structures, and penalties\n",
            "Contract Type: Service Agreement\n",
            "\n",
            "Retrieving context from Pinecone...\n",
            "   Generating embedding for finance query...\n",
            "   Querying Pinecone index: 'contract-agents'\n",
            "   Retrieved 8 finance clauses (score > 0.1)\n",
            "     - Clause ID: finance_0, Score: 0.529, Text length: 263 chars\n",
            "     - Clause ID: finance_1, Score: 0.436, Text length: 71 chars\n",
            "     - Clause ID: finance_2, Score: 0.254, Text length: 50 chars\n",
            "     - Clause ID: legal_1, Score: 0.215, Text length: 187 chars\n",
            "     - Clause ID: operations_0, Score: 0.209, Text length: 127 chars\n",
            "     - Clause ID: compliance_0, Score: 0.149, Text length: 150 chars\n",
            "     - Clause ID: legal_0, Score: 0.146, Text length: 121 chars\n",
            "     - Clause ID: operations_1, Score: 0.144, Text length: 123 chars\n",
            "\n",
            "[DEBUG] Retrieved 8 clauses:\n",
            "  1. In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision ...\n",
            "  2. ), Recipient shall reimburse Provider for all such Out-of-Pocket Costs....\n",
            "  3. Provider shall provide Recipient with monthly invo...\n",
            "\n",
            "Combining retrieved chunks...\n",
            "   Retrieved Chunks: 8\n",
            "   Combined Text Length: 2091 characters\n",
            "   Context combined successfully\n",
            "\n",
            "Combined context preview (first 400 chars):\n",
            "CONTRACT FINANCIAL CLAUSES FOR ANALYSIS:\n",
            "\n",
            "CLAUSE 1:\n",
            "Type: finance\n",
            "Relevance Score: 0.529\n",
            "Content:\n",
            "In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, including, without limitation, license fees and payments to third-party service providers or subcontractors (such included expenses, collectively, \n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 2:\n",
            "Type: finance\n",
            "Relevance Score: 0.436\n",
            "Content:\n",
            "), Recipient shall reimburse Provider for all such Out-of-Pocket Costs.\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 3:\n",
            "Type: finance\n",
            "Relevance Score: 0.254\n",
            "Content:\n",
            "Provider shall provide Recipient with monthly invo\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 4:\n",
            "Type: legal\n",
            "Relevance Score: 0.215\n",
            "Content:\n",
            "The other party shall give notice of termination in writing to the other party, which notice shall specify in reasonable detail the event(s) of default that give rise to such termination.\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 5:\n",
            "Type: operations\n",
            "Relevance Score: 0.209\n",
            "Content:\n",
            "Collectible Concepts Group will obtain any licenses deemed by the Joint Venturers to add value in the marketing of the Products\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 6:\n",
            "Type: compliance\n",
            "Relevance Score: 0.149\n",
            "Content:\n",
            "The receiving party will not disclose the other party's confidential information to any third parties without the other party's prior written consent.\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 7:\n",
            "Type: legal\n",
            "Relevance Score: 0.146\n",
            "Content:\n",
            "The other party asserts any rights in or to the terminating party's intellectual property in violation of this Agreement.\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 8:\n",
            "Type: operations\n",
            "Relevance Score: 0.144\n",
            "Content:\n",
            "Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distribution of the Products\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Running finance agent...\n",
            "  Configuration: timeout=360s, max_tokens=800\n",
            "   Agent: Finance Agent\n",
            "   Model: gemma2:9b\n",
            "   Timeout: 360000s \n",
            "   Sending query to Ollama via HTTP API...\n",
            "   Clauses Extracted: 28\n",
            "   Risk Level: medium\n",
            "   Confidence: 0.85\n",
            "   Agent execution complete\n",
            "\n",
            "Validating output...\n",
            "   Clauses extracted: 28\n",
            "   Risk level assessed: medium\n",
            "   Confidence score: 0.85\n",
            "   Analysis length: 3218 characters\n",
            "   Financial terms found: payment, fee, invoice, interest, billing, liability, cost\n",
            "\n",
            "   Validation Status: PASSED\n",
            "\n",
            "Generating risk summary...\n",
            "   Total Clauses: 28\n",
            "   Overall Risk: MEDIUM\n",
            "   Confidence: 0.85\n",
            "   Validation: PASSED\n",
            "\n",
            "   Financial Risks:\n",
            "      - Moderate financial obligations\n",
            "      - Standard penalty terms apply\n",
            "\n",
            "   Recommendations:\n",
            "      - Monitor invoice timelines closely\n",
            "      - Set up automated payment reminders\n",
            "      - Review interest calculation methods\n",
            "\n",
            "Saving baseline results...\n",
            "\n",
            "   JSON saved: ../Data/Results/Pipelines\\finance_pipeline_20260115_215018.json\n",
            "   TXT summary saved: ../Data/Results/Pipelines\\finance_summary_20260115_215018.txt\n",
            "\n",
            "[PACKAGING] Packaging baseline output...\n",
            "   Pipeline output packaged\n",
            "   Keys: ['pipeline', 'timestamp', 'metadata', 'query_template', 'retrieval_keywords', 'retrieval_stats', 'finance_analysis', 'validation', 'risk_summary', 'validation_status', 'status', 'execution_success']\n",
            "   Status: completed\n",
            "   Execution: Success\n",
            "   Complete output saved: ../Data/Results/Pipelines\\finance_pipeline_complete_20260115_215018.json\n",
            "   Quick summary saved: ../Data/Results/Pipelines\\finance_summary_quick_20260115_215018.txt\n",
            "RESULTS SUMMARY\n",
            "Status: SUCCESS\n",
            "Clauses Extracted: 28\n",
            "Risk Level: MEDIUM\n",
            "Confidence: 0.85\n",
            "Validation: PASSED\n",
            "\n",
            "Financial Risks:\n",
            "  - Moderate financial obligations\n",
            "  - Standard penalty terms apply\n",
            "\n",
            "Recommendations:\n",
            "  - Monitor invoice timelines closely\n",
            "  - Set up automated payment reminders\n",
            "  - Review interest calculation methods\n",
            "\n",
            "Full Finance Analysis\n",
            "--------------------------------------------------------------------------------\n",
            "##  Financial Analysis of Service Agreement\n",
            "\n",
            "Based on the provided clauses, here's a structured analysis of the financial terms:\n",
            "\n",
            "**1. Payment Terms:**\n",
            "\n",
            "* **Schedules & Due Dates:** The contract lacks specific details regarding payment schedules and due dates. Clause 3 mentions \"monthly invoices,\" suggesting a monthly billing cycle, but no specific due date is stated.\n",
            "* **Invoice Generation & Delivery:** Provider will issue monthly invoices to Recipient.  The method of invoice delivery (e.g., email, postal mail) is not specified.\n",
            "* **Payment Methods & Processing:** The contract doesn't explicitly mention acceptable payment methods.\n",
            "\n",
            "**2. Fee Structure:**\n",
            "\n",
            "* **Types & Amounts:** \n",
            "    *  The contract mentions \"Out-of-Pocket Costs\" which Provider can be reimbursed for by Recipient (Clause 1 & 2). This includes license fees, payments to third-party service providers, and subcontractors. The exact amounts are not defined.\n",
            "    * No information is provided about any fixed fees or recurring charges for the services themselves.\n",
            "\n",
            "* **Billing Cycles:** Monthly billing is implied based on Clause 3.\n",
            "\n",
            "**3. Penalties & Late Fees:**\n",
            "\n",
            "*  The contract does not mention any specific penalties or late fees for delayed payments.\n",
            "\n",
            "**4. Interest Rates:**\n",
            "\n",
            "* The contract does not specify any interest rates or compounding terms.\n",
            "\n",
            "**5. Financial Liability:**\n",
            "\n",
            "* **Caps & Obligations:**\n",
            "    * Provider's financial liability is limited to reimbursement of \"reasonable and documented Out-of-Pocket Costs\" (Clause 1 & 2).\n",
            "    * Recipient's financial obligation is to reimburse Provider for all incurred \"Out-of-Pocket Costs.\"\n",
            "* **Risks:**\n",
            "    *  **Provider:** Risk of incurring significant \"Out-of-Pocket Costs\" without clear budget or cost control mechanisms. Potential risk of delayed reimbursement from Recipient.\n",
            "    * **Recipient:** Risk of unexpected and potentially high costs related to Provider's \"Out-of-Pocket Expenses.\"\n",
            "\n",
            "**6. Risk Assessment:** \n",
            "\n",
            "**Medium** due to the lack of clarity regarding payment schedules, fee structures for services, and potential for significant \"Out-of-Pocket Costs\" that could impact both parties financially.\n",
            "\n",
            "**7. Total Financial Obligations:**\n",
            "\n",
            "*  Uncalculable without further information on service fees, scope of work, and potential \"Out-of-Pocket Expenses.\"\n",
            "\n",
            "\n",
            "**8. Key Recommendations:**\n",
            "\n",
            "* **Negotiate Clear Payment Terms:** Define specific payment schedules, due dates, acceptable payment methods, and invoicing procedures.\n",
            "* **Establish Fee Structure for Services:** Clearly outline the fees for services provided, including any recurring charges or usage-based fees.\n",
            "* **Define \"Out-of-Pocket Costs\" in Detail:** Specify allowable expenses and establish a process for documentation, approval, and reimbursement of these costs.\n",
            "* **Consider Penalties & Late Fees:** Include provisions for penalties or late fees to incentivize timely payments and mitigate financial risk.\n",
            "* **Include Interest Rate Clauses:**  Specify interest rates applicable to overdue payments to protect both parties' financial interests.\n",
            "\n",
            "\n",
            "\n",
            "By addressing these recommendations, the contract can be revised to provide greater clarity, transparency, and financial protection for both Provider and Recipient.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Baseline files saved:\n",
            "  - ../Data/Results/Pipelines\\finance_pipeline_20260115_215018.json\n",
            "  - ../Data/Results/Pipelines\\finance_summary_20260115_215018.txt\n",
            "  - ../Data/Results/Pipelines\\finance_pipeline_complete_20260115_215018.json\n"
          ]
        }
      ],
      "source": [
        "print(\"FINANCE PIPELINE EXECUTION\")\n",
        "\n",
        "baseline_query = \"Analyze payment terms, fee structures, and penalties\"\n",
        "baseline_contract_type = \"Service Agreement\"\n",
        "\n",
        "print(f\"\\nQuery: {baseline_query}\")\n",
        "print(f\"Contract Type: {baseline_contract_type}\")\n",
        "\n",
        "print(\"\\nRetrieving context from Pinecone...\")\n",
        "baseline_finance_context = retrieve_finance_context(\n",
        "    baseline_query, \n",
        "    top_k=20, \n",
        "    score_threshold=0.1\n",
        ")\n",
        "\n",
        "print(f\"\\n[DEBUG] Retrieved {len(baseline_finance_context)} clauses:\")\n",
        "for i, clause in enumerate(baseline_finance_context[:3], 1):\n",
        "    print(f\"  {i}. {clause['text'][:100]}...\")\n",
        "\n",
        "print(\"\\nCombining retrieved chunks...\")\n",
        "baseline_combined_data = combine_finance_chunks(\n",
        "    baseline_finance_context, \n",
        "    max_length=25000\n",
        ")\n",
        "\n",
        "print(f\"\\nCombined context preview (first 400 chars):\")\n",
        "\n",
        "print(baseline_combined_data[\"combined_text\"][:40000])\n",
        "\n",
        "print(\"\\nRunning finance agent...\")\n",
        "print(f\"  Configuration: timeout=360s, max_tokens=800\")\n",
        "baseline_finance_result = run_finance_agent(\n",
        "    baseline_query, \n",
        "    baseline_combined_data[\"combined_text\"], \n",
        "    baseline_contract_type,\n",
        "    timeout=360000\n",
        ")\n",
        "\n",
        "print(\"\\nValidating output...\")\n",
        "baseline_validation_result = validate_finance_output(baseline_finance_result)\n",
        "\n",
        "print(\"\\nGenerating risk summary...\")\n",
        "baseline_risk_summary = generate_finance_risk_summary(\n",
        "    baseline_finance_result, \n",
        "    baseline_validation_result\n",
        ")\n",
        "\n",
        "print(\"\\nSaving baseline results...\")\n",
        "baseline_json_file, baseline_txt_file = save_finance_results(\n",
        "    baseline_finance_result, \n",
        "    baseline_validation_result, \n",
        "    baseline_risk_summary\n",
        ")\n",
        "\n",
        "print(\"\\n[PACKAGING] Packaging baseline output...\")\n",
        "baseline_packaged_output = package_finance_pipeline_output(\n",
        "    user_query=baseline_query,\n",
        "    finance_result=baseline_finance_result,\n",
        "    validation_result=baseline_validation_result,\n",
        "    risk_summary=baseline_risk_summary,\n",
        "    retrieved_context_data=baseline_combined_data,\n",
        "    contract_type=baseline_contract_type\n",
        ")\n",
        "\n",
        "baseline_complete_file = save_packaged_finance_output(baseline_packaged_output)\n",
        "\n",
        "\n",
        "print(\"RESULTS SUMMARY\")\n",
        "\n",
        "if baseline_finance_result.get(\"status\") == \"success\":\n",
        "    baseline_output = baseline_finance_result.get(\"output\", {})\n",
        "    baseline_clauses = len(baseline_output.get(\"extracted_clauses\", []))\n",
        "    baseline_risk = baseline_output.get(\"risk_level\", \"unknown\")\n",
        "    baseline_confidence = baseline_output.get(\"confidence\", 0.0)\n",
        "    \n",
        "    print(f\"Status: {baseline_finance_result['status'].upper()}\")\n",
        "    print(f\"Clauses Extracted: {baseline_clauses}\")\n",
        "    print(f\"Risk Level: {baseline_risk.upper()}\")\n",
        "    print(f\"Confidence: {baseline_confidence:.2f}\")\n",
        "    print(f\"Validation: {'PASSED' if baseline_validation_result['validation_passed'] else 'FAILED'}\")\n",
        "    \n",
        "    print(f\"\\nFinancial Risks:\")\n",
        "    for risk in baseline_risk_summary.get('financial_risks', []):\n",
        "        print(f\"  - {risk}\")\n",
        "    \n",
        "    print(f\"\\nRecommendations:\")\n",
        "    for rec in baseline_risk_summary.get('recommendations', [])[:3]:\n",
        "        print(f\"  - {rec}\")\n",
        "    \n",
        "    print(f\"\\nFull Finance Analysis\")\n",
        "    print(\"-\"*80)\n",
        "    print(baseline_output.get(\"finance_analysis\", \"No analysis available\"))\n",
        "    print(\"-\"*80)\n",
        "    \n",
        "else:\n",
        "    print(f\"Baseline execution failed: {baseline_finance_result.get('error', 'Unknown error')}\")\n",
        "    baseline_clauses = 0\n",
        "    baseline_risk = \"unknown\"\n",
        "    baseline_confidence = 0.0\n",
        "\n",
        "print(f\"\\nBaseline files saved:\")\n",
        "print(f\"  - {baseline_json_file}\")\n",
        "print(f\"  - {baseline_txt_file}\")\n",
        "print(f\"  - {baseline_complete_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8. Adding Keyword 'interest' and Re-run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADDING KEYWORDS AND RE-RUNNING FINANCE PIPELINE\n",
            "PREPARING INTEREST-FOCUSED KEYWORD ENHANCEMENT\n",
            "Original Keywords: payment, fee, invoice, penalty, billing, financial, cost, expense, charge, compensation, interest, rate\n",
            "Clauses: 0\n",
            "Risk Level: unknown\n",
            "Confidence: 0.00\n",
            "Modified Keywords: payment, fee, invoice, penalty, billing, financial, cost, expense, charge, compensation, interest, rate, interest, apr, late charge, compounding, default interest, accrued interest, finance charge, usury, annual rate\n",
            "Adding 9 INTEREST-RELATED keywords:\n",
            "  1. interest\n",
            "  2. apr\n",
            "  3. late charge\n",
            "  4. compounding\n",
            "  5. default interest\n",
            "  6. accrued interest\n",
            "  7. finance charge\n",
            "  8. usury\n",
            "  9. annual rate\n",
            "\n",
            "SIMULATED RESULTS\n",
            "Clauses: 4 (+4)\n",
            "Risk Level: unknown (UNCHANGED)\n",
            "Confidence: 0.12 (+0.12)\n",
            "\n",
            "OBSERVATIONS\n",
            "Risk level likely to remain stable due to interest exposure\n",
            "      ['interest', 'apr', 'late charge', '...'],\n"
          ]
        }
      ],
      "source": [
        "print(\"ADDING KEYWORDS AND RE-RUNNING FINANCE PIPELINE\")\n",
        "\n",
        "\n",
        "def rerun_finance_with_keywords(\n",
        "    additional_keywords, \n",
        "    original_query=\"Analyze payment terms and fee structures\",\n",
        "    baseline_clauses=None,\n",
        "    baseline_risk=None,\n",
        "    baseline_confidence=None\n",
        "):\n",
        "    \n",
        "    from datetime import datetime\n",
        "    \n",
        "    print(f\"\\nRe-running Finance Pipeline with Enhanced Keywords...\")\n",
        "    print(f\"UPDATED Configuration: Timeout=360s, MaxTokens=800\")\n",
        "    \n",
        "    original_keywords_fin = finance_keywords.copy()\n",
        "    \n",
        "    try:\n",
        "        original_clauses_fin = baseline_clauses if baseline_clauses is not None else len(extracted_clauses)\n",
        "    except NameError:\n",
        "        original_clauses_fin = 0\n",
        "        print(\"   No baseline clauses found, using 0\")\n",
        "    \n",
        "    try:\n",
        "        original_risk_fin = baseline_risk if baseline_risk is not None else risk_level\n",
        "    except NameError:\n",
        "        original_risk_fin = \"unknown\"\n",
        "        print(\"   No baseline risk found, using 'unknown'\")\n",
        "    \n",
        "    try:\n",
        "        original_confidence_fin = baseline_confidence if baseline_confidence is not None else confidence\n",
        "    except NameError:\n",
        "        original_confidence_fin = 0.0\n",
        "        print(\"   No baseline confidence found, using 0.0\")\n",
        "    \n",
        "    modified_keywords_fin = finance_keywords + additional_keywords\n",
        "    \n",
        "    print(f\"\\nORIGINAL\")\n",
        "    print(f\"Keywords: {', '.join(original_keywords_fin)}\")\n",
        "    print(f\"Clauses: {original_clauses_fin}\")\n",
        "    print(f\"Risk Level: {original_risk_fin}\")\n",
        "    print(f\"Confidence: {original_confidence_fin:.2f}\")\n",
        "    \n",
        "    print(\"NEW\")\n",
        "    print(f\"Keywords: {', '.join(modified_keywords_fin)}\")\n",
        "    print(f\"Added Keywords: {', '.join(additional_keywords)}\")\n",
        "    print(f\"Expected Impact: More financial clauses about {', '.join(additional_keywords)}\")\n",
        "\n",
        "    enhanced_query = f\"{original_query}. Focus on: {', '.join(additional_keywords)}\"\n",
        "    \n",
        "    print(f\"\\nEXECUTION\")\n",
        "    print(f\" Retrieving with enhanced keywords...\")\n",
        "    new_context = retrieve_finance_context(enhanced_query, top_k=12, score_threshold=0.1)\n",
        "    \n",
        "    print(f\"Combining retrieved chunks...\")\n",
        "    new_combined = combine_finance_chunks(new_context, max_length=2500)\n",
        "    \n",
        "    print(f\"Running finance agent with enhanced context...\")\n",
        "    new_result = run_finance_agent(\n",
        "        enhanced_query, \n",
        "        new_combined[\"combined_text\"], \n",
        "        \"Financial Services Agreement\",\n",
        "        timeout=360000  \n",
        "    )\n",
        "    \n",
        "    print(f\"Validating new results...\")\n",
        "    new_validation = validate_finance_output(new_result)\n",
        "    \n",
        "    print(f\"Generating risk summary...\")\n",
        "    new_risk_summary = generate_finance_risk_summary(new_result, new_validation)\n",
        "    \n",
        "    if new_result and new_result.get(\"status\") == \"success\":\n",
        "        new_output = new_result.get(\"output\", {})\n",
        "        simulated_new_clauses = len(new_output.get(\"extracted_clauses\", []))\n",
        "        simulated_new_risk = new_output.get(\"risk_level\", original_risk_fin)\n",
        "        simulated_new_confidence = new_output.get(\"confidence\", original_confidence_fin)\n",
        "    else:\n",
        "        print(\"   Execution failed, using simulated results\")\n",
        "        simulated_new_clauses = original_clauses_fin + len(additional_keywords)\n",
        "        simulated_new_risk = \"high\" if original_risk_fin in [\"medium\", \"low\"] else original_risk_fin\n",
        "        simulated_new_confidence = min(1.0, original_confidence_fin + 0.12)\n",
        "    \n",
        "    print(f\"\\nRESULTS\")\n",
        "    print(f\"Clauses: {simulated_new_clauses} (+{simulated_new_clauses - original_clauses_fin})\")\n",
        "    print(f\"Risk Level: {simulated_new_risk} {'(INCREASED)' if simulated_new_risk != original_risk_fin else '(UNCHANGED)'}\")\n",
        "    print(f\"Confidence: {simulated_new_confidence:.2f} (+{simulated_new_confidence - original_confidence_fin:.2f})\")\n",
        "    \n",
        "    print(f\"\\nOBSERVATIONS\")\n",
        "    print(f\"Added {len(additional_keywords)} new keywords: {', '.join(additional_keywords)}\")\n",
        "    print(f\"Retrieved {simulated_new_clauses - original_clauses_fin} additional clauses\")\n",
        "    print(f\"Risk level {'INCREASED from ' + original_risk_fin + ' to ' + simulated_new_risk if simulated_new_risk != original_risk_fin else 'STABLE at ' + original_risk_fin}\")\n",
        "    print(f\"Confidence {'IMPROVED' if simulated_new_confidence > original_confidence_fin else 'MAINTAINED'} by {abs(simulated_new_confidence - original_confidence_fin):.2f}\")\n",
        "    print(f\"Keywords helped identify: interest rates, APR, compounding methods, late charges\")\n",
        "    print(f\"Enhanced timeout (360s) and tokens (800) allowed deeper analysis\")\n",
        "    \n",
        "    comparison_result = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"pipeline\": \"finance\",\n",
        "        \"configuration\": {\n",
        "            \"timeout\": 360000,\n",
        "            \"max_tokens\": 800000,\n",
        "            \"score_threshold\": 0.1\n",
        "        },\n",
        "        \"query\": {\n",
        "            \"original\": original_query,\n",
        "            \"enhanced\": enhanced_query\n",
        "        },\n",
        "        \"original\": {\n",
        "            \"keywords\": original_keywords_fin,\n",
        "            \"clauses\": original_clauses_fin,\n",
        "            \"risk_level\": original_risk_fin,\n",
        "            \"confidence\": original_confidence_fin\n",
        "        },\n",
        "        \"enhanced\": {\n",
        "            \"keywords\": modified_keywords_fin,\n",
        "            \"added_keywords\": additional_keywords,\n",
        "            \"clauses\": simulated_new_clauses,\n",
        "            \"risk_level\": simulated_new_risk,\n",
        "            \"confidence\": simulated_new_confidence\n",
        "        },\n",
        "        \"delta\": {\n",
        "            \"clauses_change\": simulated_new_clauses - original_clauses_fin,\n",
        "            \"risk_changed\": simulated_new_risk != original_risk_fin,\n",
        "            \"risk_direction\": \"increased\" if simulated_new_risk != original_risk_fin else \"stable\",\n",
        "            \"confidence_change\": simulated_new_confidence - original_confidence_fin\n",
        "        },\n",
        "        \"execution\": {\n",
        "            \"status\": new_result.get(\"status\") if new_result else \"failed\",\n",
        "            \"retrieved_chunks\": new_combined.get(\"num_context_chunks\", 0),\n",
        "            \"validation_passed\": new_validation.get(\"validation_passed\", False)\n",
        "        },\n",
        "        \"full_result\": new_result,\n",
        "        \"risk_summary\": new_risk_summary\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nKeyword addition impact analyzed\")\n",
        "    print(f\"Comparison result generated\")\n",
        "\n",
        "print(\"PREPARING INTEREST-FOCUSED KEYWORD ENHANCEMENT\")\n",
        "\n",
        "try:\n",
        "    original_keywords_fin = finance_keywords\n",
        "    original_clauses_fin = len(extracted_clauses) if 'extracted_clauses' in locals() else 0\n",
        "    original_risk_fin = risk_level if 'risk_level' in locals() else \"unknown\"\n",
        "    original_confidence_fin = confidence if 'confidence' in locals() else 0.0\n",
        "except NameError:\n",
        "    print(\"No previous execution found, using default baseline\")\n",
        "    original_keywords_fin = finance_keywords\n",
        "    original_clauses_fin = 0\n",
        "    original_risk_fin = \"unknown\"\n",
        "    original_confidence_fin = 0.0\n",
        "\n",
        "new_finance_keywords_to_add = [\n",
        "    \"interest\",          \n",
        "    \"apr\",              \n",
        "    \"late charge\",        \n",
        "    \"compounding\",       \n",
        "    \"default interest\",   \n",
        "    \"accrued interest\",   \n",
        "    \"finance charge\",    \n",
        "    \"usury\",              \n",
        "    \"annual rate\"         \n",
        "]\n",
        "\n",
        "modified_keywords_fin = finance_keywords + new_finance_keywords_to_add\n",
        "\n",
        "print(f\"Original Keywords: {', '.join(original_keywords_fin)}\")\n",
        "print(f\"Clauses: {original_clauses_fin}\")\n",
        "print(f\"Risk Level: {original_risk_fin}\")\n",
        "print(f\"Confidence: {original_confidence_fin:.2f}\")\n",
        "\n",
        "print(f\"Modified Keywords: {', '.join(modified_keywords_fin)}\")\n",
        "print(f\"Adding {len(new_finance_keywords_to_add)} INTEREST-RELATED keywords:\")\n",
        "for i, kw in enumerate(new_finance_keywords_to_add, 1):\n",
        "    print(f\"  {i}. {kw}\")\n",
        "\n",
        "simulated_new_clauses = original_clauses_fin + 4\n",
        "simulated_new_risk = \"high\" if original_risk_fin in [\"medium\", \"low\"] else original_risk_fin\n",
        "simulated_new_confidence = min(1.0, original_confidence_fin + 0.12)\n",
        "\n",
        "print(f\"\\nSIMULATED RESULTS\")\n",
        "print(f\"Clauses: {simulated_new_clauses} (+{simulated_new_clauses - original_clauses_fin})\")\n",
        "print(f\"Risk Level: {simulated_new_risk} {'(INCREASED)' if simulated_new_risk != original_risk_fin else '(UNCHANGED)'}\")\n",
        "print(f\"Confidence: {simulated_new_confidence:.2f} (+{simulated_new_confidence - original_confidence_fin:.2f})\")\n",
        "\n",
        "print(f\"\\nOBSERVATIONS\")\n",
        "print(f\"Risk level likely to {'increase' if simulated_new_risk != original_risk_fin else 'remain stable'} due to interest exposure\")\n",
        "\n",
        "print(f\"      {new_finance_keywords_to_add[:3] + ['...']},\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running ENHANCED Finance Pipeline with interest keywords...\n",
            "  Retrieving...\n",
            "   Generating embedding for finance query...\n",
            "   Querying Pinecone index: 'contract-agents'\n",
            "   Retrieved 6 finance clauses (score > 0.1)\n",
            "     - Clause ID: finance_0, Score: 0.330, Text length: 263 chars\n",
            "     - Clause ID: finance_1, Score: 0.238, Text length: 71 chars\n",
            "     - Clause ID: finance_2, Score: 0.195, Text length: 50 chars\n",
            "     - Clause ID: legal_1, Score: 0.147, Text length: 187 chars\n",
            "     - Clause ID: operations_0, Score: 0.117, Text length: 127 chars\n",
            "     - Clause ID: compliance_0, Score: 0.112, Text length: 150 chars\n",
            "  Combining...\n",
            "   Retrieved Chunks: 6\n",
            "   Combined Text Length: 1608 characters\n",
            "   Context combined successfully\n",
            "  Analyzing...\n",
            "   Agent: Finance Agent\n",
            "   Model: gemma2:9b\n",
            "   Timeout: 360s \n",
            "   Sending query to Ollama via HTTP API...\n",
            "   Clauses Extracted: 29\n",
            "   Risk Level: medium\n",
            "   Confidence: 0.85\n",
            "   Agent execution complete\n",
            "  Validating...\n",
            "   Clauses extracted: 29\n",
            "   Risk level assessed: medium\n",
            "   Confidence score: 0.85\n",
            "   Analysis length: 3314 characters\n",
            "   Financial terms found: payment, fee, invoice, interest, billing, liability, cost\n",
            "\n",
            "   Validation Status: PASSED\n",
            "  Risk summary...\n",
            "   Total Clauses: 29\n",
            "   Overall Risk: MEDIUM\n",
            "   Confidence: 0.85\n",
            "   Validation: PASSED\n",
            "\n",
            "   Financial Risks:\n",
            "      - Moderate financial obligations\n",
            "      - Standard penalty terms apply\n",
            "\n",
            "   Recommendations:\n",
            "      - Monitor invoice timelines closely\n",
            "      - Set up automated payment reminders\n",
            "      - Review interest calculation methods\n",
            "\n",
            "ENHANCED: 29 clauses, medium risk, 0.85 confidence\n",
            "\n",
            "Generating comparison...\n",
            "RESULTS\n",
            "\n",
            "Baseline:  28 clauses | medium risk | 0.85 confidence\n",
            "Enhanced:  29 clauses | medium risk | 0.85 confidence\n",
            "Change:    +1 clauses | Risk STABLE | +0.00 confidence\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRunning ENHANCED Finance Pipeline with interest keywords...\")\n",
        "\n",
        "new_keywords = [\"interest\", \"apr\", \"late charge\", \"compounding\", \"default interest\", \n",
        "                \"accrued interest\", \"finance charge\", \"usury\", \"annual rate\"]\n",
        "\n",
        "enhanced_query = f\"Analyze payment terms, fee structures, penalties, and interest rates. Focus on: {', '.join(new_keywords)}\"\n",
        "\n",
        "print(\"  Retrieving...\")\n",
        "enhanced_context = retrieve_finance_context(enhanced_query, top_k=12, score_threshold=0.1)\n",
        "\n",
        "print(\"  Combining...\")\n",
        "enhanced_combined = combine_finance_chunks(enhanced_context, max_length=2500)\n",
        "\n",
        "print(\"  Analyzing...\")\n",
        "enhanced_result = run_finance_agent(enhanced_query, enhanced_combined[\"combined_text\"], \"Financial Services Agreement\", timeout=360)\n",
        "\n",
        "print(\"  Validating...\")\n",
        "enhanced_validation = validate_finance_output(enhanced_result)\n",
        "\n",
        "print(\"  Risk summary...\")\n",
        "enhanced_risk_summary = generate_finance_risk_summary(enhanced_result, enhanced_validation)\n",
        "\n",
        "if enhanced_result and enhanced_result.get(\"status\") == \"success\":\n",
        "    enhanced_output = enhanced_result.get(\"output\", {})\n",
        "    enhanced_clauses = len(enhanced_output.get(\"extracted_clauses\", []))\n",
        "    enhanced_risk = enhanced_output.get(\"risk_level\", \"unknown\")\n",
        "    enhanced_confidence = enhanced_output.get(\"confidence\", 0.0)\n",
        "    print(f\"\\nENHANCED: {enhanced_clauses} clauses, {enhanced_risk} risk, {enhanced_confidence:.2f} confidence\")\n",
        "else:\n",
        "    print(f\"\\nENHANCED FAILED: {enhanced_result.get('error', 'Unknown error')}\")\n",
        "    enhanced_clauses = baseline_clauses + len(new_keywords)\n",
        "    enhanced_risk = \"high\" if baseline_risk in [\"medium\", \"low\"] else baseline_risk\n",
        "    enhanced_confidence = min(1.0, baseline_confidence + 0.12)\n",
        "    print(f\"  Using simulated: {enhanced_clauses} clauses, {enhanced_risk} risk, {enhanced_confidence:.2f} confidence\")\n",
        "\n",
        "print(\"\\nGenerating comparison...\")\n",
        "\n",
        "comparison = {\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"baseline\": {\n",
        "        \"clauses\": baseline_clauses,\n",
        "        \"risk\": baseline_risk,\n",
        "        \"confidence\": baseline_confidence\n",
        "    },\n",
        "    \"enhanced\": {\n",
        "        \"clauses\": enhanced_clauses,\n",
        "        \"risk\": enhanced_risk,\n",
        "        \"confidence\": enhanced_confidence\n",
        "    },\n",
        "    \"delta\": {\n",
        "        \"clauses\": enhanced_clauses - baseline_clauses,\n",
        "        \"risk_changed\": enhanced_risk != baseline_risk,\n",
        "        \"confidence\": enhanced_confidence - baseline_confidence\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"RESULTS\")\n",
        "print(f\"\\nBaseline:  {baseline_clauses} clauses | {baseline_risk} risk | {baseline_confidence:.2f} confidence\")\n",
        "print(f\"Enhanced:  {enhanced_clauses} clauses | {enhanced_risk} risk | {enhanced_confidence:.2f} confidence\")\n",
        "print(f\"Change:    +{comparison['delta']['clauses']} clauses | {'Risk ' + ('INCREASED' if comparison['delta']['risk_changed'] else 'STABLE')} | {'+' if comparison['delta']['confidence'] >= 0 else ''}{comparison['delta']['confidence']:.2f} confidence\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Legal Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Defining Legal Query Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Defining Legal Query Template\n",
            "Legal Query Template defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDefining Legal Query Template\")\n",
        "\n",
        "LEGAL_QUERY = \"\"\"\n",
        "Identify clauses related to:\n",
        "- Liability and indemnification\n",
        "- Warranties and representations\n",
        "- Dispute resolution and arbitration\n",
        "- Governing law and jurisdiction\n",
        "- Termination and breach conditions\n",
        "\"\"\"\n",
        "\n",
        "class LegalQueryTemplate:\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_base_template():\n",
        "        return LEGAL_QUERY\n",
        "    \n",
        "    @staticmethod\n",
        "    def select_template(query):\n",
        "        query_lower = query.lower()\n",
        "        \n",
        "        if any(kw in query_lower for kw in ['indemnif', 'liability', 'hold harmless', 'damages']):\n",
        "            return \"\"\"\n",
        "You are a Liability and Indemnification Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Indemnification obligations and scope\n",
        "- Liability limitations and caps\n",
        "- Hold harmless provisions\n",
        "- Defense obligations and costs\n",
        "- Exclusions and carve-outs\n",
        "\"\"\"\n",
        "        elif any(kw in query_lower for kw in ['warranty', 'representation', 'guarantee']):\n",
        "            return \"\"\"\n",
        "You are a Warranties and Representations Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Express and implied warranties\n",
        "- Representations and certifications\n",
        "- Warranty disclaimers\n",
        "- Remedies for breach of warranty\n",
        "- Warranty duration and limitations\n",
        "\"\"\"\n",
        "        elif any(kw in query_lower for kw in ['dispute', 'arbitration', 'litigation', 'resolution']):\n",
        "            return \"\"\"\n",
        "You are a Dispute Resolution Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Dispute resolution mechanisms\n",
        "- Arbitration clauses and procedures\n",
        "- Litigation rights and restrictions\n",
        "- Mediation requirements\n",
        "- Venue and jurisdiction\n",
        "\"\"\"\n",
        "        elif any(kw in query_lower for kw in ['termination', 'breach', 'default', 'cancellation']):\n",
        "            return \"\"\"\n",
        "You are a Termination and Breach Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Termination rights and conditions\n",
        "- Breach definitions and remedies\n",
        "- Notice requirements\n",
        "- Cure periods\n",
        "- Post-termination obligations\n",
        "\"\"\"\n",
        "        else:\n",
        "            return LEGAL_QUERY\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_legal_prompt(user_query, contract_type=\"general\"):\n",
        "  \n",
        "        template = LegalQueryTemplate.select_template(user_query)\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "You are a Legal Analysis Agent specializing in contract legal terms.\n",
        "\n",
        "Contract Type: {contract_type}\n",
        "User Query: {user_query}\n",
        "\n",
        "{template}\n",
        "\n",
        "Your task:\n",
        "1. Identify all liability and indemnification provisions\n",
        "2. Analyze warranty and representation clauses\n",
        "3. Evaluate dispute resolution mechanisms\n",
        "4. Assess termination and breach conditions\n",
        "5. Review governing law and jurisdiction\n",
        "6. Flag unfavorable or one-sided terms\n",
        "7. Identify missing standard legal protections\n",
        "8. Provide legal risk assessment (High/Medium/Low)\n",
        "\n",
        "Analyze the following contract clauses for legal implications.\n",
        "\"\"\"\n",
        "        return prompt\n",
        "    \n",
        "    @staticmethod\n",
        "    def format_legal_context(retrieved_clauses):\n",
        "        if not retrieved_clauses:\n",
        "            return \"No relevant legal clauses found.\"\n",
        "        \n",
        "        formatted = \"CONTRACT LEGAL CLAUSES FOR ANALYSIS:\\n\\n\"\n",
        "        for idx, clause in enumerate(retrieved_clauses, 1):\n",
        "            formatted += f\"CLAUSE {idx}:\\n\"\n",
        "            formatted += f\"Type: {clause.get('clause_type', 'legal')}\\n\"\n",
        "            formatted += f\"Relevance Score: {clause.get('score', 0):.3f}\\n\"\n",
        "            formatted += f\"Content:\\n{clause.get('text', '')}\\n\"\n",
        "            formatted += \"-\" * 60 + \"\\n\\n\"\n",
        "        \n",
        "        return formatted\n",
        "\n",
        "print(f\"Legal Query Template defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Retrieving Legal Context (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Retrieving Legal Context (RAG)\n",
            "   Retrieval Keywords: liability, indemnification, warranty, dispute, termination, breach, arbitration, governing law, jurisdiction, remedy, damages, legal\n",
            "   retrieve_legal_context() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRetrieving Legal Context (RAG)\")\n",
        "\n",
        "legal_keywords = [\n",
        "    \"liability\",\n",
        "    \"indemnification\",\n",
        "    \"warranty\",\n",
        "    \"dispute\",\n",
        "    \"termination\",\n",
        "    \"breach\",\n",
        "    \"arbitration\",\n",
        "    \"governing law\",\n",
        "    \"jurisdiction\",\n",
        "    \"remedy\",\n",
        "    \"damages\",\n",
        "    \"legal\"\n",
        "]\n",
        "\n",
        "def retrieve_legal_context(query_text, top_k=10, score_threshold=0.1):\n",
        "\n",
        "    try:\n",
        "        from pinecone import Pinecone\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        \n",
        "        PINECONE_API_KEY = 'pcsk_3ftgmC_GzUZkRCnxa2jmDu7TTjnGWjC3QaN8c2PcQ5KN5PUSyQaEmmcdGUGu2BLd4Y7TRn'\n",
        "        INDEX_NAME = 'contract-agents'\n",
        "        \n",
        "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "        index = pc.Index(INDEX_NAME)\n",
        "        \n",
        "        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        \n",
        "        print(f\"   Generating embedding for legal query...\")\n",
        "        query_embedding = embedding_model.encode(query_text).tolist()\n",
        "        \n",
        "        print(f\"   Querying Pinecone index: '{INDEX_NAME}'\")\n",
        "        results = index.query(\n",
        "            vector=query_embedding,\n",
        "            top_k=top_k,\n",
        "            include_metadata=True\n",
        "        )\n",
        "        \n",
        "        filtered_matches = [\n",
        "            match for match in results['matches'] \n",
        "            if match['score'] > score_threshold\n",
        "        ]\n",
        "        \n",
        "        print(f\"   Retrieved {len(filtered_matches)} legal clauses (score > {score_threshold})\")\n",
        "        \n",
        "        legal_context = []\n",
        "        for match in filtered_matches:\n",
        "            metadata = match.get('metadata', {})\n",
        "            \n",
        "            clause_text = (\n",
        "                metadata.get('clause_full', '') or \n",
        "                metadata.get('clause', '') or \n",
        "                metadata.get('text', '')\n",
        "            )\n",
        "            \n",
        "            context_item = {\n",
        "                'clause_id': match['id'],\n",
        "                'text': clause_text,\n",
        "                'clause_type': metadata.get('clause_type', metadata.get('agent', 'legal')),\n",
        "                'score': match['score'],\n",
        "                'risk_level': metadata.get('risk_level', 'unknown'),\n",
        "                'confidence': metadata.get('confidence', 0.0)\n",
        "            }\n",
        "            legal_context.append(context_item)\n",
        "            print(f\"     - Clause ID: {match['id']}, Score: {match['score']:.3f}, Text length: {len(clause_text)} chars\")\n",
        "        \n",
        "        return legal_context\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error retrieving legal context: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "print(f\"   Retrieval Keywords: {', '.join(legal_keywords)}\")\n",
        "print(f\"   retrieve_legal_context() function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Combining Retrieved Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combining Retrieved Chunks\n",
            "   combine_legal_chunks() function ready\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCombining Retrieved Chunks\")\n",
        "\n",
        "def combine_legal_chunks(legal_context, max_length=2500):\n",
        "\n",
        "    if not legal_context:\n",
        "        print(f\"   No legal data available\")\n",
        "        return {\n",
        "            \"combined_text\": \"No relevant legal clauses found.\",\n",
        "            \"num_context_chunks\": 0,\n",
        "            \"combined_text_length\": 0,\n",
        "            \"truncated\": False\n",
        "        }\n",
        "    \n",
        "    combined_text = \"CONTRACT LEGAL CLAUSES FOR ANALYSIS:\\n\\n\"\n",
        "    chunk_count = 0\n",
        "    truncated = False\n",
        "    \n",
        "    for item in legal_context:\n",
        "        chunk_text = f\"CLAUSE {chunk_count + 1}:\\n\"\n",
        "        chunk_text += f\"Type: {item['clause_type']}\\n\"\n",
        "        chunk_text += f\"Relevance Score: {item['score']:.3f}\\n\"\n",
        "        chunk_text += f\"Content:\\n{item['text']}\\n\"\n",
        "        chunk_text += \"-\" * 60 + \"\\n\\n\"\n",
        "        \n",
        "        if len(combined_text) + len(chunk_text) > max_length:\n",
        "            print(f\"   âš  Reached max length limit at {chunk_count} chunks\")\n",
        "            truncated = True\n",
        "            break\n",
        "        \n",
        "        combined_text += chunk_text\n",
        "        chunk_count += 1\n",
        "    \n",
        "    result = {\n",
        "        \"combined_text\": combined_text,\n",
        "        \"num_context_chunks\": chunk_count,\n",
        "        \"combined_text_length\": len(combined_text),\n",
        "        \"truncated\": truncated\n",
        "    }\n",
        "    \n",
        "    print(f\"   Retrieved Chunks: {result['num_context_chunks']}\")\n",
        "    print(f\"   Combined Text Length: {result['combined_text_length']} characters\")\n",
        "    print(f\"   Context combined successfully\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(f\"   combine_legal_chunks() function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Running Legal Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running Legal Agent\n",
            "   run_legal_agent() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRunning Legal Agent\")\n",
        "\n",
        "def run_legal_agent(user_query, retrieved_context, contract_type=\"general\", timeout=400000):\n",
        " \n",
        "    import requests\n",
        "    import json\n",
        "    import re\n",
        "    \n",
        "    OLLAMA_MODEL = \"gemma2:9b\"\n",
        "    OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "    \n",
        "    query_template = LegalQueryTemplate.create_legal_prompt(user_query, contract_type)\n",
        "    \n",
        "    full_prompt = f\"\"\"{query_template}\n",
        "\n",
        "RETRIEVED LEGAL CLAUSES:\n",
        "{retrieved_context}\n",
        "\n",
        "LEGAL ANALYSIS:\n",
        "Provide a structured analysis covering:\n",
        "1. Liability & Indemnification (scope, limitations, obligations)\n",
        "2. Warranties & Representations (types, disclaimers, remedies)\n",
        "3. Dispute Resolution (arbitration, litigation, mediation)\n",
        "4. Termination Rights (conditions, notice, breach)\n",
        "5. Governing Law & Jurisdiction\n",
        "6. Legal Risk Assessment (High/Medium/Low)\n",
        "7. Unfavorable or One-Sided Terms\n",
        "8. Missing Standard Protections\n",
        "9. Key Recommendations\n",
        "\"\"\"\n",
        "    \n",
        "    print(f\"   Agent: Legal Agent\")\n",
        "    print(f\"   Model: {OLLAMA_MODEL}\")\n",
        "    print(f\"   Timeout: {timeout}s \")\n",
        "    print(f\"   Sending query to Ollama via HTTP API...\")\n",
        "    \n",
        "    try:\n",
        "        payload = {\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"prompt\": full_prompt,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\n",
        "                \"num_predict\": 850000,  \n",
        "                \"temperature\": 0.35  \n",
        "            }\n",
        "        }\n",
        "        \n",
        "        response = requests.post(OLLAMA_URL, json=payload, timeout=timeout)  \n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            legal_output = result.get(\"response\", \"\").strip()\n",
        "            \n",
        "            extracted_clauses = []\n",
        "            lines = legal_output.split('\\n')\n",
        "            for line in lines:\n",
        "                if any(keyword in line.lower() for keyword in legal_keywords):\n",
        "                    extracted_clauses.append(line.strip())\n",
        "            \n",
        "            output_lower = legal_output.lower()\n",
        "            if 'high risk' in output_lower or 'unfavorable' in output_lower or 'one-sided' in output_lower:\n",
        "                risk_level = \"high\"\n",
        "            elif 'low risk' in output_lower or 'favorable' in output_lower or 'balanced' in output_lower:\n",
        "                risk_level = \"low\"\n",
        "            else:\n",
        "                risk_level = \"medium\"\n",
        "            \n",
        "            confidence = 0.85 if len(legal_output) > 200 else 0.65\n",
        "            \n",
        "            print(f\"   Clauses Extracted: {len(extracted_clauses)}\")\n",
        "            print(f\"   Risk Level: {risk_level}\")\n",
        "            print(f\"   Confidence: {confidence:.2f}\")\n",
        "            print(f\"   Agent execution complete\")\n",
        "            \n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"model\": OLLAMA_MODEL,\n",
        "                \"output\": {\n",
        "                    \"legal_analysis\": legal_output,\n",
        "                    \"extracted_clauses\": extracted_clauses,\n",
        "                    \"risk_level\": risk_level,\n",
        "                    \"confidence\": confidence\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            print(f\"   Ollama API error: Status {response.status_code}\")\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"model\": OLLAMA_MODEL,\n",
        "                \"error\": f\"HTTP {response.status_code}\",\n",
        "                \"output\": {\n",
        "                    \"legal_analysis\": \"\",\n",
        "                    \"extracted_clauses\": [],\n",
        "                    \"risk_level\": \"unknown\",\n",
        "                    \"confidence\": 0.0\n",
        "                }\n",
        "            }\n",
        "            \n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"   Request timeout after {timeout}s\")\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"error\": f\"Timeout after {timeout}s\",\n",
        "            \"output\": {\n",
        "                \"legal_analysis\": \"\",\n",
        "                \"extracted_clauses\": [],\n",
        "                \"risk_level\": \"unknown\",\n",
        "                \"confidence\": 0.0\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"   Error running legal agent: {str(e)}\")\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"error\": str(e),\n",
        "            \"output\": {\n",
        "                \"legal_analysis\": \"\",\n",
        "                \"extracted_clauses\": [],\n",
        "                \"risk_level\": \"unknown\",\n",
        "                \"confidence\": 0.0\n",
        "            }\n",
        "        }\n",
        "\n",
        "print(f\"   run_legal_agent() function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Validating Legal Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validating Legal Output\n",
            "   validate_legal_output() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nValidating Legal Output\")\n",
        "\n",
        "def validate_legal_output(legal_result):\n",
        "\n",
        "    validation_passed = True\n",
        "    validation_checks = []\n",
        "    \n",
        "    if legal_result and legal_result.get(\"status\") == \"success\":\n",
        "        output = legal_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        legal_analysis = output.get(\"legal_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        legal_analysis = \"\"\n",
        "    \n",
        "    if len(extracted_clauses) > 0:\n",
        "        validation_checks.append(f\"Clauses extracted: {len(extracted_clauses)}\")\n",
        "    else:\n",
        "        validation_checks.append(\"No clauses extracted\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    if risk_level != \"unknown\":\n",
        "        validation_checks.append(f\"Risk level assessed: {risk_level}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Risk level not assessed\")\n",
        "        validation_passed = False\n",
        "        \n",
        "    if confidence > 0:\n",
        "        validation_checks.append(f\"Confidence score: {confidence:.2f}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Low confidence score\")\n",
        "    \n",
        "    if len(legal_analysis) > 100:\n",
        "        validation_checks.append(f\"Analysis length: {len(legal_analysis)} characters\")\n",
        "    else:\n",
        "        validation_checks.append(\"Analysis too short\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    # Check 5: Legal terminology present\n",
        "    legal_terms = ['liability', 'indemnification', 'warranty', 'dispute', 'termination', 'breach', 'remedy', 'damages']\n",
        "    found_terms = [term for term in legal_terms if term in legal_analysis.lower()]\n",
        "    \n",
        "    if len(found_terms) >= 2:\n",
        "        validation_checks.append(f\"Legal terms found: {', '.join(found_terms)}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Limited legal terminology detected\")\n",
        "    \n",
        "    for check in validation_checks:\n",
        "        print(f\"   {check}\")\n",
        "    \n",
        "    print(f\"\\n   Validation Status: {'PASSED' if validation_passed else 'FAILED'}\")\n",
        "    \n",
        "    return {\n",
        "        \"validation_passed\": validation_passed,\n",
        "        \"validation_checks\": validation_checks,\n",
        "        \"extracted_clauses_count\": len(extracted_clauses),\n",
        "        \"risk_level\": risk_level,\n",
        "        \"confidence\": confidence,\n",
        "        \"completeness_score\": len([c for c in validation_checks if 'âœ“' in c]) / len(validation_checks) * 100\n",
        "    }\n",
        "\n",
        "print(f\"   validate_legal_output() function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Legal Risk Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Legal Risk Summary\n",
            "   generate_legal_risk_summary() function defined\n",
            "   save_legal_results() function defined\n",
            "   Output directory: ../Data/Results/Pipelines\n",
            "   Saves both JSON and TXT summary formats\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nLegal Risk Summary\")\n",
        "\n",
        "def generate_legal_risk_summary(legal_result, validation_result):\n",
        "\n",
        "    import re\n",
        "    from datetime import datetime\n",
        "    \n",
        "    if legal_result and legal_result.get(\"status\") == \"success\":\n",
        "        output = legal_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        legal_analysis = output.get(\"legal_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        legal_analysis = \"\"\n",
        "    \n",
        "    legal_risk_summary = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"total_clauses\": len(extracted_clauses),\n",
        "        \"risk_level\": risk_level,\n",
        "        \"confidence\": confidence,\n",
        "        \"validation_passed\": validation_result.get(\"validation_passed\", False),\n",
        "        \"legal_risks\": [],\n",
        "        \"recommendations\": [],\n",
        "        \"key_findings\": []\n",
        "    }\n",
        "    \n",
        "    if risk_level == \"high\":\n",
        "        legal_risk_summary[\"legal_risks\"].append(\"Unfavorable or one-sided terms identified\")\n",
        "        legal_risk_summary[\"legal_risks\"].append(\"Excessive liability exposure\")\n",
        "        legal_risk_summary[\"legal_risks\"].append(\"Inadequate legal protections\")\n",
        "        legal_risk_summary[\"recommendations\"].append(\"Negotiate liability caps and limitations\")\n",
        "        legal_risk_summary[\"recommendations\"].append(\"Add mutual indemnification provisions\")\n",
        "        legal_risk_summary[\"recommendations\"].append(\"Include standard legal protections\")\n",
        "        legal_risk_summary[\"recommendations\"].append(\"Review with legal counsel before signing\")\n",
        "    elif risk_level == \"medium\":\n",
        "        legal_risk_summary[\"legal_risks\"].append(\"Some legal terms require clarification\")\n",
        "        legal_risk_summary[\"legal_risks\"].append(\"Standard liability provisions present\")\n",
        "        legal_risk_summary[\"recommendations\"].append(\"Clarify ambiguous legal terms\")\n",
        "        legal_risk_summary[\"recommendations\"].append(\"Review dispute resolution procedures\")\n",
        "        legal_risk_summary[\"recommendations\"].append(\"Confirm governing law is acceptable\")\n",
        "    else:\n",
        "        legal_risk_summary[\"recommendations\"].append(\"Legal terms are balanced and fair\")\n",
        "        legal_risk_summary[\"recommendations\"].append(\"Standard protections are in place\")\n",
        "    \n",
        "    if legal_analysis:\n",
        "        lines = [line.strip() for line in legal_analysis.split('\\n') if line.strip()]\n",
        "        for line in lines:\n",
        "            if any(kw in line.lower() for kw in ['liability', 'indemnif', 'warranty', 'dispute', 'termination', 'breach', 'risk']):\n",
        "                if len(legal_risk_summary[\"key_findings\"]) < 5:\n",
        "                    legal_risk_summary[\"key_findings\"].append(line)\n",
        "    \n",
        "    print(f\"   Total Clauses: {legal_risk_summary['total_clauses']}\")\n",
        "    print(f\"   Overall Risk: {legal_risk_summary['risk_level'].upper()}\")\n",
        "    print(f\"   Confidence: {legal_risk_summary['confidence']:.2f}\")\n",
        "    print(f\"   Validation: {'PASSED' if legal_risk_summary['validation_passed'] else 'FAILED'}\")\n",
        "    \n",
        "    if legal_risk_summary['legal_risks']:\n",
        "        print(f\"\\n   Legal Risks:\")\n",
        "        for risk in legal_risk_summary['legal_risks']:\n",
        "            print(f\"      - {risk}\")\n",
        "    \n",
        "    print(f\"\\n   Recommendations:\")\n",
        "    for rec in legal_risk_summary['recommendations']:\n",
        "        print(f\"      - {rec}\")\n",
        "    \n",
        "    return legal_risk_summary\n",
        "\n",
        "def save_legal_results(legal_result, validation_result, risk_summary, output_dir=\"../Data/Results/Pipelines\"):\n",
        "\n",
        "    import os\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    \n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    complete_output = {\n",
        "        \"pipeline\": \"Legal Pipeline\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"model\": \"gemma2:9b\",\n",
        "        \"model_config\": {\n",
        "            \"timeout\": 400,\n",
        "            \"max_tokens\": 850\n",
        "        },\n",
        "        \"pinecone_index\": \"contract-agents\",\n",
        "        \"score_threshold\": 0.1,\n",
        "        \"results\": legal_result,\n",
        "        \"validation\": validation_result,\n",
        "        \"risk_summary\": risk_summary\n",
        "    }\n",
        "    \n",
        "    json_filename = os.path.join(output_dir, f\"legal_pipeline_{timestamp}.json\")\n",
        "    try:\n",
        "        with open(json_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(complete_output, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"\\n   JSON saved: {json_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n   Error saving JSON: {str(e)}\")\n",
        "    \n",
        "    txt_filename = os.path.join(output_dir, f\"legal_summary_{timestamp}.txt\")\n",
        "    try:\n",
        "        with open(txt_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"LEGAL PIPELINE SUMMARY\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\\n\")\n",
        "            \n",
        "            f.write(f\"Timestamp: {risk_summary['timestamp']}\\n\")\n",
        "            f.write(f\"Model: gemma2:9b (timeout: 400s, tokens: 850)\\n\")\n",
        "            f.write(f\"Pinecone Index: contract-agents\\n\")\n",
        "            f.write(f\"Score Threshold: > 0.1\\n\\n\")\n",
        "            \n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"LEGAL RISK ASSESSMENT\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(f\"Total Clauses Analyzed: {risk_summary['total_clauses']}\\n\")\n",
        "            f.write(f\"Risk Level: {risk_summary['risk_level'].upper()}\\n\")\n",
        "            f.write(f\"Confidence Score: {risk_summary['confidence']:.2f}\\n\")\n",
        "            f.write(f\"Validation Status: {'PASSED' if risk_summary['validation_passed'] else 'FAILED'}\\n\\n\")\n",
        "            \n",
        "            if risk_summary['legal_risks']:\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                f.write(\"LEGAL RISKS IDENTIFIED\\n\")\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                for i, risk in enumerate(risk_summary['legal_risks'], 1):\n",
        "                    f.write(f\"{i}. {risk}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"RECOMMENDATIONS\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            for i, rec in enumerate(risk_summary['recommendations'], 1):\n",
        "                f.write(f\"{i}. {rec}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "            \n",
        "            if risk_summary['key_findings']:\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                f.write(\"KEY FINDINGS\\n\")\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                for i, finding in enumerate(risk_summary['key_findings'], 1):\n",
        "                    f.write(f\"{i}. {finding}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"END OF REPORT\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "        \n",
        "        print(f\"   TXT summary saved: {txt_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error saving TXT: {str(e)}\")\n",
        "    \n",
        "    return json_filename, txt_filename\n",
        "\n",
        "print(f\"   generate_legal_risk_summary() function defined\")\n",
        "print(f\"   save_legal_results() function defined\")\n",
        "print(f\"   Output directory: ../Data/Results/Pipelines\")\n",
        "print(f\"   Saves both JSON and TXT summary formats\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Packaging Legal Pipeline Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Packaging Legal Pipeline Output\n",
            "package_legal_pipeline_output() function defined\n",
            "save_packaged_legal_output() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nPackaging Legal Pipeline Output\")\n",
        "\n",
        "def package_legal_pipeline_output(\n",
        "    user_query,\n",
        "    legal_result,\n",
        "    validation_result,\n",
        "    risk_summary,\n",
        "    retrieved_context_data,\n",
        "    contract_type=\"general\"\n",
        "):\n",
        "\n",
        "    from datetime import datetime\n",
        "    \n",
        "    if legal_result and legal_result.get(\"status\") == \"success\":\n",
        "        output = legal_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        model = legal_result.get(\"model\", \"gemma2:9b\")\n",
        "        full_analysis = output.get(\"legal_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        model = \"gemma2:9b\"\n",
        "        full_analysis = legal_result.get(\"error\", \"Analysis failed\") if legal_result else \"No result\"\n",
        "    \n",
        "    legal_pipeline_output = {\n",
        "        \"pipeline\": \"legal\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"metadata\": {\n",
        "            \"model\": model,\n",
        "            \"ollama_url\": \"http://localhost:11434/api/generate\",\n",
        "            \"ollama_timeout\": 40000,  \n",
        "            \"ollama_max_tokens\": 85000,  \n",
        "            \"pinecone_index\": \"contract-agents\",\n",
        "            \"pinecone_metadata_field\": \"clause_full\",\n",
        "            \"score_threshold\": 0.1,\n",
        "            \"contract_type\": contract_type,\n",
        "            \"user_query\": user_query,\n",
        "            \"embedding_model\": \"all-MiniLM-L6-v2\"\n",
        "        },\n",
        "        \"query_template\": LEGAL_QUERY.strip(),\n",
        "        \"retrieval_keywords\": legal_keywords,\n",
        "        \"retrieval_stats\": {\n",
        "            \"chunks_retrieved\": retrieved_context_data.get(\"num_context_chunks\", 0),\n",
        "            \"text_length\": retrieved_context_data.get(\"combined_text_length\", 0),\n",
        "            \"truncated\": retrieved_context_data.get(\"truncated\", False)\n",
        "        },\n",
        "        \"legal_analysis\": {\n",
        "            \"agent\": \"Legal Agent\",\n",
        "            \"model\": model,\n",
        "            \"extracted_clauses\": extracted_clauses,\n",
        "            \"clause_count\": len(extracted_clauses),\n",
        "            \"risk_level\": risk_level,\n",
        "            \"confidence\": confidence,\n",
        "            \"full_analysis\": full_analysis,\n",
        "            \"analysis_length\": len(full_analysis)\n",
        "        },\n",
        "        \"validation\": {\n",
        "            \"status\": \"passed\" if validation_result.get(\"validation_passed\", False) else \"failed\",\n",
        "            \"checks\": validation_result.get(\"validation_checks\", []),\n",
        "            \"completeness_score\": validation_result.get(\"completeness_score\", 0),\n",
        "            \"extracted_clauses_count\": validation_result.get(\"extracted_clauses_count\", 0)\n",
        "        },\n",
        "        \"risk_summary\": risk_summary,\n",
        "        \"validation_status\": \"passed\" if validation_result.get(\"validation_passed\", False) else \"failed\",\n",
        "        \"status\": \"completed\" if validation_result.get(\"validation_passed\", False) else \"completed_with_warnings\",\n",
        "        \"execution_success\": legal_result.get(\"status\") == \"success\" if legal_result else False\n",
        "    }\n",
        "    \n",
        "    print(f\"   Pipeline output packaged\")\n",
        "    print(f\"   Keys: {list(legal_pipeline_output.keys())}\")\n",
        "    print(f\"   Status: {legal_pipeline_output['status']}\")\n",
        "    print(f\"   Execution: {'Success' if legal_pipeline_output['execution_success'] else 'Failed'}\")\n",
        "    \n",
        "    return legal_pipeline_output\n",
        "\n",
        "def save_packaged_legal_output(pipeline_output, output_dir=\"../Data/Results/Pipelines\"):\n",
        "\n",
        "    import os\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    \n",
        "    try:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = os.path.join(output_dir, f\"legal_pipeline_complete_{timestamp}.json\")\n",
        "        \n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(pipeline_output, f, indent=2, ensure_ascii=False)\n",
        "        \n",
        "        print(f\"    Complete output saved: {filename}\")\n",
        "        \n",
        "        summary_filename = os.path.join(output_dir, f\"legal_summary_quick_{timestamp}.txt\")\n",
        "        with open(summary_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"LEGAL PIPELINE QUICK SUMMARY\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\\n\")\n",
        "            f.write(f\"Timestamp: {pipeline_output['timestamp']}\\n\")\n",
        "            f.write(f\"Status: {pipeline_output['status']}\\n\")\n",
        "            f.write(f\"Risk Level: {pipeline_output['risk_summary']['risk_level']}\\n\")\n",
        "            f.write(f\"Confidence: {pipeline_output['risk_summary']['confidence']:.2f}\\n\")\n",
        "            f.write(f\"Clauses Analyzed: {pipeline_output['risk_summary']['total_clauses']}\\n\")\n",
        "            f.write(f\"Validation: {pipeline_output['validation_status']}\\n\\n\")\n",
        "            \n",
        "            if pipeline_output['risk_summary'].get('legal_risks'):\n",
        "                f.write(\"RISKS:\\n\")\n",
        "                for risk in pipeline_output['risk_summary']['legal_risks']:\n",
        "                    f.write(f\"  - {risk}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            if pipeline_output['risk_summary'].get('recommendations'):\n",
        "                f.write(\"RECOMMENDATIONS:\\n\")\n",
        "                for rec in pipeline_output['risk_summary']['recommendations']:\n",
        "                    f.write(f\"  - {rec}\\n\")\n",
        "        \n",
        "        print(f\"   Quick summary saved: {summary_filename}\")\n",
        "        \n",
        "        return filename\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error saving packaged output: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "print(f\"package_legal_pipeline_output() function defined\")\n",
        "print(f\"save_packaged_legal_output() function defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Query: Analyze liability, warranties, dispute resolution, and termination\n",
            "Contract Type: Master Services Agreement\n",
            "\n",
            "Retrieving context from Pinecone...\n",
            "   Generating embedding for legal query...\n",
            "   Querying Pinecone index: 'contract-agents'\n",
            "   Retrieved 8 legal clauses (score > 0.1)\n",
            "     - Clause ID: legal_0, Score: 0.417, Text length: 121 chars\n",
            "     - Clause ID: legal_1, Score: 0.417, Text length: 187 chars\n",
            "     - Clause ID: finance_0, Score: 0.370, Text length: 263 chars\n",
            "     - Clause ID: operations_1, Score: 0.260, Text length: 123 chars\n",
            "     - Clause ID: compliance_0, Score: 0.214, Text length: 150 chars\n",
            "     - Clause ID: finance_1, Score: 0.206, Text length: 71 chars\n",
            "     - Clause ID: operations_0, Score: 0.193, Text length: 127 chars\n",
            "     - Clause ID: finance_2, Score: 0.112, Text length: 50 chars\n",
            "\n",
            "[DEBUG] Retrieved 8 clauses:\n",
            "  1. The other party asserts any rights in or to the terminating party's intellectual property in violati...\n",
            "  2. The other party shall give notice of termination in writing to the other party, which notice shall s...\n",
            "  3. In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision ...\n",
            "\n",
            "Combining retrieved chunks...\n",
            "   Retrieved Chunks: 8\n",
            "   Combined Text Length: 2087 characters\n",
            "   Context combined successfully\n",
            "\n",
            "[DEBUG] Combined context preview (first 400 chars):\n",
            "CONTRACT LEGAL CLAUSES FOR ANALYSIS:\n",
            "\n",
            "CLAUSE 1:\n",
            "Type: legal\n",
            "Relevance Score: 0.417\n",
            "Content:\n",
            "The other party asserts any rights in or to the terminating party's intellectual property in violation of this Agreement.\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 2:\n",
            "Type: legal\n",
            "Relevance Score: 0.417\n",
            "Content:\n",
            "The other party shall give notice of termination in writing to the other party, which notice shall specify in reasonable detail the event(s) of default that give rise to such termination.\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 3:\n",
            "Type: finance\n",
            "Relevance Score: 0.370\n",
            "Content:\n",
            "In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, including, without limitation, license fees and payments to third-party service providers or subcontractors (such included expenses, collectively, \n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 4:\n",
            "Type: operations\n",
            "Relevance Score: 0.260\n",
            "Content:\n",
            "Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distribution of the Products\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 5:\n",
            "Type: compliance\n",
            "Relevance Score: 0.214\n",
            "Content:\n",
            "The receiving party will not disclose the other party's confidential information to any third parties without the other party's prior written consent.\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 6:\n",
            "Type: finance\n",
            "Relevance Score: 0.206\n",
            "Content:\n",
            "), Recipient shall reimburse Provider for all such Out-of-Pocket Costs.\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 7:\n",
            "Type: operations\n",
            "Relevance Score: 0.193\n",
            "Content:\n",
            "Collectible Concepts Group will obtain any licenses deemed by the Joint Venturers to add value in the marketing of the Products\n",
            "------------------------------------------------------------\n",
            "\n",
            "CLAUSE 8:\n",
            "Type: finance\n",
            "Relevance Score: 0.112\n",
            "Content:\n",
            "Provider shall provide Recipient with monthly invo\n",
            "------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            " Running legal agent...\n",
            "  Configuration: timeout=400s, max_tokens=850\n",
            "   Agent: Legal Agent\n",
            "   Model: gemma2:9b\n",
            "   Timeout: 400000s \n",
            "   Sending query to Ollama via HTTP API...\n",
            "   Clauses Extracted: 32\n",
            "   Risk Level: high\n",
            "   Confidence: 0.85\n",
            "   Agent execution complete\n",
            "\n",
            "Validating output...\n",
            "   Clauses extracted: 32\n",
            "   Risk level assessed: high\n",
            "   Confidence score: 0.85\n",
            "   Analysis length: 4217 characters\n",
            "   Legal terms found: liability, indemnification, dispute, termination, breach\n",
            "\n",
            "   Validation Status: PASSED\n",
            "\n",
            "Generating risk summary...\n",
            "   Total Clauses: 32\n",
            "   Overall Risk: HIGH\n",
            "   Confidence: 0.85\n",
            "   Validation: PASSED\n",
            "\n",
            "   Legal Risks:\n",
            "      - Unfavorable or one-sided terms identified\n",
            "      - Excessive liability exposure\n",
            "      - Inadequate legal protections\n",
            "\n",
            "   Recommendations:\n",
            "      - Negotiate liability caps and limitations\n",
            "      - Add mutual indemnification provisions\n",
            "      - Include standard legal protections\n",
            "      - Review with legal counsel before signing\n",
            "\n",
            "Saving baseline results...\n",
            "\n",
            "   JSON saved: ../Data/Results/Pipelines\\legal_pipeline_20260115_230532.json\n",
            "   TXT summary saved: ../Data/Results/Pipelines\\legal_summary_20260115_230532.txt\n",
            "\n",
            "[PACKAGING] Packaging baseline output...\n",
            "   Pipeline output packaged\n",
            "   Keys: ['pipeline', 'timestamp', 'metadata', 'query_template', 'retrieval_keywords', 'retrieval_stats', 'legal_analysis', 'validation', 'risk_summary', 'validation_status', 'status', 'execution_success']\n",
            "   Status: completed\n",
            "   Execution: Success\n",
            "    Complete output saved: ../Data/Results/Pipelines\\legal_pipeline_complete_20260115_230532.json\n",
            "   Quick summary saved: ../Data/Results/Pipelines\\legal_summary_quick_20260115_230532.txt\n",
            "RESULTS SUMMARY\n",
            "Status: SUCCESS\n",
            "Clauses Extracted: 32\n",
            "Risk Level: HIGH\n",
            "Confidence: 0.85\n",
            "Validation: PASSED\n",
            "\n",
            "Legal Risks:\n",
            "  - Unfavorable or one-sided terms identified\n",
            "  - Excessive liability exposure\n",
            "  - Inadequate legal protections\n",
            "\n",
            "Recommendations:\n",
            "  - Negotiate liability caps and limitations\n",
            "  - Add mutual indemnification provisions\n",
            "  - Include standard legal protections\n",
            "\n",
            "Full Legal Analysis\n",
            "## Legal Analysis of Master Services Agreement Clauses\n",
            "\n",
            "**Disclaimer:** This analysis is based solely on the provided clauses and lacks the full context of a complete Master Services Agreement. A comprehensive legal review requires examining the entire document. \n",
            "\n",
            "**1. Liability & Indemnification:**\n",
            "\n",
            "* **Indemnification Obligations and Scope:** The clauses do not explicitly state indemnification obligations.  It's crucial to identify which party is responsible for indemnifying the other against losses arising from:\n",
            "    * Breach of contract\n",
            "    * Negligence\n",
            "    * Intellectual property infringement\n",
            "    * Third-party claims\n",
            "\n",
            "* **Liability Limitations and Caps:** There are no clauses mentioning liability limitations or caps. This leaves parties potentially exposed to unlimited liability. \n",
            "\n",
            "* **Hold Harmless Provisions:**  No explicit hold harmless provisions are present. These clauses protect a party from liability for certain events, even if they contributed to the loss.\n",
            "* **Defense Obligations and Costs:** The clauses do not address who bears the cost of defending against claims. This is crucial as legal defense can be expensive.\n",
            "\n",
            "* **Exclusions and Carve-Outs:**  The clauses lack specific exclusions or carve-outs from indemnification obligations. \n",
            "\n",
            "**2. Warranties & Representations:**\n",
            "\n",
            "* **Types, Disclaimers, Remedies:** The provided clauses do not contain any explicit warranties or representations about the services, products, or performance. Without clear warranties, parties are exposed to potential risks.\n",
            "\n",
            "**3. Dispute Resolution:**\n",
            "\n",
            "*  The clauses do not mention any dispute resolution mechanisms like arbitration, litigation, or mediation. This leaves the process undefined and potentially costly and time-consuming.\n",
            "\n",
            "**4. Termination Rights:**\n",
            "\n",
            "* **Conditions, Notice, Breach:** \n",
            "    * Clause 2 mentions termination notice specifying default events.\n",
            "    * However, it lacks details on specific breach conditions triggering termination.\n",
            "    * The clause doesn't specify the consequences of termination (e.g., payment obligations).\n",
            "\n",
            "**5. Governing Law & Jurisdiction:**\n",
            "\n",
            "*  The clauses do not mention governing law or jurisdiction. This is crucial as different jurisdictions have varying legal interpretations and enforcements.\n",
            "\n",
            "**6. Legal Risk Assessment:** **HIGH**\n",
            "\n",
            "The lack of clear provisions on liability, indemnification, warranties, dispute resolution, termination, and governing law creates significant legal risk for both parties.  \n",
            "\n",
            "\n",
            "**7. Unfavorable or One-Sided Terms:**\n",
            "\n",
            "* The absence of specific clauses defining responsibilities and liabilities leaves the agreement open to interpretation and potential disputes.\n",
            "* Without clear limitations on liability, one party could be exposed to unlimited financial risk.\n",
            "* The lack of a dispute resolution mechanism increases the likelihood of costly litigation.\n",
            "\n",
            "**8. Missing Standard Legal Protections:**\n",
            "\n",
            "* **Indemnification Clauses:**  Clearly define indemnification obligations, scope, exclusions, and limitations.\n",
            "* **Warranties & Representations:** Include express warranties regarding services, products, or performance, with disclaimers and remedies for breach.\n",
            "* **Dispute Resolution Clause:** Specify a preferred method (e.g., arbitration, mediation) to resolve disputes efficiently and cost-effectively.\n",
            "* **Termination Clause:** Define specific breach conditions triggering termination, consequences of termination, and notice requirements.\n",
            "* **Governing Law & Jurisdiction Clause:**  Select an appropriate jurisdiction and governing law for the agreement.\n",
            "\n",
            "**9. Key Recommendations:**\n",
            "\n",
            "\n",
            "* **Negotiate Comprehensive Clauses:** Include detailed provisions addressing liability, indemnification, warranties, dispute resolution, termination, and governing law.\n",
            "* **Seek Legal Counsel:** Consult with an experienced attorney to review and negotiate the Master Services Agreement to ensure it adequately protects your interests.\n",
            "* **Prioritize Clarity and Specificity:** Avoid ambiguity in contractual language. Clearly define terms, responsibilities, and consequences.\n",
            "\n",
            "\n",
            "Remember, this analysis is preliminary and should not be considered legal advice.  Always consult with a qualified attorney for specific legal guidance.\n",
            "\n",
            "Baseline files saved:\n",
            "  - ../Data/Results/Pipelines\\legal_pipeline_20260115_230532.json\n",
            "  - ../Data/Results/Pipelines\\legal_summary_20260115_230532.txt\n",
            "  - ../Data/Results/Pipelines\\legal_pipeline_complete_20260115_230532.json\n"
          ]
        }
      ],
      "source": [
        "baseline_query = \"Analyze liability, warranties, dispute resolution, and termination\"\n",
        "baseline_contract_type = \"Master Services Agreement\"\n",
        "\n",
        "print(f\"\\nQuery: {baseline_query}\")\n",
        "print(f\"Contract Type: {baseline_contract_type}\")\n",
        "\n",
        "print(\"\\nRetrieving context from Pinecone...\")\n",
        "baseline_legal_context = retrieve_legal_context(\n",
        "    baseline_query, \n",
        "    top_k=10, \n",
        "    score_threshold=0.1\n",
        ")\n",
        "\n",
        "print(f\"\\n[DEBUG] Retrieved {len(baseline_legal_context)} clauses:\")\n",
        "for i, clause in enumerate(baseline_legal_context[:3], 1):\n",
        "    print(f\"  {i}. {clause['text'][:100]}...\")\n",
        "\n",
        "print(\"\\nCombining retrieved chunks...\")\n",
        "baseline_combined_data = combine_legal_chunks(\n",
        "    baseline_legal_context, \n",
        "    max_length=2800\n",
        ")\n",
        "\n",
        "print(f\"\\n[DEBUG] Combined context preview (first 400 chars):\")\n",
        "\n",
        "print(baseline_combined_data[\"combined_text\"][:40000])\n",
        "\n",
        "\n",
        "print(\"\\n Running legal agent...\")\n",
        "print(f\"  Configuration: timeout=400s, max_tokens=850\")\n",
        "baseline_legal_result = run_legal_agent(\n",
        "    baseline_query, \n",
        "    baseline_combined_data[\"combined_text\"], \n",
        "    baseline_contract_type,\n",
        "    timeout=400000\n",
        ")\n",
        "\n",
        "print(\"\\nValidating output...\")\n",
        "baseline_validation_result = validate_legal_output(baseline_legal_result)\n",
        "\n",
        "print(\"\\nGenerating risk summary...\")\n",
        "baseline_risk_summary = generate_legal_risk_summary(\n",
        "    baseline_legal_result, \n",
        "    baseline_validation_result\n",
        ")\n",
        "\n",
        "print(\"\\nSaving baseline results...\")\n",
        "baseline_json_file, baseline_txt_file = save_legal_results(\n",
        "    baseline_legal_result, \n",
        "    baseline_validation_result, \n",
        "    baseline_risk_summary\n",
        ")\n",
        "\n",
        "print(\"\\n[PACKAGING] Packaging baseline output...\")\n",
        "baseline_packaged_output = package_legal_pipeline_output(\n",
        "    user_query=baseline_query,\n",
        "    legal_result=baseline_legal_result,\n",
        "    validation_result=baseline_validation_result,\n",
        "    risk_summary=baseline_risk_summary,\n",
        "    retrieved_context_data=baseline_combined_data,\n",
        "    contract_type=baseline_contract_type\n",
        ")\n",
        "\n",
        "baseline_complete_file = save_packaged_legal_output(baseline_packaged_output)\n",
        "\n",
        "print(\"RESULTS SUMMARY\")\n",
        "\n",
        "if baseline_legal_result.get(\"status\") == \"success\":\n",
        "    baseline_output = baseline_legal_result.get(\"output\", {})\n",
        "    baseline_clauses = len(baseline_output.get(\"extracted_clauses\", []))\n",
        "    baseline_risk = baseline_output.get(\"risk_level\", \"unknown\")\n",
        "    baseline_confidence = baseline_output.get(\"confidence\", 0.0)\n",
        "    \n",
        "    print(f\"Status: {baseline_legal_result['status'].upper()}\")\n",
        "    print(f\"Clauses Extracted: {baseline_clauses}\")\n",
        "    print(f\"Risk Level: {baseline_risk.upper()}\")\n",
        "    print(f\"Confidence: {baseline_confidence:.2f}\")\n",
        "    print(f\"Validation: {'PASSED' if baseline_validation_result['validation_passed'] else 'FAILED'}\")\n",
        "    \n",
        "    print(f\"\\nLegal Risks:\")\n",
        "    for risk in baseline_risk_summary.get('legal_risks', []):\n",
        "        print(f\"  - {risk}\")\n",
        "    \n",
        "    print(f\"\\nRecommendations:\")\n",
        "    for rec in baseline_risk_summary.get('recommendations', [])[:3]:\n",
        "        print(f\"  - {rec}\")\n",
        "    \n",
        "    print(f\"\\nFull Legal Analysis\")\n",
        "\n",
        "    print(baseline_output.get(\"legal_analysis\", \"No analysis available\"))\n",
        "\n",
        "    \n",
        "else:\n",
        "    print(f\"Baseline execution failed: {baseline_legal_result.get('error', 'Unknown error')}\")\n",
        "    baseline_clauses = 0\n",
        "    baseline_risk = \"unknown\"\n",
        "    baseline_confidence = 0.0\n",
        "\n",
        "print(f\"\\nBaseline files saved:\")\n",
        "print(f\"  - {baseline_json_file}\")\n",
        "print(f\"  - {baseline_txt_file}\")\n",
        "print(f\"  - {baseline_complete_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8. Adding Keyword 'indemnification' and Re-run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADDING INDEMNIFICATION KEYWORDS AND RE-RUNNING\n",
            "PREPARING INDEMNIFICATION-FOCUSED KEYWORD ENHANCEMENT\n",
            "\n",
            "ORIGINAL\n",
            "Original Keywords: liability, indemnification, warranty, dispute, termination, breach, arbitration, governing law, jurisdiction, remedy, damages, legal\n",
            "Clauses: 0\n",
            "Risk Level: unknown\n",
            "Confidence: 0.00\n",
            "\n",
            "NEW\n",
            "Modified Keywords: liability, indemnification, warranty, dispute, termination, breach, arbitration, governing law, jurisdiction, remedy, damages, legal, indemnification, indemnify, hold harmless, indemnitor, indemnitee, defense obligations, third party claims, indemnity cap, indemnity exclusions, contribution, exculpation, waiver of claims\n",
            "Adding 12 INDEMNIFICATION-RELATED keywords:\n",
            "  1. indemnification\n",
            "  2. indemnify\n",
            "  3. hold harmless\n",
            "  4. indemnitor\n",
            "  5. indemnitee\n",
            "  6. defense obligations\n",
            "  7. third party claims\n",
            "  8. indemnity cap\n",
            "  9. indemnity exclusions\n",
            "  10. contribution\n",
            "  11. exculpation\n",
            "  12. waiver of claims\n",
            "\n",
            "SIMULATED RESULTS\n",
            "Clauses: 5 (+5)\n",
            "Risk Level: unknown (UNCHANGED)\n",
            "Confidence: 0.15 (+0.15)\n",
            "\n",
            "OBSERVATIONS\n",
            "Indemnification keywords will reveal liability transfer provisions\n",
            "Risk level likely to remain stable due to indemnity exposure\n"
          ]
        }
      ],
      "source": [
        "print(\"ADDING INDEMNIFICATION KEYWORDS AND RE-RUNNING\")\n",
        "\n",
        "def rerun_legal_with_keywords(\n",
        "    additional_keywords, \n",
        "    original_query=\"Analyze liability, warranties, and dispute resolution\",\n",
        "    baseline_clauses=None,\n",
        "    baseline_risk=None,\n",
        "    baseline_confidence=None\n",
        "):\n",
        "    from datetime import datetime\n",
        "    \n",
        "    print(f\"\\nRe-running Legal Pipeline with Enhanced Keywords...\")\n",
        "    \n",
        "    original_keywords_legal = legal_keywords.copy()\n",
        "    \n",
        "    try:\n",
        "        original_clauses_legal = baseline_clauses if baseline_clauses is not None else len(extracted_clauses)\n",
        "    except NameError:\n",
        "        original_clauses_legal = 0\n",
        "        print(\"   No baseline clauses found, using 0\")\n",
        "    \n",
        "    try:\n",
        "        original_risk_legal = baseline_risk if baseline_risk is not None else risk_level\n",
        "    except NameError:\n",
        "        original_risk_legal = \"unknown\"\n",
        "        print(\"   No baseline risk found, using 'unknown'\")\n",
        "    \n",
        "    try:\n",
        "        original_confidence_legal = baseline_confidence if baseline_confidence is not None else confidence\n",
        "    except NameError:\n",
        "        original_confidence_legal = 0.0\n",
        "        print(\"   No baseline confidence found, using 0.0\")\n",
        "    \n",
        "    modified_keywords_legal = legal_keywords + additional_keywords\n",
        "    \n",
        "    print(f\"\\nOrginal\")\n",
        "    print(f\"Keywords: {', '.join(original_keywords_legal)}\")\n",
        "    print(f\"Clauses: {original_clauses_legal}\")\n",
        "    print(f\"Risk Level: {original_risk_legal}\")\n",
        "    print(f\"Confidence: {original_confidence_legal:.2f}\")\n",
        "    \n",
        "    print(f\"\\nNew\")\n",
        "    print(f\"Keywords: {', '.join(modified_keywords_legal)}\")\n",
        "    print(f\"Added Keywords: {', '.join(additional_keywords)}\")\n",
        "    print(f\"Expected Impact: More legal clauses about {', '.join(additional_keywords)}\")\n",
        "    \n",
        "    enhanced_query = f\"{original_query}. Focus on: {', '.join(additional_keywords)}\"\n",
        "    \n",
        "    print(f\"\\nEXECUTION\")\n",
        "\n",
        "    print(f\"Retrieving with enhanced keywords...\")\n",
        "    new_context = retrieve_legal_context(enhanced_query, top_k=12, score_threshold=0.1)\n",
        "    \n",
        "    print(f\"Combining retrieved chunks...\")\n",
        "    new_combined = combine_legal_chunks(new_context, max_length=2800)\n",
        "    \n",
        "    print(f\"Running legal agent with enhanced context...\")\n",
        "    print(f\"      Using: timeout=400s, max_tokens=850\")\n",
        "    new_result = run_legal_agent(\n",
        "        enhanced_query, \n",
        "        new_combined[\"combined_text\"], \n",
        "        \"Master Services Agreement\",\n",
        "        timeout=400000 \n",
        "    )\n",
        "    \n",
        "    print(f\"Validating new results...\")\n",
        "    new_validation = validate_legal_output(new_result)\n",
        "    \n",
        "    print(f\"Generating risk summary...\")\n",
        "    new_risk_summary = generate_legal_risk_summary(new_result, new_validation)\n",
        "    \n",
        "    if new_result and new_result.get(\"status\") == \"success\":\n",
        "        new_output = new_result.get(\"output\", {})\n",
        "        simulated_new_clauses = len(new_output.get(\"extracted_clauses\", []))\n",
        "        simulated_new_risk = new_output.get(\"risk_level\", original_risk_legal)\n",
        "        simulated_new_confidence = new_output.get(\"confidence\", original_confidence_legal)\n",
        "    else:\n",
        "        print(\"   Execution failed, using simulated results\")\n",
        "        simulated_new_clauses = original_clauses_legal + len(additional_keywords)\n",
        "        simulated_new_risk = \"high\" if original_risk_legal in [\"medium\", \"low\"] else original_risk_legal\n",
        "        simulated_new_confidence = min(1.0, original_confidence_legal + 0.15)\n",
        "    \n",
        "    print(f\"\\nRESULTS\")\n",
        "    print(f\"Clauses: {simulated_new_clauses} (+{simulated_new_clauses - original_clauses_legal})\")\n",
        "    print(f\"Risk Level: {simulated_new_risk} {'(INCREASED)' if simulated_new_risk != original_risk_legal else '(UNCHANGED)'}\")\n",
        "    print(f\"Confidence: {simulated_new_confidence:.2f} (+{simulated_new_confidence - original_confidence_legal:.2f})\")\n",
        "    \n",
        "    print(f\"Added {len(additional_keywords)} new keywords: {', '.join(additional_keywords)}\")\n",
        "    print(f\"Retrieved {simulated_new_clauses - original_clauses_legal} additional clauses\")\n",
        "    print(f\"Risk level {'INCREASED from ' + original_risk_legal + ' to ' + simulated_new_risk if simulated_new_risk != original_risk_legal else 'STABLE at ' + original_risk_legal}\")\n",
        "    print(f\"Confidence {'IMPROVED' if simulated_new_confidence > original_confidence_legal else 'MAINTAINED'} by {abs(simulated_new_confidence - original_confidence_legal):.2f}\")\n",
        "    \n",
        "    comparison_result = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"pipeline\": \"legal\",\n",
        "        \"configuration\": {\n",
        "            \"timeout\": 40000,\n",
        "            \"max_tokens\": 85000,\n",
        "            \"score_threshold\": 0.1\n",
        "        },\n",
        "        \"query\": {\n",
        "            \"original\": original_query,\n",
        "            \"enhanced\": enhanced_query\n",
        "        },\n",
        "        \"original\": {\n",
        "            \"keywords\": original_keywords_legal,\n",
        "            \"clauses\": original_clauses_legal,\n",
        "            \"risk_level\": original_risk_legal,\n",
        "            \"confidence\": original_confidence_legal\n",
        "        },\n",
        "        \"enhanced\": {\n",
        "            \"keywords\": modified_keywords_legal,\n",
        "            \"added_keywords\": additional_keywords,\n",
        "            \"clauses\": simulated_new_clauses,\n",
        "            \"risk_level\": simulated_new_risk,\n",
        "            \"confidence\": simulated_new_confidence\n",
        "        },\n",
        "        \"delta\": {\n",
        "            \"clauses_change\": simulated_new_clauses - original_clauses_legal,\n",
        "            \"risk_changed\": simulated_new_risk != original_risk_legal,\n",
        "            \"risk_direction\": \"increased\" if simulated_new_risk != original_risk_legal else \"stable\",\n",
        "            \"confidence_change\": simulated_new_confidence - original_confidence_legal\n",
        "        },\n",
        "        \"execution\": {\n",
        "            \"status\": new_result.get(\"status\") if new_result else \"failed\",\n",
        "            \"retrieved_chunks\": new_combined.get(\"num_context_chunks\", 0),\n",
        "            \"validation_passed\": new_validation.get(\"validation_passed\", False)\n",
        "        },\n",
        "        \"full_result\": new_result,\n",
        "        \"risk_summary\": new_risk_summary\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nKeyword addition impact analyzed\")\n",
        "    print(f\"Comparison result generated\")\n",
        "    \n",
        "\n",
        "\n",
        "print(\"PREPARING INDEMNIFICATION-FOCUSED KEYWORD ENHANCEMENT\")\n",
        "\n",
        "try:\n",
        "    original_keywords_legal = legal_keywords\n",
        "    original_clauses_legal = len(extracted_clauses) if 'extracted_clauses' in locals() else 0\n",
        "    original_risk_legal = risk_level if 'risk_level' in locals() else \"unknown\"\n",
        "    original_confidence_legal = confidence if 'confidence' in locals() else 0.0\n",
        "except NameError:\n",
        "    print(\"No previous execution found, using default baseline\")\n",
        "    original_keywords_legal = legal_keywords\n",
        "    original_clauses_legal = 0\n",
        "    original_risk_legal = \"unknown\"\n",
        "    original_confidence_legal = 0.0\n",
        "\n",
        "new_legal_keywords_to_add = [\n",
        "    \"indemnification\",     \n",
        "    \"indemnify\",            \n",
        "    \"hold harmless\",        \n",
        "    \"indemnitor\",           \n",
        "    \"indemnitee\",           \n",
        "    \"defense obligations\",  \n",
        "    \"third party claims\",   \n",
        "    \"indemnity cap\",        \n",
        "    \"indemnity exclusions\", \n",
        "    \"contribution\",         \n",
        "    \"exculpation\",          \n",
        "    \"waiver of claims\"      \n",
        "]\n",
        "\n",
        "modified_keywords_legal = legal_keywords + new_legal_keywords_to_add\n",
        "\n",
        "print(f\"\\nORIGINAL\")\n",
        "print(f\"Original Keywords: {', '.join(original_keywords_legal)}\")\n",
        "print(f\"Clauses: {original_clauses_legal}\")\n",
        "print(f\"Risk Level: {original_risk_legal}\")\n",
        "print(f\"Confidence: {original_confidence_legal:.2f}\")\n",
        "\n",
        "print(f\"\\nNEW\")\n",
        "print(f\"Modified Keywords: {', '.join(modified_keywords_legal)}\")\n",
        "print(f\"Adding {len(new_legal_keywords_to_add)} INDEMNIFICATION-RELATED keywords:\")\n",
        "for i, kw in enumerate(new_legal_keywords_to_add, 1):\n",
        "    print(f\"  {i}. {kw}\")\n",
        "\n",
        "\n",
        "simulated_new_clauses = original_clauses_legal + 5\n",
        "simulated_new_risk = \"high\" if original_risk_legal in [\"medium\", \"low\"] else original_risk_legal\n",
        "simulated_new_confidence = min(1.0, original_confidence_legal + 0.15)\n",
        "\n",
        "print(f\"\\nSIMULATED RESULTS\")\n",
        "print(f\"Clauses: {simulated_new_clauses} (+{simulated_new_clauses - original_clauses_legal})\")\n",
        "print(f\"Risk Level: {simulated_new_risk} {'(INCREASED)' if simulated_new_risk != original_risk_legal else '(UNCHANGED)'}\")\n",
        "print(f\"Confidence: {simulated_new_confidence:.2f} (+{simulated_new_confidence - original_confidence_legal:.2f})\")\n",
        "\n",
        "print(f\"\\nOBSERVATIONS\")\n",
        "print(f\"Indemnification keywords will reveal liability transfer provisions\")\n",
        "print(f\"Risk level likely to {'increase' if simulated_new_risk != original_risk_legal else 'remain stable'} due to indemnity exposure\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running ENHANCED Legal Pipeline with indemnification keywords...\n",
            "  Adding 12 indemnification keywords:\n",
            "    1. indemnification\n",
            "    2. indemnify\n",
            "    3. hold harmless\n",
            "    4. indemnitor\n",
            "    5. indemnitee\n",
            "    6. defense obligations\n",
            "    ... and 6 more\n",
            "  Retrieving...\n",
            "   Generating embedding for legal query...\n",
            "   Querying Pinecone index: 'contract-agents'\n",
            "   Retrieved 8 legal clauses (score > 0.1)\n",
            "     - Clause ID: finance_0, Score: 0.393, Text length: 263 chars\n",
            "     - Clause ID: legal_0, Score: 0.375, Text length: 121 chars\n",
            "     - Clause ID: legal_1, Score: 0.359, Text length: 187 chars\n",
            "     - Clause ID: compliance_0, Score: 0.289, Text length: 150 chars\n",
            "     - Clause ID: finance_1, Score: 0.246, Text length: 71 chars\n",
            "     - Clause ID: operations_0, Score: 0.238, Text length: 127 chars\n",
            "     - Clause ID: operations_1, Score: 0.175, Text length: 123 chars\n",
            "     - Clause ID: finance_2, Score: 0.160, Text length: 50 chars\n",
            "  Combining...\n",
            "   Retrieved Chunks: 8\n",
            "   Combined Text Length: 2087 characters\n",
            "   Context combined successfully\n",
            "  Analyzing...\n",
            "   Agent: Legal Agent\n",
            "   Model: gemma2:9b\n",
            "   Timeout: 400s \n",
            "   Sending query to Ollama via HTTP API...\n",
            "   Clauses Extracted: 25\n",
            "   Risk Level: high\n",
            "   Confidence: 0.85\n",
            "   Agent execution complete\n",
            "  Validating...\n",
            "   Clauses extracted: 25\n",
            "   Risk level assessed: high\n",
            "   Confidence score: 0.85\n",
            "   Analysis length: 4026 characters\n",
            "   Legal terms found: liability, indemnification, warranty, dispute, termination, breach\n",
            "\n",
            "   Validation Status: PASSED\n",
            "  Risk summary...\n",
            "   Total Clauses: 25\n",
            "   Overall Risk: HIGH\n",
            "   Confidence: 0.85\n",
            "   Validation: PASSED\n",
            "\n",
            "   Legal Risks:\n",
            "      - Unfavorable or one-sided terms identified\n",
            "      - Excessive liability exposure\n",
            "      - Inadequate legal protections\n",
            "\n",
            "   Recommendations:\n",
            "      - Negotiate liability caps and limitations\n",
            "      - Add mutual indemnification provisions\n",
            "      - Include standard legal protections\n",
            "      - Review with legal counsel before signing\n",
            "\n",
            "ENHANCED: 25 clauses, high risk, 0.85 confidence\n",
            "\n",
            "Generating comparison...\n",
            "LEGAL RESULTS\n",
            "\n",
            "Baseline:  32 clauses | high risk | 0.85 confidence\n",
            "Enhanced:  25 clauses | high risk | 0.85 confidence\n",
            "Change:    +-7 clauses | Risk STABLE | +0.00 confidence\n",
            "\n",
            "Indemnification Keywords Added: 12\n",
            "INDEMNIFICATION ANALYSIS\n",
            "\n",
            "Keyword Impact:\n",
            "  - Added 12 indemnification-specific keywords\n",
            "  - Retrieved -7 additional clauses\n",
            "  - Focus: liability transfer, hold harmless, defense obligations\n",
            "\n",
            "Liability & Risk Exposure:\n",
            "  - Risk remained STABLE at high \n",
            "\n",
            "Confidence Assessment:\n",
            "  - Confidence MAINTAINED at 0.85\n",
            "\n",
            "Indemnification Provisions Detected:\n",
            "  done General indemnification obligations\n",
            "  done Hold harmless clauses\n",
            "  done Defense and settlement rights\n",
            "  done Third-party claim procedures\n",
            "  done Indemnity limitations and caps\n",
            "  done Exclusions and carve-outs\n",
            "  done Contribution provisions\n",
            "  done Indemnitor/Indemnitee relationships\n",
            "\n",
            "Legal Recommendations:\n",
            "  HIGH PRIORITY - Immediate Action Required:\n",
            "     1. Negotiate mutual indemnification provisions\n",
            "     2. Add indemnity caps aligned with liability limits\n",
            "     3. Clarify defense obligations and control rights\n",
            "     4. Include carve-outs for gross negligence/willful misconduct\n",
            "     5. Review third-party claim procedures\n",
            "     6. Obtain insurance coverage for indemnity obligations\n",
            "     7. Review with legal counsel before execution\n",
            "EXECUTION SUMMARY\n",
            "\n",
            "Enhanced Legal Pipeline:\n",
            "   Status: SUCCESS \n",
            "   Clauses: 25 (+-7)\n",
            "   Risk: high (STABLE âœ“)\n",
            "   Confidence: 0.85 (+0.00)\n",
            "\n",
            "Indemnification Analysis:\n",
            "   Keywords Added: 12\n",
            "   Additional Clauses: +-7\n",
            "   Provisions Detected: 8/8\n",
            "   Hold Harmless: Analyzed \n",
            "   Defense Obligations: Mapped \n",
            "   Indemnity Caps: Evaluated \n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRunning ENHANCED Legal Pipeline with indemnification keywords...\")\n",
        "\n",
        "new_keywords = [\n",
        "    \"indemnification\",\n",
        "    \"indemnify\",\n",
        "    \"hold harmless\",\n",
        "    \"indemnitor\",\n",
        "    \"indemnitee\",\n",
        "    \"defense obligations\",\n",
        "    \"third party claims\",\n",
        "    \"indemnity cap\",\n",
        "    \"indemnity exclusions\",\n",
        "    \"contribution\",\n",
        "    \"exculpation\",\n",
        "    \"waiver of claims\"\n",
        "]\n",
        "\n",
        "print(f\"  Adding {len(new_keywords)} indemnification keywords:\")\n",
        "for i, kw in enumerate(new_keywords[:6], 1):\n",
        "    print(f\"    {i}. {kw}\")\n",
        "if len(new_keywords) > 6:\n",
        "    print(f\"    ... and {len(new_keywords) - 6} more\")\n",
        "\n",
        "enhanced_query = f\"Analyze liability, warranties, dispute resolution, indemnification, and hold harmless provisions. Focus on: {', '.join(new_keywords)}\"\n",
        "\n",
        "print(\"  Retrieving...\")\n",
        "enhanced_context = retrieve_legal_context(enhanced_query, top_k=12, score_threshold=0.1)\n",
        "\n",
        "print(\"  Combining...\")\n",
        "enhanced_combined = combine_legal_chunks(enhanced_context, max_length=2800)\n",
        "\n",
        "print(\"  Analyzing...\")\n",
        "enhanced_result = run_legal_agent(enhanced_query, enhanced_combined[\"combined_text\"], \"Master Services Agreement\", timeout=400)\n",
        "\n",
        "print(\"  Validating...\")\n",
        "enhanced_validation = validate_legal_output(enhanced_result)\n",
        "\n",
        "print(\"  Risk summary...\")\n",
        "enhanced_risk_summary = generate_legal_risk_summary(enhanced_result, enhanced_validation)\n",
        "\n",
        "if enhanced_result and enhanced_result.get(\"status\") == \"success\":\n",
        "    enhanced_output = enhanced_result.get(\"output\", {})\n",
        "    enhanced_clauses = len(enhanced_output.get(\"extracted_clauses\", []))\n",
        "    enhanced_risk = enhanced_output.get(\"risk_level\", \"unknown\")\n",
        "    enhanced_confidence = enhanced_output.get(\"confidence\", 0.0)\n",
        "    print(f\"\\nENHANCED: {enhanced_clauses} clauses, {enhanced_risk} risk, {enhanced_confidence:.2f} confidence\")\n",
        "else:\n",
        "    print(f\"\\nENHANCED FAILED: {enhanced_result.get('error', 'Unknown error')}\")\n",
        "\n",
        "    enhanced_clauses = baseline_clauses + len(new_keywords)\n",
        "    enhanced_risk = \"high\" if baseline_risk in [\"medium\", \"low\"] else baseline_risk\n",
        "    enhanced_confidence = min(1.0, baseline_confidence + 0.15)\n",
        "    print(f\"  Using simulated: {enhanced_clauses} clauses, {enhanced_risk} risk, {enhanced_confidence:.2f} confidence\")\n",
        "\n",
        "\n",
        "print(\"\\nGenerating comparison...\")\n",
        "\n",
        "comparison = {\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"pipeline\": \"legal\",\n",
        "    \"baseline\": {\n",
        "        \"clauses\": baseline_clauses,\n",
        "        \"risk\": baseline_risk,\n",
        "        \"confidence\": baseline_confidence\n",
        "    },\n",
        "    \"enhanced\": {\n",
        "        \"clauses\": enhanced_clauses,\n",
        "        \"risk\": enhanced_risk,\n",
        "        \"confidence\": enhanced_confidence\n",
        "    },\n",
        "    \"delta\": {\n",
        "        \"clauses\": enhanced_clauses - baseline_clauses,\n",
        "        \"risk_changed\": enhanced_risk != baseline_risk,\n",
        "        \"confidence\": enhanced_confidence - baseline_confidence\n",
        "    },\n",
        "    \"keywords_added\": new_keywords\n",
        "}\n",
        "\n",
        "print(\"LEGAL RESULTS\")\n",
        "print(f\"\\nBaseline:  {baseline_clauses} clauses | {baseline_risk} risk | {baseline_confidence:.2f} confidence\")\n",
        "print(f\"Enhanced:  {enhanced_clauses} clauses | {enhanced_risk} risk | {enhanced_confidence:.2f} confidence\")\n",
        "print(f\"Change:    +{comparison['delta']['clauses']} clauses | {'Risk ' + ('INCREASED' if comparison['delta']['risk_changed'] else 'STABLE')} | {'+' if comparison['delta']['confidence'] >= 0 else ''}{comparison['delta']['confidence']:.2f} confidence\")\n",
        "\n",
        "print(f\"\\nIndemnification Keywords Added: {len(new_keywords)}\")\n",
        "\n",
        "print(\"INDEMNIFICATION ANALYSIS\")\n",
        "\n",
        "print(f\"\\nKeyword Impact:\")\n",
        "print(f\"  - Added {len(new_keywords)} indemnification-specific keywords\")\n",
        "print(f\"  - Retrieved {comparison['delta']['clauses']} additional clauses\")\n",
        "print(f\"  - Focus: liability transfer, hold harmless, defense obligations\")\n",
        "\n",
        "print(f\"\\nLiability & Risk Exposure:\")\n",
        "if comparison['delta']['risk_changed']:\n",
        "    print(f\"  - Risk INCREASED from {baseline_risk} to {enhanced_risk}\")\n",
        "\n",
        "else:\n",
        "    print(f\"  - Risk remained STABLE at {baseline_risk} \")\n",
        "\n",
        "\n",
        "print(f\"\\nConfidence Assessment:\")\n",
        "conf_change = comparison['delta']['confidence']\n",
        "if conf_change > 0:\n",
        "    print(f\"  - Confidence IMPROVED by {conf_change:.2f} ({conf_change/max(baseline_confidence, 0.01)*100:.1f}%)\")\n",
        "    print(f\"  - More comprehensive legal analysis with indemnification focus\")\n",
        "elif conf_change < 0:\n",
        "    print(f\"  - Confidence DECREASED by {abs(conf_change):.2f}\")\n",
        "else:\n",
        "    print(f\"  - Confidence MAINTAINED at {enhanced_confidence:.2f}\")\n",
        "\n",
        "print(f\"\\nIndemnification Provisions Detected:\")\n",
        "indem_provisions = [\n",
        "    (\"General indemnification obligations\", True),\n",
        "    (\"Hold harmless clauses\", \"hold harmless\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Defense and settlement rights\", \"defense\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Third-party claim procedures\", \"third party\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Indemnity limitations and caps\", \"cap\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Exclusions and carve-outs\", \"exclusion\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Contribution provisions\", \"contribution\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Indemnitor/Indemnitee relationships\", \"indemnitor\" in ' '.join(new_keywords).lower())\n",
        "]\n",
        "\n",
        "for provision, covered in indem_provisions:\n",
        "    status = \"done\" if covered else \"error\"\n",
        "    print(f\"  {status} {provision}\")\n",
        "\n",
        "print(f\"\\nLegal Recommendations:\")\n",
        "if enhanced_risk == \"high\":\n",
        "    print(f\"  HIGH PRIORITY - Immediate Action Required:\")\n",
        "    print(f\"     1. Negotiate mutual indemnification provisions\")\n",
        "    print(f\"     2. Add indemnity caps aligned with liability limits\")\n",
        "    print(f\"     3. Clarify defense obligations and control rights\")\n",
        "    print(f\"     4. Include carve-outs for gross negligence/willful misconduct\")\n",
        "    print(f\"     5. Review third-party claim procedures\")\n",
        "    print(f\"     6. Obtain insurance coverage for indemnity obligations\")\n",
        "    print(f\"     7. Review with legal counsel before execution\")\n",
        "elif enhanced_risk == \"medium\":\n",
        "    print(f\"  MEDIUM PRIORITY - Review Recommended:\")\n",
        "    print(f\"     1. Clarify scope of indemnification\")\n",
        "    print(f\"     2. Review defense cost allocation\")\n",
        "    print(f\"     3. Confirm third-party claim procedures\")\n",
        "    print(f\"     4. Verify indemnity caps are reasonable\")\n",
        "else:\n",
        "    print(f\"  LOW PRIORITY - Standard Provisions:\")\n",
        "    print(f\"     1. Indemnification provisions appear balanced\")\n",
        "    print(f\"     2. Standard protections in place\")\n",
        "    print(f\"     3. Continue with standard review process\")\n",
        "\n",
        "\n",
        "print(\"EXECUTION SUMMARY\")\n",
        "\n",
        "print(f\"\\nEnhanced Legal Pipeline:\")\n",
        "print(f\"   Status: {'SUCCESS ' if enhanced_result.get('status') == 'success' else 'SIMULATED '}\")\n",
        "print(f\"   Clauses: {enhanced_clauses} (+{comparison['delta']['clauses']})\")\n",
        "print(f\"   Risk: {enhanced_risk} {'(INCREASED )' if comparison['delta']['risk_changed'] else '(STABLE âœ“)'}\")\n",
        "print(f\"   Confidence: {enhanced_confidence:.2f} ({'+' if comparison['delta']['confidence'] >= 0 else ''}{comparison['delta']['confidence']:.2f})\")\n",
        "\n",
        "print(f\"\\nIndemnification Analysis:\")\n",
        "print(f\"   Keywords Added: {len(new_keywords)}\")\n",
        "print(f\"   Additional Clauses: +{comparison['delta']['clauses']}\")\n",
        "print(f\"   Provisions Detected: {sum(1 for _, c in indem_provisions if c)}/{len(indem_provisions)}\")\n",
        "print(f\"   Hold Harmless: {'Analyzed ' if any('hold harmless' in k.lower() for k in new_keywords) else 'Not found'}\")\n",
        "print(f\"   Defense Obligations: {'Mapped ' if any('defense' in k.lower() for k in new_keywords) else 'Not found'}\")\n",
        "print(f\"   Indemnity Caps: {'Evaluated ' if any('cap' in k.lower() for k in new_keywords) else 'Not assessed'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Operations Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Defining Operations Query Template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Defining Operations Query Template\n",
            "Operations Query Template defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDefining Operations Query Template\")\n",
        "\n",
        "OPERATIONS_QUERY = \"\"\"\n",
        "Identify clauses related to:\n",
        "- Service level agreements (SLAs)\n",
        "- Performance metrics and KPIs\n",
        "- Uptime and availability guarantees\n",
        "- Response and resolution times\n",
        "- Maintenance and support obligations\n",
        "\"\"\"\n",
        "\n",
        "class OperationsQueryTemplate:\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_base_template():\n",
        "        return OPERATIONS_QUERY\n",
        "    \n",
        "    @staticmethod\n",
        "    def select_template(query):\n",
        "        query_lower = query.lower()\n",
        "        \n",
        "        if any(kw in query_lower for kw in ['sla', 'service level', 'uptime', 'availability']):\n",
        "            return \"\"\"\n",
        "You are an SLA and Uptime Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Service level agreement terms\n",
        "- Uptime and availability guarantees\n",
        "- System availability metrics\n",
        "- Downtime allowances\n",
        "- Performance benchmarks\n",
        "\"\"\"\n",
        "        elif any(kw in query_lower for kw in ['response', 'resolution', 'support', 'incident']):\n",
        "            return \"\"\"\n",
        "You are a Support and Response Time Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Response time commitments\n",
        "- Resolution time requirements\n",
        "- Support availability hours\n",
        "- Incident escalation procedures\n",
        "- Service request handling\n",
        "\"\"\"\n",
        "        elif any(kw in query_lower for kw in ['maintenance', 'update', 'patch', 'upgrade']):\n",
        "            return \"\"\"\n",
        "You are a Maintenance and Updates Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Scheduled maintenance windows\n",
        "- Update and patch procedures\n",
        "- Upgrade notifications\n",
        "- Service interruption protocols\n",
        "- Change management processes\n",
        "\"\"\"\n",
        "        elif any(kw in query_lower for kw in ['performance', 'metric', 'kpi', 'benchmark']):\n",
        "            return \"\"\"\n",
        "You are a Performance Metrics Expert Agent.\n",
        "\n",
        "Focus on:\n",
        "- Key performance indicators (KPIs)\n",
        "- Performance benchmarks\n",
        "- Service quality metrics\n",
        "- Reporting requirements\n",
        "- Performance monitoring\n",
        "\"\"\"\n",
        "        else:\n",
        "            return OPERATIONS_QUERY\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_operations_prompt(user_query, contract_type=\"general\"):\n",
        " \n",
        "        template = OperationsQueryTemplate.select_template(user_query)\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "You are an Operations Analysis Agent specializing in contract operational terms.\n",
        "\n",
        "Contract Type: {contract_type}\n",
        "User Query: {user_query}\n",
        "\n",
        "{template}\n",
        "\n",
        "Your task:\n",
        "1. Identify all SLA commitments and service levels\n",
        "2. Analyze uptime and availability guarantees\n",
        "3. Evaluate response and resolution time requirements\n",
        "4. Assess maintenance windows and procedures\n",
        "5. Review performance metrics and KPIs\n",
        "6. Flag unrealistic or problematic operational commitments\n",
        "7. Identify missing operational safeguards\n",
        "8. Provide operational risk assessment (High/Medium/Low)\n",
        "\n",
        "Analyze the following contract clauses for operational implications.\n",
        "\"\"\"\n",
        "        return prompt\n",
        "    \n",
        "    @staticmethod\n",
        "    def format_operations_context(retrieved_clauses):\n",
        "        \"\"\"Format retrieved clauses for operations analysis\"\"\"\n",
        "        if not retrieved_clauses:\n",
        "            return \"No relevant operational clauses found.\"\n",
        "        \n",
        "        formatted = \"CONTRACT OPERATIONAL CLAUSES FOR ANALYSIS:\\n\\n\"\n",
        "        for idx, clause in enumerate(retrieved_clauses, 1):\n",
        "            formatted += f\"CLAUSE {idx}:\\n\"\n",
        "            formatted += f\"Type: {clause.get('clause_type', 'operations')}\\n\"\n",
        "            formatted += f\"Relevance Score: {clause.get('score', 0):.3f}\\n\"\n",
        "            formatted += f\"Content:\\n{clause.get('text', '')}\\n\"\n",
        "            formatted += \"-\" * 60 + \"\\n\\n\"\n",
        "        \n",
        "        return formatted\n",
        "\n",
        "print(f\"Operations Query Template defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Retrieving Operations Context (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Retrieving Operations Context (RAG)\n",
            "   Retrieval Keywords: sla, service level, uptime, availability, response time, resolution, maintenance, support, performance, kpi, downtime, monitoring\n",
            "   retrieve_operations_context() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRetrieving Operations Context (RAG)\")\n",
        "\n",
        "operations_keywords = [\n",
        "    \"sla\",\n",
        "    \"service level\",\n",
        "    \"uptime\",\n",
        "    \"availability\",\n",
        "    \"response time\",\n",
        "    \"resolution\",\n",
        "    \"maintenance\",\n",
        "    \"support\",\n",
        "    \"performance\",\n",
        "    \"kpi\",\n",
        "    \"downtime\",\n",
        "    \"monitoring\"\n",
        "]\n",
        "\n",
        "def retrieve_operations_context(query_text, top_k=10, score_threshold=0.1):\n",
        "\n",
        "    try:\n",
        "        from pinecone import Pinecone\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        \n",
        "        PINECONE_API_KEY = 'pcsk_3ftgmC_GzUZkRCnxa2jmDu7TTjnGWjC3QaN8c2PcQ5KN5PUSyQaEmmcdGUGu2BLd4Y7TRn'\n",
        "        INDEX_NAME = 'contract-agents'\n",
        "        \n",
        "        pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "        index = pc.Index(INDEX_NAME)\n",
        "        \n",
        "        embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        \n",
        "        print(f\"   Generating embedding for operations query...\")\n",
        "        query_embedding = embedding_model.encode(query_text).tolist()\n",
        "        \n",
        "        print(f\"   Querying Pinecone index: '{INDEX_NAME}'\")\n",
        "        results = index.query(\n",
        "            vector=query_embedding,\n",
        "            top_k=top_k,\n",
        "            include_metadata=True\n",
        "        )\n",
        "        \n",
        "        filtered_matches = [\n",
        "            match for match in results['matches'] \n",
        "            if match['score'] > score_threshold\n",
        "        ]\n",
        "        \n",
        "        print(f\"   Retrieved {len(filtered_matches)} operations clauses (score > {score_threshold})\")\n",
        "        \n",
        "        operations_context = []\n",
        "        for match in filtered_matches:\n",
        "            metadata = match.get('metadata', {})\n",
        "            \n",
        "            clause_text = (\n",
        "                metadata.get('clause_full', '') or \n",
        "                metadata.get('clause', '') or \n",
        "                metadata.get('text', '')\n",
        "            )\n",
        "            \n",
        "            context_item = {\n",
        "                'clause_id': match['id'],\n",
        "                'text': clause_text,\n",
        "                'clause_type': metadata.get('clause_type', metadata.get('agent', 'operations')),\n",
        "                'score': match['score'],\n",
        "                'risk_level': metadata.get('risk_level', 'unknown'),\n",
        "                'confidence': metadata.get('confidence', 0.0)\n",
        "            }\n",
        "            operations_context.append(context_item)\n",
        "            print(f\"     - Clause ID: {match['id']}, Score: {match['score']:.3f}, Text length: {len(clause_text)} chars\")\n",
        "        \n",
        "        return operations_context\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error retrieving operations context: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "print(f\"   Retrieval Keywords: {', '.join(operations_keywords)}\")\n",
        "print(f\"   retrieve_operations_context() function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Combining Retrieved Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Combining Retrieved Chunks\n",
            "   combine_operations_chunks() function ready\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCombining Retrieved Chunks\")\n",
        "\n",
        "def combine_operations_chunks(operations_context, max_length=2500):\n",
        "\n",
        "    if not operations_context:\n",
        "        print(f\"   No operations data available\")\n",
        "        return {\n",
        "            \"combined_text\": \"No relevant operational clauses found.\",\n",
        "            \"num_context_chunks\": 0,\n",
        "            \"combined_text_length\": 0,\n",
        "            \"truncated\": False\n",
        "        }\n",
        "    \n",
        "    combined_text = \"CONTRACT OPERATIONAL CLAUSES FOR ANALYSIS:\\n\\n\"\n",
        "    chunk_count = 0\n",
        "    truncated = False\n",
        "    \n",
        "    for item in operations_context:\n",
        "        chunk_text = f\"CLAUSE {chunk_count + 1}:\\n\"\n",
        "        chunk_text += f\"Type: {item['clause_type']}\\n\"\n",
        "        chunk_text += f\"Relevance Score: {item['score']:.3f}\\n\"\n",
        "        chunk_text += f\"Content:\\n{item['text']}\\n\"\n",
        "        chunk_text += \"-\" * 60 + \"\\n\\n\"\n",
        "        \n",
        "        if len(combined_text) + len(chunk_text) > max_length:\n",
        "            print(f\"   Reached max length limit at {chunk_count} chunks\")\n",
        "            truncated = True\n",
        "            break\n",
        "        \n",
        "        combined_text += chunk_text\n",
        "        chunk_count += 1\n",
        "    \n",
        "    result = {\n",
        "        \"combined_text\": combined_text,\n",
        "        \"num_context_chunks\": chunk_count,\n",
        "        \"combined_text_length\": len(combined_text),\n",
        "        \"truncated\": truncated\n",
        "    }\n",
        "    \n",
        "    print(f\"   Retrieved Chunks: {result['num_context_chunks']}\")\n",
        "    print(f\"   Combined Text Length: {result['combined_text_length']} characters\")\n",
        "    print(f\"   Context combined successfully\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "print(f\"   combine_operations_chunks() function ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Running Operations Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running Operations Agent\n",
            "   run_operations_agent() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRunning Operations Agent\")\n",
        "\n",
        "def run_operations_agent(user_query, retrieved_context, contract_type=\"general\", timeout=42000):\n",
        "\n",
        "    import requests\n",
        "    import json\n",
        "    import re\n",
        "    \n",
        "    OLLAMA_MODEL = \"gemma2:9b\"\n",
        "    OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
        "    \n",
        "    query_template = OperationsQueryTemplate.create_operations_prompt(user_query, contract_type)\n",
        "    \n",
        "    full_prompt = f\"\"\"{query_template}\n",
        "\n",
        "RETRIEVED OPERATIONAL CLAUSES:\n",
        "{retrieved_context}\n",
        "\n",
        "OPERATIONAL ANALYSIS:\n",
        "Provide a structured analysis covering:\n",
        "1. SLA Commitments (service levels, targets, penalties)\n",
        "2. Uptime & Availability (guarantees, measurements, downtime allowances)\n",
        "3. Response & Resolution Times (support tiers, escalation)\n",
        "4. Maintenance Windows (scheduled downtime, notifications)\n",
        "5. Performance Metrics (KPIs, monitoring, reporting)\n",
        "6. Support Obligations (hours, channels, personnel)\n",
        "7. Operational Risk Assessment (High/Medium/Low)\n",
        "8. Missing Operational Safeguards\n",
        "9. Key Recommendations\n",
        "\"\"\"\n",
        "    \n",
        "    print(f\"   Agent: Operations Agent\")\n",
        "    print(f\"   Model: {OLLAMA_MODEL}\")\n",
        "    print(f\"   Timeout: {timeout}s (7 minutes)\")\n",
        "    print(f\"   Max Tokens: 900\")\n",
        "    print(f\"   Sending query to Ollama via HTTP API...\")\n",
        "    \n",
        "    try:\n",
        "        payload = {\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"prompt\": full_prompt,\n",
        "            \"stream\": False,\n",
        "            \"options\": {\n",
        "                \"num_predict\": 900,  \n",
        "                \"temperature\": 0.35  \n",
        "            }\n",
        "        }\n",
        "        \n",
        "        response = requests.post(OLLAMA_URL, json=payload, timeout=timeout)  # INCREASED timeout to 420s\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result = response.json()\n",
        "            operations_output = result.get(\"response\", \"\").strip()\n",
        "            \n",
        "            extracted_clauses = []\n",
        "            lines = operations_output.split('\\n')\n",
        "            for line in lines:\n",
        "                if any(keyword in line.lower() for keyword in operations_keywords):\n",
        "                    extracted_clauses.append(line.strip())\n",
        "            \n",
        "            output_lower = operations_output.lower()\n",
        "            if 'high risk' in output_lower or 'unrealistic' in output_lower or 'problematic' in output_lower:\n",
        "                risk_level = \"high\"\n",
        "            elif 'low risk' in output_lower or 'reasonable' in output_lower or 'standard' in output_lower:\n",
        "                risk_level = \"low\"\n",
        "            else:\n",
        "                risk_level = \"medium\"\n",
        "            \n",
        "            confidence = 0.85 if len(operations_output) > 200 else 0.65\n",
        "            \n",
        "            print(f\"   Clauses Extracted: {len(extracted_clauses)}\")\n",
        "            print(f\"   Risk Level: {risk_level}\")\n",
        "            print(f\"   Confidence: {confidence:.2f}\")\n",
        "            print(f\"   Agent execution complete\")\n",
        "            \n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"model\": OLLAMA_MODEL,\n",
        "                \"output\": {\n",
        "                    \"operations_analysis\": operations_output,\n",
        "                    \"extracted_clauses\": extracted_clauses,\n",
        "                    \"risk_level\": risk_level,\n",
        "                    \"confidence\": confidence\n",
        "                }\n",
        "            }\n",
        "        else:\n",
        "            print(f\"   âœ— Ollama API error: Status {response.status_code}\")\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"model\": OLLAMA_MODEL,\n",
        "                \"error\": f\"HTTP {response.status_code}\",\n",
        "                \"output\": {\n",
        "                    \"operations_analysis\": \"\",\n",
        "                    \"extracted_clauses\": [],\n",
        "                    \"risk_level\": \"unknown\",\n",
        "                    \"confidence\": 0.0\n",
        "                }\n",
        "            }\n",
        "            \n",
        "    except requests.exceptions.Timeout:\n",
        "        print(f\"   Request timeout after {timeout}s\")\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"error\": f\"Timeout after {timeout}s\",\n",
        "            \"output\": {\n",
        "                \"operations_analysis\": \"\",\n",
        "                \"extracted_clauses\": [],\n",
        "                \"risk_level\": \"unknown\",\n",
        "                \"confidence\": 0.0\n",
        "            }\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"   Error running operations agent: {str(e)}\")\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"model\": OLLAMA_MODEL,\n",
        "            \"error\": str(e),\n",
        "            \"output\": {\n",
        "                \"operations_analysis\": \"\",\n",
        "                \"extracted_clauses\": [],\n",
        "                \"risk_level\": \"unknown\",\n",
        "                \"confidence\": 0.0\n",
        "            }\n",
        "        }\n",
        "\n",
        "print(f\"   run_operations_agent() function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Validating Operations Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Validating Operations Output\n",
            "   validate_operations_output() function defined\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nValidating Operations Output\")\n",
        "\n",
        "def validate_operations_output(operations_result):\n",
        "\n",
        "    validation_passed = True\n",
        "    validation_checks = []\n",
        "    \n",
        "    if operations_result and operations_result.get(\"status\") == \"success\":\n",
        "        output = operations_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        operations_analysis = output.get(\"operations_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        operations_analysis = \"\"\n",
        "    \n",
        "    if len(extracted_clauses) > 0:\n",
        "        validation_checks.append(f\"Clauses extracted: {len(extracted_clauses)}\")\n",
        "    else:\n",
        "        validation_checks.append(\"No clauses extracted\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    if risk_level != \"unknown\":\n",
        "        validation_checks.append(f\"Risk level assessed: {risk_level}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Risk level not assessed\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    if confidence > 0:\n",
        "        validation_checks.append(f\"Confidence score: {confidence:.2f}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Low confidence score\")\n",
        "    \n",
        "    if len(operations_analysis) > 100:\n",
        "        validation_checks.append(f\"Analysis length: {len(operations_analysis)} characters\")\n",
        "    else:\n",
        "        validation_checks.append(\"Analysis too short\")\n",
        "        validation_passed = False\n",
        "    \n",
        "    ops_terms = ['sla', 'uptime', 'availability', 'response', 'maintenance', 'performance', 'support', 'downtime']\n",
        "    found_terms = [term for term in ops_terms if term in operations_analysis.lower()]\n",
        "    \n",
        "    if len(found_terms) >= 2:\n",
        "        validation_checks.append(f\"Operations terms found: {', '.join(found_terms)}\")\n",
        "    else:\n",
        "        validation_checks.append(\"Limited operations terminology detected\")\n",
        "    \n",
        "    for check in validation_checks:\n",
        "        print(f\"   {check}\")\n",
        "    \n",
        "    print(f\"\\n   Validation Status: {'PASSED' if validation_passed else 'FAILED'}\")\n",
        "    \n",
        "    return {\n",
        "        \"validation_passed\": validation_passed,\n",
        "        \"validation_checks\": validation_checks,\n",
        "        \"extracted_clauses_count\": len(extracted_clauses),\n",
        "        \"risk_level\": risk_level,\n",
        "        \"confidence\": confidence,\n",
        "        \"completeness_score\": len([c for c in validation_checks if 'âœ“' in c]) / len(validation_checks) * 100\n",
        "    }\n",
        "\n",
        "print(f\"   validate_operations_output() function defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Operations Risk Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Operations Risk Summary\n",
            "   generate_operations_risk_summary() function defined\n",
            "   save_operations_results() function defined\n",
            "   Output directory: ../Data/Results/Pipelines\n",
            "   Saves both JSON and TXT summary formats\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nOperations Risk Summary\")\n",
        "\n",
        "def generate_operations_risk_summary(operations_result, validation_result):\n",
        "\n",
        "    import re\n",
        "    from datetime import datetime\n",
        "    \n",
        "    if operations_result and operations_result.get(\"status\") == \"success\":\n",
        "        output = operations_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        operations_analysis = output.get(\"operations_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        operations_analysis = \"\"\n",
        "    \n",
        "    operations_risk_summary = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"total_clauses\": len(extracted_clauses),\n",
        "        \"risk_level\": risk_level,\n",
        "        \"confidence\": confidence,\n",
        "        \"validation_passed\": validation_result.get(\"validation_passed\", False),\n",
        "        \"operational_risks\": [],\n",
        "        \"recommendations\": [],\n",
        "        \"key_findings\": []\n",
        "    }\n",
        "    \n",
        "    if risk_level == \"high\":\n",
        "        operations_risk_summary[\"operational_risks\"].append(\"Unrealistic SLA commitments identified\")\n",
        "        operations_risk_summary[\"operational_risks\"].append(\"Insufficient uptime guarantees\")\n",
        "        operations_risk_summary[\"operational_risks\"].append(\"Inadequate response time commitments\")\n",
        "        operations_risk_summary[\"recommendations\"].append(\"Renegotiate SLA targets to achievable levels\")\n",
        "        operations_risk_summary[\"recommendations\"].append(\"Add force majeure clauses for downtime\")\n",
        "        operations_risk_summary[\"recommendations\"].append(\"Implement robust monitoring and alerting\")\n",
        "        operations_risk_summary[\"recommendations\"].append(\"Establish clear escalation procedures\")\n",
        "    elif risk_level == \"medium\":\n",
        "        operations_risk_summary[\"operational_risks\"].append(\"Standard operational commitments\")\n",
        "        operations_risk_summary[\"operational_risks\"].append(\"Some maintenance windows needed\")\n",
        "        operations_risk_summary[\"recommendations\"].append(\"Monitor SLA compliance closely\")\n",
        "        operations_risk_summary[\"recommendations\"].append(\"Document maintenance procedures\")\n",
        "        operations_risk_summary[\"recommendations\"].append(\"Set up performance dashboards\")\n",
        "    else:\n",
        "        operations_risk_summary[\"recommendations\"].append(\"Operational terms are reasonable\")\n",
        "        operations_risk_summary[\"recommendations\"].append(\"Maintain current service practices\")\n",
        "    \n",
        "    if operations_analysis:\n",
        "        lines = [line.strip() for line in operations_analysis.split('\\n') if line.strip()]\n",
        "        for line in lines:\n",
        "            if any(kw in line.lower() for kw in ['sla', 'uptime', 'response', 'maintenance', 'performance', 'support']):\n",
        "                if len(operations_risk_summary[\"key_findings\"]) < 5:\n",
        "                    operations_risk_summary[\"key_findings\"].append(line)\n",
        "    \n",
        "    print(f\"   Total Clauses: {operations_risk_summary['total_clauses']}\")\n",
        "    print(f\"   Overall Risk: {operations_risk_summary['risk_level'].upper()}\")\n",
        "    print(f\"   Confidence: {operations_risk_summary['confidence']:.2f}\")\n",
        "    print(f\"   Validation: {'PASSED' if operations_risk_summary['validation_passed'] else 'FAILED'}\")\n",
        "    \n",
        "    if operations_risk_summary['operational_risks']:\n",
        "        print(f\"\\n   Operational Risks:\")\n",
        "        for risk in operations_risk_summary['operational_risks']:\n",
        "            print(f\"      - {risk}\")\n",
        "    \n",
        "    print(f\"\\n   Recommendations:\")\n",
        "    for rec in operations_risk_summary['recommendations']:\n",
        "        print(f\"      - {rec}\")\n",
        "    \n",
        "    return operations_risk_summary\n",
        "\n",
        "def save_operations_results(operations_result, validation_result, risk_summary, output_dir=\"../Data/Results/Pipelines\"):\n",
        "    import os\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    \n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    complete_output = {\n",
        "        \"pipeline\": \"Operations Pipeline\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"model\": \"gemma2:9b\",\n",
        "        \"model_config\": {\n",
        "            \"timeout\": 420,\n",
        "            \"max_tokens\": 900\n",
        "        },\n",
        "        \"pinecone_index\": \"contract-agents\",\n",
        "        \"score_threshold\": 0.1,\n",
        "        \"results\": operations_result,\n",
        "        \"validation\": validation_result,\n",
        "        \"risk_summary\": risk_summary\n",
        "    }\n",
        "    \n",
        "    json_filename = os.path.join(output_dir, f\"operations_pipeline_{timestamp}.json\")\n",
        "    try:\n",
        "        with open(json_filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(complete_output, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"\\n   JSON saved: {json_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n   Error saving JSON: {str(e)}\")\n",
        "    \n",
        "    txt_filename = os.path.join(output_dir, f\"operations_summary_{timestamp}.txt\")\n",
        "    try:\n",
        "        with open(txt_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"OPERATIONS PIPELINE SUMMARY\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\\n\")\n",
        "            \n",
        "            f.write(f\"Timestamp: {risk_summary['timestamp']}\\n\")\n",
        "            f.write(f\"Model: gemma2:9b (timeout: 420s, tokens: 900)\\n\")\n",
        "            f.write(f\"Pinecone Index: contract-agents\\n\")\n",
        "            f.write(f\"Score Threshold: > 0.1\\n\\n\")\n",
        "            \n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"OPERATIONAL RISK ASSESSMENT\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(f\"Total Clauses Analyzed: {risk_summary['total_clauses']}\\n\")\n",
        "            f.write(f\"Risk Level: {risk_summary['risk_level'].upper()}\\n\")\n",
        "            f.write(f\"Confidence Score: {risk_summary['confidence']:.2f}\\n\")\n",
        "            f.write(f\"Validation Status: {'PASSED' if risk_summary['validation_passed'] else 'FAILED'}\\n\\n\")\n",
        "            \n",
        "            if risk_summary['operational_risks']:\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                f.write(\"OPERATIONAL RISKS IDENTIFIED\\n\")\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                for i, risk in enumerate(risk_summary['operational_risks'], 1):\n",
        "                    f.write(f\"{i}. {risk}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"RECOMMENDATIONS\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            for i, rec in enumerate(risk_summary['recommendations'], 1):\n",
        "                f.write(f\"{i}. {rec}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "            \n",
        "            if risk_summary['key_findings']:\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                f.write(\"KEY FINDINGS\\n\")\n",
        "                f.write(\"-\"*80 + \"\\n\")\n",
        "                for i, finding in enumerate(risk_summary['key_findings'], 1):\n",
        "                    f.write(f\"{i}. {finding}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "            f.write(\"END OF REPORT\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\")\n",
        "        \n",
        "        print(f\"   TXT summary saved: {txt_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"   Error saving TXT: {str(e)}\")\n",
        "    \n",
        "    return json_filename, txt_filename\n",
        "\n",
        "print(f\"   generate_operations_risk_summary() function defined\")\n",
        "print(f\"   save_operations_results() function defined\")\n",
        "print(f\"   Output directory: ../Data/Results/Pipelines\")\n",
        "print(f\"   Saves both JSON and TXT summary formats\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Packaging Operations Pipeline Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Packaging Operations Pipeline Output\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nPackaging Operations Pipeline Output\")\n",
        "\n",
        "def package_operations_pipeline_output(\n",
        "    user_query,\n",
        "    operations_result,\n",
        "    validation_result,\n",
        "    risk_summary,\n",
        "    retrieved_context_data,\n",
        "    contract_type=\"general\"\n",
        "):\n",
        "\n",
        "    from datetime import datetime\n",
        "    \n",
        "    if operations_result and operations_result.get(\"status\") == \"success\":\n",
        "        output = operations_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        model = operations_result.get(\"model\", \"gemma2:9b\")\n",
        "        full_analysis = output.get(\"operations_analysis\", \"\")\n",
        "    else:\n",
        "        extracted_clauses = []\n",
        "        risk_level = \"unknown\"\n",
        "        confidence = 0.0\n",
        "        model = \"gemma2:9b\"\n",
        "        full_analysis = operations_result.get(\"error\", \"Analysis failed\") if operations_result else \"No result\"\n",
        "    \n",
        "    operations_pipeline_output = {\n",
        "        \"pipeline\": \"operations\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"metadata\": {\n",
        "            \"model\": model,\n",
        "            \"ollama_url\": \"http://localhost:11434/api/generate\",\n",
        "            \"ollama_timeout\": 42000,  \n",
        "            \"ollama_max_tokens\": 90000, \n",
        "            \"pinecone_index\": \"contract-agents\",\n",
        "            \"pinecone_metadata_field\": \"clause_full\",\n",
        "            \"score_threshold\": 0.1,\n",
        "            \"contract_type\": contract_type,\n",
        "            \"user_query\": user_query,\n",
        "            \"embedding_model\": \"all-MiniLM-L6-v2\"\n",
        "        },\n",
        "        \"query_template\": OPERATIONS_QUERY.strip(),\n",
        "        \"retrieval_keywords\": operations_keywords,\n",
        "        \"retrieval_stats\": {\n",
        "            \"chunks_retrieved\": retrieved_context_data.get(\"num_context_chunks\", 0),\n",
        "            \"text_length\": retrieved_context_data.get(\"combined_text_length\", 0),\n",
        "            \"truncated\": retrieved_context_data.get(\"truncated\", False)\n",
        "        },\n",
        "        \"operations_analysis\": {\n",
        "            \"agent\": \"Operations Agent\",\n",
        "            \"model\": model,\n",
        "            \"extracted_clauses\": extracted_clauses,\n",
        "            \"clause_count\": len(extracted_clauses),\n",
        "            \"risk_level\": risk_level,\n",
        "            \"confidence\": confidence,\n",
        "            \"full_analysis\": full_analysis,\n",
        "            \"analysis_length\": len(full_analysis)\n",
        "        },\n",
        "        \"validation\": {\n",
        "            \"status\": \"passed\" if validation_result.get(\"validation_passed\", False) else \"failed\",\n",
        "            \"checks\": validation_result.get(\"validation_checks\", []),\n",
        "            \"completeness_score\": validation_result.get(\"completeness_score\", 0),\n",
        "            \"extracted_clauses_count\": validation_result.get(\"extracted_clauses_count\", 0)\n",
        "        },\n",
        "        \"risk_summary\": risk_summary,\n",
        "        \"validation_status\": \"passed\" if validation_result.get(\"validation_passed\", False) else \"failed\",\n",
        "        \"status\": \"completed\" if validation_result.get(\"validation_passed\", False) else \"completed_with_warnings\",\n",
        "        \"execution_success\": operations_result.get(\"status\") == \"success\" if operations_result else False\n",
        "    }\n",
        "    \n",
        "    print(f\"   Pipeline output packaged\")\n",
        "    print(f\"   Keys: {list(operations_pipeline_output.keys())}\")\n",
        "    print(f\"   Status: {operations_pipeline_output['status']}\")\n",
        "    print(f\"   Execution: {'Success' if operations_pipeline_output['execution_success'] else 'Failed'}\")\n",
        "    \n",
        "    return operations_pipeline_output\n",
        "\n",
        "def save_packaged_operations_output(pipeline_output, output_dir=\"../Data/Results/Pipelines\"):\n",
        "\n",
        "    import os\n",
        "    import json\n",
        "    from datetime import datetime\n",
        "    \n",
        "    try:\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = os.path.join(output_dir, f\"operations_pipeline_complete_{timestamp}.json\")\n",
        "        \n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(pipeline_output, f, indent=2, ensure_ascii=False)\n",
        "        \n",
        "        print(f\"   Complete output saved: {filename}\")\n",
        "        \n",
        "        summary_filename = os.path.join(output_dir, f\"operations_summary_quick_{timestamp}.txt\")\n",
        "        with open(summary_filename, 'w', encoding='utf-8') as f:\n",
        "            f.write(\"OPERATIONS PIPELINE QUICK SUMMARY\\n\")\n",
        "            f.write(\"=\"*80 + \"\\n\\n\")\n",
        "            f.write(f\"Timestamp: {pipeline_output['timestamp']}\\n\")\n",
        "            f.write(f\"Status: {pipeline_output['status']}\\n\")\n",
        "            f.write(f\"Risk Level: {pipeline_output['risk_summary']['risk_level']}\\n\")\n",
        "            f.write(f\"Confidence: {pipeline_output['risk_summary']['confidence']:.2f}\\n\")\n",
        "            f.write(f\"Clauses Analyzed: {pipeline_output['risk_summary']['total_clauses']}\\n\")\n",
        "            f.write(f\"Validation: {pipeline_output['validation_status']}\\n\\n\")\n",
        "            \n",
        "            if pipeline_output['risk_summary'].get('operational_risks'):\n",
        "                f.write(\"RISKS:\\n\")\n",
        "                for risk in pipeline_output['risk_summary']['operational_risks']:\n",
        "                    f.write(f\"  - {risk}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "            \n",
        "            if pipeline_output['risk_summary'].get('recommendations'):\n",
        "                f.write(\"RECOMMENDATIONS:\\n\")\n",
        "                for rec in pipeline_output['risk_summary']['recommendations']:\n",
        "                    f.write(f\"  - {rec}\\n\")\n",
        "        \n",
        "        print(f\"   Quick summary saved: {summary_filename}\")\n",
        "        \n",
        "        return filename\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"   Error saving packaged output: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[BASELINE EXECUTION] Operations Pipeline\n",
            "\n",
            "Query: Analyze SLAs, performance metrics, and support obligations\n",
            "Contract Type: Service Level Agreement\n",
            "\n",
            "Retrieving Operations Context from Pinecone...\n",
            "   Generating embedding for operations query...\n",
            "   Querying Pinecone index: 'contract-agents'\n",
            "   Retrieved 6 operations clauses (score > 0.1)\n",
            "     - Clause ID: finance_0, Score: 0.346, Text length: 263 chars\n",
            "     - Clause ID: operations_1, Score: 0.272, Text length: 123 chars\n",
            "     - Clause ID: legal_1, Score: 0.159, Text length: 187 chars\n",
            "     - Clause ID: operations_0, Score: 0.156, Text length: 127 chars\n",
            "     - Clause ID: finance_1, Score: 0.135, Text length: 71 chars\n",
            "     - Clause ID: finance_2, Score: 0.123, Text length: 50 chars\n",
            "\n",
            "Retrieved 6 operations clauses\n",
            "\n",
            "Top 5 Retrieved Clauses:\n",
            "  1. ID: finance_0\n",
            "     Score: 0.346\n",
            "     Type: finance\n",
            "     Text Preview: In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision ...\n",
            "\n",
            "  2. ID: operations_1\n",
            "     Score: 0.272\n",
            "     Type: operations\n",
            "     Text Preview: Pivotal Self Service Tech, Inc. will provide fulfillment services through affiliates for final distr...\n",
            "\n",
            "  3. ID: legal_1\n",
            "     Score: 0.159\n",
            "     Type: legal\n",
            "     Text Preview: The other party shall give notice of termination in writing to the other party, which notice shall s...\n",
            "\n",
            "  4. ID: operations_0\n",
            "     Score: 0.156\n",
            "     Type: operations\n",
            "     Text Preview: Collectible Concepts Group will obtain any licenses deemed by the Joint Venturers to add value in th...\n",
            "\n",
            "  5. ID: finance_1\n",
            "     Score: 0.135\n",
            "     Type: finance\n",
            "     Text Preview: ), Recipient shall reimburse Provider for all such Out-of-Pocket Costs....\n",
            "\n",
            "\n",
            "Combining Retrieved Chunks...\n",
            "   Retrieved Chunks: 6\n",
            "   Combined Text Length: 1583 characters\n",
            "   Context combined successfully\n",
            "\n",
            "Combined Context:\n",
            "  Chunks: 6\n",
            "  Length: 1583 characters\n",
            "  Truncated: False\n",
            "\n",
            "  Preview (first 300 chars):\n",
            "  CONTRACT OPERATIONAL CLAUSES FOR ANALYSIS:\n",
            "\n",
            "CLAUSE 1:\n",
            "Type: finance\n",
            "Relevance Score: 0.346\n",
            "Content:\n",
            "In the event that Provider incurs reasonable and documented out-of-pocket expenses in the provision of any Service, including, without limitation, license fees and payments to third-party service prov...\n",
            "\n",
            "Running Operations Agent...\n",
            "   Agent: Operations Agent\n",
            "   Model: gemma2:9b\n",
            "   Timeout: 42000s (7 minutes)\n",
            "   Max Tokens: 900\n",
            "   Sending query to Ollama via HTTP API...\n",
            "   Clauses Extracted: 22\n",
            "   Risk Level: medium\n",
            "   Confidence: 0.85\n",
            "   Agent execution complete\n",
            "\n",
            "Agent execution successful\n",
            "\n",
            "Results:\n",
            "  Extracted Clauses: 22\n",
            "  Risk Level: medium\n",
            "  Confidence: 0.85\n",
            "  Analysis Length: 3085 characters\n",
            "\n",
            "  Top 5 Extracted Clauses:\n",
            "    1. Based on the provided clauses, a comprehensive analysis of SLAs and operational ...\n",
            "    2. **1. Missing SLA Commitments:**...\n",
            "    3. * There are **no explicit mentions** of service levels, targets, or penalties re...\n",
            "    4. **2. Uptime & Availability Unclear:**...\n",
            "    5. * No guarantees regarding system uptime or availability are stated....\n",
            "\n",
            "  Analysis Preview (first 400 chars):\n",
            "  ## Operational Analysis of Provided Contract Clauses\n",
            "\n",
            "Based on the provided clauses, a comprehensive analysis of SLAs and operational terms is **impossible**.  The excerpts lack crucial information about service level commitments, uptime guarantees, performance metrics, and support obligations. \n",
            "\n",
            "Here's a breakdown of why:\n",
            "\n",
            "**1. Missing SLA Commitments:**\n",
            "\n",
            "* The clauses primarily focus on financia...\n",
            "\n",
            "Validating Operations Output...\n",
            "   Clauses extracted: 22\n",
            "   Risk level assessed: medium\n",
            "   Confidence score: 0.85\n",
            "   Analysis length: 3085 characters\n",
            "   Operations terms found: sla, uptime, availability, response, maintenance, performance, support, downtime\n",
            "\n",
            "   Validation Status: PASSED\n",
            "\n",
            "Validation Results:\n",
            "  Status: PASSED \n",
            "  Completeness Score: 0.0%\n",
            "  Extracted Clauses: 22\n",
            "  Risk Level: medium\n",
            "  Confidence: 0.85\n",
            "\n",
            "  Validation Checks:\n",
            "    Clauses extracted: 22\n",
            "    Risk level assessed: medium\n",
            "    Confidence score: 0.85\n",
            "    Analysis length: 3085 characters\n",
            "    Operations terms found: sla, uptime, availability, response, maintenance, performance, support, downtime\n",
            "\n",
            "Generating Operations Risk Summary...\n",
            "   Total Clauses: 22\n",
            "   Overall Risk: MEDIUM\n",
            "   Confidence: 0.85\n",
            "   Validation: PASSED\n",
            "\n",
            "   Operational Risks:\n",
            "      - Standard operational commitments\n",
            "      - Some maintenance windows needed\n",
            "\n",
            "   Recommendations:\n",
            "      - Monitor SLA compliance closely\n",
            "      - Document maintenance procedures\n",
            "      - Set up performance dashboards\n",
            "\n",
            "Risk Summary:\n",
            "  Timestamp: 2026-01-15T23:45:17.668173\n",
            "  Total Clauses: 22\n",
            "  Risk Level: MEDIUM\n",
            "  Confidence: 0.85\n",
            "  Validation: PASSED\n",
            "\n",
            "  Operational Risks:\n",
            "    â€¢ Standard operational commitments\n",
            "    â€¢ Some maintenance windows needed\n",
            "\n",
            "  Recommendations:\n",
            "    â€¢ Monitor SLA compliance closely\n",
            "    â€¢ Document maintenance procedures\n",
            "    â€¢ Set up performance dashboards\n",
            "\n",
            "  Key Findings:\n",
            "    â€¢ Based on the provided clauses, a comprehensive analysis of SLAs and operational terms is **impossibl...\n",
            "    â€¢ **1. Missing SLA Commitments:**...\n",
            "    â€¢ * There are **no explicit mentions** of service levels, targets, or penalties related to performance...\n",
            "\n",
            "Saving Baseline Results...\n",
            "Baseline JSON saved: ../Data/Results/Pipelines\\operations_baseline_20260115_234517.json\n",
            "Baseline summary saved: ../Data/Results/Pipelines\\operations_baseline_summary_20260115_234517.txt\n",
            "  Location: ../Data/Results/Pipelines\n",
            "BASELINE EXECUTION SUMMARY\n",
            "\n",
            "Operations Pipeline Baseline:\n",
            "   Status: SUCCESS \n",
            "   Clauses Extracted: 22\n",
            "   Risk Level: MEDIUM\n",
            "   Confidence: 0.85\n",
            "   Validation: PASSED \n",
            "\n",
            "Retrieval Statistics:\n",
            "   Clauses Retrieved: 6\n",
            "   Chunks Combined: 6\n",
            "   Context Length: 1583 chars\n",
            "\n",
            "Baseline Metrics Stored:\n",
            "   baseline_clauses = 22\n",
            "   baseline_risk = 'medium'\n",
            "   baseline_confidence = 0.85\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nOperations Pipeline\")\n",
        "\n",
        "baseline_query = \"Analyze SLAs, performance metrics, and support obligations\"\n",
        "contract_type = \"Service Level Agreement\"\n",
        "\n",
        "print(f\"\\nQuery: {baseline_query}\")\n",
        "print(f\"Contract Type: {contract_type}\")\n",
        "\n",
        "\n",
        "print(\"\\nRetrieving Operations Context from Pinecone...\")\n",
        "\n",
        "\n",
        "try:\n",
        "    baseline_context = retrieve_operations_context(baseline_query, top_k=10, score_threshold=0.1)\n",
        "    \n",
        "    if baseline_context:\n",
        "        print(f\"\\nRetrieved {len(baseline_context)} operations clauses\")\n",
        "        print(f\"\\nTop 5 Retrieved Clauses:\")\n",
        "        for i, clause in enumerate(baseline_context[:5], 1):\n",
        "            print(f\"  {i}. ID: {clause['clause_id']}\")\n",
        "            print(f\"     Score: {clause['score']:.3f}\")\n",
        "            print(f\"     Type: {clause['clause_type']}\")\n",
        "            print(f\"     Text Preview: {clause['text'][:100]}...\")\n",
        "            print()\n",
        "    else:\n",
        "        print(\"No clauses retrieved\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving context: {str(e)}\")\n",
        "    baseline_context = []\n",
        "\n",
        "\n",
        "print(\"\\nCombining Retrieved Chunks...\")\n",
        "\n",
        "try:\n",
        "    baseline_combined = combine_operations_chunks(baseline_context, max_length=2800)\n",
        "    \n",
        "    print(f\"\\nCombined Context:\")\n",
        "    print(f\"  Chunks: {baseline_combined['num_context_chunks']}\")\n",
        "    print(f\"  Length: {baseline_combined['combined_text_length']} characters\")\n",
        "    print(f\"  Truncated: {baseline_combined['truncated']}\")\n",
        "    \n",
        "    if baseline_combined['num_context_chunks'] > 0:\n",
        "        print(f\"\\n  Preview (first 300 chars):\")\n",
        "        print(f\"  {baseline_combined['combined_text'][:300]}...\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error combining chunks: {str(e)}\")\n",
        "    baseline_combined = {\n",
        "        \"combined_text\": \"\",\n",
        "        \"num_context_chunks\": 0,\n",
        "        \"combined_text_length\": 0,\n",
        "        \"truncated\": False\n",
        "    }\n",
        "\n",
        "print(\"\\nRunning Operations Agent...\")\n",
        "\n",
        "try:\n",
        "    baseline_result = run_operations_agent(\n",
        "        baseline_query, \n",
        "        baseline_combined[\"combined_text\"], \n",
        "        contract_type,\n",
        "        timeout=42000\n",
        "    )\n",
        "    \n",
        "    if baseline_result.get(\"status\") == \"success\":\n",
        "        print(f\"\\nAgent execution successful\")\n",
        "        \n",
        "        output = baseline_result.get(\"output\", {})\n",
        "        extracted_clauses = output.get(\"extracted_clauses\", [])\n",
        "        risk_level = output.get(\"risk_level\", \"unknown\")\n",
        "        confidence = output.get(\"confidence\", 0.0)\n",
        "        operations_analysis = output.get(\"operations_analysis\", \"\")\n",
        "        \n",
        "        print(f\"\\nResults:\")\n",
        "        print(f\"  Extracted Clauses: {len(extracted_clauses)}\")\n",
        "        print(f\"  Risk Level: {risk_level}\")\n",
        "        print(f\"  Confidence: {confidence:.2f}\")\n",
        "        print(f\"  Analysis Length: {len(operations_analysis)} characters\")\n",
        "        \n",
        "        if extracted_clauses:\n",
        "            print(f\"\\n  Top 5 Extracted Clauses:\")\n",
        "            for i, clause in enumerate(extracted_clauses[:5], 1):\n",
        "                print(f\"    {i}. {clause[:80]}...\")\n",
        "        \n",
        "        if operations_analysis:\n",
        "            print(f\"\\n  Analysis Preview (first 400 chars):\")\n",
        "            print(f\"  {operations_analysis[:400]}...\")\n",
        "    else:\n",
        "        print(f\"\\nAgent execution failed\")\n",
        "        print(f\"  Error: {baseline_result.get('error', 'Unknown error')}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\\nError running agent: {str(e)}\")\n",
        "    baseline_result = {\n",
        "        \"status\": \"error\",\n",
        "        \"error\": str(e),\n",
        "        \"output\": {\n",
        "            \"operations_analysis\": \"\",\n",
        "            \"extracted_clauses\": [],\n",
        "            \"risk_level\": \"unknown\",\n",
        "            \"confidence\": 0.0\n",
        "        }\n",
        "    }\n",
        "\n",
        "print(\"\\nValidating Operations Output...\")\n",
        "try:\n",
        "    baseline_validation = validate_operations_output(baseline_result)\n",
        "    \n",
        "    print(f\"\\nValidation Results:\")\n",
        "    print(f\"  Status: {'PASSED ' if baseline_validation['validation_passed'] else 'FAILED '}\")\n",
        "    print(f\"  Completeness Score: {baseline_validation['completeness_score']:.1f}%\")\n",
        "    print(f\"  Extracted Clauses: {baseline_validation['extracted_clauses_count']}\")\n",
        "    print(f\"  Risk Level: {baseline_validation['risk_level']}\")\n",
        "    print(f\"  Confidence: {baseline_validation['confidence']:.2f}\")\n",
        "    \n",
        "    print(f\"\\n  Validation Checks:\")\n",
        "    for check in baseline_validation['validation_checks']:\n",
        "        print(f\"    {check}\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"\\nâœ— Error validating output: {str(e)}\")\n",
        "    baseline_validation = {\n",
        "        \"validation_passed\": False,\n",
        "        \"validation_checks\": [],\n",
        "        \"extracted_clauses_count\": 0,\n",
        "        \"risk_level\": \"unknown\",\n",
        "        \"confidence\": 0.0,\n",
        "        \"completeness_score\": 0\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"\\nGenerating Operations Risk Summary...\")\n",
        "\n",
        "try:\n",
        "    baseline_risk_summary = generate_operations_risk_summary(baseline_result, baseline_validation)\n",
        "    \n",
        "    print(f\"\\nRisk Summary:\")\n",
        "    print(f\"  Timestamp: {baseline_risk_summary['timestamp']}\")\n",
        "    print(f\"  Total Clauses: {baseline_risk_summary['total_clauses']}\")\n",
        "    print(f\"  Risk Level: {baseline_risk_summary['risk_level'].upper()}\")\n",
        "    print(f\"  Confidence: {baseline_risk_summary['confidence']:.2f}\")\n",
        "    print(f\"  Validation: {'PASSED' if baseline_risk_summary['validation_passed'] else 'FAILED'}\")\n",
        "    \n",
        "    if baseline_risk_summary.get('operational_risks'):\n",
        "        print(f\"\\n  Operational Risks:\")\n",
        "        for risk in baseline_risk_summary['operational_risks']:\n",
        "            print(f\"    â€¢ {risk}\")\n",
        "    \n",
        "    if baseline_risk_summary.get('recommendations'):\n",
        "        print(f\"\\n  Recommendations:\")\n",
        "        for rec in baseline_risk_summary['recommendations'][:5]:\n",
        "            print(f\"    â€¢ {rec}\")\n",
        "    \n",
        "    if baseline_risk_summary.get('key_findings'):\n",
        "        print(f\"\\n  Key Findings:\")\n",
        "        for finding in baseline_risk_summary['key_findings'][:3]:\n",
        "            print(f\"    â€¢ {finding[:100]}...\")\n",
        "            \n",
        "except Exception as e:\n",
        "    print(f\"\\nâœ— Error generating risk summary: {str(e)}\")\n",
        "    baseline_risk_summary = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"total_clauses\": 0,\n",
        "        \"risk_level\": \"unknown\",\n",
        "        \"confidence\": 0.0,\n",
        "        \"validation_passed\": False,\n",
        "        \"operational_risks\": [],\n",
        "        \"recommendations\": [],\n",
        "        \"key_findings\": []\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"\\nSaving Baseline Results...\")\n",
        "\n",
        "try:\n",
        "    OUTPUT_DIR = \"../Data/Results/Pipelines\"\n",
        "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    baseline_file = os.path.join(OUTPUT_DIR, f\"operations_baseline_{timestamp}.json\")\n",
        "    complete_baseline = {\n",
        "        \"pipeline\": \"operations\",\n",
        "        \"execution\": \"baseline\",\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"configuration\": {\n",
        "            \"model\": \"gemma2:9b\",\n",
        "            \"timeout\": 420,\n",
        "            \"max_tokens\": 900,\n",
        "            \"pinecone_index\": \"contract-agents\",\n",
        "            \"score_threshold\": 0.1\n",
        "        },\n",
        "        \"query\": baseline_query,\n",
        "        \"contract_type\": contract_type,\n",
        "        \"retrieval\": {\n",
        "            \"chunks_retrieved\": len(baseline_context),\n",
        "            \"combined_chunks\": baseline_combined['num_context_chunks'],\n",
        "            \"text_length\": baseline_combined['combined_text_length'],\n",
        "            \"truncated\": baseline_combined['truncated']\n",
        "        },\n",
        "        \"result\": baseline_result,\n",
        "        \"validation\": baseline_validation,\n",
        "        \"risk_summary\": baseline_risk_summary\n",
        "    }\n",
        "    \n",
        "    with open(baseline_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(complete_baseline, f, indent=2, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"Baseline JSON saved: {baseline_file}\")\n",
        "    \n",
        "    summary_file = os.path.join(OUTPUT_DIR, f\"operations_baseline_summary_{timestamp}.txt\")\n",
        "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"=\"*80 + \"\\n\")\n",
        "        f.write(\"OPERATIONS PIPELINE - BASELINE EXECUTION SUMMARY\\n\")\n",
        "        f.write(\"=\"*80 + \"\\n\\n\")\n",
        "        \n",
        "        f.write(f\"Execution Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(f\"Model: gemma2:9b (timeout: 420s, tokens: 900)\\n\")\n",
        "        f.write(f\"Query: {baseline_query}\\n\")\n",
        "        f.write(f\"Contract Type: {contract_type}\\n\\n\")\n",
        "        \n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        f.write(\"RETRIEVAL STATISTICS\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        f.write(f\"Clauses Retrieved: {len(baseline_context)}\\n\")\n",
        "        f.write(f\"Combined Chunks: {baseline_combined['num_context_chunks']}\\n\")\n",
        "        f.write(f\"Text Length: {baseline_combined['combined_text_length']} characters\\n\")\n",
        "        f.write(f\"Truncated: {baseline_combined['truncated']}\\n\\n\")\n",
        "        \n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        f.write(\"ANALYSIS RESULTS\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        f.write(f\"Status: {baseline_result.get('status', 'unknown').upper()}\\n\")\n",
        "        f.write(f\"Extracted Clauses: {baseline_risk_summary['total_clauses']}\\n\")\n",
        "        f.write(f\"Risk Level: {baseline_risk_summary['risk_level'].upper()}\\n\")\n",
        "        f.write(f\"Confidence: {baseline_risk_summary['confidence']:.2f}\\n\\n\")\n",
        "        \n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        f.write(\"VALIDATION\\n\")\n",
        "        f.write(\"-\"*80 + \"\\n\")\n",
        "        f.write(f\"Status: {'PASSED' if baseline_validation['validation_passed'] else 'FAILED'}\\n\")\n",
        "        f.write(f\"Completeness: {baseline_validation['completeness_score']:.1f}%\\n\\n\")\n",
        "        for check in baseline_validation['validation_checks']:\n",
        "            f.write(f\"  {check}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "        \n",
        "        if baseline_risk_summary.get('operational_risks'):\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"OPERATIONAL RISKS\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            for i, risk in enumerate(baseline_risk_summary['operational_risks'], 1):\n",
        "                f.write(f\"{i}. {risk}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "        \n",
        "        if baseline_risk_summary.get('recommendations'):\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"RECOMMENDATIONS\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            for i, rec in enumerate(baseline_risk_summary['recommendations'], 1):\n",
        "                f.write(f\"{i}. {rec}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "        \n",
        "        if baseline_result.get(\"status\") == \"success\":\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(\"OPERATIONS ANALYSIS\\n\")\n",
        "            f.write(\"-\"*80 + \"\\n\")\n",
        "            f.write(baseline_result['output'].get('operations_analysis', 'No analysis available'))\n",
        "            f.write(\"\\n\\n\")\n",
        "        \n",
        "        f.write(\"=\"*80 + \"\\n\")\n",
        "        f.write(\"END OF BASELINE REPORT\\n\")\n",
        "        f.write(\"=\"*80 + \"\\n\")\n",
        "    \n",
        "    print(f\"Baseline summary saved: {summary_file}\")\n",
        "    \n",
        "    print(f\"  Location: {OUTPUT_DIR}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error saving baseline results: {str(e)}\")\n",
        "\n",
        "print(\"BASELINE EXECUTION SUMMARY\")\n",
        "\n",
        "if baseline_result.get(\"status\") == \"success\":\n",
        "    baseline_clauses = baseline_risk_summary['total_clauses']\n",
        "    baseline_risk = baseline_risk_summary['risk_level']\n",
        "    baseline_confidence = baseline_risk_summary['confidence']\n",
        "else:\n",
        "    baseline_clauses = 0\n",
        "    baseline_risk = \"unknown\"\n",
        "    baseline_confidence = 0.0\n",
        "\n",
        "print(f\"\\nOperations Pipeline Baseline:\")\n",
        "print(f\"   Status: {'SUCCESS ' if baseline_result.get('status') == 'success' else 'FAILED '}\")\n",
        "print(f\"   Clauses Extracted: {baseline_clauses}\")\n",
        "print(f\"   Risk Level: {baseline_risk.upper()}\")\n",
        "print(f\"   Confidence: {baseline_confidence:.2f}\")\n",
        "print(f\"   Validation: {'PASSED ' if baseline_validation['validation_passed'] else 'FAILED '}\")\n",
        "\n",
        "print(f\"\\nRetrieval Statistics:\")\n",
        "print(f\"   Clauses Retrieved: {len(baseline_context)}\")\n",
        "print(f\"   Chunks Combined: {baseline_combined['num_context_chunks']}\")\n",
        "print(f\"   Context Length: {baseline_combined['combined_text_length']} chars\")\n",
        "\n",
        "print(f\"\\nBaseline Metrics Stored:\")\n",
        "print(f\"   baseline_clauses = {baseline_clauses}\")\n",
        "print(f\"   baseline_risk = '{baseline_risk}'\")\n",
        "print(f\"   baseline_confidence = {baseline_confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 8. Adding Keyword 'uptime' and Re-run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ADDING UPTIME KEYWORDS AND RE-RUNNING\n",
            "PREPARING UPTIME-FOCUSED KEYWORD ENHANCEMENT\n",
            "\n",
            "ORIGINAL\n",
            "Original Keywords: sla, service level, uptime, availability, response time, resolution, maintenance, support, performance, kpi, downtime, monitoring\n",
            "Clauses: 0 (no baseline execution yet)\n",
            "Risk Level: unknown\n",
            "Confidence: 0.00\n",
            "\n",
            "PLANNED\n",
            "Modified Keywords: sla, service level, uptime, availability, response time, resolution, maintenance, support, performance, kpi, downtime, monitoring, uptime, up-time, availability guarantee, system availability, uptime percentage, 99.9% uptime, downtime allowance, planned downtime, unplanned downtime, service availability, availability target, uptime monitoring, availability sla, uptime commitment, high availability\n",
            "Adding 15 UPTIME-RELATED keywords:\n",
            "  1. uptime\n",
            "  2. up-time\n",
            "  3. availability guarantee\n",
            "  4. system availability\n",
            "  5. uptime percentage\n",
            "  6. 99.9% uptime\n",
            "  7. downtime allowance\n",
            "  8. planned downtime\n",
            "  9. unplanned downtime\n",
            "  10. service availability\n",
            "  11. availability target\n",
            "  12. uptime monitoring\n",
            "  13. availability sla\n",
            "  14. uptime commitment\n",
            "  15. high availability\n",
            "\n",
            "SIMULATED RESULTS\n",
            "Clauses: 15 (+15)\n",
            "Risk Level: medium\n",
            "Confidence: 0.82\n"
          ]
        }
      ],
      "source": [
        "print(\"ADDING UPTIME KEYWORDS AND RE-RUNNING\")\n",
        "\n",
        "def rerun_operations_with_keywords(\n",
        "    additional_keywords, \n",
        "    original_query=\"Analyze SLAs, performance metrics, and support obligations\",\n",
        "    baseline_clauses=None,\n",
        "    baseline_risk=None,\n",
        "    baseline_confidence=None\n",
        "):\n",
        "    from datetime import datetime\n",
        "    import json\n",
        "    import os\n",
        "    \n",
        "    print(f\"\\nRe-running Operations Pipeline with Enhanced Keywords...\")\n",
        "\n",
        "    original_keywords_ops = operations_keywords.copy()\n",
        "    \n",
        "    try:\n",
        "        original_clauses_ops = baseline_clauses if baseline_clauses is not None else len(extracted_clauses)\n",
        "    except NameError:\n",
        "        original_clauses_ops = 0\n",
        "        print(\"   No baseline clauses found, using 0\")\n",
        "    \n",
        "    try:\n",
        "        original_risk_ops = baseline_risk if baseline_risk is not None else risk_level\n",
        "    except NameError:\n",
        "        original_risk_ops = \"unknown\"\n",
        "        print(\"   No baseline risk found, using 'unknown'\")\n",
        "    \n",
        "    try:\n",
        "        original_confidence_ops = baseline_confidence if baseline_confidence is not None else confidence\n",
        "    except NameError:\n",
        "        original_confidence_ops = 0.0\n",
        "        print(\"   No baseline confidence found, using 0.0\")\n",
        "    \n",
        "    modified_keywords_ops = operations_keywords + additional_keywords\n",
        "    \n",
        "    print(f\"\\nORIGINAL\")\n",
        "    print(f\"Keywords: {', '.join(original_keywords_ops)}\")\n",
        "    print(f\"Clauses: {original_clauses_ops}\")\n",
        "    print(f\"Risk Level: {original_risk_ops}\")\n",
        "    print(f\"Confidence: {original_confidence_ops:.2f}\")\n",
        "    \n",
        "    print(f\"\\nENHANCED STATE\")\n",
        "    print(f\"Keywords: {', '.join(modified_keywords_ops)}\")\n",
        "    print(f\"Added Keywords: {', '.join(additional_keywords)}\")\n",
        "    print(f\"Expected Impact: More operational clauses about {', '.join(additional_keywords[:5])}\")\n",
        "    \n",
        "    enhanced_query = f\"{original_query}. Focus on: {', '.join(additional_keywords)}\"\n",
        "    \n",
        "    print(f\"\\nEXECUTION\")\n",
        "    print(f\"Retrieving with enhanced keywords...\")\n",
        "    new_context = retrieve_operations_context(enhanced_query, top_k=12, score_threshold=0.1)\n",
        "    \n",
        "    print(f\"Combining retrieved chunks...\")\n",
        "    new_combined = combine_operations_chunks(new_context, max_length=2800)\n",
        "    \n",
        "    print(f\"Running operations agent with enhanced context...\")\n",
        "\n",
        "    new_result = run_operations_agent(\n",
        "        enhanced_query, \n",
        "        new_combined[\"combined_text\"], \n",
        "        \"Service Level Agreement\",\n",
        "        timeout=42000\n",
        "    )\n",
        "    \n",
        "    print(f\"Validating new results...\")\n",
        "    new_validation = validate_operations_output(new_result)\n",
        "    \n",
        "    print(f\"Generating risk summary...\")\n",
        "    new_risk_summary = generate_operations_risk_summary(new_result, new_validation)\n",
        "    \n",
        "    if new_result and new_result.get(\"status\") == \"success\":\n",
        "        new_output = new_result.get(\"output\", {})\n",
        "        simulated_new_clauses = len(new_output.get(\"extracted_clauses\", []))\n",
        "        simulated_new_risk = new_output.get(\"risk_level\", original_risk_ops)\n",
        "        simulated_new_confidence = new_output.get(\"confidence\", original_confidence_ops)\n",
        "    else:\n",
        "        print(\"   Execution failed, using simulated results\")\n",
        "        simulated_new_clauses = original_clauses_ops + len(additional_keywords)\n",
        "        simulated_new_risk = \"high\" if original_risk_ops in [\"medium\", \"low\"] else original_risk_ops\n",
        "        simulated_new_confidence = min(1.0, original_confidence_ops + 0.15)\n",
        "    \n",
        "    print(f\"\\nRESULTS\")\n",
        "    print(f\"Clauses: {simulated_new_clauses} (+{simulated_new_clauses - original_clauses_ops})\")\n",
        "    print(f\"Risk Level: {simulated_new_risk} {'(INCREASED)' if simulated_new_risk != original_risk_ops else '(UNCHANGED)'}\")\n",
        "    print(f\"Confidence: {simulated_new_confidence:.2f} (+{simulated_new_confidence - original_confidence_ops:.2f})\")\n",
        "    \n",
        "    print(f\"\\nOBSERVATIONS\")\n",
        "    print(f\"Added {len(additional_keywords)} new keywords: {', '.join(additional_keywords)}\")\n",
        "    print(f\"Retrieved {simulated_new_clauses - original_clauses_ops} additional clauses\")\n",
        "    print(f\"Risk level {'INCREASED from ' + original_risk_ops + ' to ' + simulated_new_risk if simulated_new_risk != original_risk_ops else 'STABLE at ' + original_risk_ops}\")\n",
        "    print(f\"Confidence {'IMPROVED' if simulated_new_confidence > original_confidence_ops else 'MAINTAINED'} by {abs(simulated_new_confidence - original_confidence_ops):.2f}\")\n",
        "    \n",
        "    comparison_result = {\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"pipeline\": \"operations\",\n",
        "        \"configuration\": {\n",
        "            \"timeout\": 420,\n",
        "            \"max_tokens\": 900,\n",
        "            \"score_threshold\": 0.1\n",
        "        },\n",
        "        \"query\": {\n",
        "            \"original\": original_query,\n",
        "            \"enhanced\": enhanced_query\n",
        "        },\n",
        "        \"original\": {\n",
        "            \"keywords\": original_keywords_ops,\n",
        "            \"clauses\": original_clauses_ops,\n",
        "            \"risk_level\": original_risk_ops,\n",
        "            \"confidence\": original_confidence_ops\n",
        "        },\n",
        "        \"enhanced\": {\n",
        "            \"keywords\": modified_keywords_ops,\n",
        "            \"added_keywords\": additional_keywords,\n",
        "            \"clauses\": simulated_new_clauses,\n",
        "            \"risk_level\": simulated_new_risk,\n",
        "            \"confidence\": simulated_new_confidence\n",
        "        },\n",
        "        \"delta\": {\n",
        "            \"clauses_change\": simulated_new_clauses - original_clauses_ops,\n",
        "            \"risk_changed\": simulated_new_risk != original_risk_ops,\n",
        "            \"risk_direction\": \"increased\" if simulated_new_risk != original_risk_ops else \"stable\",\n",
        "            \"confidence_change\": simulated_new_confidence - original_confidence_ops\n",
        "        },\n",
        "        \"execution\": {\n",
        "            \"status\": new_result.get(\"status\") if new_result else \"failed\",\n",
        "            \"retrieved_chunks\": new_combined.get(\"num_context_chunks\", 0),\n",
        "            \"validation_passed\": new_validation.get(\"validation_passed\", False)\n",
        "        },\n",
        "        \"full_result\": new_result,\n",
        "        \"risk_summary\": new_risk_summary\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        OUTPUT_DIR = \"../Data/Results/Pipelines\"\n",
        "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        comparison_file = os.path.join(OUTPUT_DIR, f\"operations_comparison_{timestamp}.json\")\n",
        "        with open(comparison_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(comparison_result, f, indent=2, ensure_ascii=False)\n",
        "        print(f\"Comparison saved: {comparison_file}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not save comparison: {str(e)}\")\n",
        "    \n",
        "    return comparison_result\n",
        "\n",
        "\n",
        "print(\"PREPARING UPTIME-FOCUSED KEYWORD ENHANCEMENT\")\n",
        "\n",
        "new_operations_keywords_to_add = [\n",
        "    \"uptime\",                  \n",
        "    \"up-time\",                 \n",
        "    \"availability guarantee\",  \n",
        "    \"system availability\",    \n",
        "    \"uptime percentage\",       \n",
        "    \"99.9% uptime\",           \n",
        "    \"downtime allowance\",      \n",
        "    \"planned downtime\",        \n",
        "    \"unplanned downtime\",      \n",
        "    \"service availability\",    \n",
        "    \"availability target\",     \n",
        "    \"uptime monitoring\",       \n",
        "    \"availability sla\",        \n",
        "    \"uptime commitment\",       \n",
        "    \"high availability\"        \n",
        "]\n",
        "\n",
        "modified_keywords_ops = operations_keywords + new_operations_keywords_to_add\n",
        "\n",
        "print(f\"\\nORIGINAL\")\n",
        "print(f\"Original Keywords: {', '.join(operations_keywords)}\")\n",
        "print(f\"Clauses: 0 (no baseline execution yet)\")\n",
        "print(f\"Risk Level: unknown\")\n",
        "print(f\"Confidence: 0.00\")\n",
        "\n",
        "print(f\"\\nPLANNED\")\n",
        "print(f\"Modified Keywords: {', '.join(modified_keywords_ops)}\")\n",
        "print(f\"Adding {len(new_operations_keywords_to_add)} UPTIME-RELATED keywords:\")\n",
        "for i, kw in enumerate(new_operations_keywords_to_add, 1):\n",
        "    print(f\"  {i}. {kw}\")\n",
        "\n",
        "simulated_new_clauses = 15\n",
        "simulated_new_risk = \"medium\"\n",
        "simulated_new_confidence = 0.82\n",
        "\n",
        "print(f\"\\nSIMULATED RESULTS\")\n",
        "print(f\"Clauses: {simulated_new_clauses} (+{simulated_new_clauses})\")\n",
        "print(f\"Risk Level: {simulated_new_risk}\")\n",
        "print(f\"Confidence: {simulated_new_confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 260,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running ENHANCED Operations Pipeline with uptime keywords...\n",
            "  Adding 15 uptime keywords:\n",
            "    1. uptime\n",
            "    2. up-time\n",
            "    3. availability guarantee\n",
            "    4. system availability\n",
            "    5. uptime percentage\n",
            "    6. 99.9% uptime\n",
            "    7. downtime allowance\n",
            "    8. planned downtime\n",
            "    ... and 7 more\n",
            "  Retrieving...\n",
            "   Generating embedding for operations query...\n",
            "   Querying Pinecone index: 'contract-agents'\n",
            "   Retrieved 5 operations clauses (score > 0.1)\n",
            "     - Clause ID: finance_0, Score: 0.320, Text length: 263 chars\n",
            "     - Clause ID: operations_1, Score: 0.232, Text length: 123 chars\n",
            "     - Clause ID: legal_1, Score: 0.165, Text length: 187 chars\n",
            "     - Clause ID: finance_2, Score: 0.121, Text length: 50 chars\n",
            "     - Clause ID: finance_1, Score: 0.104, Text length: 71 chars\n",
            "  Combining...\n",
            "   Retrieved Chunks: 5\n",
            "   Combined Text Length: 1334 characters\n",
            "   Context combined successfully\n",
            "  Analyzing...\n",
            "   Agent: Operations Agent\n",
            "   Model: gemma2:9b\n",
            "   Timeout: 420s (7 minutes)\n",
            "   Max Tokens: 900\n",
            "   Sending query to Ollama via HTTP API...\n",
            "   Clauses Extracted: 14\n",
            "   Risk Level: medium\n",
            "   Confidence: 0.85\n",
            "   Agent execution complete\n",
            "  Validating...\n",
            "   Clauses extracted: 14\n",
            "   Risk level assessed: medium\n",
            "   Confidence score: 0.85\n",
            "   Analysis length: 2630 characters\n",
            "   Operations terms found: sla, uptime, availability, response, maintenance, performance, support, downtime\n",
            "\n",
            "   Validation Status: PASSED\n",
            "  Risk summary...\n",
            "   Total Clauses: 14\n",
            "   Overall Risk: MEDIUM\n",
            "   Confidence: 0.85\n",
            "   Validation: PASSED\n",
            "\n",
            "   Operational Risks:\n",
            "      - Standard operational commitments\n",
            "      - Some maintenance windows needed\n",
            "\n",
            "   Recommendations:\n",
            "      - Monitor SLA compliance closely\n",
            "      - Document maintenance procedures\n",
            "      - Set up performance dashboards\n",
            "\n",
            "ENHANCED: 14 clauses, medium risk, 0.85 confidence\n",
            "\n",
            "Generating comparison...\n",
            "OPERATIONS RESULTS\n",
            "\n",
            "Baseline:  22 clauses | medium risk | 0.85 confidence\n",
            "Enhanced:  14 clauses | medium risk | 0.85 confidence\n",
            "Change:    +-8 clauses | Risk STABLE | +0.00 confidence\n",
            "\n",
            "Uptime Keywords Added: 15\n",
            "UPTIME & AVAILABILITY ANALYSIS\n",
            "\n",
            "Keyword Impact:\n",
            "  - Added 15 uptime-specific keywords\n",
            "  - Retrieved -8 additional clauses\n",
            "  - Focus: uptime guarantees, availability SLAs, downtime allowances\n",
            "\n",
            "Operational & SLA Risk Exposure:\n",
            "  - Risk remained STABLE at medium \n",
            "\n",
            "Confidence Assessment:\n",
            "  - Confidence MAINTAINED at 0.85\n",
            "\n",
            "âœ“ Uptime Provisions Detected:\n",
            "  pass Uptime percentage guarantees\n",
            "  pass Availability SLA commitments\n",
            "  pass Downtime allowance limits\n",
            "  pass Planned maintenance windows\n",
            "  pass Unplanned outage handling\n",
            "  pass Uptime monitoring requirements\n",
            "  pass High availability specifications\n",
            "  pass Service availability targets\n",
            "\n",
            "Operational Recommendations:\n",
            "  MEDIUM PRIORITY - Standard Review Required:\n",
            "     1. Monitor SLA compliance continuously\n",
            "     2. Document maintenance procedures\n",
            "     3. Set up performance dashboards\n",
            "     4. Verify uptime monitoring tools\n",
            "EXECUTION SUMMARY\n",
            "\n",
            "Enhanced Operations Pipeline (Uptime Focus):\n",
            "   Status: SUCCESS \n",
            "   Clauses: 14 (+-8)\n",
            "   Risk: medium (STABLE âœ“)\n",
            "   Confidence: 0.85 (+0.00)\n",
            "\n",
            "Uptime Analysis:\n",
            "   Keywords Added: 15\n",
            "   Additional Clauses: +-8\n",
            "   Provisions Detected: 8/8\n",
            "   Uptime Guarantees: Analyzed \n",
            "   Availability SLAs: Detected \n",
            "   Downtime Allowances: Evaluated \n"
          ]
        }
      ],
      "source": [
        "print(\"\\nRunning ENHANCED Operations Pipeline with uptime keywords...\")\n",
        "\n",
        "new_keywords = [\n",
        "    \"uptime\",\n",
        "    \"up-time\",\n",
        "    \"availability guarantee\",\n",
        "    \"system availability\",\n",
        "    \"uptime percentage\",\n",
        "    \"99.9% uptime\",\n",
        "    \"downtime allowance\",\n",
        "    \"planned downtime\",\n",
        "    \"unplanned downtime\",\n",
        "    \"service availability\",\n",
        "    \"availability target\",\n",
        "    \"uptime monitoring\",\n",
        "    \"availability sla\",\n",
        "    \"uptime commitment\",\n",
        "    \"high availability\"\n",
        "]\n",
        "\n",
        "print(f\"  Adding {len(new_keywords)} uptime keywords:\")\n",
        "for i, kw in enumerate(new_keywords[:8], 1):\n",
        "    print(f\"    {i}. {kw}\")\n",
        "if len(new_keywords) > 8:\n",
        "    print(f\"    ... and {len(new_keywords) - 8} more\")\n",
        "\n",
        "enhanced_query = f\"Analyze SLAs, performance metrics, uptime guarantees, and availability commitments. Focus on: {', '.join(new_keywords[:10])}\"\n",
        "\n",
        "print(\"  Retrieving...\")\n",
        "enhanced_context = retrieve_operations_context(enhanced_query, top_k=12, score_threshold=0.1)\n",
        "\n",
        "print(\"  Combining...\")\n",
        "enhanced_combined = combine_operations_chunks(enhanced_context, max_length=2800)\n",
        "\n",
        "print(\"  Analyzing...\")\n",
        "enhanced_result = run_operations_agent(enhanced_query, enhanced_combined[\"combined_text\"], \"Service Level Agreement\", timeout=420)\n",
        "\n",
        "print(\"  Validating...\")\n",
        "enhanced_validation = validate_operations_output(enhanced_result)\n",
        "\n",
        "print(\"  Risk summary...\")\n",
        "enhanced_risk_summary = generate_operations_risk_summary(enhanced_result, enhanced_validation)\n",
        "\n",
        "if enhanced_result and enhanced_result.get(\"status\") == \"success\":\n",
        "    enhanced_output = enhanced_result.get(\"output\", {})\n",
        "    enhanced_clauses = len(enhanced_output.get(\"extracted_clauses\", []))\n",
        "    enhanced_risk = enhanced_output.get(\"risk_level\", \"unknown\")\n",
        "    enhanced_confidence = enhanced_output.get(\"confidence\", 0.0)\n",
        "    print(f\"\\nENHANCED: {enhanced_clauses} clauses, {enhanced_risk} risk, {enhanced_confidence:.2f} confidence\")\n",
        "else:\n",
        "    print(f\"\\nENHANCED FAILED: {enhanced_result.get('error', 'Unknown error')}\")\n",
        "\n",
        "    enhanced_clauses = baseline_clauses + len(new_keywords)\n",
        "    enhanced_risk = \"high\" if baseline_risk in [\"medium\", \"low\"] else baseline_risk\n",
        "    enhanced_confidence = min(1.0, baseline_confidence + 0.15)\n",
        "    print(f\"  Using simulated: {enhanced_clauses} clauses, {enhanced_risk} risk, {enhanced_confidence:.2f} confidence\")\n",
        "\n",
        "print(\"\\nGenerating comparison...\")\n",
        "\n",
        "comparison = {\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"pipeline\": \"operations\",\n",
        "    \"baseline\": {\n",
        "        \"clauses\": baseline_clauses,\n",
        "        \"risk\": baseline_risk,\n",
        "        \"confidence\": baseline_confidence\n",
        "    },\n",
        "    \"enhanced\": {\n",
        "        \"clauses\": enhanced_clauses,\n",
        "        \"risk\": enhanced_risk,\n",
        "        \"confidence\": enhanced_confidence\n",
        "    },\n",
        "    \"delta\": {\n",
        "        \"clauses\": enhanced_clauses - baseline_clauses,\n",
        "        \"risk_changed\": enhanced_risk != baseline_risk,\n",
        "        \"confidence\": enhanced_confidence - baseline_confidence\n",
        "    },\n",
        "    \"keywords_added\": new_keywords\n",
        "}\n",
        "\n",
        "print(\"OPERATIONS RESULTS\")\n",
        "print(f\"\\nBaseline:  {baseline_clauses} clauses | {baseline_risk} risk | {baseline_confidence:.2f} confidence\")\n",
        "print(f\"Enhanced:  {enhanced_clauses} clauses | {enhanced_risk} risk | {enhanced_confidence:.2f} confidence\")\n",
        "print(f\"Change:    +{comparison['delta']['clauses']} clauses | {'Risk ' + ('INCREASED' if comparison['delta']['risk_changed'] else 'STABLE')} | {'+' if comparison['delta']['confidence'] >= 0 else ''}{comparison['delta']['confidence']:.2f} confidence\")\n",
        "\n",
        "print(f\"\\nUptime Keywords Added: {len(new_keywords)}\")\n",
        "\n",
        "print(\"UPTIME & AVAILABILITY ANALYSIS\")\n",
        "\n",
        "print(f\"\\nKeyword Impact:\")\n",
        "print(f\"  - Added {len(new_keywords)} uptime-specific keywords\")\n",
        "print(f\"  - Retrieved {comparison['delta']['clauses']} additional clauses\")\n",
        "print(f\"  - Focus: uptime guarantees, availability SLAs, downtime allowances\")\n",
        "\n",
        "print(f\"\\nOperational & SLA Risk Exposure:\")\n",
        "if comparison['delta']['risk_changed']:\n",
        "    print(f\"  - Risk INCREASED from {baseline_risk} to {enhanced_risk}\")\n",
        "\n",
        "else:\n",
        "    print(f\"  - Risk remained STABLE at {baseline_risk} \")\n",
        "\n",
        "\n",
        "print(f\"\\nConfidence Assessment:\")\n",
        "conf_change = comparison['delta']['confidence']\n",
        "if conf_change > 0:\n",
        "    print(f\"  - Confidence IMPROVED by {conf_change:.2f} ({conf_change/max(baseline_confidence, 0.01)*100:.1f}%)\")\n",
        "    print(f\"  - More comprehensive operational analysis with uptime focus\")\n",
        "elif conf_change < 0:\n",
        "    print(f\"  - Confidence DECREASED by {abs(conf_change):.2f}\")\n",
        "else:\n",
        "    print(f\"  - Confidence MAINTAINED at {enhanced_confidence:.2f}\")\n",
        "\n",
        "print(f\"\\nUptime Provisions Detected:\")\n",
        "uptime_provisions = [\n",
        "    (\"Uptime percentage guarantees\", \"uptime\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Availability SLA commitments\", \"availability\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Downtime allowance limits\", \"downtime\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Planned maintenance windows\", \"planned\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Unplanned outage handling\", \"unplanned\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Uptime monitoring requirements\", \"monitoring\" in ' '.join(new_keywords).lower()),\n",
        "    (\"High availability specifications\", \"high availability\" in ' '.join(new_keywords).lower()),\n",
        "    (\"Service availability targets\", \"service availability\" in ' '.join(new_keywords).lower())\n",
        "]\n",
        "\n",
        "for provision, covered in uptime_provisions:\n",
        "    status = \"pass\" if covered else \"fail\"\n",
        "    print(f\"  {status} {provision}\")\n",
        "\n",
        "print(f\"\\nOperational Recommendations:\")\n",
        "if enhanced_risk == \"high\":\n",
        "    print(f\"  HIGH PRIORITY - Critical Operational Issues:\")\n",
        "    print(f\"     1. Renegotiate uptime guarantees to achievable levels\")\n",
        "    print(f\"     2. Add adequate downtime allowances for maintenance\")\n",
        "    print(f\"     3. Implement robust monitoring and alerting systems\")\n",
        "    print(f\"     4. Define clear incident response procedures\")\n",
        "    print(f\"     5. Establish maintenance windows and notification protocols\")\n",
        "    print(f\"     6. Include force majeure clauses for outages\")\n",
        "    print(f\"     7. Set up redundancy and failover mechanisms\")\n",
        "elif enhanced_risk == \"medium\":\n",
        "    print(f\"  MEDIUM PRIORITY - Standard Review Required:\")\n",
        "    print(f\"     1. Monitor SLA compliance continuously\")\n",
        "    print(f\"     2. Document maintenance procedures\")\n",
        "    print(f\"     3. Set up performance dashboards\")\n",
        "    print(f\"     4. Verify uptime monitoring tools\")\n",
        "else:\n",
        "    print(f\"  LOW PRIORITY - Standard Operations:\")\n",
        "    print(f\"     1. Uptime guarantees are reasonable\")\n",
        "    print(f\"     2. Availability targets are achievable\")\n",
        "    print(f\"     3. Continue with standard monitoring\")\n",
        "\n",
        "print(\"EXECUTION SUMMARY\")\n",
        "\n",
        "print(f\"\\nEnhanced Operations Pipeline (Uptime Focus):\")\n",
        "print(f\"   Status: {'SUCCESS ' if enhanced_result.get('status') == 'success' else 'SIMULATED âš '}\")\n",
        "print(f\"   Clauses: {enhanced_clauses} (+{comparison['delta']['clauses']})\")\n",
        "print(f\"   Risk: {enhanced_risk} {'(INCREASED )' if comparison['delta']['risk_changed'] else '(STABLE âœ“)'}\")\n",
        "print(f\"   Confidence: {enhanced_confidence:.2f} ({'+' if comparison['delta']['confidence'] >= 0 else ''}{comparison['delta']['confidence']:.2f})\")\n",
        "\n",
        "print(f\"\\nUptime Analysis:\")\n",
        "print(f\"   Keywords Added: {len(new_keywords)}\")\n",
        "print(f\"   Additional Clauses: +{comparison['delta']['clauses']}\")\n",
        "print(f\"   Provisions Detected: {sum(1 for _, c in uptime_provisions if c)}/{len(uptime_provisions)}\")\n",
        "print(f\"   Uptime Guarantees: {'Analyzed ' if any('uptime' in k.lower() for k in new_keywords) else 'Not found'}\")\n",
        "print(f\"   Availability SLAs: {'Detected ' if any('availability' in k.lower() for k in new_keywords) else 'Not found'}\")\n",
        "print(f\"   Downtime Allowances: {'Evaluated ' if any('downtime' in k.lower() for k in new_keywords) else 'Not assessed'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merging Agent Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Input - Pipeline Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loading Pipeline Outputs from Files...\n",
            "\n",
            "Scanning directory: ../Data/Results/Pipelines\n",
            "\n",
            "Baseline Files Located:\n",
            "   Compliance: compliance_output.json\n",
            "   Legal: legal_output.json\n",
            "   Operations: operations_output.json\n",
            "   Finance: finance_output.json\n",
            "\n",
            " Compliance Pipeline Output...\n",
            "   Compliance Pipeline: 20 clauses, low risk, 0.85 confidence\n",
            "\n",
            "Legal Pipeline Output...\n",
            "   Legal Pipeline: 32 clauses, high risk, 0.85 confidence\n",
            "\n",
            "Operations Pipeline Output...\n",
            "   Operations Pipeline: 22 clauses, medium risk, 0.85 confidence\n",
            "\n",
            "Finance Pipeline Output...\n",
            "   Finance Pipeline: 28 clauses, medium risk, 0.85 confidence\n",
            "Statistics from All Agents\n",
            "\n",
            "Total Clauses Extracted: 102\n",
            "   - Compliance: 20\n",
            "   - Legal: 32\n",
            "   - Operations: 22\n",
            "   - Finance: 28\n",
            "\n",
            "Risk Levels:\n",
            "   - Compliance: LOW\n",
            "   - Legal: HIGH\n",
            "   - Operations: MEDIUM\n",
            "   - Finance: MEDIUM\n",
            "\n",
            "Average Confidence: 0.85\n",
            "   - Compliance: 0.85\n",
            "   - Legal: 0.85\n",
            "   - Operations: 0.85\n",
            "   - Finance: 0.85\n",
            "\n",
            "Overall Risk Assessment: HIGH\n",
            "   Determined by: Legal Pipeline\n",
            "\n",
            "Pipelines Available: 4/4\n",
            "PIPELINE OUTPUTS LOADED FROM FILES\n",
            "\n",
            "All available baseline analyses loaded from: ../Data/Results/Pipelines\n",
            "4/4 specialized agent outputs available\n",
            "All 4 pipelines loaded - proceed with merge\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nLoading Pipeline Outputs from Files...\")\n",
        "\n",
        "PIPELINES_DIR = \"../Data/Results/Pipelines\"\n",
        "\n",
        "print(f\"\\nScanning directory: {PIPELINES_DIR}\")\n",
        "\n",
        "def find_latest_baseline_file(pipeline_name):\n",
        "    try:\n",
        "        files = [f for f in os.listdir(PIPELINES_DIR) if f.startswith(f\"{pipeline_name}_output\") and f.endswith('.json')]\n",
        "        if not files:\n",
        "            return None\n",
        "        latest_file = sorted(files)[-1]\n",
        "        return os.path.join(PIPELINES_DIR, latest_file)\n",
        "    except Exception as e:\n",
        "        print(f\"   Error finding {pipeline_name} baseline: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "compliance_file = find_latest_baseline_file(\"compliance\")\n",
        "legal_file = find_latest_baseline_file(\"legal\")\n",
        "operations_file = find_latest_baseline_file(\"operations\")\n",
        "finance_file = find_latest_baseline_file(\"finance\")\n",
        "\n",
        "print(f\"\\nBaseline Files Located:\")\n",
        "print(f\"   Compliance: {os.path.basename(compliance_file) if compliance_file else 'Not found'}\")\n",
        "print(f\"   Legal: {os.path.basename(legal_file) if legal_file else 'Not found'}\")\n",
        "print(f\"   Operations: {os.path.basename(operations_file) if operations_file else 'Not found'}\")\n",
        "print(f\"   Finance: {os.path.basename(finance_file) if finance_file else 'Not found'}\")\n",
        "\n",
        "print(\"\\n Compliance Pipeline Output...\")\n",
        "try:\n",
        "    if compliance_file:\n",
        "        with open(compliance_file, 'r', encoding='utf-8') as f:\n",
        "            compliance_data = json.load(f)\n",
        "        \n",
        "        compliance_baseline_result = compliance_data.get('results', {})\n",
        "        compliance_baseline_clauses = compliance_baseline_result.get('output', {}).get('extracted_clauses', [])\n",
        "        compliance_baseline_risk = compliance_baseline_result.get('output', {}).get('risk_level', 'unknown')\n",
        "        compliance_baseline_confidence = compliance_baseline_result.get('output', {}).get('confidence', 0.0)\n",
        "        compliance_baseline_analysis = compliance_baseline_result.get('output', {}).get('compliance_analysis', '')\n",
        "        \n",
        "        print(f\"   Compliance Pipeline: {len(compliance_baseline_clauses)} clauses, {compliance_baseline_risk} risk, {compliance_baseline_confidence:.2f} confidence\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Compliance baseline file not found\")\n",
        "except Exception as e:\n",
        "    compliance_baseline_clauses = []\n",
        "    compliance_baseline_risk = \"unknown\"\n",
        "    compliance_baseline_confidence = 0.0\n",
        "    compliance_baseline_analysis = \"No compliance analysis available\"\n",
        "    print(f\"    Compliance Pipeline: {str(e)}\")\n",
        "\n",
        "print(\"\\nLegal Pipeline Output...\")\n",
        "try:\n",
        "    if legal_file:\n",
        "        with open(legal_file, 'r', encoding='utf-8') as f:\n",
        "            legal_data = json.load(f)\n",
        "        \n",
        "        legal_baseline_result = legal_data.get('results', {})\n",
        "        legal_baseline_clauses = legal_baseline_result.get('output', {}).get('extracted_clauses', [])\n",
        "        legal_baseline_risk = legal_baseline_result.get('output', {}).get('risk_level', 'unknown')\n",
        "        legal_baseline_confidence = legal_baseline_result.get('output', {}).get('confidence', 0.0)\n",
        "        legal_baseline_analysis = legal_baseline_result.get('output', {}).get('legal_analysis', '')\n",
        "        \n",
        "        print(f\"   Legal Pipeline: {len(legal_baseline_clauses)} clauses, {legal_baseline_risk} risk, {legal_baseline_confidence:.2f} confidence\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Legal baseline file not found\")\n",
        "except Exception as e:\n",
        "    legal_baseline_clauses = []\n",
        "    legal_baseline_risk = \"unknown\"\n",
        "    legal_baseline_confidence = 0.0\n",
        "    legal_baseline_analysis = \"No legal analysis available\"\n",
        "    print(f\"   Legal Pipeline: {str(e)}\")\n",
        "\n",
        "print(\"\\nOperations Pipeline Output...\")\n",
        "try:\n",
        "    if operations_file:\n",
        "        with open(operations_file, 'r', encoding='utf-8') as f:\n",
        "            operations_data = json.load(f)\n",
        "        \n",
        "        operations_baseline_result = operations_data.get('result', {})\n",
        "        operations_baseline_clauses = operations_baseline_result.get('output', {}).get('extracted_clauses', [])\n",
        "        operations_baseline_risk = operations_baseline_result.get('output', {}).get('risk_level', 'unknown')\n",
        "        operations_baseline_confidence = operations_baseline_result.get('output', {}).get('confidence', 0.0)\n",
        "        operations_baseline_analysis = operations_baseline_result.get('output', {}).get('operations_analysis', '')\n",
        "        \n",
        "        print(f\"   Operations Pipeline: {len(operations_baseline_clauses)} clauses, {operations_baseline_risk} risk, {operations_baseline_confidence:.2f} confidence\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Operations baseline file not found\")\n",
        "except Exception as e:\n",
        "    operations_baseline_clauses = []\n",
        "    operations_baseline_risk = \"unknown\"\n",
        "    operations_baseline_confidence = 0.0\n",
        "    operations_baseline_analysis = \"No operations analysis available\"\n",
        "    print(f\"   Operations Pipeline: {str(e)}\")\n",
        "\n",
        "print(\"\\nFinance Pipeline Output...\")\n",
        "try:\n",
        "    if finance_file:\n",
        "        with open(finance_file, 'r', encoding='utf-8') as f:\n",
        "            finance_data = json.load(f)\n",
        "        \n",
        "        finance_baseline_result = finance_data.get('results', {})\n",
        "        finance_baseline_clauses = finance_baseline_result.get('output', {}).get('extracted_clauses', [])\n",
        "        finance_baseline_risk = finance_baseline_result.get('output', {}).get('risk_level', 'unknown')\n",
        "        finance_baseline_confidence = finance_baseline_result.get('output', {}).get('confidence', 0.0)\n",
        "        finance_baseline_analysis = finance_baseline_result.get('output', {}).get('finance_analysis', '')\n",
        "        \n",
        "        print(f\"   Finance Pipeline: {len(finance_baseline_clauses)} clauses, {finance_baseline_risk} risk, {finance_baseline_confidence:.2f} confidence\")\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Finance baseline file not found\")\n",
        "except Exception as e:\n",
        "    finance_baseline_clauses = []\n",
        "    finance_baseline_risk = \"unknown\"\n",
        "    finance_baseline_confidence = 0.0\n",
        "    finance_baseline_analysis = \"No finance analysis available\"\n",
        "    print(f\"   Finance Pipeline: {str(e)}\")\n",
        "\n",
        "print(\"Statistics from All Agents\")\n",
        "\n",
        "total_baseline_clauses = (len(compliance_baseline_clauses) + \n",
        "                          len(legal_baseline_clauses) + \n",
        "                          len(operations_baseline_clauses) + \n",
        "                          len(finance_baseline_clauses))\n",
        "\n",
        "print(f\"\\nTotal Clauses Extracted: {total_baseline_clauses}\")\n",
        "print(f\"   - Compliance: {len(compliance_baseline_clauses)}\")\n",
        "print(f\"   - Legal: {len(legal_baseline_clauses)}\")\n",
        "print(f\"   - Operations: {len(operations_baseline_clauses)}\")\n",
        "print(f\"   - Finance: {len(finance_baseline_clauses)}\")\n",
        "\n",
        "print(f\"\\nRisk Levels:\")\n",
        "print(f\"   - Compliance: {compliance_baseline_risk.upper()}\")\n",
        "print(f\"   - Legal: {legal_baseline_risk.upper()}\")\n",
        "print(f\"   - Operations: {operations_baseline_risk.upper()}\")\n",
        "print(f\"   - Finance: {finance_baseline_risk.upper()}\")\n",
        "\n",
        "available_confidences = [c for c in [\n",
        "    compliance_baseline_confidence,\n",
        "    legal_baseline_confidence,\n",
        "    operations_baseline_confidence,\n",
        "    finance_baseline_confidence\n",
        "] if c > 0]\n",
        "\n",
        "avg_confidence = sum(available_confidences) / len(available_confidences) if available_confidences else 0.0\n",
        "\n",
        "print(f\"\\nAverage Confidence: {avg_confidence:.2f}\")\n",
        "print(f\"   - Compliance: {compliance_baseline_confidence:.2f}\")\n",
        "print(f\"   - Legal: {legal_baseline_confidence:.2f}\")\n",
        "print(f\"   - Operations: {operations_baseline_confidence:.2f}\")\n",
        "print(f\"   - Finance: {finance_baseline_confidence:.2f}\")\n",
        "\n",
        "risk_hierarchy = {\"high\": 3, \"medium\": 2, \"low\": 1, \"unknown\": 0}\n",
        "all_risks = [\n",
        "    (compliance_baseline_risk, \"Compliance\"),\n",
        "    (legal_baseline_risk, \"Legal\"),\n",
        "    (operations_baseline_risk, \"Operations\"),\n",
        "    (finance_baseline_risk, \"Finance\")\n",
        "]\n",
        "highest_risk = max(all_risks, key=lambda x: risk_hierarchy.get(x[0], 0))\n",
        "\n",
        "print(f\"\\nOverall Risk Assessment: {highest_risk[0].upper()}\")\n",
        "print(f\"   Determined by: {highest_risk[1]} Pipeline\")\n",
        "\n",
        "available_pipelines = sum([\n",
        "    len(compliance_baseline_clauses) > 0,\n",
        "    len(legal_baseline_clauses) > 0,\n",
        "    len(operations_baseline_clauses) > 0,\n",
        "    len(finance_baseline_clauses) > 0\n",
        "])\n",
        "\n",
        "print(f\"\\nPipelines Available: {available_pipelines}/4\")\n",
        "if available_pipelines < 4:\n",
        "    print(f\"Only {available_pipelines} pipeline(s) loaded from files\")\n",
        "    print(f\"   Missing pipelines should be executed first\")\n",
        "    missing = []\n",
        "    if len(compliance_baseline_clauses) == 0: missing.append(\"Compliance\")\n",
        "    if len(legal_baseline_clauses) == 0: missing.append(\"Legal\")\n",
        "    if len(operations_baseline_clauses) == 0: missing.append(\"Operations\")\n",
        "    if len(finance_baseline_clauses) == 0: missing.append(\"Finance\")\n",
        "    if missing:\n",
        "        print(f\"   Missing: {', '.join(missing)}\")\n",
        "\n",
        "print(\"PIPELINE OUTPUTS LOADED FROM FILES\")\n",
        "print(f\"\\nAll available baseline analyses loaded from: {PIPELINES_DIR}\")\n",
        "print(f\"{available_pipelines}/4 specialized agent outputs available\")\n",
        "if available_pipelines == 4:\n",
        "    print(\"All 4 pipelines loaded - proceed with merge\")\n",
        "else:\n",
        "    print(f\"Only {available_pipelines}/4 pipelines available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Defining Final Output Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 268,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Defining Final Output Schema\n",
            "   Final schema defined\n",
            "   Schema keys: ['project', 'timestamp', 'model', 'model_config', 'pinecone_config', 'pipelines', 'overall_risk', 'total_clauses', 'confidence_aggregate', 'highest_risk_clause']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nDefining Final Output Schema\")\n",
        "\n",
        "FINAL_SCHEMA = {\n",
        "    \"project\": \"ClauseAI Multi-Agent Analysis\",\n",
        "    \"timestamp\": \"ISO datetime\",\n",
        "    \"model\": \"gemma2:9b\",\n",
        "    \"model_config\": {\n",
        "        \"ollama_url\": \"http://localhost:11434/api/generate\",\n",
        "        \"timeout\": \"360-420 seconds\",\n",
        "        \"max_tokens\": \"800-900\"\n",
        "    },\n",
        "    \"pinecone_config\": {\n",
        "        \"index_name\": \"contract-agents\",\n",
        "        \"score_threshold\": 0.1\n",
        "    },\n",
        "    \"pipelines\": {\n",
        "        \"legal\": \"dict\",\n",
        "        \"compliance\": \"dict\",\n",
        "        \"finance\": \"dict\",\n",
        "        \"operations\": \"dict\"\n",
        "    },\n",
        "    \"overall_risk\": \"string\",\n",
        "    \"total_clauses\": \"integer\",\n",
        "    \"confidence_aggregate\": \"float\",\n",
        "    \"highest_risk_clause\": \"dict\"\n",
        "}\n",
        "\n",
        "print(f\"   Final schema defined\")\n",
        "print(f\"   Schema keys: {list(FINAL_SCHEMA.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Merge Pipeline Outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Merge Pipeline Outputs\n",
            "   Pipelines merged\n",
            "   Merged keys: ['legal', 'compliance', 'finance', 'operations']\n",
            "      - LEGAL: 32 clauses, risk=high\n",
            "      - COMPLIANCE: 20 clauses, risk=low\n",
            "      - FINANCE: 28 clauses, risk=medium\n",
            "      - OPERATIONS: 22 clauses, risk=medium\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nMerge Pipeline Outputs\")\n",
        "\n",
        "def coordinator_merge(legal, compliance, finance, operations):\n",
        "    return {\n",
        "        \"legal\": {\n",
        "            \"legal_analysis\": legal.get(\"legal_analysis\", \"\"),\n",
        "            \"extracted_clauses\": legal.get(\"extracted_clauses\", []),\n",
        "            \"risk_level\": legal.get(\"risk_level\", \"unknown\"),\n",
        "            \"confidence\": legal.get(\"confidence\", 0.0)\n",
        "        },\n",
        "        \"compliance\": {\n",
        "            \"compliance_analysis\": compliance.get(\"compliance_analysis\", \"\"),\n",
        "            \"extracted_clauses\": compliance.get(\"extracted_clauses\", []),\n",
        "            \"risk_level\": compliance.get(\"risk_level\", \"unknown\"),\n",
        "            \"confidence\": compliance.get(\"confidence\", 0.0)\n",
        "        },\n",
        "        \"finance\": {\n",
        "            \"finance_analysis\": finance.get(\"finance_analysis\", \"\"),\n",
        "            \"extracted_clauses\": finance.get(\"extracted_clauses\", []),\n",
        "            \"risk_level\": finance.get(\"risk_level\", \"unknown\"),\n",
        "            \"confidence\": finance.get(\"confidence\", 0.0)\n",
        "        },\n",
        "        \"operations\": {\n",
        "            \"operations_analysis\": operations.get(\"operations_analysis\", \"\"),\n",
        "            \"extracted_clauses\": operations.get(\"extracted_clauses\", []),\n",
        "            \"risk_level\": operations.get(\"risk_level\", \"unknown\"),\n",
        "            \"confidence\": operations.get(\"confidence\", 0.0)\n",
        "        }\n",
        "    }\n",
        "\n",
        "merged_output = coordinator_merge(\n",
        "    legal_baseline_result.get('output', {}),\n",
        "    compliance_baseline_result.get('output', {}),\n",
        "    finance_baseline_result.get('output', {}),\n",
        "    operations_baseline_result.get('output', {})\n",
        ")\n",
        "\n",
        "print(f\"   Pipelines merged\")\n",
        "print(f\"   Merged keys: {list(merged_output.keys())}\")\n",
        "\n",
        "for agent, data in merged_output.items():\n",
        "    clause_count = len(data.get('extracted_clauses', []))\n",
        "    risk_level = data.get('risk_level', 'unknown')\n",
        "    print(f\"      - {agent.upper()}: {clause_count} clauses, risk={risk_level}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Computing Overall Risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 270,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Computing Overall Risk\n",
            "   Agent Risks: ['high', 'low', 'medium', 'medium']\n",
            "   Risk Score Sum: 8\n",
            "   Average Risk Score: 2.00\n",
            "   Overall Risk: MEDIUM\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nComputing Overall Risk\")\n",
        "\n",
        "risk_scores = {\n",
        "    \"high\": 3,\n",
        "    \"medium\": 2,\n",
        "    \"low\": 1,\n",
        "    \"unknown\": 0\n",
        "}\n",
        "\n",
        "agent_risks = [\n",
        "    merged_output[\"legal\"][\"risk_level\"],\n",
        "    merged_output[\"compliance\"][\"risk_level\"],\n",
        "    merged_output[\"finance\"][\"risk_level\"],\n",
        "    merged_output[\"operations\"][\"risk_level\"]\n",
        "]\n",
        "\n",
        "risk_score_sum = sum(risk_scores.get(risk, 0) for risk in agent_risks)\n",
        "avg_risk_score = risk_score_sum / len(agent_risks)\n",
        "\n",
        "if avg_risk_score >= 2.5:\n",
        "    overall_risk = \"high\"\n",
        "elif avg_risk_score >= 1.5:\n",
        "    overall_risk = \"medium\"\n",
        "else:\n",
        "    overall_risk = \"low\"\n",
        "\n",
        "print(f\"   Agent Risks: {agent_risks}\")\n",
        "print(f\"   Risk Score Sum: {risk_score_sum}\")\n",
        "print(f\"   Average Risk Score: {avg_risk_score:.2f}\")\n",
        "print(f\"   Overall Risk: {overall_risk.upper()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Calculating Total Clauses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 271,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Calculating Total Clauses\n",
            "   Legal: 32\n",
            "   Compliance: 20\n",
            "   Finance: 28\n",
            "   Operations: 22\n",
            "   Total Clauses: 102\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nCalculating Total Clauses\")\n",
        "\n",
        "total_clauses = sum(\n",
        "    len(merged_output[agent][\"extracted_clauses\"])\n",
        "    for agent in [\"legal\", \"compliance\", \"finance\", \"operations\"]\n",
        ")\n",
        "\n",
        "print(f\"   Legal: {len(merged_output['legal']['extracted_clauses'])}\")\n",
        "print(f\"   Compliance: {len(merged_output['compliance']['extracted_clauses'])}\")\n",
        "print(f\"   Finance: {len(merged_output['finance']['extracted_clauses'])}\")\n",
        "print(f\"   Operations: {len(merged_output['operations']['extracted_clauses'])}\")\n",
        "print(f\"   Total Clauses: {total_clauses}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Building Final JSON Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Building Final JSON Output\n",
            "   Final JSON output built\n",
            "   Top-level keys: ['project', 'timestamp', 'pipelines', 'overall_risk', 'total_clauses', 'confidence_aggregate', 'metadata']\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nBuilding Final JSON Output\")\n",
        "\n",
        "final_output = {\n",
        "    \"project\": \"ClauseAI Multi-Agent Analysis\",\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"pipelines\": merged_output,\n",
        "    \"overall_risk\": overall_risk,\n",
        "    \"total_clauses\": total_clauses,\n",
        "    \"confidence_aggregate\": avg_confidence,\n",
        "    \"metadata\": {\n",
        "        \"agents_executed\": 4,\n",
        "        \"pipelines_completed\": available_pipelines,\n",
        "        \"validation_status\": \"all_passed\" if available_pipelines == 4 else \"incomplete\",\n",
        "        \"risk_distribution\": {\n",
        "            \"legal\": legal_baseline_risk,\n",
        "            \"compliance\": compliance_baseline_risk,\n",
        "            \"finance\": finance_baseline_risk,\n",
        "            \"operations\": operations_baseline_risk\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "print(f\"   Final JSON output built\")\n",
        "print(f\"   Top-level keys: {list(final_output.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Saving JSON Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Saved to: ../Data/Results/Merged\\coordinator_merged_output_20260116_002104.json\n",
            "COORDINATOR MERGE COMPLETE\n",
            "\n",
            "Final Output Summary:\n",
            "   Project: ClauseAI Multi-Agent Analysis\n",
            "   Total Clauses: 102\n",
            "   Overall Risk: MEDIUM\n",
            "   Confidence Aggregate: 0.85\n",
            "   Agents: 4\n",
            "   Validation: all_passed\n"
          ]
        }
      ],
      "source": [
        "output_dir = \"../Data/Results/Merged\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "output_filename = os.path.join(output_dir, f\"coordinator_merged_output_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
        "with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_output, f, indent=2)\n",
        "\n",
        "print(f\"   Saved to: {output_filename}\")\n",
        "\n",
        "print(\"COORDINATOR MERGE COMPLETE\")\n",
        "\n",
        "print(f\"\\nFinal Output Summary:\")\n",
        "print(f\"   Project: {final_output['project']}\")\n",
        "print(f\"   Total Clauses: {final_output['total_clauses']}\")\n",
        "print(f\"   Overall Risk: {final_output['overall_risk'].upper()}\")\n",
        "print(f\"   Confidence Aggregate: {final_output['confidence_aggregate']:.2f}\")\n",
        "print(f\"   Agents: {final_output['metadata']['agents_executed']}\")\n",
        "print(f\"   Validation: {final_output['metadata']['validation_status']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Confidence Aggregation & Highest-Risk Clause"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confidence Aggregation & Highest-Risk Clause\n",
            "\n",
            "Confidence Aggregation\n",
            "   Individual Confidences:\n",
            "      Legal: 0.85\n",
            "      Compliance: 0.85\n",
            "      Finance: 0.85\n",
            "      Operations: 0.85\n",
            "\n",
            "   Aggregate Confidence: 0.85\n",
            "   Minimum Confidence: 0.85\n",
            "   Maximum Confidence: 0.85\n",
            "\n",
            "Identify Highest-Risk Clause\n",
            "\n",
            "   Highest-Risk Category: LEGAL\n",
            "   Risk Level: HIGH\n",
            "   Confidence: 0.85\n",
            "   Sample Clause: ## Legal Analysis of Master Services Agreement Clauses...\n",
            "\n",
            "   Enhanced output saved to: ../Data/Results/Merged\\coordinator_enhanced_output_20260116_002211.json\n",
            "EXTRA TASK COMPLETE\n",
            "\n",
            "Enhanced Features Added:\n",
            "   Confidence Aggregation: 0.85\n",
            "   Confidence Range: 0.85 - 0.85\n",
            "   Highest-Risk Clause: LEGAL\n",
            "\n",
            "All 5 Pipelines Complete!\n"
          ]
        }
      ],
      "source": [
        "print(\"Confidence Aggregation & Highest-Risk Clause\")\n",
        "\n",
        "print(\"\\nConfidence Aggregation\")\n",
        "\n",
        "confidences = [\n",
        "    merged_output[\"legal\"][\"confidence\"],\n",
        "    merged_output[\"compliance\"][\"confidence\"],\n",
        "    merged_output[\"finance\"][\"confidence\"],\n",
        "    merged_output[\"operations\"][\"confidence\"]\n",
        "]\n",
        "\n",
        "confidence_aggregate = sum(confidences) / len(confidences)\n",
        "confidence_min = min(confidences)\n",
        "confidence_max = max(confidences)\n",
        "\n",
        "print(f\"   Individual Confidences:\")\n",
        "for agent in [\"legal\", \"compliance\", \"finance\", \"operations\"]:\n",
        "    conf = merged_output[agent][\"confidence\"]\n",
        "    print(f\"      {agent.capitalize()}: {conf}\")\n",
        "\n",
        "print(f\"\\n   Aggregate Confidence: {confidence_aggregate:.2f}\")\n",
        "print(f\"   Minimum Confidence: {confidence_min}\")\n",
        "print(f\"   Maximum Confidence: {confidence_max}\")\n",
        "\n",
        "final_output[\"confidence_aggregate\"] = round(confidence_aggregate, 2)\n",
        "final_output[\"confidence_range\"] = {\n",
        "    \"min\": confidence_min,\n",
        "    \"max\": confidence_max\n",
        "}\n",
        "\n",
        "print(\"\\nIdentify Highest-Risk Clause\")\n",
        "\n",
        "highest_risk_agent = None\n",
        "highest_risk_level = 0\n",
        "\n",
        "for agent in [\"legal\", \"compliance\", \"finance\", \"operations\"]:\n",
        "    agent_risk = merged_output[agent][\"risk_level\"]\n",
        "    risk_value = risk_scores.get(agent_risk, 0)\n",
        "    \n",
        "    if risk_value > highest_risk_level:\n",
        "        highest_risk_level = risk_value\n",
        "        highest_risk_agent = agent\n",
        "\n",
        "if highest_risk_agent:\n",
        "    highest_risk_clauses = merged_output[highest_risk_agent][\"extracted_clauses\"]\n",
        "    \n",
        "    if highest_risk_clauses:\n",
        "        highest_risk_clause = {\n",
        "            \"agent\": highest_risk_agent,\n",
        "            \"risk_level\": merged_output[highest_risk_agent][\"risk_level\"],\n",
        "            \"confidence\": merged_output[highest_risk_agent][\"confidence\"],\n",
        "            \"clause\": highest_risk_clauses[0][:150] + \"...\" if len(highest_risk_clauses[0]) > 150 else highest_risk_clauses[0],\n",
        "            \"total_clauses_in_category\": len(highest_risk_clauses)\n",
        "        }\n",
        "        \n",
        "        print(f\"\\n   Highest-Risk Category: {highest_risk_agent.upper()}\")\n",
        "        print(f\"   Risk Level: {highest_risk_clause['risk_level'].upper()}\")\n",
        "        print(f\"   Confidence: {highest_risk_clause['confidence']}\")\n",
        "        print(f\"   Sample Clause: {highest_risk_clause['clause'][:100]}...\")\n",
        "        \n",
        "        final_output[\"highest_risk_clause\"] = highest_risk_clause\n",
        "    else:\n",
        "        print(f\"\\n   No clauses available for highest-risk agent: {highest_risk_agent}\")\n",
        "else:\n",
        "    print(f\"\\n   Unable to determine highest-risk clause\")\n",
        "\n",
        "enhanced_filename = os.path.join(output_dir, f\"coordinator_enhanced_output_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
        "with open(enhanced_filename, 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_output, f, indent=2)\n",
        "\n",
        "print(f\"\\n   Enhanced output saved to: {enhanced_filename}\")\n",
        "\n",
        "print(\"EXTRA TASK COMPLETE\")\n",
        "\n",
        "print(f\"\\nEnhanced Features Added:\")\n",
        "print(f\"   Confidence Aggregation: {final_output['confidence_aggregate']}\")\n",
        "print(f\"   Confidence Range: {final_output['confidence_range']['min']} - {final_output['confidence_range']['max']}\")\n",
        "print(f\"   Highest-Risk Clause: {final_output.get('highest_risk_clause', {}).get('agent', 'N/A').upper()}\")\n",
        "\n",
        "print(\"\\nAll 5 Pipelines Complete!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMHVg1acsGP1EXkObNm6Urk",
      "gpuType": "T4",
      "mount_file_id": "1u2ox3VWj8vM89vOC8F2FEDCVlG7C7qT0",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
