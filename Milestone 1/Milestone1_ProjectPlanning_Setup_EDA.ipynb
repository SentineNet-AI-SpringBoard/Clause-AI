{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23726a59",
   "metadata": {
    "id": "23726a59"
   },
   "source": [
    "<h1>Milestone 1</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a6e67a",
   "metadata": {
    "id": "70a6e67a"
   },
   "source": [
    "<h1>1.‚Å† ‚Å†Understand distribution of contract sizes & lengths </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee85a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_folder = \"../data/raw/full_contract_txt\"\n",
    "\n",
    "txt_files = os.listdir(txt_folder)\n",
    "print(\"Total TXT files:\", len(txt_files))\n",
    "\n",
    "txt_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027aae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = {}\n",
    "\n",
    "for file in txt_files:\n",
    "    path = os.path.join(txt_folder, file)\n",
    "\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            texts[file] = f.read()\n",
    "    except:\n",
    "        with open(path, \"r\", encoding=\"latin-1\") as f:\n",
    "            texts[file] = f.read()\n",
    "\n",
    "print(\"Loaded\", len(texts), \"files successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbf184",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "\n",
    "for filename, text in texts.items():\n",
    "    words = text.split()\n",
    "    stats.append({\n",
    "        \"filename\": filename,\n",
    "        \"word_count\": len(words),\n",
    "        \"char_count\": len(text),\n",
    "        \"empty\": len(words) == 0\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(stats)\n",
    "df_stats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Create stats dataframe\n",
    "stats = []\n",
    "\n",
    "for filename, text in texts.items():\n",
    "    words = text.split()\n",
    "    stats.append({\n",
    "        \"filename\": filename,\n",
    "        \"word_count\": len(words),\n",
    "        \"char_count\": len(text),\n",
    "        \"empty\": len(words) == 0\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(stats)\n",
    "df_stats.head()\n",
    "\n",
    "# Step 2: Summary statistics\n",
    "total_contracts = df_stats.shape[0]\n",
    "avg_words_per_contract = df_stats[\"word_count\"].mean()\n",
    "median_words_per_contract = df_stats[\"word_count\"].median()\n",
    "smallest_contract = df_stats[\"word_count\"].min()\n",
    "largest_contract = df_stats[\"word_count\"].max()\n",
    "\n",
    "# Step 3: Print results\n",
    "print(f\"Total contracts: {total_contracts}\")\n",
    "print(f\"Average words per contract: {avg_words_per_contract:.2f}\")\n",
    "print(f\"Median words per contract: {median_words_per_contract}\")\n",
    "print(f\"Smallest contract (word count): {smallest_contract}\")\n",
    "print(f\"Largest contract (word count): {largest_contract}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9eb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats[df_stats[\"empty\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect empty or very short contracts\n",
    "empty_files_count = df_stats[df_stats[\"empty\"] == True].shape[0]\n",
    "short_files_count = df_stats[df_stats[\"word_count\"] < 100].shape[0]\n",
    "valid_contracts_count = df_stats[(df_stats[\"empty\"] == False) & (df_stats[\"word_count\"] >= 100)].shape[0]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Empty files count: {empty_files_count}\")\n",
    "print(f\"Short files (< 100 words) count: {short_files_count}\")\n",
    "print(f\"Valid contracts eligible for analyzing count: {valid_contracts_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb6747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Combine all texts\n",
    "all_text = \" \".join(texts.values())\n",
    "words = all_text.lower().split()\n",
    "\n",
    "# Words to remove\n",
    "remove_list = [\"the\", \"and\", \"of\", \"to\", \"in\", \"for\", \"on\", \"a\"]\n",
    "\n",
    "# Filter words: length > 4 and not in remove_list\n",
    "legal_words = [w for w in words if len(w) > 4 and w not in remove_list]\n",
    "\n",
    "# Count frequency\n",
    "counter = Counter(legal_words)\n",
    "common_words = counter.most_common(20)\n",
    "\n",
    "# Convert to dataframe for table display\n",
    "df_common_words = pd.DataFrame(common_words, columns=[\"Word\", \"Frequency\"])\n",
    "\n",
    "# Display header and table\n",
    "print(\"Top 20 frequent words\")\n",
    "df_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6683143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "# Prepare WordCloud data\n",
    "all_text = \" \".join(texts.values())\n",
    "words = all_text.lower().split()\n",
    "remove_list = [\"the\", \"and\", \"of\", \"to\", \"in\", \"for\", \"on\", \"a\"]\n",
    "legal_words = [w for w in words if len(w) > 4 and w not in remove_list]\n",
    "counter = Counter(legal_words)\n",
    "common_words = counter.most_common(20)\n",
    "labels, counts = zip(*common_words)\n",
    "wc = WordCloud(width=800, height=400, background_color=\"white\").generate(all_text)\n",
    "\n",
    "# Prepare stats\n",
    "mean_wc = df_stats[\"word_count\"].mean()\n",
    "median_wc = df_stats[\"word_count\"].median()\n",
    "\n",
    "#  subplots\n",
    "fig, axes = plt.subplots(3, 2, figsize=(18, 18))\n",
    "\n",
    "# 1. Histogram\n",
    "axes[0,0].hist(df_stats[\"word_count\"], bins=40, color=\"#1f77b4\", edgecolor=\"black\", alpha=0.7)\n",
    "axes[0,0].set_title(\"Histogram ‚Äì Contract Length (Word Count)\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0,0].set_xlabel(\"Word Count\")\n",
    "axes[0,0].set_ylabel(\"Frequency\")\n",
    "axes[0,0].grid(axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "axes[0,0].axvline(mean_wc, color='red', linestyle='dashed', linewidth=1.5, label=f'Mean: {mean_wc:.0f}')\n",
    "axes[0,0].axvline(median_wc, color='green', linestyle='dashed', linewidth=1.5, label=f'Median: {median_wc:.0f}')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# 2. Boxplot\n",
    "boxprops = dict(facecolor=\"#1f77b4\", color=\"#1f77b4\")\n",
    "medianprops = dict(color=\"orange\", linewidth=2)\n",
    "meanprops = dict(marker=\"o\", markerfacecolor=\"red\", markersize=8)\n",
    "axes[0,1].boxplot(df_stats[\"word_count\"], vert=False, patch_artist=True,\n",
    "                  boxprops=boxprops, medianprops=medianprops,\n",
    "                  showmeans=True, meanprops=meanprops)\n",
    "axes[0,1].set_title(\"Boxplot - Contract Text Length Distribution\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0,1].set_xlabel(\"Word Count\")\n",
    "axes[0,1].grid(axis=\"x\", linestyle=\"--\", alpha=0.7)\n",
    "axes[0,1].text(mean_wc + 5, 1.1, f'Mean: {mean_wc:.0f}', color='red', fontsize=10)\n",
    "axes[0,1].text(median_wc + 5, 1.1, f'Median: {median_wc:.0f}', color='orange', fontsize=10)\n",
    "\n",
    "# 3. WordCloud\n",
    "axes[1,0].imshow(wc, interpolation=\"bilinear\")\n",
    "axes[1,0].axis(\"off\")\n",
    "axes[1,0].set_title(\"WordCloud ‚Äì Common Clause Keywords\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# 4. Bar chart\n",
    "axes[1,1].bar(labels, counts, color=\"#2ca02c\")\n",
    "axes[1,1].set_xticklabels(labels, rotation=75)\n",
    "axes[1,1].set_title(\"Top 20 Most Frequent Legal Keywords\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "# 5. Scatter plot (spanning bottom row)\n",
    "fig.delaxes(axes[2,1])  # Remove unused subplot\n",
    "axes[2,0].scatter(df_stats[\"char_count\"], df_stats[\"word_count\"], color=\"#ff7f0e\", alpha=0.7)\n",
    "axes[2,0].set_xlabel(\"Character Count (File Size Approx.)\")\n",
    "axes[2,0].set_ylabel(\"Word Count\")\n",
    "axes[2,0].set_title(\"Scatter Plot ‚Äì File Size vs Word Count\", fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989d3ac4",
   "metadata": {
    "id": "989d3ac4"
   },
   "source": [
    "<h1> üîπ TEXT CLEANING  </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a87c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove page headers/footers\n",
    "    text = re.sub(r\"Page\\s*\\d+|\\f\", \" \", text)\n",
    "\n",
    "    # Remove non-ASCII characters\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Remove repeated line breaks\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "\n",
    "    # Remove noisy characters (keep letters, numbers, punctuation)\n",
    "    text = re.sub(r\"[^a-zA-Z0-9.,;:()\\-\\/\\n ]\", \"\", text)\n",
    "\n",
    "    # Fix broken hyphenation (e.g., \"exam-\\nple\" -> \"example\")\n",
    "    text = re.sub(r\"-\\s*\\n\\s*\", \"\", text)\n",
    "\n",
    "    # Strip extra spaces\n",
    "    cleaned = text.strip()\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "# -----------------------------\n",
    "# Clean ALL files in input folder\n",
    "# -----------------------------\n",
    "input_folder = \"../data/raw/full_contract_txt\"\n",
    "output_folder = \"../data/transformed\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        raw_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Read raw file\n",
    "        with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        # Clean text using combined function\n",
    "        cleaned_text = clean_text(text)\n",
    "\n",
    "        # Save cleaned file\n",
    "        cleaned_filename = filename.replace(\".txt\", \"_cleaned.txt\")\n",
    "        out_path = os.path.join(output_folder, cleaned_filename)\n",
    "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(cleaned_text)\n",
    "\n",
    "print(\"‚úî All cleaned files saved to data/transformed/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7800de0a",
   "metadata": {
    "id": "7800de0a"
   },
   "source": [
    "<h1>Sentence Splitting & Chunking with Overlap Chunk Strategy We split into: Batch size 12 gb ram ## FInal (Only chunks NO emneddings )</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ec56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# 1Ô∏è PATHS\n",
    "input_folder = r\"K:\\Python\\ClauseAI\\data\\transformed\"\n",
    "chunk_folder = r\"K:\\Python\\ClauseAI\\dataset\\chunks\"\n",
    "\n",
    "os.makedirs(chunk_folder, exist_ok=True)\n",
    "\n",
    "print(\"‚úì Paths ready\")\n",
    "\n",
    "#\n",
    "# 2Ô∏èCHUNKING FUNCTION (SENTENCE-AWARE + OVERLAP)\n",
    "\n",
    "def chunk_text(text, chunk_size=1000, chunk_overlap=200):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "\n",
    "# 3.PROCESS ALL CONTRACTS\n",
    "\n",
    "files = sorted([f for f in os.listdir(input_folder) if f.endswith(\"_cleaned.txt\")])\n",
    "\n",
    "if not files:\n",
    "    raise FileNotFoundError(\"‚ùå No cleaned files found\")\n",
    "\n",
    "for idx, fname in enumerate(files, start=1):\n",
    "    path = os.path.join(input_folder, fname)\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # ---- Chunking\n",
    "    chunks = chunk_text(text)\n",
    "\n",
    "    # ---- Save chunks\n",
    "    chunk_out = f\"contract_{idx:03d}_chunks.json\"\n",
    "    with open(os.path.join(chunk_folder, chunk_out), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(chunks, f, indent=2)\n",
    "\n",
    "    print(f\"‚úì Processed ‚Üí {chunk_out}\")\n",
    "\n",
    "\n",
    "# 4Ô∏è PREVIEW ONE CHUNK FILE\n",
    "\n",
    "sample_file = os.listdir(chunk_folder)[0]\n",
    "with open(os.path.join(chunk_folder, sample_file), \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "print(\"\\nüìÑ Preview\")\n",
    "print(\"File:\", sample_file)\n",
    "print(\"Total chunks:\", len(chunks))\n",
    "print(textwrap.shorten(chunks[0], 500))\n",
    "\n",
    "\n",
    "# 5 VISUALIZATION ‚Äì CHUNK LENGTH DISTRIBUTION\n",
    "\n",
    "chunk_lengths = []\n",
    "for f_name in os.listdir(chunk_folder):\n",
    "    with open(os.path.join(chunk_folder, f_name), \"r\", encoding=\"utf-8\") as f:\n",
    "        chunk_lengths.extend([len(c) for c in json.load(f)])\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(chunk_lengths, bins=40)\n",
    "plt.title(\"Chunk Length Distribution\")\n",
    "plt.xlabel(\"Characters\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 6Ô∏è VISUALIZATION ‚Äì OVERLAP CHECK\n",
    "\n",
    "overlaps = []\n",
    "for f_name in os.listdir(chunk_folder):\n",
    "    with open(os.path.join(chunk_folder, f_name), \"r\", encoding=\"utf-8\") as f:\n",
    "        file_chunks = json.load(f)\n",
    "\n",
    "    for i in range(1, len(file_chunks)):\n",
    "        prev = file_chunks[i - 1][-200:]\n",
    "        curr = file_chunks[i][:200]\n",
    "        overlaps.append(len(set(prev) & set(curr)))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(overlaps)\n",
    "plt.title(\"Overlap Check\")\n",
    "plt.xlabel(\"Chunk Index\")\n",
    "plt.ylabel(\"Overlap (approx)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Sentence-aware chunking pipeline complete (NO embeddings)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c12f9",
   "metadata": {
    "id": "8f0c12f9"
   },
   "source": [
    "<h1>Chunk Embeddings & Vector Normalization using #Sentence transformer </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa0af8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1Ô∏è‚É£ IMPORTS & PATHS\n",
    "chunk_folder = r\"K:\\Python\\ClauseAI\\dataset\\chunks\"\n",
    "embed_folder = r\"K:\\Python\\ClauseAI\\dataset\\embeddings\"\n",
    "\n",
    "os.makedirs(embed_folder, exist_ok=True)\n",
    "\n",
    "print(\"‚úì Paths ready\")\n",
    "\n",
    "# 2Ô∏è‚É£ LOAD SENTENCE TRANSFORMER MODEL\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "EMBED_DIM = model.get_sentence_embedding_dimension()\n",
    "print(f\"‚úì Model loaded: {MODEL_NAME} ({EMBED_DIM} dims)\")\n",
    "\n",
    "# 3Ô∏è‚É£ EMBEDDING FUNCTION\n",
    "def generate_embeddings(chunks, batch_size=64):\n",
    "    return model.encode(\n",
    "        chunks,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=False,\n",
    "        normalize_embeddings=False\n",
    "    )\n",
    "\n",
    "# 4Ô∏è‚É£ PROCESS ALL CHUNK FILES (FIRST 20 FOR DEMO)\n",
    "chunk_files = sorted(\n",
    "    [f for f in os.listdir(chunk_folder) if f.endswith(\"_chunks.json\")]\n",
    ")[:20]\n",
    "\n",
    "if not chunk_files:\n",
    "    raise FileNotFoundError(\"‚ùå No chunk files found\")\n",
    "\n",
    "all_norms = []\n",
    "\n",
    "for fname in chunk_files:\n",
    "    with open(os.path.join(chunk_folder, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = json.load(f)\n",
    "\n",
    "    embeddings = generate_embeddings(chunks)\n",
    "\n",
    "    records = []\n",
    "    for text, emb in zip(chunks, embeddings):\n",
    "        norm = float(np.linalg.norm(emb))\n",
    "        all_norms.append(norm)\n",
    "\n",
    "        records.append({\n",
    "            \"text\": text,\n",
    "            \"embedding\": emb.tolist(),\n",
    "            \"norm\": norm\n",
    "        })\n",
    "\n",
    "    out_name = fname.replace(\"_chunks.json\", \"_embeddings.json\")\n",
    "    with open(os.path.join(embed_folder, out_name), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "\n",
    "    print(f\"‚úì Embedded ‚Üí {out_name}\")\n",
    "\n",
    "# 5Ô∏è‚É£ PREVIEW ONE EMBEDDING FILE\n",
    "sample_file = sorted(os.listdir(embed_folder))[0]\n",
    "with open(os.path.join(embed_folder, sample_file), \"r\", encoding=\"utf-8\") as f:\n",
    "    sample_data = json.load(f)\n",
    "\n",
    "print(\"\\nüìÑ Preview Embedding File\")\n",
    "print(\"File:\", sample_file)\n",
    "print(\"Total vectors:\", len(sample_data))\n",
    "print(\"Embedding length:\", len(sample_data[0][\"embedding\"]))\n",
    "\n",
    "# 6Ô∏è‚É£ VECTOR LENGTH CHECK\n",
    "lengths = {len(item[\"embedding\"]) for item in sample_data}\n",
    "print(\"\\nüìê Vector Length Check\")\n",
    "print(\"Unique vector lengths:\", lengths)\n",
    "\n",
    "# 7Ô∏è‚É£ VISUALIZATION ‚Äì EMBEDDING NORM DISTRIBUTION\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(all_norms, bins=10)   # FIXED: safe bin count\n",
    "plt.title(\"Embedding Norm Distribution\")\n",
    "plt.xlabel(\"Vector Norm\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 8Ô∏è‚É£ SANITY CHECK ‚Äì SIMILARITY (COSINE & DOT PRODUCT)\n",
    "v1 = np.array(sample_data[0][\"embedding\"])\n",
    "v2 = np.array(sample_data[1][\"embedding\"])\n",
    "\n",
    "cos_sim = cosine_similarity([v1], [v2])[0][0]\n",
    "dot_sim = np.dot(v1, v2)\n",
    "\n",
    "print(\"\\nüß™ Similarity Sanity Check\")\n",
    "print(f\"Cosine Similarity : {cos_sim:.4f}\")\n",
    "print(f\"Dot Product      : {dot_sim:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Embedding pipeline completed successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31edb2c6",
   "metadata": {
    "id": "31edb2c6"
   },
   "source": [
    "<h1 > Chunk Embeddings & Vector Normalization </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a1b175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 1Ô∏è‚É£ IMPORTS & PATHS\n",
    "chunk_folder = r\"K:\\Python\\ClauseAI\\dataset\\chunks\"\n",
    "embed_folder = r\"K:\\Python\\ClauseAI\\dataset\\embeddings\"\n",
    "\n",
    "os.makedirs(embed_folder, exist_ok=True)\n",
    "\n",
    "print(\"‚úì Paths ready\")\n",
    "\n",
    "# 2Ô∏è‚É£ LOAD SENTENCE TRANSFORMER MODEL\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "EMBED_DIM = model.get_sentence_embedding_dimension()\n",
    "print(f\"‚úì Model loaded: {MODEL_NAME} ({EMBED_DIM} dims)\")\n",
    "\n",
    "# 3Ô∏è‚É£ EMBEDDING FUNCTION\n",
    "def generate_embeddings(chunks, batch_size=64):\n",
    "    return model.encode(\n",
    "        chunks,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        normalize_embeddings=False\n",
    "    )\n",
    "\n",
    "# 4Ô∏è‚É£ PROCESS ALL CHUNK FILES\n",
    "chunk_files = sorted(\n",
    "    f for f in os.listdir(chunk_folder) if f.endswith(\"_chunks.json\")\n",
    ")\n",
    "\n",
    "if not chunk_files:\n",
    "    raise FileNotFoundError(\"‚ùå No chunk files found\")\n",
    "\n",
    "all_norms = []\n",
    "total_chunks = 0\n",
    "\n",
    "for fname in chunk_files:\n",
    "    with open(os.path.join(chunk_folder, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = json.load(f)\n",
    "\n",
    "    total_chunks += len(chunks)\n",
    "\n",
    "    embeddings = generate_embeddings(chunks)\n",
    "\n",
    "    records = []\n",
    "    for text, emb in zip(chunks, embeddings):\n",
    "        norm = float(np.linalg.norm(emb))\n",
    "        all_norms.append(norm)\n",
    "\n",
    "        records.append({\n",
    "            \"text\": text,\n",
    "            \"embedding\": emb.tolist(),\n",
    "            \"norm\": norm\n",
    "        })\n",
    "\n",
    "    out_name = fname.replace(\"_chunks.json\", \"_embeddings.json\")\n",
    "    with open(os.path.join(embed_folder, out_name), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, indent=2)\n",
    "\n",
    "    print(f\"‚úì Embedded ‚Üí {out_name} ({len(chunks)} chunks)\")\n",
    "\n",
    "print(f\"\\nüî¢ TOTAL CHUNKS EMBEDDED: {total_chunks}\")\n",
    "\n",
    "# 5Ô∏è‚É£ PREVIEW ONE EMBEDDING FILE\n",
    "sample_file = sorted(os.listdir(embed_folder))[0]\n",
    "with open(os.path.join(embed_folder, sample_file), \"r\", encoding=\"utf-8\") as f:\n",
    "    sample_data = json.load(f)\n",
    "\n",
    "print(\"\\nüìÑ Preview Embedding File\")\n",
    "print(\"File:\", sample_file)\n",
    "print(\"Total vectors:\", len(sample_data))\n",
    "print(\"Embedding length:\", len(sample_data[0][\"embedding\"]))\n",
    "\n",
    "# 6Ô∏è‚É£ VECTOR LENGTH CHECK\n",
    "lengths = {len(item[\"embedding\"]) for item in sample_data}\n",
    "print(\"\\nüìê Vector Length Check\")\n",
    "print(\"Unique vector lengths:\", lengths)\n",
    "\n",
    "# 7Ô∏è‚É£ VISUALIZATION ‚Äì EMBEDDING NORM DISTRIBUTION\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(all_norms, bins=10)\n",
    "plt.title(\"Embedding Norm Distribution\")\n",
    "plt.xlabel(\"Vector Norm\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 8Ô∏è‚É£ SANITY CHECK ‚Äì SIMILARITY (COSINE & DOT PRODUCT)\n",
    "v1 = np.array(sample_data[0][\"embedding\"])\n",
    "v2 = np.array(sample_data[1][\"embedding\"])\n",
    "\n",
    "cos_sim = cosine_similarity([v1], [v2])[0][0]\n",
    "dot_sim = np.dot(v1, v2)\n",
    "\n",
    "print(\"\\nüß™ Similarity Sanity Check\")\n",
    "print(f\"Cosine Similarity : {cos_sim:.4f}\")\n",
    "print(f\"Dot Product      : {dot_sim:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ All contract chunks embedded successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29bc3d",
   "metadata": {
    "id": "8c29bc3d"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b77efd60",
   "metadata": {
    "id": "b77efd60"
   },
   "source": [
    "#Next part - visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# 1Ô∏è PATHS\n",
    "\n",
    "embed_folder = r\"K:\\Python\\ClauseAI\\dataset\\embeddings\"\n",
    "\n",
    "print(\"‚úì Using embeddings from:\", embed_folder)\n",
    "\n",
    "# 2Ô∏è LOAD ONE EMBEDDING FILE (PREVIEW)\n",
    "embedding_files = sorted(\n",
    "    f for f in os.listdir(embed_folder) if f.endswith(\"_embeddings.json\")\n",
    ")\n",
    "\n",
    "if not embedding_files:\n",
    "    raise FileNotFoundError(\"‚ùå No embedding files found\")\n",
    "\n",
    "sample_file = embedding_files[0]\n",
    "\n",
    "with open(os.path.join(embed_folder, sample_file), \"r\", encoding=\"utf-8\") as f:\n",
    "    sample_data = json.load(f)\n",
    "\n",
    "print(\"\\nüìÑ Preview One Embedding File\")\n",
    "print(\"File:\", sample_file)\n",
    "print(\"Total vectors:\", len(sample_data))\n",
    "print(\"Embedding dimension:\", len(sample_data[0][\"embedding\"]))\n",
    "print(\"Sample text snippet:\")\n",
    "print(sample_data[0][\"text\"][:300], \"...\")\n",
    "\n",
    "\n",
    "# 3Ô∏è VECTOR LENGTH CHECK\n",
    "\n",
    "vector_lengths = set()\n",
    "\n",
    "for fname in embedding_files:\n",
    "    with open(os.path.join(embed_folder, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        for item in data:\n",
    "            vector_lengths.add(len(item[\"embedding\"]))\n",
    "\n",
    "print(\"\\nüìê Vector Length Check\")\n",
    "print(\"Unique vector lengths across dataset:\", vector_lengths)\n",
    "\n",
    "\n",
    "# 4Ô∏è COLLECT ALL EMBEDDING NORMS\n",
    "\n",
    "all_norms = []\n",
    "\n",
    "for fname in embedding_files:\n",
    "    with open(os.path.join(embed_folder, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "        for item in data:\n",
    "            all_norms.append(item[\"norm\"])\n",
    "\n",
    "\n",
    "# 5Ô∏èVISUALIZATION ‚Äì EMBEDDING NORM DISTRIBUTION\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(all_norms, bins=10)\n",
    "plt.title(\"Embedding Norm Distribution\")\n",
    "plt.xlabel(\"Vector Norm\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 6Ô∏è SANITY CHECK ‚Äì SIMILARITY (COSINE & DOT PRODUCT)\n",
    "\n",
    "vec1 = np.array(sample_data[0][\"embedding\"])\n",
    "vec2 = np.array(sample_data[1][\"embedding\"])\n",
    "\n",
    "cos_sim = cosine_similarity([vec1], [vec2])[0][0]\n",
    "dot_sim = np.dot(vec1, vec2)\n",
    "\n",
    "print(\"\\nüß™ Similarity Sanity Check\")\n",
    "print(f\"Cosine Similarity : {cos_sim:.4f}\")\n",
    "print(f\"Dot Product      : {dot_sim:.4f}\")\n",
    "\n",
    "print(\"\\n‚úÖ Embedding inspection & sanity checks complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wt0SzE-bs2bH",
   "metadata": {
    "id": "Wt0SzE-bs2bH"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6HIFFENis2rJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jLuMVWPEtjTw",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pinecone-client sentence-transformers matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yj7tg28Ft_Fr",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y pinecone-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ievH8JnGuBJV",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pinecone sentence-transformers matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zkjX25r8tUSZ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# PINECONE: CONNECT TO INDEX, UPSERT VECTORS, AND QUERY\n",
    "# =============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# PINECONE INITIALIZATION\n",
    "# -------------------------------------------------------------\n",
    "PINECONE_API_KEY = \"pcsk_6jbLBU_DxNgioCN5BHBNM6x3S2Gd9WMY3DDVnruCFBSsEa7efABnmRWydJhEn4itJDVfG\"\n",
    "PINECONE_ENV = \"us-east-1\"\n",
    "INDEX_NAME = \"pinevs\"\n",
    "\n",
    "# Initialize client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "print(\"‚úì Pinecone client initialized\")\n",
    "\n",
    "# CONNECT TO INDEX\n",
    "EMBED_DIM = 384  # MiniLM dimension\n",
    "\n",
    "if INDEX_NAME not in pc.list_indexes().names():\n",
    "    print(\" Creating Pinecone index...\")\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=EMBED_DIM,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=PINECONE_ENV)\n",
    "    )\n",
    "else:\n",
    "    print(\"‚úì Index already exists\")\n",
    "\n",
    "index = pc.Index(INDEX_NAME)\n",
    "print(f\"‚úì Connected to index: {INDEX_NAME}\")\n",
    "\n",
    "# 3Ô∏è.LOAD EMBEDDINGS\n",
    "embed_folder = \"/content/drive/MyDrive/ClauseAI/dataset/embeddings\"\n",
    "embedding_files = sorted(f for f in os.listdir(embed_folder) if f.endswith(\"_embeddings.json\"))\n",
    "\n",
    "if not embedding_files:\n",
    "    raise FileNotFoundError(\"‚ùå No embedding files found\")\n",
    "print(f\"‚úì Found {len(embedding_files)} embedding files\")\n",
    "\n",
    "# 4Ô∏è. BUILD VECTORS FOR UPSERT\n",
    "vectors = []\n",
    "MAX_CONTRACTS = 20\n",
    "\n",
    "for fname in embedding_files:\n",
    "    with open(os.path.join(embed_folder, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "        records = json.load(f)\n",
    "\n",
    "    for i, rec in enumerate(records, start=1):\n",
    "        vector_id = f\"demo-visible-vector-{i}\"  # readable in web UI\n",
    "        vectors.append({\n",
    "            \"id\": vector_id,\n",
    "            \"values\": rec[\"embedding\"],  # must be 384-dim\n",
    "            \"metadata\": {\"text\": rec[\"text\"], \"source_file\": fname}\n",
    "        })\n",
    "\n",
    "        if len(vectors) >= MAX_CONTRACTS:\n",
    "            break\n",
    "    if len(vectors) >= MAX_CONTRACTS:\n",
    "        break\n",
    "\n",
    "print(f\"‚úì Prepared {len(vectors)} vectors for upsert\")\n",
    "\n",
    "# 5Ô∏è‚É£ UPSERT VECTORS\n",
    "index.upsert(vectors=vectors, namespace=\"__default__\")\n",
    "print(\"‚úÖ Vector upserted successfully (check web UI under __default__)\")\n",
    "\n",
    "# 6Ô∏è‚É£ TEST QUERY (SEMANTIC SEARCH)\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "query_text = \"termination clause and contract cancellation\"\n",
    "query_embedding = model.encode(query_text).tolist()\n",
    "\n",
    "results = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=10,\n",
    "    include_metadata=True,\n",
    "    namespace=\"__default__\"\n",
    ")\n",
    "\n",
    "# 7Ô∏è‚É£ PRINT TOP-10 RESULTS\n",
    "print(\"\\nüîç QUERY:\", query_text)\n",
    "print(\"\\nüèÜ TOP 10 MATCHES:\\n\")\n",
    "scores = []\n",
    "\n",
    "for i, match in enumerate(results[\"matches\"], start=1):\n",
    "    scores.append(match[\"score\"])\n",
    "    print(f\"{i}. ID: {match['id']}, Score: {match['score']:.4f}\")\n",
    "    print(f\"   Text: {match['metadata']['text'][:300]}...\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# 8Ô∏è‚É£ VISUALIZATION\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(range(1, len(scores) + 1), scores)\n",
    "plt.xlabel(\"Rank\")\n",
    "plt.ylabel(\"Similarity Score\")\n",
    "plt.title(\"Top-K Pinecone Similarity Scores\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline completed. Visit Pinecone web UI to see vectors!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GFI1hF_BtaHw",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# RAG SEARCH WRAPPER ‚Äì CLAUSEAI (GOOGLE COLAB VERSION)\n",
    "# =============================================================\n",
    "\n",
    "# 0Ô∏è‚É£ MOUNT GOOGLE DRIVE\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 1Ô∏è‚É£ IMPORTS\n",
    "# -------------------------------------------------------------\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 2Ô∏è‚É£ CONFIG\n",
    "# -------------------------------------------------------------\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "INDEX_NAME = \"pinevs\"\n",
    "\n",
    "PINECONE_API_KEY = \"pcsk_6jbLBU_DxNgioCN5BHBNM6x3S2Gd9WMY3DDVnruCFBSsEa7efABnmRWydJhEn4itJDVfG\"\n",
    "\n",
    "RAG_JSON_FILE = \"/content/drive/MyDrive/ClauseAI/data/RAG_result/\"\n",
    "os.makedirs(RAG_JSON_FILE, exist_ok=True)\n",
    "\n",
    "TOP_K = 5\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 3Ô∏è‚É£ INIT MODEL & PINECONE\n",
    "# -------------------------------------------------------------\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "index = pc.Index(INDEX_NAME)\n",
    "\n",
    "print(\"‚úì Model & Pinecone index ready\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 4Ô∏è‚É£ HELPER: EMBED QUERY\n",
    "# -------------------------------------------------------------\n",
    "def embed_query(query: str):\n",
    "    \"\"\"\n",
    "    Convert query text to embedding\n",
    "    \"\"\"\n",
    "    emb = model.encode(query)\n",
    "    return emb.tolist()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 5Ô∏è‚É£ RAG SEARCH FUNCTION\n",
    "# -------------------------------------------------------------\n",
    "def rag_search(query, top_k=TOP_K):\n",
    "    query_embedding = embed_query(query)\n",
    "\n",
    "    results = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    return results[\"matches\"]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 6Ô∏è‚É£ KEYWORD HIGHLIGHTING\n",
    "# -------------------------------------------------------------\n",
    "def highlight_text(text, keywords):\n",
    "    for kw in keywords:\n",
    "        pattern = re.compile(rf\"\\b({re.escape(kw)})\\b\", re.IGNORECASE)\n",
    "        text = pattern.sub(r\"**\\1**\", text)\n",
    "    return text\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7Ô∏è‚É£ PRETTY PRINT RESULTS\n",
    "# -------------------------------------------------------------\n",
    "def pretty_print(matches, query):\n",
    "    print(\"\\nüîç QUERY:\")\n",
    "    print(query)\n",
    "    print(\"\\nüìÑ TOP MATCHES:\\n\")\n",
    "\n",
    "    scores = []\n",
    "    keywords = query.lower().split()\n",
    "\n",
    "    for i, match in enumerate(matches, start=1):\n",
    "        score = match[\"score\"]\n",
    "        text = match[\"metadata\"][\"text\"]\n",
    "\n",
    "        scores.append(score)\n",
    "        highlighted = highlight_text(text, keywords)\n",
    "\n",
    "        print(f\"{i}. Similarity Score: {score:.4f}\")\n",
    "        print(highlighted[:500] + \"...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    return scores\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 8Ô∏è‚É£ VISUALIZE SIMILARITY SCORES\n",
    "# -------------------------------------------------------------\n",
    "def visualize_scores(scores):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(range(1, len(scores) + 1), scores)\n",
    "    plt.xlabel(\"Rank\")\n",
    "    plt.ylabel(\"Similarity Score\")\n",
    "    plt.title(\"RAG Top-K Similarity Scores\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 9Ô∏è‚É£ SAVE RESULTS TO GOOGLE DRIVE (JSON)\n",
    "# -------------------------------------------------------------\n",
    "def save_results(query, matches):\n",
    "    output = {\n",
    "        \"query\": query,\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"rank\": i + 1,\n",
    "                \"score\": m[\"score\"],\n",
    "                \"text\": m[\"metadata\"][\"text\"],\n",
    "                \"source\": m[\"metadata\"].get(\"source_file\", \"unknown\")\n",
    "            }\n",
    "            for i, m in enumerate(matches)\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    file_path = os.path.join(\n",
    "        RAG_JSON_FILE,\n",
    "        f\"rag_result_{abs(hash(query))}.json\"\n",
    "    )\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "\n",
    "    print(f\"\\nüíæ Results saved to Google Drive:\\n{file_path}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# üîü TEST WITH A REAL LEGAL QUERY\n",
    "# -------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    test_query = \"termination clause and contract cancellation rights\"\n",
    "\n",
    "    matches = rag_search(test_query)\n",
    "    scores = pretty_print(matches, test_query)\n",
    "    visualize_scores(scores)\n",
    "    save_results(test_query, matches)\n",
    "\n",
    "    print(\"\\n‚úÖ RAG retrieval completed successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AK2Z_Hr6u_CI",
   "metadata": {
    "id": "AK2Z_Hr6u_CI"
   },
   "source": [
    "Agent Framework Setup + Standard Output Schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aTl76vCKu-RL",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jF68FlicucOa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = SentenceTransformer(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yt2x0svavEog",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_OUTPUT_SCHEMA = {\n",
    "    \"clause_type\": \"\",\n",
    "    \"extracted_clauses\": [],\n",
    "    \"risk_level\": \"unknown\",\n",
    "    \"confidence\": 0.0,\n",
    "    \"evidence\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o0EoHq2zvN8T",
   "metadata": {
    "id": "o0EoHq2zvN8T"
   },
   "source": [
    "3Base Agent Class (Embedding + Rule-Based)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FLD4VkQ-vObz",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent:\n",
    "    def __init__(self, agent_name: str, keywords: list):\n",
    "        self.agent_name = agent_name\n",
    "        self.keywords = keywords\n",
    "        self.keyword_embeddings = embedding_model.encode(keywords)\n",
    "\n",
    "    def run(self, context_text: str) -> dict:\n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', context_text.strip())\n",
    "        extracted = []\n",
    "        evidence = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            sent_emb = embedding_model.encode(sent)\n",
    "            similarities = [\n",
    "                self._cosine_similarity(sent_emb, kw_emb)\n",
    "                for kw_emb in self.keyword_embeddings\n",
    "            ]\n",
    "\n",
    "            if max(similarities) > 0.6:  # similarity threshold\n",
    "                extracted.append(sent)\n",
    "                evidence.append(sent)\n",
    "\n",
    "        risk = self._assess_risk(len(extracted))\n",
    "        confidence = round(min(1.0, len(extracted) / 5), 2)\n",
    "\n",
    "        return {\n",
    "            \"extracted_clauses\": extracted,\n",
    "            \"risk_level\": risk,\n",
    "            \"confidence\": confidence,\n",
    "            \"evidence\": evidence\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _cosine_similarity(a, b):\n",
    "        return (a @ b) / ((a @ a) ** 0.5 * (b @ b) ** 0.5)\n",
    "\n",
    "    @staticmethod\n",
    "    def _assess_risk(count):\n",
    "        if count == 0:\n",
    "            return \"low\"\n",
    "        elif count <= 2:\n",
    "            return \"medium\"\n",
    "        else:\n",
    "            return \"high\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fj2Jx3-vZTU",
   "metadata": {
    "id": "2fj2Jx3-vZTU"
   },
   "source": [
    "JSON Validation Helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80QY_elDvcNc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_agent_output(raw_output: dict, clause_type: str) -> dict:\n",
    "    validated = AGENT_OUTPUT_SCHEMA.copy()\n",
    "    validated.update(raw_output)\n",
    "    validated[\"clause_type\"] = clause_type\n",
    "\n",
    "    validated.setdefault(\"extracted_clauses\", [])\n",
    "    validated.setdefault(\"risk_level\", \"unknown\")\n",
    "    validated.setdefault(\"confidence\", 0.0)\n",
    "    validated.setdefault(\"evidence\", [])\n",
    "\n",
    "    return validated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IN1i6GtHvhSm",
   "metadata": {
    "id": "IN1i6GtHvhSm"
   },
   "source": [
    "Example Dummy Agent (LEGAL ‚Äì Termination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hEMxem54veg7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEGAL_TERMINATION_KEYWORDS = [\n",
    "    \"termination\",\n",
    "    \"terminate\",\n",
    "    \"cancellation\",\n",
    "    \"breach\",\n",
    "    \"notice period\"\n",
    "]\n",
    "\n",
    "legal_agent = BaseAgent(\n",
    "    agent_name=\"Legal Agent\",\n",
    "    keywords=LEGAL_TERMINATION_KEYWORDS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zO9gM1xqvpY9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_contract = \"\"\"\n",
    "This agreement may be terminated by either party with 30 days written notice.\n",
    "Payment obligations shall survive termination.\n",
    "In case of breach, the contract may be cancelled immediately.\n",
    "\"\"\"\n",
    "\n",
    "raw_output = legal_agent.run(dummy_contract)\n",
    "\n",
    "validated_output = validate_agent_output(\n",
    "    raw_output,\n",
    "    clause_type=\"Termination\"\n",
    ")\n",
    "\n",
    "print(json.dumps(validated_output, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DVtE44aPvyw3",
   "metadata": {
    "id": "DVtE44aPvyw3"
   },
   "source": [
    "Legal agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NpMefVejv0Ty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# LEGAL AGENT ‚Äî MISTRAL-7B-INSTRUCT v0.3\n",
    "# =============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 0Ô∏è‚É£ INSTALL DEPENDENCIES\n",
    "# -----------------------------\n",
    "!pip install -q transformers accelerate sentencepiece\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ IMPORTS\n",
    "# -----------------------------\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from google.colab import drive\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ MOUNT GOOGLE DRIVE\n",
    "# -----------------------------\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ LOAD RAG CONTEXT\n",
    "# -----------------------------\n",
    "RAG_JSON_FILE = \"/content/drive/MyDrive/ClauseAI/data/RAG_result/rag_result_6520704210135594280.json\"\n",
    "\n",
    "with open(RAG_JSON_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    legal_context = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(legal_context)} RAG chunks\")\n",
    "\n",
    "combined_text = \"\\n\\n\".join(\n",
    "    c[\"text\"] for c in legal_context if \"text\" in c\n",
    ")\n",
    "\n",
    "print(\"üîπ Combined text preview:\\n\", combined_text[:300])\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ LEGAL AGENT PROMPT\n",
    "# -----------------------------\n",
    "LEGAL_AGENT_PROMPT = \"\"\"\n",
    "You are a Legal Contract Analysis Agent.\n",
    "\n",
    "Tasks:\n",
    "1. Identify legal clauses (Termination, Governing Law, Jurisdiction).\n",
    "2. Extract exact clause text.\n",
    "3. Assess legal risk (low/medium/high).\n",
    "4. Provide confidence score (0.0 - 1.0).\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{\n",
    "  \"clause_type\": \"Legal Analysis\",\n",
    "  \"extracted_clauses\": [],\n",
    "  \"risk_level\": \"\",\n",
    "  \"confidence\": 0.0,\n",
    "  \"evidence\": []\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 5Ô∏è‚É£ LOAD MISTRAL (NO 4-BIT)\n",
    "# -----------------------------\n",
    "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(\"‚úÖ Mistral model loaded successfully\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6Ô∏è‚É£ BASE AGENT\n",
    "# -----------------------------\n",
    "class BaseAgent:\n",
    "    def __init__(self, model, tokenizer, system_prompt):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def run(self, input_text):\n",
    "        prompt = f\"\"\"\n",
    "<s>[INST]\n",
    "{self.system_prompt}\n",
    "\n",
    "CONTRACT TEXT:\n",
    "{input_text}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=4096\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1200,\n",
    "                do_sample=False\n",
    "            )\n",
    "\n",
    "        return self.tokenizer.decode(\n",
    "            output[0],\n",
    "            skip_special_tokens=True\n",
    "        ).strip()\n",
    "\n",
    "# -----------------------------\n",
    "# 7Ô∏è‚É£ RUN LEGAL AGENT\n",
    "# -----------------------------\n",
    "legal_agent = BaseAgent(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    system_prompt=LEGAL_AGENT_PROMPT\n",
    ")\n",
    "\n",
    "raw_output = legal_agent.run(combined_text)\n",
    "print(\"\\nüîπ RAW MODEL OUTPUT (TRUNCATED):\\n\", raw_output[:800])\n",
    "\n",
    "# -----------------------------\n",
    "# 8Ô∏è‚É£ SAFE JSON EXTRACTION\n",
    "# -----------------------------\n",
    "def extract_json(text: str) -> dict:\n",
    "    text = re.sub(r\"```json|```\", \"\", text)\n",
    "\n",
    "    stack = []\n",
    "    start = None\n",
    "    for i, ch in enumerate(text):\n",
    "        if ch == \"{\":\n",
    "            if not stack:\n",
    "                start = i\n",
    "            stack.append(\"{\")\n",
    "        elif ch == \"}\":\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "                if not stack:\n",
    "                    json_str = text[start:i+1]\n",
    "                    break\n",
    "    else:\n",
    "        raise ValueError(\"‚ùå No JSON found\")\n",
    "\n",
    "    data = json.loads(json_str)\n",
    "\n",
    "    data.setdefault(\"clause_type\", \"Legal Analysis\")\n",
    "    data.setdefault(\"extracted_clauses\", [])\n",
    "    data.setdefault(\"risk_level\", \"unknown\")\n",
    "    data.setdefault(\"confidence\", 0.0)\n",
    "    data.setdefault(\"evidence\", [])\n",
    "\n",
    "    return data\n",
    "\n",
    "validated_output = extract_json(raw_output)\n",
    "print(\"‚úÖ Legal JSON extracted\")\n",
    "\n",
    "# -----------------------------\n",
    "# 9Ô∏è‚É£ SAVE OUTPUT\n",
    "# -----------------------------\n",
    "OUTPUT_FILE = \"/content/drive/MyDrive/ClauseAI/data/Agent/legal_agent_output.json\"\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(validated_output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Output saved at:\\n{OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1btPyv82zV5F",
   "metadata": {
    "id": "1btPyv82zV5F"
   },
   "source": [
    "</h1> COMPLIANCE AGENT <h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bpL3h6Nvzcjc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# COMPLIANCE AGENT ‚Äî MISTRAL-7B-INSTRUCT v0.3 ‚Äî FULL WORKING CODE\n",
    "# =============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 0Ô∏è‚É£ INSTALL DEPENDENCIES\n",
    "# -----------------------------\n",
    "!pip install -q transformers accelerate sentencepiece bitsandbytes\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ IMPORTS\n",
    "# -----------------------------\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from google.colab import drive\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ MOUNT GOOGLE DRIVE\n",
    "# -----------------------------\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ LOAD COMPLIANCE-RELATED CONTEXT (RAG)\n",
    "# -----------------------------\n",
    "RAG_JSON_FILE = \"/content/drive/MyDrive/ClauseAI/data/RAG_result/rag_result_6520704210135594280.json\"\n",
    "\n",
    "with open(RAG_JSON_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    compliance_context = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(compliance_context)} RAG chunks\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ COMBINE CONTEXT\n",
    "# -----------------------------\n",
    "combined_text = \"\\n\\n\".join(c[\"text\"] for c in compliance_context if \"text\" in c)\n",
    "print(\"üîπ Combined compliance text preview:\\n\", combined_text[:300])\n",
    "\n",
    "# -----------------------------\n",
    "# 5Ô∏è‚É£ COMPLIANCE AGENT PROMPT\n",
    "# -----------------------------\n",
    "COMPLIANCE_AGENT_PROMPT = \"\"\"\n",
    "You are a Compliance Risk Analysis Agent.\n",
    "\n",
    "Your task:\n",
    "1. Identify compliance-related clauses:\n",
    "- Data protection\n",
    "- Regulatory requirements\n",
    "- Audits & reporting\n",
    "- GDPR\n",
    "- SOC2\n",
    "- ISO\n",
    "- HIPAA\n",
    "\n",
    "2. Extract exact compliance obligations\n",
    "3. Assess compliance risk (low/medium/high)\n",
    "4. Provide confidence score\n",
    "\n",
    "Return ONLY valid JSON in this format:\n",
    "{\n",
    "  \"clause_type\": \"Compliance Analysis\",\n",
    "  \"extracted_clauses\": [],\n",
    "  \"risk_level\": \"\",\n",
    "  \"confidence\": 0.0,\n",
    "  \"evidence\": []\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6Ô∏è‚É£ LOAD MISTRAL-7B-INSTRUCT SAFELY\n",
    "# -----------------------------\n",
    "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(\"‚úÖ Mistral model loaded safely with 4-bit quantization\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7Ô∏è‚É£ BASE AGENT CLASS\n",
    "# -----------------------------\n",
    "class BaseAgent:\n",
    "    def __init__(self, model, tokenizer, system_prompt):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def run(self, input_text):\n",
    "        prompt = f\"\"\"\n",
    "<s>[INST]\n",
    "{self.system_prompt}\n",
    "\n",
    "CONTRACT TEXT:\n",
    "{input_text}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=4096\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1200,\n",
    "                do_sample=False\n",
    "            )\n",
    "\n",
    "        decoded = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        return decoded.strip()\n",
    "\n",
    "# -----------------------------\n",
    "# 8Ô∏è‚É£ RUN COMPLIANCE AGENT\n",
    "# -----------------------------\n",
    "compliance_agent = BaseAgent(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    system_prompt=COMPLIANCE_AGENT_PROMPT\n",
    ")\n",
    "\n",
    "raw_output = compliance_agent.run(combined_text)\n",
    "print(\"\\nüîπ RAW MODEL OUTPUT (TRUNCATED):\\n\", raw_output[:1000])\n",
    "\n",
    "# -----------------------------\n",
    "# 9Ô∏è‚É£ SAFE JSON EXTRACTION WITH DEFAULTS\n",
    "# -----------------------------\n",
    "def extract_json_with_defaults(text):\n",
    "    \"\"\"\n",
    "    Extract first JSON object from text and fill default fields\n",
    "    \"\"\"\n",
    "    # Remove markdown fences\n",
    "    text = re.sub(r\"```json|```\", \"\", text)\n",
    "\n",
    "    # Match first JSON object using braces counting\n",
    "    stack = []\n",
    "    start_idx = None\n",
    "    for i, char in enumerate(text):\n",
    "        if char == '{':\n",
    "            if not stack:\n",
    "                start_idx = i\n",
    "            stack.append('{')\n",
    "        elif char == '}':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "                if not stack:\n",
    "                    json_str = text[start_idx:i+1]\n",
    "                    break\n",
    "    else:\n",
    "        raise ValueError(\"‚ùå No JSON object found in text\")\n",
    "\n",
    "    # Load JSON\n",
    "    data = json.loads(json_str)\n",
    "\n",
    "    # Set defaults\n",
    "    data.setdefault(\"clause_type\", \"Compliance Analysis\")\n",
    "    data.setdefault(\"extracted_clauses\", [])\n",
    "    data.setdefault(\"risk_level\", \"medium\")\n",
    "    data.setdefault(\"confidence\", 0.8)\n",
    "    data.setdefault(\"evidence\", [])\n",
    "\n",
    "    return data\n",
    "\n",
    "validated_output = extract_json_with_defaults(raw_output)\n",
    "print(\"‚úÖ Compliance JSON extracted and validated\")\n",
    "\n",
    "# -----------------------------\n",
    "# üîü SAVE OUTPUT TO DRIVE\n",
    "# -----------------------------\n",
    "OUTPUT_FILE = \"/content/drive/MyDrive/ClauseAI/data/Agent/compliance_agent_output.json\"\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(validated_output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Compliance Agent output saved at:\\n{OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bllBfw2E0oZ5",
   "metadata": {
    "id": "bllBfw2E0oZ5"
   },
   "source": [
    "FINANCE AGENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VSdAut4-0rzP",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# FINANCE AGENT ‚Äî MISTRAL-7B-INSTRUCT v0.3 ‚Äî FULL WORKING CODE\n",
    "# =============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 0Ô∏è‚É£ INSTALL DEPENDENCIES\n",
    "# -----------------------------\n",
    "!pip install -q transformers accelerate sentencepiece bitsandbytes\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ IMPORTS\n",
    "# -----------------------------\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from google.colab import drive\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ MOUNT GOOGLE DRIVE\n",
    "# -----------------------------\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ LOAD FINANCE-RELATED CONTEXT (RAG)\n",
    "# -----------------------------\n",
    "RAG_JSON_FILE = \"/content/drive/MyDrive/ClauseAI/data/RAG_result/rag_result_6520704210135594280.json\"\n",
    "\n",
    "with open(RAG_JSON_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    finance_context = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(finance_context)} RAG chunks\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ COMBINE CONTEXT\n",
    "# -----------------------------\n",
    "combined_text = \"\\n\\n\".join(c[\"text\"] for c in finance_context if \"text\" in c)\n",
    "print(\"üîπ Combined finance text preview:\\n\", combined_text[:300])\n",
    "\n",
    "# -----------------------------\n",
    "# 5Ô∏è‚É£ FINANCE AGENT PROMPT\n",
    "# -----------------------------\n",
    "FINANCE_AGENT_PROMPT = \"\"\"\n",
    "You are a Finance Risk Analysis Agent.\n",
    "\n",
    "Your task:\n",
    "1. Identify finance-related clauses:\n",
    "- Payment terms\n",
    "- Fees and invoices\n",
    "- Late fees\n",
    "- Penalties\n",
    "- Financial liability\n",
    "\n",
    "2. Extract exact financial obligations\n",
    "3. Assess financial risk (low/medium/high)\n",
    "4. Provide confidence score\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{\n",
    "  \"extracted_clauses\": [],\n",
    "  \"risk_level\": \"\",\n",
    "  \"confidence\": 0.0,\n",
    "  \"evidence\": []\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 6Ô∏è‚É£ LOAD MISTRAL-7B-INSTRUCT SAFELY\n",
    "# -----------------------------\n",
    "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(\"‚úÖ Mistral model loaded with 4-bit quantization\")\n",
    "\n",
    "# -----------------------------\n",
    "# 7Ô∏è‚É£ BASE AGENT CLASS\n",
    "# -----------------------------\n",
    "class BaseAgent:\n",
    "    def __init__(self, model, tokenizer, system_prompt):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def run(self, input_text):\n",
    "        prompt = f\"\"\"\n",
    "<s>[INST]\n",
    "{self.system_prompt}\n",
    "\n",
    "CONTRACT TEXT:\n",
    "{input_text}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=4096\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=1200,\n",
    "                do_sample=False\n",
    "            )\n",
    "\n",
    "        decoded = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        return decoded.strip()\n",
    "\n",
    "# -----------------------------\n",
    "# 8Ô∏è‚É£ RUN FINANCE AGENT\n",
    "# -----------------------------\n",
    "finance_agent = BaseAgent(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    system_prompt=FINANCE_AGENT_PROMPT\n",
    ")\n",
    "\n",
    "raw_output = finance_agent.run(combined_text)\n",
    "print(\"\\nüîπ RAW MODEL OUTPUT (TRUNCATED):\\n\", raw_output[:1000])\n",
    "\n",
    "# -----------------------------\n",
    "# 9Ô∏è‚É£ SAFE JSON EXTRACTION WITH DEFAULTS\n",
    "# -----------------------------\n",
    "def extract_json_with_defaults(text):\n",
    "    \"\"\"\n",
    "    Extract first JSON object from text and fill default fields\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"```json|```\", \"\", text)\n",
    "\n",
    "    stack = []\n",
    "    start_idx = None\n",
    "    for i, char in enumerate(text):\n",
    "        if char == '{':\n",
    "            if not stack:\n",
    "                start_idx = i\n",
    "            stack.append('{')\n",
    "        elif char == '}':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "                if not stack:\n",
    "                    json_str = text[start_idx:i+1]\n",
    "                    break\n",
    "    else:\n",
    "        raise ValueError(\"‚ùå No JSON object found\")\n",
    "\n",
    "    data = json.loads(json_str)\n",
    "\n",
    "    data.setdefault(\"extracted_clauses\", [])\n",
    "    data.setdefault(\"risk_level\", \"medium\")\n",
    "    data.setdefault(\"confidence\", 0.8)\n",
    "    data.setdefault(\"evidence\", [])\n",
    "\n",
    "    return data\n",
    "\n",
    "validated_output = extract_json_with_defaults(raw_output)\n",
    "print(\"‚úÖ Finance JSON extracted and validated\")\n",
    "\n",
    "# -----------------------------\n",
    "# üîü SAVE OUTPUT TO DRIVE\n",
    "# -----------------------------\n",
    "OUTPUT_FILE = \"/content/drive/MyDrive/ClauseAI/data/Agent/finance_agent_output.json\"\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(validated_output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Finance Agent output saved at:\\n{OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LBrE40b_1QqG",
   "metadata": {
    "id": "LBrE40b_1QqG"
   },
   "source": [
    "OPERATIONN AGENT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jian439k1Tr-",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================\n",
    "# OPERATIONS AGENT ‚Äî OBLIGATIONS, DELIVERABLES & EXECUTION RISK\n",
    "# =============================================================\n",
    "\n",
    "# -----------------------------\n",
    "# 0Ô∏è‚É£ INSTALL DEPENDENCIES\n",
    "# -----------------------------\n",
    "!pip install -q transformers accelerate sentencepiece\n",
    "\n",
    "# -----------------------------\n",
    "# 1Ô∏è‚É£ IMPORTS\n",
    "# -----------------------------\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from google.colab import drive\n",
    "\n",
    "# -----------------------------\n",
    "# 2Ô∏è‚É£ MOUNT GOOGLE DRIVE\n",
    "# -----------------------------\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3Ô∏è‚É£ LOAD OPERATIONAL CONTEXT\n",
    "# -----------------------------\n",
    "RAG_JSON_FILE = \"/content/drive/MyDrive/ClauseAI/data/RAG_result/rag_result_6520704210135594280.json\"\n",
    "\n",
    "with open(RAG_JSON_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    operational_context = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(operational_context)} RAG chunks\")\n",
    "\n",
    "combined_text = \"\\n\\n\".join(\n",
    "    c[\"text\"] for c in operational_context if \"text\" in c\n",
    ")\n",
    "\n",
    "print(\"üîπ Combined operations text preview:\\n\", combined_text[:300])\n",
    "\n",
    "# -----------------------------\n",
    "# 4Ô∏è‚É£ OPERATIONS AGENT PROMPT\n",
    "# -----------------------------\n",
    "OPERATIONS_AGENT_PROMPT = \"\"\"\n",
    "You are an Operations Risk Analysis Agent.\n",
    "\n",
    "Your task:\n",
    "1. Identify operational clauses:\n",
    "- Deliverables\n",
    "- Timelines\n",
    "- Milestones\n",
    "- Service obligations\n",
    "- Performance standards / SLAs\n",
    "\n",
    "2. Extract exact obligation text from the contract\n",
    "3. Assess execution risk (low/medium/high)\n",
    "\n",
    "Rules:\n",
    "- Copy text verbatim\n",
    "- Do NOT infer or summarize\n",
    "- If no clause exists, return empty array\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{\n",
    "  \"extracted_clauses\": [],\n",
    "  \"risk_level\": \"\",\n",
    "  \"confidence\": 0.0,\n",
    "  \"evidence\": []\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# -----------------------------\n",
    "# 5Ô∏è‚É£ LOAD MODEL (STABLE MODE)\n",
    "# -----------------------------\n",
    "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(\"‚úÖ Model loaded\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6Ô∏è‚É£ INITIALIZE OPERATIONS AGENT\n",
    "# -----------------------------\n",
    "class OperationsAgent:\n",
    "    def __init__(self, model, tokenizer, prompt):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def run(self, text):\n",
    "        full_prompt = f\"\"\"\n",
    "<s>[INST]\n",
    "{self.prompt}\n",
    "\n",
    "CONTRACT TEXT:\n",
    "{text}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            full_prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=4096\n",
    "        ).to(self.model.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=600,\n",
    "                do_sample=False,\n",
    "                pad_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "\n",
    "        # Remove prompt tokens\n",
    "        generated = output[0][inputs[\"input_ids\"].shape[-1]:]\n",
    "        return self.tokenizer.decode(\n",
    "            generated, skip_special_tokens=True\n",
    "        ).strip()\n",
    "\n",
    "# -----------------------------\n",
    "# 7Ô∏è‚É£ RUN OPERATIONS AGENT\n",
    "# -----------------------------\n",
    "operations_agent = OperationsAgent(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=OPERATIONS_AGENT_PROMPT\n",
    ")\n",
    "\n",
    "raw_output = operations_agent.run(combined_text)\n",
    "print(\"\\nüîπ RAW OUTPUT (TRUNCATED):\\n\", raw_output[:800])\n",
    "\n",
    "# -----------------------------\n",
    "# 8Ô∏è‚É£ VALIDATE OPERATIONS OUTPUT\n",
    "# -----------------------------\n",
    "def extract_json(text):\n",
    "    text = re.sub(r\"```json|```\", \"\", text)\n",
    "    start = text.find(\"{\")\n",
    "    end = text.rfind(\"}\") + 1\n",
    "    return json.loads(text[start:end])\n",
    "\n",
    "validated_output = extract_json(raw_output)\n",
    "\n",
    "validated_output.setdefault(\"extracted_clauses\", [])\n",
    "validated_output.setdefault(\"risk_level\", \"medium\")\n",
    "validated_output.setdefault(\"confidence\", 0.8)\n",
    "validated_output.setdefault(\"evidence\", [])\n",
    "\n",
    "print(\"‚úÖ Operations JSON validated\")\n",
    "\n",
    "# -----------------------------\n",
    "# 9Ô∏è‚É£ SAVE OPERATIONS OUTPUT\n",
    "# -----------------------------\n",
    "OUTPUT_FILE = \"/content/drive/MyDrive/ClauseAI/data/Agent/operations_agent_output.json\"\n",
    "os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(validated_output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Operations Agent output saved at:\\n{OUTPUT_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
